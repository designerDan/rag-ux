### youtube_k4fKBqu-Ris.txt

um secondly as as Merrick suggested um
although the the basis of my of the talk
is Gibson's ecological psychology there
are the phrase ecological psychology is
a source of some confusion because there
are in fact three different
psychologists in the United States
who've used that phrase to describe
their work and those are can be easily U
mixed up you know one of them is Gibson
another is Roger Barker who I will talk
about a little bit although I'm going be
mounting Barker's ideas on a gibsonian
foundation which I I take from some
bararan has been okay with them and then
there's Yuri Bron from Brenner's work
who also describes his work as
ecological psychology and I'm not going
to be talking about that at all so
sometimes that phrase is misleading
because you you need to you read it you
don't know which position we're talking
about Unfortunately they they although
they knew one another they never got
together to straighten out who was going
to use which term um um secondly my my
apologies in advance if I if I
misinterpret any of the views of an
action theorists uh I'm not new to an
action Theory I I mean I've been reading
about it periodically over the years I I
I read the aella uh Thompson and rash
book when it came out but I haven't been
keeping up with it it's only been the
last two weeks that I've sort of done a
crash course so I there may be some
things I say that are incorrect and and
please uh Excuse excuse that
also in that regard one of my major
goals is to make sure that Gibson's
understood properly the ecological
approach is understood properly and
um I I I'm not here to convince you that
this is a a good way to go I just want
you to reject it on the grounds in which
it is offering rather than on some other
grounds which it isn't uh pretending to
offer uh the other difference I think is
that Gibson's I think Gibson's um goals
were more modest than what I gather most
inter in action theorists and Gibson was
primarily trying to develop a theory of
perception not a philosophy of life you
know not an approach to life overall um
he certainly thought that his views
about perception could be the basis for
thinking about other things like other
forms of cognition other than perception
but primarily he's focusing on
perception and principally visual
perception although not
solely um
um let me add I I said put something
phrase something in a particular way a
moment ago and let me go back to that
we're not I'm not going to be drawing a
distinction between perception and
cognition rather perception is a form of
cognition the term cognition just refers
to various ways of coming to know and
perceiving is one of those ways and
there are other ways which don't involve
perceiving although I I like I would
like to think they're built on a
foundation of perceiving
um and and then the other thing which I
I think is really great is that um as I
look over the some of the literature it
that an act of an action Theory um the
overlap between it and ecological Psy
psychology is is great so that means the
differences are small and they're
interesting and and we can really
squabble over them so we don't have to
sort of deal with some of the
fundamental assumptions which I think we
we
share um I guess the way I just want to
start out is something a phrase that's
been used a bit over the last couple of
days um in that there have been some
diagrams where we have the organism and
we're talking about the organism as
having autonomy and then there's this
bigger box around it and the phrase is
often used everything
else okay I'm interested in everything
else and or more specifically the focus
that I want to take is is not beginning
with the
organism okay but rather beginning with
the organism involved environment
relationship which which is a dynamic
relationship um so let me Begin by
giving you an outline of where I'm going
to
go I I tried to find something
appropriate I I gather this is the golf
resort in the early moment of a
construction I'm not quite sure um but
here's roughly the outline and it's it's
going to hop a little bit but you so you
at least you'll know first of all I'm
going to talk about some principles of
ecological
psychology and and I want contrast it to
picture perception not so much because
you I think you subscribe to this but
rather I think there are some issues
about the differences between picture
perception and environmental perception
which get dicey between the two
views uh and then I want to illustrate
some of these points with some research
um and uh of mine on navigation then
I'll move to the concept of affordances
which is of course probably gotten more
attention than outside of ecological
psychology than anything else and uh at
that point I'm going to move into the
the positions that I've developed
somewhat in not independent but as an
extension of the gibsonian so kind of up
to here I'm going to be doing chapter in
verse of ecological psychology which
most folks that I um associate with
would agree but then basically move into
how how I've pushed the field a little
bit and that'll be talking about
cultural
historical processes then then the last
two points is I want to root this
theoretical position in a philosophical
Foundation um this has been a problem um
the the point one of the major goals of
my book was to try to do just that many
people read Gibson and they think well
these are interesting ideas but they
don't fit into anything I've ever seen
before where do they come from so what I
want to do is in a very brief um period
of time try to then embed ecological
psychology into a Phil philosophical
foundation and that will be William
James's radic
purism and then lastly to kind of create
some fodder for discussion I want to say
a few things uh about um inaction and
particularly inactive inactive
approaches to perception and ecological
psychology and how I think they're
different and and that may give us some
things to throw
around okay so let let me start as I
said I want to start with everything
else and so that means I want to start
with the environment so I'm going to
just in sort of follow the way that
Gibson sort of introduces his his last
book what's remarkable about his last
book if if you've not seen it his book
is called the ecological approach to
perception but the first you don't get
to anything about the organism until
you're halfway through the book the
entire first half of the book is about
the environment which is kind of
peculiar most books on perception and
psychology begin you know with the
receptors and perhaps a physical
analysis of
stimulation um and and and but but the
receptors come early the brain comes
early Gibson's going to deal with the
perceiver pretty late um so let's first
talk about the environment um by the way
I noticed just that as your steering
wheels are on the wrong side of the car
for me it turns out your toggle switches
are reversed so I may be going backwards
when I want to go forwards on this so
let's see so what are some of the
principles what are some of the things
we need to know about environments first
environments
surround and are extended that is to say
if we take a if we have an organism an
organism situated in an environment
environment is
extended and and and surrounds the
individual and this is the
case um this is a a ubiquitous property
of
environments uh the second property of
environments is that they are
structured um that is to say that
they're not amorphous there's variation
um we the we can spend a lot of time
talking about these structures certainly
there there are textures there are
objects um there's there's Horizon
there's an intrinsic up and down
um and there's a nesting of properties
such you we have sort of smaller
structures nested within larger
structures and so
on so and again this is true of of any
environment this including the one we're
in
okay
so the person situated in an environment
the environment is extended and it
surrounds the individual the environment
has structure now let's talk about the
organism U oh well I'm I'm jumping ahead
now now this is um Gibson considers
these three three terms kind of critical
to his theory um substances surfaces and
medium okay so first of all in the the
environment consists of matter material
substances
and um and sub and substance has
surfaces and a surface is a boundary
between um an object and a medium in
this case you can see that the surface
um is um adjacent to a water medium um
but also the the a surface of an object
uh can interface with with the air as a
medium and so um in in the case of
vision we have a source of of light
which interacts with surfaces and
critically the light is affected by is
structured by the character of the
surface in terms of its texture in terms
of its color in terms of its orientation
relative to the light so what we're
concerned about here is not so much um
the light from the light source but
rather light that's reflected off of
surfaces
so for for so for example and this this
I apologize this is if I if I was more
skilled at PowerPoint you might be able
to see this a little better but but the
idea is what we're interested in is the
way in which light is reflected off of
surfaces and
fills the local environment with
reflected light the reflected light is
going to be structured with reference to
the surfaces
um um that it reflects from again in
terms of in terms of carrying
information about texture color
orientation shape and so
on um
so oh yeah and we could although the
light is reflected in all directions we
could put a perceiver at any place in
that environment and and in this case
just an eye it's not adequate view of a
perceiver it's only part of a proc
receiver obviously um and then that
perceiver will be in a position to begin
to sample the ambient uh structured
light and um if you have any questions
or clarification I please please raise
them um matters of debate I I'd rather
save Until the End John who saying
things about the environment you God I'm
sorry who's who is saying all these
things about the environment you God me
God yeah I tend not to think about
myself in that way
um
we know a lot we know about the a lot
about light and how light interacts with
surfaces and so if we think about the
environment for the moment independent
of the organism we can begin to describe
how light interacts with the features of
the environment independent of the
organism I mean it's not independent of
the organism I what you're saying as
independent of the organism is a
rarefication of the knowledge that human
scientists consist in particular
what I said
was you you didn't hear what I said then
because I said I said for the moment
we're looking at the environment
independent of the organism we're just
we we're going to talk about an organism
environment system but we're going to
first take the environment as the figure
in the organism as the ground and then
we're going to flip it in just a
minute
um it must be I guess let me just follow
up that point with with something else
What in in in traditional approaches to
to perception again if we're looking at
the the information for perceiving
typically it's described in terms of
physical variables like wavelengths of
light for example or wavelengths
intensity of sound what's going on here
is an attempt to develop a an account of
of the physics of the situation not in
terms of um the sources of energy but
rather how the sources of energy
interact with environmental surfaces so
what's going on is an attempt to develop
something that we could call ecological
physics okay and specifically what I'm
talking about here is something that
we'll call ecological Optics as opposed
to
Optics okay Optics refers to how light
interacts with lenses ecological Optics
refers to how light interacts with
surfaces
um and we can talk about how light inter
with lenses independent of people and
that doesn't mean we have a God's eye
view we're just we're just carving out a
part of the
world okay then turning to the organism
what we know about organisms as you all
well know is that organisms are are
active uh they're
mobile and
um and if we put these two pieces
together if we have environments that
extend and Surround and that are
structured and we have organisms that
are mobile then what they're going to be
able to what they're going to need are
ways of guiding themselves through this
structured
world so perceiving
fundamentally uh is a process that
enables organisms to better move through
the
environment sometimes as is in the case
of the earthworm the the detection is of
a very proximal
environment other times in the case of
um other organisms such as us we're
detecting properties at a at at a
greater distance but the main but the
point is that on the one hand perceiving
operate um operates in the service of
action that is to say we perceive in
order to help us better move around get
resources and so
on it's a it's a functional account of
why perceiving um is
exists and so you can see that um
perceiving is guiding the actions of uh
these two individuals these two children
um being able to see the cliff Edge or
the visual Cliff enables the child to
avoid falling off okay so perceiving has
a very functional role and and notice
that I'm not talking about perceiving an
action necessarily as you'll see as two
different processes but really as a
synergistic processes because in fact we
can reverse that and we can say that not
only does perceiving support action but
action also supports perceiving and why
is that the case because there it's it's
really pretty easy to demonstrate that
if you if you grab an object and don't
move your hand with respect to its
surfaces it's often very hard to to
identify what it is you're holding on to
but if you move your hand relative to
the surfaces it's quite easy to identify
what you're holding on to so action
supports perceiving even as perceiving
uh supports action so here we have a
case of of a physician you know
palpating a patient I mean you you may
notice that your physician doesn't just
kind of place his or her hand on your
skin and leave it there as if they're
healers they're pushing and prodding and
probing what they're trying to do is get
information they're trying to understand
about what what um the what structures
they're they're confronted with with the
patient um and in fact people are very
keen on allowing um having experiences
where actions reveal
structures um now let let me talk a bit
about what action one of the things that
action
um provides for perceiving this is an
experiment um done with with young
infants and uh what what they're shown
is um
an object in different
um in different axes okay and what the
baby baby's in a car seat and and it's
and it's goes travels around this Arc
looking at this object and what it gets
is these various transformations of the
object in this case it's oriented on a
different axis and so on two different
objects and and the question that's uh
of Interest here is you know what um
what is the baby perceiving now this is
a terribly difficult question to ask
obviously because babies don't won't
tell you what they're perceiving the
standard procedure which is not without
some criticism is the habituation
Paradigm which many of you know about um
so if the the basic idea of the
habituation Paradigm is um the babies
will continue to look at something until
they and and then we'll lose interest
then you show them something else if
they if they show no interest in the
second thing the presumption is they see
the second thing as being similar to the
first thing if they suddenly you know if
it gets their attention then Pres
assumably they see it as somehow
different so the question is um do do do
babies perceive these different um
projective uh presentations as being
different projections and this is
important for an action theory in terms
of the action Theory perception or do
they perceive it as an object that's a
single object that's perceived from
different points of view in other words
do they detect um the object um with
regard to uh an invariant structure an
invariant structure is is structure that
is constant across changes of
orientation in this
case
okay so um to perceive an object is to
perceive its invariant structure meaning
that you can recognize it from
any uh
position and now we can sort of include
we can get back into why action plays a
role here because action enables you to
engage the object from different angles
in different ways so that you can
extract the invariant yeah
Sor the
baby
no we're just just getting different
viewpoints we're just getting different
viewpoints right right and which is why
this is actually interesting because
this baby's not had prior exper well
other than being carried around by its
mother perhaps has not had experience uh
has Li had limited experience but it but
by through exposure it can presumably
detect something that's common across
all the all the
um um
viewpoints I'm going on a little sleep
so my words will sometimes elude
me what is the result of the study baby
yeah oh yes yeah and and and yes so the
baby has no if you if you present then
the object from a certain particular
point of view and the baby habituates to
it you change the orientation the baby
still it doesn't dishabituate in other
words it recognizes and as best as we
can tell it recognizes the object
independent of any particular viewing
position in other words what it's done
presumably and I'll try to be clearer
about the notion of invariant as I go is
that it's detected a property that um is
common across varying viewing positions
in other words it doesn't perceive a
projection now an important Point here
which I'll come to in a minute this
suggests that
the notion of and and and of of
perceiving as being based on a retinal
image makes no sense at all because the
retinal image of course are projected uh
projections of an object a
two-dimensional projection and this is
exactly what the baby appears not to be
doing just ask you again for
clarification you said an invariant
property but didn't say what is the
property of property an invariant
property
of it's an invariant property of the
object but to anticipate an earlier the
the next point but um that's available
to a perceiver to a moving
perceiver so I mean the in other words
the invariant isn't just and this will
be important for our differences or
agreements or discussion it's the
invariant isn't just sitting out there
it's something that is revealed through
action but it's revealed but what's
revealed is a what's revealed is a
property of the
object so give me well come I'll come
way back I'll come back to that I
promise but just but it's not like the
baby's not moving the baby's eyes are
moving it's not that there's
no but but but the eyes don't really
change the the visual angle very much
well but it's a little bit like the
detecting
so you you need to get you need to vary
to detect the invariance of the object
you you
vary
sad it isn't the cads that make a
difference because the cads you're not
changing your viewing position when you
have catic movement I'm talking about
literally moving to another viewing
position even even a little and I'll
show you some evidence for that later on
but but again if you have any doubts
about this I this is I'll just I
demonstrate this with my introductory
psychology class I mean you just pick a
friend and find some common objects and
then tell them to close their eyes and
put the object in their hand and and
tell them not to move their hand and ask
them to identify the
object they're going to have a hard time
ask them to move it around and it is
easy what's the difference between those
two cases by moving the object in your
hand what you're doing is you're
detecting invariant properties of the
object through action yeah um I would
say that's very different from baby
because also if you move an object
across somebody else's hand yeah it's
also difficult for the person to
identify where you're moving the baby
around I also want to ask what age yeah
I you know I I my memory's crummy but
we're talking about on the order of
three to four weeks um you're right but
but not completely it turns out that
self-produced action does reveal more
information and I'll show I'll try to
show you why but you don't necessarily
have to have self produced action you
can also have passive movement I would
say in the baby case that's not actually
active perception but it's mul in terms
of
vular visual invariance or something
like vestibular information gives you no
vestibular gives you no information
about that and there's no a there's no
Ence going on because the baby's not
doing anything except engaging in cads
but then I wouldn't say sensory motor
I'm not I'd never use the word sensory
motor again can we put in the discuss
and in fact I'm never going to use the
phrase sensory motor in fact I think the
the notion of sensory is is dead wrong
okay but I'll come back to
that okay so if we now instead conveying
a baby around in an arc we have a person
who can can move around what the person
is is able to do is sort of adopt
different Vantage points in the ambient
optic array and actually create
transformations in the ambient optic
array um and here is um since I don't
have the talents of doing any animation
this is a poor man's animation um whoops
to why is this just going on and on um
sorry this is my left right problem
here
okay so as we move what we're it's
essentially what that moving perceiver
is doing is is is essentially what you
do when you move an object in your hand
but in this case the body is moving in
the world and creating and this is the
this is key transformations in the optic
array which enable invariant to be
separated or detected in the array in
other words it's not that you're
perceiving something that's static you
need to introduce change in order to
reveal what's
Constant transformation like invariants
are revealed through
Transformations they're not and for that
reason invariants are not frozen in time
they're only revealed over time and I
can't emphasize that
enough okay that is to say I so I'll say
it again which that invariants are not
these Frozen Source let's say basis of
information but rather they're only
revealed over time and they're revealed
over time because the perceiver produces
Transformations through movements of the
body which reveal invariance so so um it
so it's it's a fully Dynamic process
although Gibson didn't use that
terminology okay so what have I said so
far quick summary I said that
environments surround and are extended
organisms are mobile and that we
develop sensitivities receptor
sensitivities that guide movement in
some cases only ey spots uh vibration
detectors chemical receptors and so on
but they they develop in in the service
of um of action and reciprocally action
uh facilitates perceiving action reveals
structure and perceiving is the
detection of structure over
time so let me slow down in these last
two points perceiving is the detection
of structure over time and this is going
to be a crucial difference between
sensation and perception because
Sensations as classically defined do not
vary over time they're they're they're
patches of light they're pinpoints of
sound of bits of
sound so they they do not support
perception I'll but I'll come back to
that um the next point which has kind of
been implicit in what I've just said but
I I I want to um emphasize it is and
because I think this is a place when I
read the inaction literature where
Gibson's misunderstood frequently
there's this notion that there seems to
be this expression that information is
is out there in the environment and and
in a sense it is but not completely
because in fact information is revealed
through action information is relational
and I'll show you a couple of examples
of that in other words information is is
generated by perceivers actions in
relation to environmental structures now
notice that's not what that's not an
inaction uh consistent phrase I didn't
say that structure is generated through
action
what I said is structure is
revealed through action okay now and
again I may be misreading the literature
and I'll you have you'll have your
chance to tell me that here's a here's a
basic here's a really clear indication
of this and this is this is the notion
of optical flow or Optic flow when you
move through the environment remember
first of all environments are
structured okay we're not moving through
an an unstructured
void there surfaces as we move through
the environment what's happens is we
generate a flow pattern coming from the
reflection of light off of
surfaces okay and it's a very compelling
flow pattern because you you've all
experienced it if you've been to an IMAX
movie um that or you know or there's all
sorts of illusions of movement where you
feel yourself moving and you're not
really moving it's because Optical the
flow of optical information is
information about self-movement
okay
now um a couple of points to make about
this is one that this clearly points to
the fact that the information is
relational because Optical in the case
of self-generated optical flow as I'm
moving through the world and the world
flows around me it only flows around me
if I'm moving it does optic flow does
not exist if I stop the instant I stop
it goes away so in other words Optical
flow information is relational
information because it only is present
when the perceiver is engaging the
environment okay and you could say well
maybe it's an ephant copy but in fact as
you as you know from the example I
offered you a minute ago you can be
sitting still in a movie theater and
still get compelling feelings of of
movement and in fact it's such a subtle
sort of information that there's this
experiment um wonderful experiment done
by David Lee where he he brings people
into into a room um David leaves at
Edinburgh and um and has them stand on a
balance beam okay I mean it's it's it's
just a a plank that's that's narrower
than their their foot length and um
unbeknownst to them the walls of the
room and walls in the ceiling are
independent of the floor and there and
it's suspended on a crane so what David
and his and his colleagues do is shift
the walls just a little bit one way or
the other almost
imperceptibly and what happens that well
you you kind of imagine it so you're
standing on a balance beam and the walls
just shift just a little bit this
way what do you think
happens person falls forward shift it
the other way the person falls backwards
because optic what he's doing by
Shifting the walls is generating optic
flow and optic flow is information about
self-movement in this case it's he's
producing the change but normally and
again this is the important point we are
producing the information now we're not
producing the information in our
heads we're generating the information
through our interaction with the world
yeah I think probably idea if you
explain your term information because
it's yeah in information um what I mean
by that is is is is a characteristic of
the um
the the let's say the light or the sound
the array of it which specifies some
feature of the
environment okay so in this so in this
case if I'm if I'm looking uh it's I'm
manipulating the object in my hand um
this information is that which is
invariant that the enironment that I
discover as I manipulate the object okay
so in so information specifies
properties of the environment why is
that important well go back to one of my
earliest claims that perceiving is a
function that enables organisms to
engage their environment you want to be
able to perceive the environment that
you're moving around in you want to be
able to perceive resources and Hazards
and so on and so
um what you're doing is detecting um
properties that specify these distal
surfaces and these properties are
I it I I can elaborate on this are
somewhat ambiguous in a stationary
array but they're not in a moving
array not computational information no
no it's got nothing to do with
computation in fact I haven't talked
about anything going on in the head I'm
talking about the organism environment
interaction Ezekiel I totly understand
uh I think the main
point uh you know like the importance of
of moving the the you know the ways of
relating and somehow uh connecting to
this in varing structures but I'm very
confused with the language that you use
sometimes because I mean sometimes you
say that things are revealed through
Transformations as if I am you know the
discoverer or something that is out
there and just now you said that through
that Movement we producing information
and and and and and I know that you know
information in this
relational but the the terminology
sometimes seems to imply that actually
is something that is out there and I am
actually the discoverer of something
that is out there as opposed to
something that is actually produced in
that interaction the these are these are
really hard issues um and and and and
but I what I'm trying I and I want to
come back to talking about independent
the notion of independent versus
relational later but but what I want to
say is that the the information is
revealed in the organ organism
environment interaction but it's but the
information the invariant is is a pro is
a potential property given a moving
perceiver so it in in a sense it we have
to get away from the notion of there's
an environment that's independent of us
you know that is this but we also and
what I worry about is the other move of
of talking about the the environment
that we experience in our heads I think
the danger for the ecological
psychologist is being read as saying
that the information is in the world
indep of the organism that isn't true
but I think the the the the the um the
reciprocal danger of the an action
position is being read that everything's
going on in the head and we need to what
we where we need to converge is a clear
sense of what we mean by relational so
so let's we'll have that
conversation um let me see what comes
next oh yeah so this is just a a since I
don't have a movie this is a give you a
sense of what Optical flow Fields look
like and and and again you you readily
use this information just think about if
you're driving how you maintain a
constant distance between the car in
front of
you you could I suppose do a complex
calculation but all you need to do if if
you want to maintain a constant distance
from from the car in front of you is
just to keep the the size of the object
constant of the object in front of you
it starts to get bigger you're getting
closer it just it gets smaller you're
moving away so you you kind of adjust
your movement in order to to achieve
that that
goal uh again and this gets back to um
ezekiel's point I I want to say that
Optical flow environmental information
is relational it emerges from an
organism environment interaction but but
that needs some clarification I
realize but let me just on that point uh
let me I don't want to I don't want to
be accused of cherry picking but I
looked through the inaction literature a
bit to see where Gibson is referred to
and and this is one point and I think it
points out how Gibson's
misunderstood um although Gibson's not
mentioned in this quotation this this
statement is in the context of talking
about ecological
psychology um and there's there's parts
of this that that I would agree with and
parts of it I don't so for the
inactivist sense I haven't identified
the source and I could if you want but
for the inactivist sense is not an
invariance present in the
environment well from an ecological
point of view I I don't even know what
that
means okay because we're not even
talking about senses we're talking about
invariants that emerge in organism
environment
relationships and um and certainly
they're not
retrieved they're
detected okay it's it's not like the
we're fishing out there in the world but
they emerge from the dynamic
interaction um the second sentence I
agree with except the word dialogue
would have to be fleshed out invariances
are instead the outcome of the dialogue
between the active principles of the
organism in action and the structure of
the environment I'm good with that
although we'd have to make sure we both
agree about what we mean by
dialogue um but then the next sentence
gets us gets us back into some dicey
territory the finding of meaning must be
enacted it is it is always a formative
activity well that's where we might
disagree because I want to say that uh
the finding of the discovery of
structure
um is not about the extraction of
information but but really the discovery
of information it's extraction suggest
that it's out there and we're just sort
of pulling it out by moving around we're
actually creating structure
yeah the word sense the does not mean
sensation what does it
mean
un to doation it has to do with
sense
okay that okay I I accept that if that's
then that's a different intention but
but I think it's but I think well I
would also want to say but we can fight
about this later that the phrase sense
making is is is deeply problematic I
agree with the of what's intended by the
phrase but I think the phrase is deeply
problematic for because the distinction
between sensation and perception is
conflated there and I want to separate
them but that's for a few minutes from
now but thank you if I Mis if I misre
that
um then then I apologize but I but
basically the sentiment of
organisms passively receiving
information is just not an ecological
claim um and I want to say that the
notion of the the phrase the world is
brought forth or the world is enacted I
think is is deeply problematic for
reasons which I'll come to and I'm sure
I'm annoying many of you by saying that
let me try to illustrate a few of these
points with some research because I'm
not a philosopher I'm a psychologist so
I have to have some bonafides as a
someone who does data collection okay so
um what prompted This research uh
essentially is is I I mean I come out of
environmental psychology I'm a very I'm
very dissatisfied environmental
psychologist and um environmental
psychologists have historically said
that people find their way around in the
world because they have these mental
representations often called cognitive
Maps which they use to guide themselves
for a bunch of reasons uh that that
seems to be very wrongheaded
particularly if perception occurs over
time so the question I was interested in
is well clearly people can find their
way from point A to point B is there
information in the path of locomotion
that they utilize in finding their way
um and I just wanted to get a start on
this uh question so let me introduce two
terms first of all and these are from
Gibson um the first term is Vista and
and essentially he defines Vista as you
know that which can be seen from here
other words if from a given observation
Point all that you can
see the second term is
transition and a transition is when you
are essentially moving from one Vista to
another so in the course of moving
through a transition you're leaving one
Vista and and and opening up a new
one and um let me see yeah okay and so
what what I want to say here is that um
the hypothesis is that what's critical
in finding your way is learning a path
in terms of a sequence of
Transitions and again a transition is
the revealing of a new Vista and and and
if you will an
exiting uh of of the prior one um and I
can elaborate on that a little bit but
let me just say that what's important
about a transition is that it's
generated again through
action so if you imagine yourself
walking although the reflection is
making it hard to see if you imagine
yourself walking let's say around this
Bend in the
road you can stop transition information
by just stopping
walking okay in other words it's the
kind of relational information akin to
Optical flow information it's
self-generated but it's generated in
relationship to environmental structures
if you don't have an arrangement of
Vistas or maybe put it simply if you
don't have let's say a surface uding
another
surface and when you move you know more
the surface behind is revealed or
concealed but that's a function of your
movement but this but the occlusion is
there in the world
this Bend in the road is in the road you
okay so the experiment quite simply and
this is busy and maybe impossible to see
um what first of all what you have to do
is is is take this and put it up here
this is a continuous time record I I
should have tried to print it in the
landscape but I'm primitive um and um
and what's happening is the perceiver
there a a videotape of a walk 20-minute
walk through a complex environment was
created um and then participants in a
laboratory were just asked to watch it
and just to press a key on the computer
when they saw something that was um
useful for finding their
way okay so basically the the film is
playing this you can't see is is
time this is the number of responses
okay and
um and
what you can see on first viewing um
It's Kind it's a bit all over the place
there's some responses in in certain
places that that are more like um that
are clustered more than others if if you
can see these brackets is that possible
from the
back yeah sorry about that well this
bracket there's brackets here what those
brackets are are independent judges
identified where the transitions were in
the root okay so what we're trying to do
here is see
where the responses are relative to the
transitions in the route the transitions
are def defined independently of the
receivers by some judges and we're just
asking people to to to press the bar key
uh the space bar now this is on first
viewing but this is the record on second
viewing after they've seen it once and
now they're going through it a second
time and we give them the same
instructions you now press the space bar
at at at points that'll be useful for
wayfinding and what you can see in the
change is first of all the variability
gets greatly reduced but also the
responses with a few
exceptions cluster at the
transitions in other words to to put it
in the language I used a minute ago is
that in in traveling through the
environment they've detected information
which it's useful for them to find their
way and that information happens to be
transitional information which is
self-generated in relationship to the
environment
okay it's relational information that's
critical and so it's analogous to the
notion of an invariant specifying an
object through Movement we detect
relational in moving an object or moving
with respect to an object we detect the
structure of the
object um but the structure is revealed
as we move with regard to it similarly
the structure of a path of locomotion is
the discovered As you move through
it um oops wrong
key it's better to work on your own
computer but so be it okay so my point
here is that critical for finding one's
way are transitions and just as in terms
of a design point of view because
designers are interested in these
questions
not as you know not all transitions are
equally distinctive as
others um I don't know about in your
country but in the US I mean hospitals
are notoriously confusing for finding
your way because every hallway every
turn looks like the last one but but if
you if the transitions are
distinctive okay if the new information
that appears at the turn is is is
distinctive each time then then wayf
finding orientation is is far easier and
this is where this kind of work can can
can um dovetail with uh design
questions
and as my students will tell you I say
everything many many times again this
information transitional information is
generated through action it's not in the
environment per
se but it arises from the environment
through action because of the way that
the surfaces are are are are um
established in the environment
okay so summarizing what I just said um
I guess I don't need to go through all
this I get this is mostly as a point of
um to show a break in the flow now let
me contrast this view of perceiving with
the standard view of perceiving um and
um and the standard view of perceiving
is um that of um
assuming that Vision Works as if we're
perceiving
pictures this
um this notion goes back to the idea
that you're assuming that vision is
based on the projection of an image on
the
retina okay uh it has a very old
pedigree it goes back at least as far as
Kepler who who writes I say there is
Vision when a representation of the
whole hemisphere of the world that is
before the eye and a bit more fixes
itself on essentially the
retina theories in visual perception
continue to claim that Vision begins
with a retinal image even some people in
the ecological Camp will use that phrase
and I really don't like that um and one
of the reasons is because a retinal
image is basically
static and it's flat and the world that
we experience is neither of those
things okay so um let me just continue
um and certainly this view becomes
pretty Central in Western culture
particularly in the development of
representational art uh through people
like um Da Vinci and others quite early
um really brought into um becoming a
major idea with the work of people like
vermier and the development of a Comm
obscura which plays a critical role in
the development of representational
painting okay but the the question is
does this the way Vision Works and
um it it it s it suggests that the first
step in vision is static an image on the
perceiver and that results in a
sensation perception distinction this
first level is essentially sensation
which presumably is impoverished or
limited uh in as I'll show at the end of
my talk noi talks about it as
perspectival views
yeah yeah because well for the simple
reason I mean you're certainly right
that that there's movement on the retina
but notice that if if you if you go back
if you think about just photography I
mean one of the first things you have to
learn if you're a child is not to move
the camera because the image blurs you
take a moment in time and
it's but if yeah but you're right except
that to get a clear image you need a
moment of non-movement your shutter will
take care of that but our let me
continue but our experience is of a
continuous world so how do we explain
that the typical view is that the brain
is sent these static images that then
get
assembled
okay yeah that's actually very strange
because uh in order to sample something
you need to deide a window in which you
say within this period we assume
something sta or something like that
file yeah I I don't dispute that at all
I'm I'm just giving you the standard
line I'm not defending this position no
no no but I I don't think that
anyone
they themselves stud
pictur but what what but if you look at
I'm serious if you look at most most
accounts of visual perception in
Psychology today the the first step is
going to be a momentary slice of
information that's frozen in time a cad
and so if we're picking up these
momentary slices we have to assemble
them to perceive a dynamic
World however if we're not detecting
static slices if we're detecting
information over time continuously we've
created a false problem if you see what
I'm saying and so the the the
traditional approach and and I'm
mentioning this because I I I I think
there's some dangers of this in in
action theory is to create this
distinction between sort of the input
which is somehow limited relative to the
experience and some subsequent action of
the organism which which essentially
produces the full-blown experience you
understand what I'm saying there there's
sort of a first step which is somewhat
impoverished relative to the experience
like seeing an seeing an object from a
certain
perspective and there's the experience
of seeing the object you know in the
round in the
full that distinction is is is
only warranted if in fact this
description of sensation is um is valid
but now I'm trying to show you that from
a cultural historical point of view the
notion of a static image come doesn't
come out of the study of vision it comes
out of the study of representational Art
and was incorporated into
Vision people like I I well come to this
person in a minute oh but let me just
elaborate so typically the stories you
get
in in the um mainstream psychological
theory and this comes out of the major
figure in all this is hel 19th century
theorist helmholdt is that so what
happens in perceiving is that you first
get some partial cues and then they need
to be assembled or integrated helmold
said you make an inference based on
partial cues so the difference between
sensation and perception is that
sensation are these these um somewhat
reduced information um let me
say properties that do not fully account
for the experience of the environment
but only
partially and and then we need to enrich
that elaborate that or another way of
saying that in this this is when I'll
come back to the inaction view of
perception is that
um that perspectival views of objects
need to be converted into experience of
the object by the perceiver and I and
and I and I going to dispute
that but that'll be clear at the very
end um but what this leads to is a
position that none of us in the room
want to be in which is this position
here because if the early stages of in
this case Vision are somewhat
impoverished and the organism has to
therefore assemble these various
impoverished uh pieces of information to
experience the world what you have is
experience separated from the world and
we don't want to be there by the way
this come if you'll notice figure one
two this comes from chapter one of a
book on perception undergraduate
textbook this this is essentially
telling students here's how Vision Works
okay Dart could have written this text
book
right and it's not by the way a quirky
one this is a mainstream I mean it's
it's Goldstein Sensational perception
it's one of the biggest selling
perception books in the United States
which is by the way very interesting
it's called sensation and perception and
in index the word sensation doesn't OCC
once huh interesting interesting but but
and and and that doesn't surprise me but
but the entire account of perception
although he's in in Sub in various
additions he's giving more and more uh
space to ecological Theory but the
entire account of visual perception is
based on the assumption that there's a
difference between sensation and
perception and that sensation is the
first step and what Gibson wants to
argue as as I'll hope to make clear a
little bit is that sensation has nothing
to do with perception because sensation
doesn't carry any
information um and so we get to this
this position which you all probably are
quite familiar with starting with lock
it it's evident the Mind knows things
not immediately but only by the
intervention of ideas or dare I say
sensory motor
coordinations it has of them I was
probably a cheap shot but okay but I
want but I'm trying to set up the
argument for later our knowledge is
therefore real only as so far as there
is a Conformity between our ideas in our
heads and the reality out there we're
creating Two
Worlds and as Fred's been saying for the
last couple
days I gather none of us want to create
two
worlds okay whereas what Gibson writes
and it limits perceiving to the now
Gibson argues that traditional theories
of perception take it for granted that
what we see now present experience is
the sensory basis of our perception of
the environment that's just restating
what I just said traditional theories
assume that what we see now is the
sensory basis of perception but he says
that that the perceptual process does
not begin with this momentary pattern
perceiving begins with the pickup of
invariance over
time perceiving is a process that occurs
over
time um sorry for the monologue but I
but I want to lay these things out in a
minute I'll shift to some other things
which are more my contributions one of
the things that the cognitivists hate
about Gibson although I think this
doesn't bother many of you so much is
they'll say but that that means that
memory doesn't play a role in
perceiving
um but if perceiving occurs over
time memory doesn't necessarily play the
the the standard role that it does in
visual perception he writes the theory
of information pickup does not need
memory it does not have to have as a
basic postulate the effect of past
experience on our present way a present
Way by experience by way of memory it
does however and this relates to skill
needs to need to explain learning that
is the Improvement of practice uh of
perceiving with practice and the
education of of attention the state of a
perceptual system is altered when it is
attuned to information of a certain sort
the system has then become sensitized
differences are noticed that were not
previously noticed features become
distinctive that were formally vague so
you're the judge of list data but with
the the memory how would you explain the
baby experience of the rotation without
some sort of like memory placeholder
that's not a skill that is a placeholder
of there's an object in my present
environment that looks something like
this it's it's it's it's the problem
here is is is the problem of the word
memory because it means different things
if you mean the effects of sort of Prior
exposure cumulatively on the present
sure you can't discount what your
history if you mean that there's this
memory Trace in your head that you
therefore used to enrich the moment the
momentary sensory pattern Gibson's going
to say no and and that latter point is
what the standard CLA the cognitivist
claim of perception is so he's going
he's attacking the cognitivists here the
cognitivist use of memory and theories
of
perception um and so as as I want to say
what's happening and and and Gibson
doesn't develop this too far is is that
in the in the course of an individual's
lifetime there's ongoing
atunement so at any given moment you
bring a history of perceptual
attunements sensitivities if you will um
to the situation and and I think that's
part of what we mean by being skilled
except in that case we're talking more
about perception action
processes all right let me um move ahead
in just a second uh but just to
reinforce something so the received view
the traditional view draws a distinction
between sensation and perception
Sensations are sort of impoverished
input perception is the full awareness
of the environment um perception of the
environment is indirect because you
experience the environment in terms of
um the perception that you've created
rather than the detection of the
properties of the environment
immediately uh and what it leads to is
mediation theories and and enrichment
theories the the debate I want to have
with with some of you maybe later is
whether um noi and oran's theory is a
mediation Theory I'm inclined to think
that it is but I might be
wrong um okay well let's move
on here's Now for Something Completely
Different
sorry if you um if you imagine that
you're an 8-year-old child and out in
the
field what what do you experience
there yeah yeah it's it's I mean I would
assume for many of you it's like I'm I'm
on that tree right away right it's it's
a tree um that affords climbing now why
does it afford climbing let's go back to
the
previous photo what makes it a climbable
tree we can I mean it's not hard to
start enumerating the reasons right the
trunks low to the ground um blah blah
blah blah blah you know we can name it
and so in fact we can talk about trees
as a category of objects but trees
differ in their influences this is not a
climbable tree although I mean you can
climb and I and I certainly have done it
as a kid it's not fun and it tends to be
really
messy
um that is not a particularly climbable
tree for a human
being uh that is it affords climbing to
to some extent that's a good that
affords climbing that
doesn't and in other words what the the
point I'm trying to make here is that we
can distinguish objects that might fall
in the same let's say abstract category
the same concept but we can distinguish
them in terms of their affordance
properties okay so it not only are trees
do do trees afford climbing but you can
name all kinds of things that afford
climbing in a child's
environment right so what is it that
makes something climbable well among
other things it has to be properly
scaled to your body you have to be able
to reach you know the the ledge or the
surface and so on so notice that what
makes it climbable is its relationship
to you
so and let's take the notion of a Sit
surface what affords sitting on is
relative to the perceiver this this is a
wall in in front of the Student Union at
my college which begins you know very
low at one point and keeps getting
higher and higher and higher and I just
had my two friends Phil and Joe you know
kind of occupy two positions on this
wall and you can see although I'm
forcing the point Phil could sit on this
but not comfortably it's readly afford
sitting for for Joe at at this point at
redley if we're sitting for Phil but
it's the same wall in other words given
the different sizes relative to the
perceiver the affordance
changes and this case I'm perfectly
happy to say we're talking about
embodied properties of the environment
we're describing the environment with
respect to the body
okay some data um
hopefully many of you know this work
this is Bill Warren's classic and
classic experiment on
affordances um and the um the results
are very
revealing so what you have here is an
experiment where where people are asked
to judge whether they can step up on a
on a on a step on a riser okay and what
the experiment can do is veryy the Riser
height okay so the the the the the
distance between the two step surfaces
can be very small it can be really big
we've experienced steps that vary in
that way so all the perceivers are asked
to do is just say yes or no the step is
climbable and um he he gets participants
who are short short legs participants
who have long legs ask them to make
these
judgments and this line is the is the
50% it's in other words when when
participants are saying half of the time
that they can climb the step and not
surprisingly the shorter participants
are saying yes 50% of the time at a
lower Riser height than the tall
participants
okay right so what what's really cool is
then instead of let me go back to the
previous slide instead of using the
height of the Riser as our metric let's
use a body scaled measure in this case
Riser height relative to leg
length if you take this the height of
the Riser and divide it into the
person's leg length you get a ratio and
a ratio is this is a ratio of the of the
body environment
relationship if you then convert the
obsa to a pi value that is to say to a
relational value
they
meet and what does that say what it says
is that they are
perceiving relational
information that affords stepping up on
a
Surface okay this this experiment has
been replicated in with a lot of
different kinds of materials since then
this was published in '
87 what what I what I think is important
about this
I think it's a fairly convincing
demonstration as have been the
subsequent experiments that information
is
relational okay that is to say the
perceivers regardless of their height
are perceiving relational information
that affords stepping up
on
um if well hesitate I won't go there
another thing that another experiment
which I find really very interesting
it's it's kind of related to this in
this this is experiment by Len Mark at
Miami University of Ohio and he's having
people judge whether a seat affords
sitting on and it's it's a stool that
can be cranked up and cranked down okay
so you can vary the height of the seat
and you're asking people you know can
you sit on it and here's the 50
basically here's here's the the zero and
it's scaled differently here but it's
it's the perceived vers compared to the
actual height and you can see that um
people are overestimating but not by
very much they're relatively accurate in
judging whether a particular seat height
will afford sitting on the overestimates
are an interesting side issue which we
could come back
to so what these are subsequent trials
and and this is if if a person was
judging the height of the seat um
relative to um their height as being the
same then then then their score would be
zero so this would be an
underestimate this would be an
overestimate so they're slightly
overestimating the height of the seat
that's not the that is that's not the
important point now what he does in this
experiment though is he does the same
thing again but he puts blocks on
people's shoes that elevates their
height by a number of inches and and
what you see not surprisingly is now
they're
underestimating okay but the but the
important point is what
happens what have they learned in this
in this experiment so far have they
learned um sort of the absolute height
of the seat or they learning body scaled
information
so what happens in the rest of the
experiment in this case the individuals
are just standing still looking at the
seat in this case they're allowed to
move and so you can you can see that
generally the pattern of overestimates
still obtains but but but roughly these
are pretty accurate judgments we're
talking about minimal differences I mean
these are
centimeters but what's the most
interesting point of these data is is is
are these guys here the ones wearing
blocks on their shoes and that in fact
as they move they
re-calibrate their
judgments okay so movement enables them
to recalibrate what is what affords
sitting on and what doesn't it's a
dynamic
process
hopefully that's the end of that okay
now let's push this a little further is
aordance
Judgment body scaled everything I've set
up to now suggests the answer is
yes um but a new line of research is is
largely by Dennis profit and his
students um is is pushing the boundaries
a little more let's let's say uh we have
an experiment here uh and we want to
know
does altering body mass by wearing a
backpack affect your perception of
environmental
properties now what does that mean if
you're wearing a backpack what we're
we're thinking is that it changes your
relationship to the environment and if
environments are perceived relationally
you ought to perceive them differently
and so in prophet's experiment he has
people wearing backpacks not necessarily
with babies in them weighted backpacks
and uh and he asked them to judge the
the slope of the hill in one case a 5°
slope in another case a 31° slope these
are the judgments with no backpacks
these are the judgments with backpacks
okay there wasn't they had a a ha haptic
measure it was just sort of using a a
board to kind of tilt to make a judgment
that didn't show the effect but Visual
and veral reports show that if your if
your body masses increased the slope of
the Hill seems um more severe both with
5 and 31° slopes this has been
replicated in lots lots of ways uh
here's one replication where people are
judging distance not slope this is
Judgment of distance um estimated
distance to actual distance without a
backpack and and you you see um a fairly
accurate pattern although again what's
peculiar in this work is you get these
Under and Over estimates which we could
talk about later the most important
point though is the relative differences
you're wearing a heavy backpack your
body masses increased distance seem
farther okay does that mean therefore
you're perceiving the world
subjectively no it means you're
perceiving the world in relationship to
your
body okay does it mean you're perceiving
the world independent of your body you
know as as sometimes gibsonian are
accused of saying of course not this
precisely reinforces the gibsonian point
that you're perceiving the world
relationally so it's Not Mere body
scaling but action
possibilities I want to say that a es if
you'd like a definition that I wrote at
6: a.m. this morning so I might
backtrack a little bit uh affordances
are action possibilities of the
environment taken with respect to an
individual uh Gibson
is emphasizes that they're neither
objective nor
subjective you can say they're both or
we'd rather say they're neither that the
objective subjective dichotomy is really
not helpful at all in psychology and
Fred's been making that point over the
last few days it's it rather than being
objective or subjective it's properties
of an organ envir organism environment
relationship and in doing that what
we're adopting is a psychological level
of analysis when we're doing when we're
adopting a relational view rather than a
physical or a mental and well no I say a
physical analysis when we adopt a
psychological level of analysis um we're
we're talking among other things about
functional properties relative to the
perceiver in this case of
affordances okay uh end of part one but
that was a big that was most of the talk
let let me tell you about the ways in
which I've tried to push these ideas a
little
bit
um and uh and it has to do with the way
in which evolutionary biologists have
been thinking about
adaptation um even though and and here
I'll just make a snide remark even
though evolutionary psychologists
haven't figured this out yet
evolutionary biology talks about
adaptation in a way that psychologists
often don't the standard way of talking
about adaptation comes out of Herbert
Spencer Spencer in the 19th century and
it's the notion that an animal adjusts
to the environment Spencer put it we
adjust the adjustment of inner to
Outer in in the 18 1950s William James
wrote a devastating essay on this trying
to indicate why this is so wrongheaded
um but let me just take a simple
approach to this instead we want to say
that adaptation not only involves
organisms adjusting but also changing
their environment to better fit with it
it involves an organism environment
reciprocity and if you start looking for
evidence of this it's all over the place
there's a great book if you haven't read
it called Niche construction that was
published about 10 years ago which is
all about the ways in which organisms
from
microorganisms to humans alter their
environment to better live in it and
here's just a few
examples
um so um I don't know if beavers are
native to this part of the world but but
this is a beaver dam this is constructed
um as a lodge for for beavers to live
with their families and and raise their
young and so on and it's assembled by
creating um these nests uh spider webs
are another example of Niche
Construction in the case of beaver dams
they might last for several months in
the case of a spider's web it might last
for a matter of
hours um termite
Hills um this one is a particularly
interesting one um and Fred mentioned
leaf cutter ants um what with these
chaps do is not only do they create
these huge underground um spaces to live
in but they also transport leaves in to
create essentially agriculture within
their nest that in other words they
produce their own food
supply now what I'm trying to say then
is that it isn't that the organisms are
merely adjusting to the environment but
we're also changing the environment to
better adjust to it this is this ongoing
cycle of Niche construction and um these
are Bower bird nests these huge nests
and here's the strange creatures you
know building you know changing their
environment to to better support their
activities um in the
woods Niche construction is ubiquitous
it's everywhere it's with all species
and and humans have developed it to a
high art what are we doing when we we're
engaging in its construction we're
creating new
affordances we're creating properties
that support action relative to the
individual and um and a great deal of of
um we could look at a sort of a major
slice of cultural Evolution as Niche
construction we're completely in an
artificial setting right now in some
ways artificial not in the sense that
it's NE it isn't made up of there's
probably some organic fibers here or
something right but it's artificial in
the sense that we've created it in order
to better carry out what we hope to do
in
here um and
so just to make make this part short so
these Niche construction and general so
generally social cultural influences are
collective and cumulative and as is is
well known especially in many European
uh much European thinking that each of
us is then born into an environment that
is already structured by sociocultural
activities in other words so if if these
activities produce affordance create
affordances then we each of us are born
into an environment that's filled with
affordances some of which are wholly
produced by human activ ity so this is
another misunderstanding of affordances
affordances is often thought to be
they're just
natural but that's a red herring the
natural social distinction is is phony
human activity produces affordances it
creates affordances out of natural
materials there is no distinction
between the two in fact what I want to
argue but I won't do it here
um but but hopefully in another future
paper is although we often talk about
social affordances what I want to say is
that affordances by and large for humans
are
social because we make
them we create our environments and
these are not environments in our head
they're real environments that we live
in um virtually every object in this
room is has an affordance property
that's been created to support activity
and as children or if you're new to a
culture you have to engage the
environment in order to somehow discover
those properties Fred do you have a
point okay um and so as I said each of
us is born into an environment that's
filled with affording structures I'm I'm
not talking about meaning here because
that'll just send us down a road but I
happy to do that subsequently um and
these are they're very different kinds
of environments I I sort of use these
pictures to contrast this one with these
two as the very different kinds of
Worlds that children enter into that are
um structured to varying degrees have
different types of affordances um the
environments provide different tools for
children um to engage so here's a young
child manipulating a book even though
the child isn't yet at reading age
presumably so the child is familiar with
a book here's a much discussed
photograph um that you would never see
in most western cultures of a of a
barely walking baby holding a machete um
but in this particular culture that's a
perfectly reasonable thing to do uh and
even we we get rather carried away
sometimes in our environments okay now
now let me take one last step what I've
been doing so
far is I said that what I want to talk
about is everything else namely the
environment okay and that's I've been
trying to fill in the everything else um
with affordances
that
um are present due to Natural
circumstances but also designed and and
and Modified by
humans um but there's
another set of environmental structures
that is greatly neglected and so um and
this is the work of Roger Barker Roger
Barker is a psychologist if you haven't
heard of him you're in good company
because in fact many psychologists
trained today have never heard of him
and yet he's some in the in the 60s who
won like the the highest award that APA
gives okay I mean he in his day he he
was incredibly distinguished and um let
me talk about what what he did what
prompted Barker's work is is a very
interesting experience
um at about midcareer when he was fairly
welln his his all of his prior work had
to been had been developmental uh
studies he he was a postto of LaVine he
co-published with Kurt LaVine and uh and
was a very very well-known developmental
psychologist anyway Barker reports in in
his um in his Memoirs that one day he
was driving riding on a train through
these small towns in in
Illinois and um and he realized that
even though at this moment he probably
knew as much about developmental
psychology as most people and he was he
was up to date with the literature he
had no idea what was going on in any of
these small towns he couldn't predict a
thing about what these kids were doing
he was recognizing in fact that what we
don't know is what happens in everyday
life so he did what biologists have long
done and and he proceeded Jane Goodall
by a good decade and a half um
established a research station in the
small town and began studying
Behavior
okay now um I'll have to make a long
story short but one of the most
interesting things that comes out of
this research and it's not anything he
expected it it really surprised him and
I'll I'll try to tell you why is that he
identified that their higher order and
by that I mean collectively
generated and by that I mean generated
by multiple people structures in the
environment that um create
opportunities uh
for our lives and um so let me get right
to the point and I'm going to be really
brief on this because time is short he
calls these environmental structures
these higher order structures Behavior
settings um I'll offer I'll get to more
precise in just a minute he Behavior
settings are Dynamic relatively stabled
Tim limited ecological
entities um and the easiest way to
explain a behavior setting it's actually
quite easy to explain it you're in one
okay a behavior setting is a pattern of
behavior in this case it's the behavior
of you someone lecturing and others you
know attending the lecture or whatever
supported by the mil he called it the
muu I'm going to say I think affordances
really fits in nicely here the the by
the way the the reference if you don't
know about Barker which I is is at the
bottom of the page here are the
properties of behavior settings they
occur natur as a function of the
collective actions of individuals they
pop into existence games pop into
existence um uh classrooms
meetings parades you can kind of go on
and on and on these are collective
activities um but they're structured
they're composed of D of a dynamic
pattern of individuals and
affordances um they are objective in the
sense that and this is in that this
Behavior setting has a specifiable
geographic location anybody have a GPS
on
them you can specify where this Behavior
setting is
objectively it has a temporal
boundary started at 9:25 ends at I'm
going to shoot for
1120 um if I started before 9:30 that
would have been I would have been
talking I would not have been in a
behavior setting at the time
so there's there's a Collective
Agreement about where Behavior settings
are and when they start and when they
end okay so they're relatively stable
structures but have a particular uh life
there this issue is what I'm currently
doing research on um Behavior the the
settings are discriminable you can you
know when you enter a behavior setting
and you can and and you and you and you
know the meaning of the setting you know
what's going on at the place that's an
empirical claim which I hope to have
some some data for in a few
months um they're quasi stable meaning
that they respond to threats to the
Integrity so let's say let's say instead
of a lecture this is a classroom and you
and you have one sort of disruptive
child who's threatening the Integrity of
the setting yeah what what you say Ellen
says to John John Sit Down You're ruin
you're mess you're interrupting the
class and so that leave that to the
debate after and that sort of returns
the this this helps to restore the
setting integrity and if John still
doesn't respond to Ellen then we just
bodily throw them out the door in other
words it's it's a it's a biological
entity we're talking about that's
Collective that operates to maintain its
own
stability um what's and I what I think
is really cool about Barker is he's
thinking at a level that most
psychologists never get to he's thinking
about extra individual environmental
structures
um they exist of any of any independent
of anyone's experience because if you
step out of the room to go to the
bathroom we don't just all flop as you
know mannequins we're we're going on
without you okay
um and and I can say a lot more about
that what led Barker to this discovery
is really pretty interesting um what he
did in his work is he had um he he he
and his research team followed children
throughout their
day and basically just recorded
everything that they did and this and
the setting that they were
in and what he wanted to know is what
could I use to predict the behavior of
children at any given time the
Assumption there there are a couple
assumptions you could make one
assumption is that if you knew about the
kid's
personality you could predict what
they'd be doing at every any given time
or what bar thought if you knew what the
child just immediately experienced like
a stimulus you might be predict what
might immediately occur none of those
things turn out it turns out that the
best predictor of what a child is doing
in that town at any given time is just
knowing where they
are another a nice way of phrasing it is
that the behavior of different children
in the same
setting had less variability than the
behavior of a single child across
settings I don't know about you but what
I think this is like an incredibly cool
idea that and and if we don't work hard
it's going to be
forgotten nobody because no one's doing
this work
anymore so um I'll push on so another so
Behavior settings um are all over the
environment we enter them we help
constru we help uh generate them they
constrain our Behavior they create
possibilities we move through the
environment by entering and leaving
Behavior settings all the time so
getting back to the everything else what
I'm going to say is that part of what's
the everything else outside of the
organism are affordances and behavior
settings generated relationally okay
they're independent but they're not
independent that's a debatable point
obviously um so I would like to say that
behavior settings and affordances
constitute the ecological resources of a
place from a psychological point of view
it they
essentially create opportunities for
doing things and and we can construct
them like we call you know America
organized this so we can this this
Behavior setting has been constructed
but it's not constructed in our heads
it's constructed in the
world so if if um if you can indulge me
for another just few
minutes
um it's it's not good practice to put
maybe the most abstract part of the talk
toward the very end but um but I I want
to try to give you just a general sense
of what sort of philosophical Foundation
all this rests
on let me say that James's radical
empiricism is not the only influence on
Gibson's work he's influenced by a lot
of other ideas including gal psychology
but it's this thread which which I think
is particularly
important because it gets it it provides
grounds for his account of U
realism
um first of all what about the pedigree
uh William James developed the the
philosophy radical empiricism it's in
the principles of psychology published
in 1890 but it's it's embedded in it if
you don't look for it you won't find it
he starts developing the ideas in the
1890s and and and his in his book um and
radicalism publish is appears in 1912
after his death um one of his students
uh who saw himself as the standard
Bearer for radical empiricism in the
subsequent years was Edwin
Holt and Edwin Holt was Gibson's
graduate Mentor so part of what I do in
the book is kind of establish that
lineage so what I want to say basically
say is that the Rel the kinds of
relational claims that I've been making
all along rest on James Z and IAL
empiricism first of all and and and I am
making this very brief first of all what
does James attacking he he with radical
empiricism he's he's attacking the
entire English psychology derived from
locken Hume and the entire German
Psychology from herbart so far as they
treat ideas as separate subjective
entities in the mind that come and go
other words what James is rejecting is
mentalism both the Bri empiricist
tradition and the Continental
tradition not
surprisingly folks who become deeply
influenced by James's writings or huso
and subsequently haiger and meranti you
know so so that that whole you know
alternative you know you know begins
partly uh and and just partly with James
so there are three uh he he lays out
three principles of of radical
empiricism
um by radic he means that um it must be
an empiricism that admits into its
construction its theoretical
construction um it is it neither admits
into it anything that's not directly
experienced
okay or uh and it doesn't exclude
anything that is directly experienced
and the next point is the the point that
separates him from those two traditions
because and this is the most radical
part of radical imp systm because what
James claims is that what is directly
experienced is not only things or
objects but the relations between
them
okay if if you know a bit about Hume I
mean the problem the whole problem with
induction with Hume is that we we see
these separate entities and then we make
inferences from them based
on contiguity of past experience but the
assumtion is that those relations The
Continuous relations are not perceived
they're inferred that's that's hume's
point and James is saying no they're
perceived they're
inexperienced and this this is just
elaborates that point but parts of
experience hold together from next to
nEXt by relations that are themselves
part of
experience so if you know you might be
familiar with James is writing about the
stream of Consciousness right and he
talks about there's resting places and
transition places is that ringabell
right the transitions are the relations
although he doesn't put it that way in
the principles this that's a diff
this um terminology comes later um the
directly apprehended Universe needs in
short no extraneous trans empirical
connective
support that is to say it doesn't need
sort of mental um
functions to connect the
pieces nor does it need a Godlike Force
to connect the pieces that's really what
he's as a as a footnote that's what he's
worried about his major theoretical
adversary at this time was um idealism
which which isn't really much on the
scene now and that's what he's kind of
worried about here um but he wants to
say it's not that God ties the
connections together but they're there
in the world
Okay so so then what is
experienced James begins with the claim
that we we have to we start with the
supposition that there's only one Primal
stuff or material he's notice he's kind
of not sure about which word he wants to
use here in the world rather than two in
other words that we don't start with
matter and mind what we start with is
experience of which everything else is
composed and we call that pure
experience
it's useful to think about it as as sort
of a mathematical limit okay it's it's
it's um for the time being it is is
unqualified actuality it's what's there
it's it's an it has a certain immediacy
and we act on
it um and and it's and the notion of an
object or a subject is only virtually
present in the now it comes about by
differentiating
the structure of immediate experience
everybody with me so
far okay because I'm I'm going to do one
more thing but but but it's I think it's
critical um this is a passage from James
and I'm going to give it to you in in
pieces okay he says let the reader begin
with a perceptual experience that is to
say now the
presentation in the so-called uh
physical object his actual field of
vision the room he sits in so let's be
begin with the room we sit
in the whole Philosophy from democratus
has been one long Wrangle over the
Paradox that what is evidently one
reality the room we live we are
currently situated in can be talked
about in two different ways it can be
talked about as being out there and in
here
okay that's from from a an a pragmatist
point of view that is just a hopeless
sit situation to be
in so then the question becomes how the
puzzle of how one identical room can be
in two places that is to say in the
outer world and in your mind is at
bottom the puzzle of how one identical
Point can be on two
lines and it can be if it's situated at
their inter at their
intersection
and it if it be that pure experience of
the room this sort of immediacy of our
experience this pre-reflective
experience to use a more
phenomenological phrase uh were a place
of intersection of two processes which
connected it with different groups of
Associates
respectively it be it could be counted
twice over I I I'll try to clarify this
although it REM would remain all the
time a numerical single thing so we're
experiencing something that is the
conjoining of two
histories okay that can be traced back
independently of one another but the
experience but experience itself is at
that um moment of
convergence um the experience is a
member of diverse processes that can be
followed away from it along entirely
different lines one of them is the
reader's personal
biography in other words all the things
in your history that have the use a
gibsonian phrase that have attuned you
to the possibilities of this
setting and the other is the history of
the house in which the room is
apart the very same
that um that is to say immediate
experience is the Terminus at quem of a
lot of previous physical operations like
carpentering P papering Furnishing
warming and so on in other words Niche
construction and
of a of a lot of future ones as a room
the experience has occupied that spot
and that environment for 30 years so in
other words what I think he's offering
us here um is experience as not being
separated in terms of environment and
person although that comes subsequently
on
reflection but rather experience that
immediately points both to the
environment and the person
simultaneously like an
affordance one I think nice development
of this idea and hopefully um Kurt
LaVine is getting rediscovered and it's
well it's it's it's really quite
warranted LaVine wouldn't describe
himself as a jamesian but if you if you
know about LaVine he he conceptualized
behavior and that's the term he used is
as being situated in a psychological
field and so this this is the person
these are the various regions of the
psychological field if he were to go on
he would would talk about the valences
that these might have which might draw
or repel the person to these areas and
so behavior is a function of these
multiple forces he's thinking of and
James was just at the beginning of this
notice the Venus talking about field
Theory not Newtonian
physics okay the gal psychologists were
all colleagues of
Einstein what the reason I introduced
LaVine is because I this diagram which I
I really really like so this is that
area that I just showed you a minute ago
which in which is the person and the
environment you know combined okay but
this is it over time and so at this
let's say at any point along here the
character of the person is a function of
its history just as the character of the
environment is a function of its history
as James said and so experience or in
linian terms the life space is a
convergence of these two histories
Gibson didn't particularly like this
because it was a little too
phenomenological for him but but so
summary comments um I won't get to so
what what do I have what's my
beef with um in action theory of
perception and um let me just return to
this diagram
here um to remind you that the
traditional theory which we're all
trying get away from draws a sensation
perception distinction it tends to put
perception in the interior of the
organism and they tend to be mediational
theories and I feel that and I might be
reading it wrong so correct me but I
feel like Ina the inaction theory
perception comes very close to repeating
these same problems let me let me just
try to show you why um let me just show
a couple passages from from Noah's
book uh can you not read that because of
the
color can you see that
okay well well let me I tried to put the
quotations in one color so you could
separate the quotations from my comments
um this quotation and the one that's on
the next slide go together so let me
think take them both together Noah
writes to
encounter its visual potential and that
and the visual potential of of the
object to be perceived
is to encounter its actual shape in
other words when we encounter the
potential we perceive the actual shape
now where do we get the potential when
you experience an object as cubicle
merely on the basis of its perspectival
aspect you do so because you bring to
bear in this experience your sensory
motor knowledge of the relation between
CH changes in the cubes aspect and
movement hopefully this is familiar if
this is unfamiliar then not being able
to read this would have been impossible
to follow I'm sure to experience the
figure as a cube one the basis of how it
looks is to understand how its look
changes as you move Okay now what's
wrong with
this well first of all I think it starts
to reintroduce sensation and per the
sensation perception distinction and let
me show you how um is this at all
visible back
there okay this is this is the again the
Crux is that P perspectival properties
and a perspect perspectival property is
the object seen from a particular
Vantage
Point are not nearly visible qualities
such as shape and size they are looks of
things their visual appearances to see a
circular plate from an angle for example
is to see something with an elliptical
perspectival
shape and to understand how that
perspectival shape would vary as a
function of one's movements with respect
to the perceived object so in other
words you perceive the perspectival
shape and you also see the virtual shape
of the object because you anticipate you
know what would emerge if you did this
that or the other thing um we can do
this because we understand implicitly
that circularity is given in the way how
things look with respect to shape varies
as a result of movement now there's a
couple of things I think are really
wrong with this and and and um first of
all I think it's really bad
phenomenology
because you don't
see elliptical
shapes you see circular
shapes you don't see perspectival you
know appearances you perceive objects in
the full so what I'm afraid and and and
he probably would disagree with me I'm
sure is what we're doing here is we're
kind of slipping back into a per
sensation perception mode again and if
you do that then the sensory motor
coordination that follows
might lead us back into a mentalism that
we don't want to get back into because
it's all happening as you will off stage
instead of happening in the encounter
between the organism and the
environment I'm nearly
finished
um moreover in the way this has been
phrased the idea of an invariant is
missing that is to say if we don't
detect perspectival shapes what we
detect our invariance through action
literally action not anticipated action
not motor schemas but by Bloody moving
around the world okay and um I mean I
could sort of hammer this home I think
but again my experience of circularity
just as my experience of the variation
in its perspectival
shape we don't perceive perspectival
shape unless we're thinking about
picture perception and picture
perception we have to be very concerned
about perspect shape because we're
dealing with a flat surface um I won't I
won't belabor that point but let me take
one statement that comes from Noah's
book action and perception where he
explicitly talks about Gibson and and I
and I can hope to show why he's
misreading Gibson and and I'm I'm and
I'm a little surprised he does because I
also know that he knows Gibson's work
pretty well so I I don't quite
understand what accounts for this uh
Gibson's view can now be usefully
reformulated in the context of the
inactive approach to perceive structure
uh is to perceive structure in sensory
motor
contingencies that is to say in your
anticipation of what something would
look at look like if you moved in
certain ways to see that something is
flat is precisely to see that it has
giving rise to certain possibilities of
sensory motor contingencies and I would
say well first of all you don't perceive
it as flat and secondly what because
what you do is you detect in the
invariant structure in relationship to
your movements in the world so that
takes experience and puts it back at the
kind of in the relationship between the
organism and the environment and what we
can argue about momentarily is what I
think this account does it's a really
slippery slope that heads you back into
mentalism and I don't think that and I
know that's not where you want to
go so if if gibsonian Theory can offer
you anything it might be able to perhaps
fine-tune uh that and um so this kind of
phrase just to re reiterate the E the
ecological notion of structure is
lost what does structure mean in the
context what does structure and sensory
motor contingencies mean I have no idea
but I can tell you what structure means
in an ecological point of view because
in some cases we can specify it
mathematically like in the case of the
Riser height relative to leg
length I can I can talk about it in a
very concrete
way it sort of leaves open and how the
organism is anchored to the world again
it sort of it hearkens back to how I
started the talk it's like there's the
organism and there's everything else
that's not good enough everything else
isn't good enough you know what is the
everything else um and action without
resistance and this was a topic of two
days ago you know that that that's
provided by the task structure or the
environment has no
structure okay so I will conclude an
over long talk at that
point thank
you

### merged.md

What does it take to be good at design? If you follow the increasingly popularized design thinking model you’ll be led to conclude it takes empathy, imagination, experimentation, curiosity, and resilience. While those are virtuous qualities to possess being good at design is much more simple than that.

Design is an act of creating futures. How can that be simple? The act of designing is not simple. The list of what it takes to be good at it is. You can distill design into exploration, abduction, and constriction. You don’t need empathy unless you are designing for someone other than yourself.

Exploration is what sets you on the path. Good explorers enjoy seeing what can be seen. As much as we work to improve the process and inputs of design the truth is that design, just like everything else, is an act of trial and error. Exploration fuels the trials in spite of the errors. Good design is seeing the possible you need an explorers spirit to do that. From a practical standpoint exploration is generating a whole lot of tries. First idea, best idea is the sign of a poor designer. Fifth idea, pretty good idea is the sign of a good designer.

Abduction is a fancy word for sussing causes from the murk of consequences. Good designers need to keep half a mind on the consequences of their choices. This is the essence of design. Realizing a future is coordinating consequences to produce an outcome. Abduction is saying, ‘I did A and saw C. B causes C.’ Abduction is always a guess. If you can’t discover the cause of a consequence you can’t plan around it. The only way to get better at abduction is exploration.

Constriction is a really poor word but it ended in -ion so I’m going with it. Constriction is setting up the bounds of the space. The world may be your oyster but you can’t design without some manner of limiting criteria. Nature supplies you with one in the more of an aim, objective, goal, purpose, or desired outcome. Being good at design is creating a tighter boundary than a goal. SMART goals may work but aren’t quite the direction to go. Think of constriction less of, ‘I’m hungry and want a hamburger’ and more of ,’I’m hungry and want a buffalo burger on wheat with organic tomatoes, arugula, and dijon mustard.’ The boundaries are more tightly defined so now you can go about creating that burger. The design is in the constriction not the creation. Good designers are specific.

Any discussion about literacy and design can be considered splitting hairs. The beauty of concepts is that they are so fuzzy. Exploration is imagination, experimentation, curiosity, and resilience. Abduction is experimentation. Constriction is a terrible word, shame on me, but the idea of defining a space is central to design. Understand these ideas and you’ll be good at design.

[[_SVA]]
https://community.openai.com/t/building-chatbot-for-client-business-using-gpt-3-5-turbo/281411/2

https://stackoverflow.blog/2023/10/18/retrieval-augmented-generation-keeping-llms-relevant-and-current/

https://thesequence.substack.com/p/guest-post-retrieval-augmented-generation
#ux #ai 

AI is different than traditional computation and demands different considerations.

Well defined problems statement are vital in the world of AI with design. AI might not be the solution for the problem you're trying to solve.

AI brings the most value when you need to give recommendations, anticipate disruptions, and detect liabilities. Here's a Spotify playlist of some hits you'll enjoy. Expect that you're going to have X amount of spike in usage. Here are some mitigation strategies for this spike. AI is good at looking across vast interactions and detect fraud.

Comb through topics: help research, personalization through natural language, collect large amounts of information and parse it at scale.

We need to consider how to keep the human in the loop.

Explainability, drift, and fairness are the three pillars of AI trust.

IBM has 10 insurers and 25 retailers on mainframe. They process 90% of all credit card transactions. IBM's mainframes contain 80% of the world's business data.

AI is probabilistic and traditional computing is deterministic. Deterministic is prescriptive and predictable. If the user does this then this happen. Because the data changes over time the AI's output will change over time.

Affordances & Signifiers are still true to AI design. Making the AI evident in the experience builds trust. 'You're about to interact with an AI. Continue?' Track the decisions AI has made in your software. You might denote that this stock has performed well and the AI making a prediction it will continue to perform well otherwise you customers will lose track of what is true and what is fiction, what is real and what is a guess.

The ideal UX for AI ensures the human has control and maintains the final decision. 'Would you like for our system to purchase the stock for you?'

A good UX for AI includes implicit, explicit, or dual feedback loops.

Can use surveys, comments, as feedback mechanisms to improve. You can track how many back and forths were exchanged before the user got the answer they wanted as a quality metric. Did this answer you question is only half the story, what the experience was like getting to the answer is the other half.

Whenever possible explain how the AI predicted the output/outcome.

Explaining your information sources is critical to build trust with LLM specifically since they are trained on the widest data swath. 'I was able to determine this information from these sources.' Citations, even in the text of something it creating from RAG data like a financial report. Like '(1) hyperlinks to the documents.'

A dev and a data scientist are the core AI team.

Rebecca Hemstad
1:39 PM
'Explainability - the method of explainability will likely depend on the nature of the input. There are fundamentally 5 prompt methods: iterative, summarizing, inferring, transforming, expanding. So @Daniel - it sounds like your example was based on summarizing for that specific issue - yeah - probably source for explainability'

Prompt tuning and fine-tuning are how you keep responses relevant to your customers and keep them speaking in their language.

Jocelyne Light
1:49 PM
'I worked on project with a dev/data scientist where we used AI to pull topics out of 1500+ podcast episodes.'

AI still needs the instruction and quality controls to corale its output.
Because so much thinking is about problem solving we believe that more information will reveal the cause and allow us to remove it thereby solving the problem. We’re operating in a deductive manner smattered with induction. We play at Sherlock Holmes thinking ‘if only I knew more, then the solution would be revealed.’ Information is good for mapping context but does little to help you move forward. After all, you can’t know about the future until it happens. Hunting for more information is tactic of fear and avoidance. Creating information through action is the virtuous cycle we all need to set ourselves upon.

[[_SVA]]
That's what Hollywood is wanting. Play a movie for KREA, maybe make the movie a public movie, record the capture, is that illegal?
Find a public script or public shot list to a movie and feed that into a GPT to make a movie.
Find an ancient script and tell GPT to turn it into a script and shot list/screen breakdown for a movie.
https://www.techsmith.com/blog/shot-list/
 Breakdown
  Who, Characters
   Where, Environment
   Colors
   Sounds
   Style
   Lighting
   Dress
   Doing
   Audience vantage
   Scene Composition, Aspect Ratio
Create a shot list from the script above with the columns "scene number, shot number, description, design notes, cinematographer notes". #prompts
https://chatgptaihub.com/chatgpt-prompts-for-filmmakers/#3-storyboarding #prompts
Feed those shot lists into SD, use DP and DC as prompts. Use these images to train a model for interpreting.
Combine those shots with eleven Labs to give you a cinematic. You can sell a cinematic to a movie producer. They're going to take it and run it through their buddies to get whatever works for them. Fine. You've sold the idea. Let 'em run with it.
Even better, the camera to image. Pipe a camera feed in and get animated results.
Maybe you can find public shots or templates. That it can watch. Public stock footage? Stock footage?
Make a Hard Boiled detective movie!
Make a 90-minute movie in less than 90 minutes. Is it possible?
I used AI to turn my interpretation of your post into a movie response. #money
AI made a video based off its reaction to your post. Learn how to do this.
Using information that is open to the public. Most of it for a data and not a monetary exchange.

Turn the Mission comics report into a captivating 1-2 minute video #money

Cost
 - 11/mo elevenLabs - voicing

Footage
 - https://www.gettyimages.com/creative-video
 - https://www.gettyimages.com/editorial-video


#ux 

https://adplist.carrd.co/

88 years old

Why aren't people solving the problem?

Design understands people and the artificial things which we call technology. Design needs to lead the way because it is the ultimate. Designers don't want to leave their skills to understand politics, economics, and that's why they aren't CEOs.

Design is not art and art is not design. Design is sussing out the underlying issues to important problems and pointing the effort towards people.

HCD is wrong. 4 principles. HCD doesn't cover that physical devices destroy the environment through mining and manufacturing of tech. Burning piles of junk in India poisoning the air because of what we design.

We focus too much on craft which comes from art. Brilliant teachings in Singapore. Liberal studies in your design curriculum.

The biggest picture is humanity and all the ecological resources that support humanity. Design can help facilitate solutions from the people who live with the problems. [[Co-creation is anti-colonial.]]

The neural network architecture hasn't changed much since the 70s. There's been no theoretical breakthrough for today's AI only an increase in computing power and capacity. Instead of 3 neural layers there are 100s. Look into Jeff Hinton.

Complexity is in the world. Simplicity is in the head. Adding more buttons might introduce simplicity. Think about bartending interfaces where there are so many categories so everything can be a button or so away.

Mis en pla - everything in its place. Everything was wear it needed to be is what enabled the bus driver to learn this complicated system.

Apple fell in love with aesthetic at the cost of usability. Hired a great industrial designer who wanted it to look simple. Remove the buttons, remove the labels, remove the bevel.

The hard part about of design is making it simple when something goes wrong.

The way you work in industry is very different than the way you work in academia. Going back and forth between industry and academia to understand the principles but driven by industrial desires.

Novelists understand people because they have to to hold interest across time and page count. There's nothing in STEM about people. Bring the humanities into STEM. In the physical sciences if you can't measure it, Lord Kelvin, you can't measure that in the social sciences.

Designers are doers not just thinkers. We have to understand something about everything. Don Norman has never found an instance where a designer could not help.

Good designers always ask, 'is this the right problem?' - a handbook for design

My device would work better if people used them correctly. - If you find yourself saying this, you need a designer.

Don Norman designs designers. Design itself is not where we're getting the answers. What matters is what people do with what you design.

UN has list of 17 sustainable development goals. Pick one of the first 16 goals and design for it.
bool is good for spike traps
int is good for points in a play session
string is good for character names

#unity #programming 
#ux #ai
This means that each variable needs to have its own data type associated with it when it is declared.

#programming 
[[Build a circle of mentors with six people.]] Co-pilots are your long-haul, ride or die, people who expect to be in the suck with you when it happens. Co-pilots are also equals. Co is not a derogatory association. Co means I choose this not I am bound to you.
#ux #ai
#ux #ai 


No two threads can access the same resource. Threads must line up and cannot go until the current thread is finished.

https://medium.com/@magnusram/java-multithreading-what-is-a-blocking-operation-187a7304ccd1#:~:text=When%20we%20say%20that%20a,or%20queue%20is%20not%20empty.

In java, read() method blocks until some input is available for reading.

1) **InputStream.read()** which blocks until input data is available, an exception is thrown or end of Stream is detected.

2) **ServerSocket.accept()** which listens for incoming socket connection in Java and blocks until a connection is made.

3) **InvokeAndWait()** wait until code is executed from [Event Dispatcher thread](http://javarevisited.blogspot.com/2011/09/swing-interview-questions-answers-in.html).

  
  
Read more: [https://javarevisited.blogspot.com/2012/02/what-is-blocking-methods-in-java-and.html#ixzz89GNFl44T](https://javarevisited.blogspot.com/2012/02/what-is-blocking-methods-in-java-and.html#ixzz89GNFl44T)

#code 
When it comes to a successful design there’s only one measure that matters. Do the people you designed for see the value you intended in your design?

It might be useful to understand causation, correlation, leverage, entitlement, or any of the other sophisticated measurement concepts to find out if that statement is true. Like much else in this life I think there’s a simpler way. It’s a much less mathematical way. It’s a much more human way. If you want to know how successful your design is just look at who uses it and how they use it.

[[_SVA]]
Virtual 90min $495 once a week, Monday @ 4
B2B Sales, SPIN selling, analyze an MSA, save time, make more and make more money

Aggregated video content in https://aionlineclassroom.com/

6k videos, CustomGPT trained on all the videos, chatBot recommends video context based on your query

Used Pinterest API to pull out AI infographics and posters. Took about a month to build overall.

It's not about trusting the content, it's about trusting the curator.

Twitter API is 42k/mo at full bore.
Now that you can have anything you have to be good at recognizing what you want. The skill shifts from pure creation from nothing and the act of molding, curating, and edit what you're given into what you want. This skill is based on vision so the people with taste and discernment will be the more successful one. 
It is genuinely rare to find someone that can be considered good at dealing with disagreement. For reasons beyond my comprehension the fight or flight response is triggered by a disagreement. I think that a lot of energy is required to remake thoughts. The brain is inherently lazy. The brain protects the energy resource it has by triggering emotions of combat or retreat. Thoughts are not a physical threat but we feel them as such.

Dealing with disagreement is the act of making space inside your mind for a conflicting perspective. Dealing with disagreement is not the same as arguing well. Shouting matches are not dealing with disagreement. Dealing with disagreement is not the same as someone who doesn’t back down from conflict. Bullies don’t deal with disagreement. Dealing with disagreement is not the same as debate though the decorum may look similar. Debate is an academic practice for intellectuals. Disagreement happens between all people and rarely carries a formal structure.

Making space inside your mind is surprisingly easy. We do it all the time when we like someone we meet. We make concession for our friends at an alarming rate. There is a danger here, friend or enemy are not useful constructs when dealing with disagreement. You won’t be successful trying to see someone with whom you disagree as a friend if they weren’t a friend before you disagreed. You cultivate your better nature before your interactions not during them. Abandon the whole friend/enemy dichotomy and stick with person. Don’t assign a value. A blank slate is a perfectly acceptable starting point.

From this blank slate agree to adopt a posture of exploration and compassion. Persuasion is not the goal. Understanding is. When it arises, channel your rage into bridging the gap instead of reinforcing your side or assaulting theirs. Disagreement is a powerful chance to establish shared purposes and values. Deal with it well and we all benefit.

[[_SVA]]
#ux #ai 


You spew truth at me with the vitriol of a raving dog and say you care about me. You hate behind the safety of your truth. ‘Truth has no sides’, you say. ‘It is truth therefore it is always the right side.’ Your arrogance betrays you, you small-minded infant. Truth has infinite sides. There may only be one truth but it is not for us to grasp. You misunderstand facts for truths. You cry, ‘objective truth!’ As if facts dictate reality. In the equation of existence reality produces facts. Perspective is what you strive for but you hate instead. You refuse to see from my perspective the things which I hold to be self-evident, the truths of my world, the facts of my reality. You want to care, you want to love, you want to foster a better society? If you did you wouldn’t think your truth matters more than mine.

[[_SVA]]
If you need to design a system, map a system, understand a system, create a system, overturn a system, basically do anything but ignore a system here are the conversational prompts to get you the information you need. 

What are the tasks for our audience? What’s the core, repeatable behavior our audience is looking to engage in? What is the change our audience seeks? What outcome is our audience expecting? What do they want accomplished? What are the variables involved in making that happen? How do the variables interact? What outcomes do they produce? What’s their environment like? What contexts do the variables create? How do the variables change? What flows between them? What value does the system create, reinforce, neglect, remove? Where are the beneficial redundancies? Where are the beneficial synergies? Where are leverage points? Who is involved in organizing, maintaining, and controlling this system? What does their communication flow look like? Who can kill a deal? Who do we need for implementation, release, funding? Where are the landmines to changing the system? Short, mid, and long-term? Do we have a complete list of who we’re doing this for and the changes we’re going to make? Have we listed the benefits our changes will bring about? Is everyone on board? Do we need to convince anyone else? How will we run this? Are we agile? What’s our process? What are the odds of success? The odds of failure?

[[_SVA]]
#ux #ai 

Research input must be continual and collected data must be refreshed from time to time.
Sensation is raw input and perception is neural interpretation. Our perceptions sometimes fool us.

#IxD 
#ux #ai 

https://www.youtube.com/watch?v=5HgkawZdihU

Help. I need some info. Help. Not just any info.

When you go to do a thing you'll go to AI like the way when you go to the internet you go to a browser. [[The processing of converting applications into interfaces is the domain of UX.]]

ChatGPT EXPLODED because we simplified the interface to a text prompt. More simplified the interaction with AI at large. You no longer need to build the AI to work with the AI.

Removes the fear of approaching certain tasks, namely a person without art skills making beautiful images. You can use ChatGPT to help you make better prompts for ChatGPT.

Cellphones. Text is primary means of communication for inter-office comms. AI at its core is texting to an intelligent computer.

No patent generated by AI will be accepted by the copyright office. Stop calling things that aren't AI, AI. We don't need AI in our toasters.

Logistic regression, logic trees are some terms to talk about.

Fraud detection, response analysis, and email open rate are good return for your investment.

Brainstorming tool not final
Don't ban it
Researching interest and need

In making decisions under conditions of uncertainty consequences must dominate the probabilities. 

In all instances where there are more unknown variables than know variables your design must be driven by the probable consequences of your decisions. If you can't trace your design forward through time then stop until you can. 

A few tactics that can help you improve your clairvoyance.
 - Ask everyone for advice on how to improve your design based on the defined goals and constraints
 - Find an entity that is analogous to your situation and trace it's path through history. Learn the successes and failures from similar efforts by others.
 - Construct or purchase a predictive model. Take advantage of math's concreteness by plugging your data into established formulae. Judge the results.
 - Consult a psychic. It may and or may not provide insight. Consider this an extension of the first point about asking everyone for advice.

[[_SVA]]
John Maeda shows us how UX has shifted because the prototyping is not UX related. What is being prototyped are models, not experiences. Can we do this is the first answer we need becuase we figure out the experience of it. The people working on models are metaphorically equivalent to engine builders. What's the UX of an engine? What's the UX of a model?
Make me a website for this product
Make me a survey to assess the value and desirability of this product
search the web and give me keywords for top search results
create an image for my youtube's thumbnail showcasing these trends
Give me a list of the most common UX tasks
 - search IxDF/ Coursera/ Reddit/ etc
 - describe what you do on a daily basis
Act like Daniel Kahneman and give me an analysis(?)
Give me a base rate for {x}
Create a designer GPT for ToLoPoSoGo, TEC, Design Thinking
Distilling a decade of experience into the design essentials
Beyond technique: People skills for succeeding as a UX designer
CustomGPT sentiment analysis as a lead generation tool, if the sentiment is correct then drive them to book a call
[[Build a circle of mentors with six people.]] You study compass holders. You're looking for successful behaviors in relevant situations to emulate. Compass holders are beacons that call you forward.
Complicated data reaching out to the internet for the complicated things. Maybe you want a fine-tuned Llama.

https://www.linkedin.com/in/bradley-surkamer-13973774/
https://www.linkedin.com/in/kevinferguson1/
https://www.linkedin.com/in/chernst/
https://www.linkedin.com/in/aafricawala/

7B data points being multiplied over and over and over again. 7B takes 7x4 GB memory. 70x4 is 280GB memory.

Mixture of Experts (MoE) use a lot of memory too, mixtral 7bx8 use 40GB of RAM in my laptop even when it is 7b, but it runs faster even on cpu

Pick an expert part is mixture of experts methodology. One big model delegating to smaller models.

24GB for NVidia, H100 is 10+k
RTX4090 only has 30GB of memory.
Mac can run bigger models because of unified memory.

Ollama and Ollama webUI. Ollama is just the storage. You still need a RAG implementation. NVidia has Chat w/RTX. AnythingLLM point to Ollama for RAG.

You'll need to train a model or wrap it with guardrails if you want the model the behavior differently than it currently does. Like don't talk politics or religion.


It has been known since the advent of weaponized aircrafts that during warfare the side which controls the skies has the advantage. It has also been known for a while that the first predators of humankind were large birds of prey. If you get a chill whenever a shadow passes overhead then you can thank your evolved neurology. The high ground as the upper hand is common knowledge. 

Given the extreme susceptibility to harm humans have from anything coming from above you’d think we’d be more concerned with looking up. Instead, being the eyeballs in the front of the head creatures we are, we are focused the most on what is in front of us. It makes sense, you can’t look in all directions at once.

Looking up is a competitive advantage. Up is a dimension few people consider yet it contains the potential for impact greater than any other dimension. It might not make sense in the world of metaphor and analogy to look up but in the world of physics it does. What you pay attention to alters how you navigate life. Pay attention to what others won’t and you see things others can’t.

Point of fact. If you ever want to win a game of hide and seek, find a spot that is up.

[[_SVA]]
Roboflow, tools for computer vision developers
Roboflow has stuff for plant health
Can help you learn how to train models without learning code
Good for students
roboflow.com/opencv
Transformer based architecture has proved beneficial across task types.
CLIP + VQGAN architecture predates Stable Diffusion and most other diffusion models.
Focus on data that is out of distribution.
Vision inputs have traditionally been camera based but in occluded environments like fog these cameras are insufficient. Shift to incorporating thermal cameras, polarized cameras, event(?) cameras, and depth inputs.
  
Splats use historical inputs and fill in the blanks with generative AI.
Regulations to force forgetting, maybe after 3 years of storage. Search was limited by regulations to avoid forever memory.
Splat results are compressed into a neural network.
If I get this level of quality then do this.
Execution engine to check quality steps and write to production systems.
How do I know which generation is best for my context, then you have this validation engine.
We may be moving too fast and will have a lot of false starts in 2024 especially as it relates to interacting with the physical world.
$200 subscription in Tesla per month for 8 hours of full-cell driving.
[[Artistic control is still missing from generative visual AI for it to usurp traditional methods.]]
[[Cost of hosting Llama is not less than ChatGPT.]]
Meta might be open sourcing their tech to prevent vendor lock for people using OpenAI. Meta could change to closed-sourcing on a dime, which would monetarily bone everyone using their tech.
EU AI Act Cheat sheet by Oliver Patel
Regulate the use, not the tech. Regulate the outcomes not the process.
#ux #ai 


What benefit can we draw from adopting a stereotype? Stereotypes are expectations. The stereotype is a shared understanding. When you know the stereotype you fall under then you gain the advantage. You immediately understand the shared expectations. You know the stereotype. You know the rules. You can see yourself through a communal lens.

Of course stereotypes have a negative value. They lend to false and often threatening assumptions and you are assigned a stereotype. These rules are forced upon you. These expectations indeterminate of your being.

Consider instead adopting a stereotype. Pick your favorite one. One that gives you the most of what you currently feel you lack. You can pick one that gives you less of what you’re gaining if what you’re gaining isn’t what you wanted. You’re adopting a role. Playing a part. I suppose this thinking can lead to mocking if you adopt a stereotype as a form of denigration.

What can you gain from playing into expectations that force people to see you in a different stereotype? Choose the stereotype you want to be known as and act accordingly.

[[_SVA]]
Working agreement
 - what do you want approval over?
 - Feedback, how to give, get, and when
 - How do you want your project to go?
 - Non-negotiables?
	 - absence forfeits your rights
	 - no work-for-hire, license or buy-out
payment for Sprints, 50% to start
35% after first review, 15% to close


Start with project goals and success measures
Require content in advance.
Set and remind deadlines
Make consequences matter
 - what happens when deadlines aren't met
	 - if you miss deadline we get to make the decision
	 - if you miss the deadline we cancel the project
Backup the project

Written approval
Don't revisit approved work
Send invoices at best moments
Keep track of revisions on closed work as future work
Two revisions tends to be the sweet spot

Begin on the designated start date not before, includes communication
5% increase in time and cost to cover surprises - contingency fee

Call out favors
Creating tension requires you to see the other person as stuck in a state which is not beneficial, does not generate value, maybe generates negative value, and could be harmful. This person is blind to what you have to bring. What you have to bring removes them from the non-beneficial state into the utopia you provide. If only they would move. Tension is the force to get them to move. You genuinely want these people to experience the better you are providing. You need to make them tense enough that they seek resolution in what you're offering. Hacking this for a quick dollar corrodes your integrity and makes it harder to succeed multiple times. Bring your generosity to your people and show them a reason to be uncomfortable with their current state.
#ux #ai 

From that online Meetup.

Do not try to replace your user
- the operator needs to know what the AI is doing
- being held accountable for the results of AI
Understand the problem, clarify the scenario
- we help you with capacity planning, issues with queries
Do not forget a feedback loop
- model may drift
AI is all about context
- How do you know the user needs?
- [[Do not have the AI guess what the user already knows.]]
UX for AI is not well defined
- reverse engineering problem with AI code, why did the AI write the code the way it did?
- what makes this code good code for my situation and task?
- [[AI "here's what I'm going to do, are you good with this?"]]
Start small
- before adding your AI feature, build your data foundation
[[Don't build a single model to solve them all, have multiple AIs.]]
In the beginning there is joy, elation, surprise. Then routine sets in. Habits form. Dull and drab become the colors we use to paint the world around us. Discontent overtakes joy. Grey. Everything is grey.

Get weird with it. Too often we wait for new to happen to us. What if we create it instead? Maybe not new to everyone but new to us. You have permission. Go!

[[_SVA]]
Here are a few questions to help you make better decisions.
 - Have I done this before? If so, what has changed since last time? How likely are those changes to affect the outcome?
 - Who has done something similar? How likely is it my results will mirror theirs?
 - Given everything I know I don’t know and everything I don’t know I don’t know, how afraid am I that I am wrong?
 - What can I do to prove myself incompetent to make this decision?

Decisions are about balancing need, risk, and benefit in an uncertain environment. Improving decisions means improving the accuracy of your prediction model. The more you can uncover the factors at play and decrease the likelihood of them changing the more likely your predictions will be accurate.

[[_SVA]]
There's a general hierarchy to design and it goes; make it work then make it look good. Or, in design vernacular, make it useful and usable before you make it beautiful. This is a fair stance to take. It is sensible and logical. Nobody wants a beautiful brick when they ask for a tea kettle.

This stance does not acknowledge that when your audience experiences your design they experience it from the outside in. They see beauty and form first. Those imply use. Aesthetics signal affordances. This is a basic postulate of perception. Considering this it is wise to stop positioning aesthetics as the undeserving bastard child of your product conception. Aesthetics is not a second-class citizen. Aesthetics is the ambassador to your product experience.

If adding functionality disrupts the overall design aesthetic you're compromising your user's experience so stop it.
#ux #ai 


The endpoints are always more clearly defined than the space between. One point is here and now, the other is there and then. You’ll know the endpoints because it’s how you operate. You imagine a change and seek to make that change happen. You’re rarely unclear on the change and rarely clear how to get there. This is by design. If the pathways were known it would limit the endpoints. You would only be able to do what you already knew how to do. You could only go places you’d already been.

You’re not like that.

You have dreams and desires, aspirations and future expectations. You define the destination then set about the difficult task of getting there.

The space between is where you show what makes you you.

Get comfortable in the in-between. It’s where all the good stuff is.

[[_SVA]]
[[Build a circle of mentors with six people.]] Connectors are the people you see who like to introduce people they know to other people they know. Connectors get a thrill out of finding commonalities and then bringing those in common together. They generally have a wide social network though it's not a requirement. The best way to meet them is to show up where you think they'll be and show up with something in common.
https://www.youtube.com/watch?v=PaCmpygFfXo

Links: - makemore on github: [https://github.com/karpathy/makemore](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbFh5QWN1dExpWWpQcWVqaURYZjNwdHpuREQ1UXxBQ3Jtc0tsSUk5QXZSVWZSSGcyYkxZUmszXzlqdlY2MWI1X1hHYUpObjlBYnpVVVM2cEdSUXdDS0xjbnpqeUdqQkU0dEE5eEhURW9EMmVzekNlTV9wblpmT2dnWkc3Q2xobHdRWVN5NHAyZHpmMjBzMTZqRkxHNA&q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fmakemore&v=PaCmpygFfXo) - jupyter notebook I built in this video: [https://github.com/karpathy/nn-zero-t...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbmVKODI0R0RqOXA1Uy10dDJ3OWUzRjZMbXZVZ3xBQ3Jtc0tsWlNkbDJkLXY3M1Q1NzBJRmJrR1BJemZqZG1HRFFZVHdoNEtwdk1NNHBDOUpWUFJCSlg3dVNUQXJQOHVPaTYwei1xZjk4RXA3cGstSFFGWGZVUzdINnlhUGliUVI3b3F3cXVfZmc1bGtrclF0M2JoRQ&q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fnn-zero-to-hero%2Fblob%2Fmaster%2Flectures%2Fmakemore%2Fmakemore_part1_bigrams.ipynb&v=PaCmpygFfXo) - my website: [https://karpathy.ai](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbHZ4QmlUUHJBMFA1Y0REU0wyQ044emtiV3JrUXxBQ3Jtc0trZmtaeUVYOWlaaUVNclNfQ0UxdWN3X0xfU2otSUJhdWxMQ095bFhudFZjRkNYV3FxaHVaY3BndWdEdHVYX1dkaHRfdE9QdWNiWkJzU01vSFJjMkxta1VXbHZaMU91cnhnSzdmeVJhcm9kOVNucDNxcw&q=https%3A%2F%2Fkarpathy.ai%2F&v=PaCmpygFfXo) - my twitter:   [![](https://www.gstatic.com/youtube/img/watch/social_media/twitter_1x_v2.png) / karpathy](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbkQwWDlPd0lwMldOV0pfeFFHWUF0dllCQkE4d3xBQ3Jtc0trY2R1bl9faHVSMWMxR0JQX3Q1VDVuVXo2ZDFfU3dMakpxQ0JCWllqOFJnaVZ2ejNPZjFqUHFyUTR6UzZPcTBDNVFNTEp2TDZyT3ZObjdmc3BuSS1pckNFLVJDaXNHc0VSYTU0Z2pKb0JCajAzS3kzcw&q=https%3A%2F%2Ftwitter.com%2Fkarpathy&v=PaCmpygFfXo)   - (new) Neural Networks: Zero to Hero series Discord channel:   [![](https://www.gstatic.com/youtube/img/watch/social_media/discord_1x.png) / discord](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqblZOV241ZWtySE96VDBoSU5mMmZOTGYyUVlUd3xBQ3Jtc0tsR1BNVWowVDJOd0RYZksxQlBoZ3lTa3FkWGpYRk84YjBnVi1kck1uTlFkYjNkRWdJUVQzcmY4ZXZRNVJKa2ZvMTMxNzdYZ3ZoUnltLXA1aERwc3lxRWZBSkUwdjhhd0RvOE8xVmJFcFZMbkx2X3VPbw&q=https%3A%2F%2Fdiscord.gg%2F3zy8kqD9Cp&v=PaCmpygFfXo)   , for people who'd like to chat more and go beyond youtube comments

Useful links for practice: - Python + Numpy tutorial from CS231n [https://cs231n.github.io/python-numpy...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbEtOMXJEUUV0V1gyZkh5UlEzY1NNMlV4STMtQXxBQ3Jtc0trenJ4Unp4enQxakUwcXBoaGx5aUlNUXRnWnZRalV3R3dmZ0kyY2pjMUlWcVh1MmtYaVRSaU5mdVhNR2l2TExyeEd4RTIyQVkyOGVkd0M2Z3lYZFh2cDF1bGJfRDJWSzNUWng2S3ZVX1J4aURkTXUxWQ&q=https%3A%2F%2Fcs231n.github.io%2Fpython-numpy-tutorial%2F&v=PaCmpygFfXo) . We use torch.tensor instead of numpy.array in this video. Their design (e.g. broadcasting, data types, etc.) is so similar that practicing one is basically practicing the other, just be careful with some of the APIs - how various functions are named, what arguments they take, etc. - these details can vary. - PyTorch tutorial on Tensor [https://pytorch.org/tutorials/beginne...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbW55ZG9yOFB5eFR6R0FPNXhqaERoQk1LU1lQZ3xBQ3Jtc0trQXlwdHNDeEtfWnpCampScC1nMjFLVlNudlpVOWxwcWNTVXhqaFZGQWRKM25PMzhaWmpjQmNjWUVuQTFNQUk1c21zRkVwOGxWY0JhbWo3UDVJdGVpRXlUbW1xZExsTVRBYXZJdllUMFFCal9faTJkVQ&q=https%3A%2F%2Fpytorch.org%2Ftutorials%2Fbeginner%2Fbasics%2Ftensorqs_tutorial.html&v=PaCmpygFfXo) - Another PyTorch intro to Tensor [https://pytorch.org/tutorials/beginne...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbUFtR3d1akdpZ2RTS2VkN3E1SlJHVUxROWF6QXxBQ3Jtc0ttUTAzaVBhYlNtamJnMnltdGdQcmRsaWxUZ0FxY3FEem1QaThpc1ZtVUQ0bnhtZXBidjRGV0ktSDRMbHJCMThxSUNNd1RuZ05oc193Z3pxNU80YThwUU4xN2RpTHdLUWp4VVd3QlZBSnROQ2V1cmtGSQ&q=https%3A%2F%2Fpytorch.org%2Ftutorials%2Fbeginner%2Fnlp%2Fpytorch_tutorial.html&v=PaCmpygFfXo) 

E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?
E02: split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?
E03: use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?
E04: we saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?
E05: look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead? 
E06: meta-exercise! Think of a fun/interesting exercise and complete it. 

Will make more that are alike, i.e. Baby names.
A sequence of characters

NLP uses <> brackets to denote special tokens.

Take them through a softmax, normalize, then gradiate the learning.

For the latter parts of the series
https://www.youtube.com/@AndrejKarpathy/videos

My file
https://www.kaggle.com/code/ntoned/makemore-project
Still not able to build applications on top of multimodal models.
F Jazz Blues
| F9//// | Bb7//// | F9//// | F9//F7#9// | Bb7//// | Bbdim//// | F9//Eb9// | D7#9//// | Gm7//// | C7//// | F9//D7#9// | Gm7//C7// |

Scales
F7 : F blues (country)
F7 : F7 bebop, F mix
Bb7 : Fm blues (gospel), Bb mix, Bb7 bebop
D7#9: Fm blues, F7 bebop, G harm min
Gm7/C7: G dorian, C7 bebop

Theory
Tritones on Dom7 because of guide tones
D7 = V7 of ii (Gm)
D7 in key of F is secondary dominant
V7alt = V7#9, V7b9, V7#5, V7b5, et al

Practice
Aural (10 mins)
  - Sing up to La and back
  - Sing thirds up to La and back
Shapes (25 mins)
 - F Major
 - F7 Bebop
 - F Major Pent
 - F Minor Pent
 - F Major Blues
 - F Minor Blues
Bebop (25 mins)
 - Flex 1: 1,1-2,1-3,1-4,1-5,1
 - Flex 2: Alternating 1, 3, 5
 - Flex 2b: 1-2,3-4,5-6
 - Flex 3: Climb the scale down to 5 (say the notes)
 - Flex #4: alternate start from 9 down to root, start from 9 up to three
 - 3 to 3
 - 5 to 5
 - b7 to b7
 - Start on 9
 - Start on 9 chromatically down to root
 - Start on 4
 - Start on 6
 - 2 up to 3 chromatically (the major blues/mixolydian)
 - Bebop lick
 - Bebop lick up 2
 - Bebop lick up 3
 - Bebop lick up 4
 - Bebop lick up 5
Pieces (25 mins)
 - Etude 1 (in position)
 - Etude 2 (in position)
 - Groove blues (in position)
 - Country blues n’ bebop
 - Walk the bass
 **- All the things you are**
 - Straight no chaser
 - White Christmas
[[For interviewing to be fair and effective it needs to tolerate culture, discomfort, and biases.]]Biases sway decisions long before you become aware a decision needs to be made. Biases are formed when we compare a new experience to a previous one. These create grooves in your brain patterns. Grooves are desirable because they are a path towards effortless. Descriptive bias is picture matching. In something new you only see what you've seen before. Skepticism about your intuitions is healthy. The person you need to be most skeptical about is yourself. You need to be curious to see beyond your first impression. Dig deep and talk about past behaviors and growth. Diversity doesn't mean compromising on quality. Bias shifts standards leading to you being tough on one person and soft on another. Remember, 'fit' is not the point.
[https://meetu.ps/e/MMn4n/6gTv8/i](https://meetu.ps/e/MMn4n/6gTv8/i)

Channel for posted recording
https://www.youtube.com/channel/UCp7pR7BJNnRueEuLSau0TzA

Generative models learn the data distribution in their data set. the 1940s gave rise to the dream of AI. 1960s gave us deep learning. 1970s gave us neural networks. 1980s got backpropagation.
1990 is LSTM. 2000s gave us GANs. 2010s gave us transformers. 2020s is the OpenAI decade.

OpenAI was founded in 2015.

Contrastive language image pretraining CLIP
Language is a remarkable phenomena. Sounds strung together to communicate electrical pulses in our brain. Language has added immense nuance to human communication and has enabled a lot of humanity’s progress. While it may be true that it’s not what you said but how you said there can be no denying that what you said matters. Imagine someone screaming positive sentiments at you or crying while professing love. You’ll experience a fair amount of cognitive dissonance as a result and you won’t have confidence in your ability to respond appropriately.

Given that language is important for aligning on understanding what might be the language of design? What are the words designers can use to make sure they are talking about the same thing? Does design even have a language?

Jargon and lingo are variations on this idea that I won’t talk about right now. Design has core ideas such as audience, constraints, context, culture, semantics, logic, emotions, decisions, value, benefit, outcomes, need, use, and aesthetic. This is the language of design. These aren’t foreign ideas or made up terms. These words aren’t unique to design but they are at the center of the practice of design. Listen for how often you use these words and then use them more. Encourage others to use them. If you want to be a good designer learn this language. Language matters.

[[_SVA]]
#ux #ai 

https://www.ericsson.com/en/ai/ux-design-in-ai

Four main components of trust are competence, benevolence, integrity, and charisma. An AI solution needs to consider them all.

Heuristics
Make sure the AI solves an actual need. Make the AI explainable. Show evidence the AI is learning. Give a way to trial an AI. Keep the user in control. Make the system adapt to explicit and implicit feedback. Set appropriate expectations. Be transparent with data storage, collection, and handling. Give the AI an appeal to be understandable.
Good. Quit trying to rationalize it and just accept it. Whatever it is doesn’t owe you sense. Your insecurities about rational thought are your problem. The ideas which form the foundation of our existence didn’t make sense when they were proposed. Not to the people who didn’t allow them the opportunity to make sense.

Mental friction is uncomfortable. I get it. Comporting your mental state with non-sensical ideas sucks. You’ve got willpower. You can avoid that discomfort but don’t drag anyone else or the idea along with you. We need ideas that don’t make sense. Logic is the slowest, clumsiest, and most energy intensive way of progressing. It’s the safest so we default to it. It may seem paradoxical that in order for new ideas to make sense they have to be accepted as non-sensical. You don’t change the idea, you let the idea change you. Or you don’t. That’s on you.

The next time you come across something that doesn’t make sense just let it.

[[_SVA]]
#ux #ai 

Nothing for us without us.
#ai #ux

https://5754110.fs1.hubspotusercontent-na1.net/hubfs/5754110/CG%20_%20How%20to%20Build%20Your%20Computer%20Vision%20System.pdf

https://5754110.fs1.hubspotusercontent-na1.net/hubfs/5754110/2_27%20Capgemini%20AI%20Dev%20Day.pdf

https://www.linkedin.com/posts/capgemini-aie-sf_aideveloperday-computervision-largevisualmodels-activity-7170873906818396160-bUoL

Roboflow, tools for computer vision developers
Roboflow has stuff for plant health
Can help you learn how to train models without learning code
Good for students
roboflow.com/opencv
[[OpenCV predicts 2024 as another great year for open source.]]


A team would survey power lines and power towers. Then classify each image. Now you've got a drone.

Inspection time reduction
Accuracy Increase
Visible and thermal camera to look at heat signatures.
Vigilance
This is how we got Amazon Go.

Quinn Killough
Manufacturing
SAM
SegGPT
DINO v2
GPT-4(Vision)
LVM and visual prompting

What's the weird thing to do with this?
What doesn't make sense to use this tech for?

Defect detection, image classification, scene analysis, assembly verification, object location & guidance, counting/sorting are all identified use cases, retail store shelf analysis. How many times you look at the Zoom camera vs looking elsewhere. Detecting boats in satellite images.

Mise en pla, making sure the right things are in the right spot.
Is it organized? Marie Kondo method.

Domain LVM understands the space and can use unlabeled image data. Used to train downstream models but is not the one you use. Created bottom up instead of default to refined. Can be used to generate synthetic data.

HIPPA for imagery in medical field. Synthetic data is a stopgap solution. Synthetic data is also a great way to make money.

Base subscription and cloud usage determine the price. Large models are handled financially separately.

Can you take it with you? Yes.

100k unlabeled images to train LVM.

Is it mold?

Dillon Laird
Scope -> Collect -> Train -> Deploy -> Collect -> Train -> Deploy loop.
Classification, object detection, and semantic segmentation are project types.
Will an 80% accuracy model work? How many sigmas do you need?

Image classification maybe not great for picking out scratches on an advil pill. Object detection is a tight box and might be a better model. Semantic segmentation is the most information.

Image classification needs a lot of images and labeling in easy. Object detection takes fewer images but the labeling effort is high. Semantic segmentation requires the least images but the labeling is the highest.

If a human can only identify an object 80% of the time the computer vision model likely won't exceed that. Be sure the give the humans and the computer the same images. I would feel the scratch to see if it is deep before discarding it.

Some pills may be scratched, some chipped, and some poked with a needle. This is high variability. You need to simulate or provide images on the various contexts the image will be present in.

Standardized lighting and image capture process reduces variability and thus problem difficulty.

Do you have enough data samples for your sigmas? Maybe your current defect count is 60% and you know this can get you to 80%.

If you can reduce it to a 3D tensor we can work with that otherwise you only have access to RGB.

If you give labeling software mixed results they won't get it right that often. Do we label paths in the parking lot as roads or no?

More important than hyperparameters is the data you give the model. Iterate on data as the primary mechanism for model improvement. Evaluate models on a fixed data set. Deploy early to figure out the performance and deploy in shadow mode to minimize the impact of the deployment.

Default augmentations like changing the orientation, flipping the image, rotating it, changing the lighting is a way to give you cheap synthetic data.

Andrej Karpathy talks about Tesla production AI iteration on edge case data.

36 megapixel max then the image gets sized down.

Consistent separate hold outet. Add no class.
 
Anchor free detection. Semi-supervised learning.

You'll get a good breakdown of LandingAI and how it works in their community.
https://community.landing.ai/c/landinglens-fundamentals
LoRA is the method developed and used by Stable Diffusion. LoRA is Low-Rank Adaptations. 

#LoRA 

```query
tag:LoRA
```

#ux #ai 

[[Build a circle of mentors with six people.]] If you've ever thought about paying someone to watch you work for a day and suggest effeciencies for your workflow then you know what an optimizer is. Sometimes we are trying too hard and going nowhere. Optimizers will point that out and help you move from it.
This is what keeps it fast.

#LoRA 
Everything will decay. Ruin is inevitable. Immortality is a curse. The end is part of the design yet it is rarely considered. There’s also a tremendous negative value to the idea of the end. Fear dictates that we keep what we have regardless of its continued worth or benefit to us. For that reason we accumulate much more readily than we discard. Certain physical objects are designed to decay specifically to promote the cycle of repurchase. This is called designed obsolescence and it has virtue thought not always.

What I mean here by designing ruin is a similar practice. The near term is only one of many timeframes to design for. It is likely that your design will outlast your involvement so the mid, far, and eternal terms need consideration. Designing ruin is focusing on the latter. Consider how the design will wear, break down, and be repaired. Give your designs a life and a death. Design by the human hand is control over the process. Don’t leave the end to chance.

[[_SVA]]
No story of design starts with now. Now is not a destination. Now is alive with potential but stagnant with change. Design is a means to realize what can be. This means that you have to start with where you want to go and end with where you are. Design fills the space between.

This isn’t revelatory. The operating model for human motion is reaching a destination. We’re all driven towards something other than what we have. The trick is to develop an awareness of the insignificance of where you are compared to where you want to go. The driving question of design is not ‘how do we get there from here’ it is instead ‘how do we get here from there?’

[[_SVA]]
#marketing
In some sense the entirety of design exists to satisfy our own and other people’s values. In fact, it’d be difficult to argue against the idea that all action, all motion, all human effort exists to satisfy our own and other people’s values. What makes anybody do anything? Even the act of acting has value. Kinesthetic pleasure is pleasure. The notion that design creates value is somewhat of a moot revelation but worth being reminded of at points. It’s possible the manner in which design satisfies our values is novel to design. If you find yourself looking at the biggest picture you might see that everything is design. 

The important takeaway from this is that design exists to serve value so start there.

[[_SVA]]
In certain cultures, outside the box is a valuable place to think. Paradoxically, outside the norm is rarely a valued place to live. People…*shakes head*

Thinking outside the box can’t happen without the box. Aristotle revealed to us that we naturally create boxes. Modern nomenclature refers to that as classification or labeling. Like and dislike are boxes. Up and down are boxes. Beautiful and ugly are boxes. You get the idea.

The mind cannot deal with the infinite. The whole architecture of our mind is there to create form from chaos. Without ‘is’ and ‘is not’ we would blob about until our inevitable demise.

Whether you rail against the box or conform to it you still are reacting to the box. The box gives you freedom to decide, to choose, to act, to be. The box is about as close to a truism as an idea can get. Celebrate the box. The box is not a bad thing.

[[_SVA]]
[[Keywords are words the programming language reserves for their needs, like and/or/if/else.]]

[[Operators tell the computer to perform an action.]]

[[Expressions are strings of arguments like 10/2 + 3 and 2 + 3 * 6.]]

#programming #beginner 
Think of the long view. The thousand-yard stare. You can lift your head up and find longer arcs. You see the arc of seasons, suns, planets, and aeons. You see the arc of the archetypes, the arc of the watchers, the arc of the ink black waters of eternity. If you look back you can see the arc of human intention, human storytelling, the human experience. You desire to know where it’s all going. What’s next? yet it is not for you to know. We must content ourselves with our reactions to the moment. The long dark arc is for none to see save the archetypes, watchers, and mystery inhabitants of the ink dark deep.

[[_SVA]]
#ux #ai 

[[Design for workflows not monoliths.]]
Hero
 [[We know that we value certainty]]
 [[Giving form to vision]]
 [[Deformation professionelle]]
 [[End with the beginning]]
 [[Designing for complexity]]
 [[Beneficial pressure]]
 [[What makes it worthwhile]]
 [[You can't optimize yourself in the moment]]
 [[The arc of human intention]]
 [[Designing better]]
 [[Value in the context of design]]
 [[The toil and reward of critique]]
 [[Literacy and design]]
 [[Style, curation, editing, and MML training are the tools of the GPT world.]]
Sage
 [[Design for feature parity]]
 [[Improving outputs]]
 [[Designing for teams]]
 [[What needs to be true?]]
 [[Making better decisions]]
 [[Rational decisions]]
 [[Explaining design]]
 [[The design of learning]]
 [[Analyzing motivations]]
 [[Designing society]]
 [[Designing for context and outcome]]
 [[Designing for irrational people]]
 [[Design's purpose is predictable change]]
 [[Language matters]]
 [[The space between]]
 [[Designing a worldview]]
 [[Brain architecture]]
 [[Relationships are the final frontier]]
 [[System stress benefits from being designed]]
 [[Design reasoning is abductive]]
 [[Insight comes from odd angles]]
 [[A system design conversation]]
 [[Surviving failure]]
 [[The meaning of design]]
 [[When work is resolved it feels natural]]
 [[The interface is the system]]
 [[Design is meant to trigger your audience]]
 [[Business processes tend toward optimization]]
 [[Acceptance is what we crave in order to belong]]
 [[If you make a point to talk about integrity there's a good chance you've been betrayed in the past.]]
Explorer
 [[Design for the greatest good]]
 [[The environment is a factor]]
 [[Old design]]
 [[Escaping design]]
 [[The freedom of the box]]
 [[Instinctual exploration]]
 [[Designing your future self]]
 [[The thread keeps the story together]]
 [[People are the beginning and end of design]]
Jester
 [[When in doubt talk about pizza]]
 [[You design your behaviors based on your goals]]
 [[Don't hit them where it hurts, hit them where it helps]]
 [[Design for wasted time]]
 [[You may need to bore yourself into climbing the mountain]]
 [['Yes, and' only gets you halfway]]
 [[Boredom is a generative force]]
 [[Design's great paradox]]
 [[Design doesn't have to be serious]]
 [[Playing a stereotype]]
 [[Designing measures]]
 [[More about the space between]]
 [[What happened to all the fun?]]
 [[Play is design]]
 [[Infinite pie]]
 [[The ease of mastery]]
 [[Nobody looks up]]
Outlaw
 [[Die to your self-righteousness]]
 [[Conflicting truths are not a thing]]
 [[Overthrowing a government]]
 [[Designing bad ideas]]
 [[Interruption as a design decision]]
 [[Ineffective design]]
 [[Innocence as a tactic]]
 [[Machiavelli's promise]]
 [[Momentous energy]]
 [[But it doesn't make sense]]
 [[Dealing with disagreement]]
 [[Guilt is a profoundly positive emotion]]
 [[Mistakes and originality]]
 [[The design of ruin]]
 [[The information trap]]
 [[The great deception of design]]
 [[Why is a bad idea]]
 [[Stop wielding your truth as a weapon]]
 [[Input matters less than your process]]
 [[Stop sacrificing aesthetics for functionality]]
 [[Plans are works of fiction]]
 [[Numbes offer a false assurance]]
 [[You can lie with data]]



Operating agreements
LPR industry
AI legal outsourcing
Expensive celebrity talent & humor for the ads
$500/mo for customGPT
Entertainment in the crucible due to WINS, words, images, numbers, sounds.
Give me 5-8 important things to look at for AI each week #money
Self-discover with self-compose reasoning structures may be important
Shorten the time to value
People want to know how to use AI to get money from people.
90mins for $495, get people into a room sharing their actual questions, value prop to CEO, how do I learn top insurance pain points in three minutes? - chatGPT with RAG #money
AWS Tableau is Quicksite, Q is their AI for AWS.
The largest cloud war dwarves dinky LLMs even the 2B ones.
Microsoft generates 2B in cash weekly, without prompt or attention.

Corners present opportunities to discover what is around them. The possibility of seeing what you don’t see propels you forward. The unknown excites you. For reasons ancient and unknowable you seek what can be sought. Not for greed. For the pleasures of the journey. You are an explorer.

Exploration is an act to be highly valued in the field of design. Exploration defines the design space. You’re tracing the edges within which you create. You’re supplying the inputs. You’re refining the model.

Exploration leads us forward. Let yourself be entranced by the unknown. The next corner beckons.

[[_SVA]]
Fear is a known motivator. Fear itself is the six hundred pound guerrilla of the group. Generally fear is an expression of an avoidance of loss. Fear shows up when you imagine yourself losing something of value. Maslow postulates that the needs of shelter, sustenance, and positive social interactions carry the most value. By extension imaging the loss of any one of those needs will induce the greatest fear. Fear is not rational and will motivate us in irrational ways. Behaviors during a frightened state need to be considered in isolation. Let’s be pedantic about it. The behavior is not irrational but contextually rational to a frightened state.

Greed is the growth side of fear. Fear is loss. Greed is gain. Fear drives when it wants. Greed takes over in-between. Greed has a strong negative stigma in many religious-based modern cultures. Greed begins as a selfish desire. Much in the way that fear of individual loss is felt greater than fear of collective loss, so too does greed concern itself to the individual before the collective. Greed can be pointed at a gain for many.

Laziness as a motivator is tied to the conservation of life on the anatomical level. Life energy is abundant but finite. We all die. Living bodies have inherited an understanding of this fact over the course of evolution. Laziness is a built in mechanism for conserving energy and prolonging existence. Laziness is the mechanism that causes you to evaluate a decision on the basis of effort required. All things being equal alternatives requiring the least effort are the ones we choose. Desiring not to extend unnecessary effort is not a character flaw, it is instead a virtue of smart people.

Purposes motivate people. Purposes are an inner state linked to an outer goal. Inner states are drive. Outer results are goals. Emotions are neural memories of body states. Desire to change our inner states produces an inner vision of outer results. The value in that combination gives purpose and once purpose is attained the body acts. The plan is set, execute. Purposes can be conflicting, false, and redefined. Action doesn’t guarantee results. Try and err. The drive continues until the purpose is dissolved or the drive is overcome by another more urgent drive.

Fear, greed, and laziness motivate a change of inner state away from loss of value and energy or towards gain. The change is conceived of internally as an outer result. You’ve now formed an image of your desired state and a plan to move there. Once formed you set about trying to find the least effortful way to get there.

[[_SVA]]
Rubber Ducking AI
Legal Eagle Courtroom drama by AI
 - How do you return the blood?

#ai 
#ux #ai 


#ux #ai 

You share this in common with ## other people.

You are %likely to benefit from {x}.
#ux #ai #ml


Grocery shopping, cooking, driving, pushing text to a blog
It's best not to know you can't do something before you go do it. You'll create your own way and that will be your greatest advantage. Great chess masters lose to beginners because the beginners don't know how to play the game. The chess masters never see them coming.

[[_SVA]]
All creative solutions must be logical in hindsight. Of course we were going to end up here. The general sentiment is one of obvious resolution. That's not the process to create the solution. That part is unnatural, meandering, manic, and frightful. You need the faith that the resolution will come but don't think you can avoid the discomfort. It's the reward that makes the effort worthwile.
[[Build a circle of mentors with six people.]] Yoda is good at what you are not. The thinking isn't above you. Yoda may be an equal in an area of your weakness.
#ux #ai 

[Nadia Piet](https://www.linkedin.com/in/ACoAAAgsQl8B9ZOTT6tUAzqeR_udMdUGlr-K1AY)  
https://aixdesign.co/toolkit
https://raindrop.io/aixdesign/a-ix-design-library-18077843/theme=light&sort=-created

UX of AI challenges
Trust & transparency
Autonomy & control
Value alignment
#ux #ai 

https://www.microsoft.com/en-us/ai/responsible-ai

Is a guide from 2022 that talks about how Microsoft will evaluate their AI systems.


Your pedantic semantics of challenge people over users is painfully idiotic. The idea of current users and future users has value
Obviously. Everything benefits from being designed. Well, everything that has been designed benefits the people and situations for which it was designed. What was excluded from consideration may gain benefit from design or it may not. System stress is certainly something we cannot let happen by accident. All systems contain stress points. These occur only within the confines of the system. System’s are isolated ecologies. Any stress will result from the design, intentionally or not. Since stress will happen it’s better for designers to work with it up front. If you wait to deal with stress when it emerges you may have to make drastic changes to your design to accommodate the effects of the stress.

An example, however basic and archaic, is a keystone in an arch. Physics prevents us from creating an arch without some manner of keystone, even a conceptual one. The arch contains stress from gravity. The keystone distributes that stress. Buckminster Fuller created a geodesic dome based on the principles of stress distributions. He designed a system that understood how to handle the stress it would encounter and generate. He intentionally designed, or discovered, the stress points of the geodesic dome system.

Consider the systems you’ve built for yourself. Perhaps you have a routine you’ve designed. If you’ve ever encounter a moment where it’s burdensome to complete your routine then you’ve encountered system stress. Perhaps you adapted your routine accordingly. Maybe you pulled some elements out, rearranged others, or abandoned your routine entirely. If you have then you’re designing. I postulate you would receive more benefit from your routine if you had accommodated for the stresses earlier in your design process. Perhaps you couldn’t because attention is limited and humans can’t consider the infinite factors which contribute to the current moment. That’s fine but now you know and you can use that knowledge going forward.

Give yourself some slack. You may find you’ll have a better life because of it.

[[_SVA]]
#ux #ai 

https://www.ibm.com/design/ai/
https://www.ibm.com/design/ai/ethics/everyday-ethics

Designers must account for a system that can understand, reason, learn, and interact. IBM states the value of design is to improve lives and leave the world better than we found it.

AI has four characteristics: it understands context through structured and unstructured data, it makes considered arguments, AI is trained and not programmed, AI interactions are natural and unobtrusive.

AI NEEDS context, which in IBM's way is defined as the holistic view of a complete human experience, including emotional, physical, system, and domain knowledge.

Insights in what AI gets us. There is still a need to solve for users and not be constrained by technical capabilities or requirements.

Guidelines
 - Establish a fully-realized AI profile shared between the system and user.
 - Deliver multi-step context-aware interactions.
 - [[Display provable authenticity of the system's interactions.]]
 - Establish the system's tone, personality, and presence.
These guidelines are based on Mark Knapp's relationship model considering only the first phases of Initiating through Bonding.

AI Essentials framework for building an AI:
 - Intent: Align on the business and user intent(s) for your solution.
 - Data: Document the data you could use to make your idea a reality.
 - Understanding: Determine what you will need to teach your AI.
 - Reasoning: Bring your ideas down to earth.
 - Knowledge: Brainstorm the direct and indirect effects of your AI.

AI is capable of achieving higher quality outcomes faster than humanly possible. AI is expected to aid our pursuit of knowledge and improve the human condition.

Common AI use cases.
 - Accelerate research and discovery
 - Enrich your interactions
 - Anticipate and preempt disruptions
 - Recommend with confidence
 - Scale expertise and learning
 - Detect liabilities and mitigate risk
Generally looking for patterns in heaps of data.

AI works either through an algorithm or mathematically sequenced events or AI works through a model ala machine learning. Models are helpful when specifying rigid rules in hard or abundant e.g. stock trading, identifying cancer, predicting preferences, etc.

Machine learning has three general subcategories: supervised, unsupervised, and reinforcement. Supervised learning requires examples for accuracy. Unsupervised learning is good for finding hidden connections in oceans of data. 

The ingredients of a reinforcement learning problem are: 
 - an agent, 
 - its environment, 
 - a way for the agent to interact with its environment, and 
 - a way for the agent to get feedback on its actions within the environment (called a reward function or feedback function).

ML can detect patterns of abandonment in your product and classify a user as at risk of leaving.

You data needs to be of representative sample size. Your data needs to be as free of missing and incomplete information as possible. Related data sources need to be consolidated in the same location. Your data needs to be consistent and offer up as few conflicts as possible. Don't conflate correlation and causation. Consider the famous ice cream sales and murder rate correlation where the missing variable was temperature.

ML is always, by construction, a form of statistical discrimination. It cannot function without bias.

A note of caveat: [[Imperceptible AI is not ethical AI.]]
https://www.ethicscanvas.org/
https://standards.ieee.org/initiatives/autonomous-intelligence-systems/
https://www.ibm.com/design/research/

IBM sees 5 main focus areas for designers and AI.
 - Accountability is on everyone for considering the AI's impact in the world. You must know the policies governing your AI.
 - Align your AI with the norms and values of your audience. I add culture. Your AI learns and needs to align on the values as well.
 - Explainability is providing detail from the AI about its decision process.
 - Fairness means ongoing research and data collection which is representative of a diverse population. 
 - User Data Rights is radical transparency into what data, when, how and how to turn it off.

IBM embraces five pillars of AI.
 - Explainability
 - Fairness
 - Robustness
 - Transparency
 - Privacy
Design is a feature of humanity’s ability to project. It’s a meta act similar to orchestration. What design allows us to do is be proactive. We know humans continually seek to change their state and status. Design is what allows us to do that. Well, design is the name we’ve attached to the activity. The way of the universe is what allows us to do that.

Your actions are what produce outcomes. Design guides your actions. Design puts elements together. When they line up in our mind we execute.

You can design on the fly. In some sense design is always momentary. The more traditional view of design is as a precursor, completed before action is taken. Insecurities drive the traditional view. We refuse to handle chaos. We’re biologically built to create meaning from chaos but that act is energy intensive so we avoid it. We avoid paying attention to the thought. We’re always creating meaning from chaos. We can’t avoid it but we can refuse to consciously acknowledge that fact.

With design, we’re continually imagining the outcomes of our actions. How do the actions build on each other? I do this then this will happen and because this happened then I do this. Or you can come at it backwards. I need this to happen so I will do this which needs this to happen so I will do this.

You’re tracing a path through anticipated consequences to realize the change you seek. You can consider design as forethought but it’s not just thinking about the chain of causation, it is actively manipulating the elements until the end of the chain gets you what you want.

Design is uncomfortably human but that means everyone does it. Every person seeks change. Design is how we’re able to achieve it.

[[_SVA]]

Rendition(TM) will make code from a Figam file -> Feed Rendition code -> AI summarizes code -> AI guesses which component to use -> AI rewrites the code
#ux #ai 


#ux #ai 

https://pair.withgoogle.com
Ho!, man. So much to go through. 
Would take 7 days to go through at 2 a day.

https://pair.withgoogle.com/guidebook/
Legitimately more than you can hold in working memory. Not you, you savant, but you, like me, standard in memory.

Challenges are getting started
  - aim for using AI to create valuable personalized experience while avoiding using AI because you can as that may lead to poor and lower quality experiences
  - what is our knowledge graph structure that will support this AI feature.
  - aim for setting the right expectations about the AI especially if the AI is used in high stakes situations and avoid overselling the capabilities.
  - aim to explain the benefit and avoid emphasizing the underlying technology
  - Consider false positives, false negatives, and ways to provide a way forward and change the product to accommodate them. False negatives are more impactful on moral than false positives.
  - Be data conscious and partner with a data person.
  - Expect play and experimentation as AI is added to more and more software.
Use cases
 - read mass amounts of text and make it presentable
 - make your images easier to search and organize by people, places, and things
 - create meaningful content from your photo library via an immersive story player
 - tuning out toxic comments aka spot abusive language https://conversationai.github.io/
 - [[A precision x recall matrix can help prioritize AI features and design.]]
Onboarding
 - point out what you get right and that you are getting more right i.e. progressing will lead to more engagement
 - Create a test drive situation, a playground of sorts to test features, like with a toggle.
 - Aim for using familiar concepts and avoid novelty when familiarity is the solution.
 - Slowly give the AI more control the more the user uses it.
Explaining the system
 - Give examples of what the AI might be better at and also where the user might be better to step in
 - Aim to show the model confidence if possible in a way that is easy to interpret and avoid using numbers in ambiguous situations i.e. 'most likely' can be better than '82%.'
 - Aim to explain the AI decisions that impact trust and avoid explaining complex rationale.
 - Explaining the complex is beneficial if pushed to a separate area like during onboarding or as marketing materials or a help center.
 - Provide specific and general output explanations, i.e. 'this plant is most likely poison oak because of YXA features' and 'this app uses color, shape et al to identify plants.'
Responsible dataset building
 - Dig deep into labeler variations as the different ways people describe the same thing offer beneficial data quality insights.
 - Get help from domain experts throughout the development lifecycle.
 - Clean, clear, and declutter your dataset at regular intervals.
 - Co-create the labels with the data labelers when doing supervised learning.
 - Make sure the data you train on is representative of the data you'll get from your users, i.e. people likely won't take professional level photos so don't train on those.
 - Attach dataset meta on authorship ala https://sites.research.google/datacardsplaybook/
Trust
 - At all times communicate what data is being collected, how it is being used, and how to turn it off.
 - Bolster responses with third-party confirmation, citations, and/or social proof.
 - Allow users to provide feedback through roman voting, hiding, flagging, and standard communication channels.
 - Aim to reveal and allow approval for options and avoid automating too much too fast without proper undos or decision trees.
 - Automate more when the risk is low or failure tolerance is high or both.
 - When the AI fails prove context, next steps, and actionable links to the user.
Feedback
 - Always tell people what information you need from them, what you are going to do with it, and what they get out of it.
 - Implicit feedback are logging data like time of day usage and the number of accept or reject recommendations.
 - Explicit feedback is audience commentary and must be aligned with ways the model can be improved.
 - Communicate specifically how the feedback will change their individual experience.
Control
 - control over your data at all times
 - you need to allow people to adapt their outputs, edit the experience, and even turn the AI off
 - [[People want control when they enjoy what they do, feel personally responsible for the outcome, are in a high-stakes situation, or find it difficult to communicate preference.]]
Automation balance
 - People will give up control when they are unable or the task is unpleasant or unsafe.
 - A framework to determine what to automate: https://ieeexplore.ieee.org/abstract/document/844354
Support for failure AKA Error handling 
 - Defining "errors" and "failures", identifying their sources whether user, system, or context ala breakfast at night and providing ways forward.
 - Inform the user the system improves over time. Failure now is not failure forever.
 - Context errors often present as true positives. Failstates often present as true negatives.
 - Look for errors the user doesn't perceive.
 - Make failure safe, boring, and a natural part of the product.
 - Avoid making dangerous failures interesting or over-explaining your system vulnerabilities.
 - Be cautious of compounding errors from other ML models.
Data ethics, governance, and other matters
 - source responsibly
 - prepare and document your data
 - design for labelers and labeling
 - make your data high-quality from the get
 - The most important data considerations for quality are predictive power, relevance, fairness, privacy, and security.
 - Google's call to responsible AI: https://ai.google/responsibility/responsible-ai-practices/
	 - Be human-centered
	 - Have training and monitoring metrics
	 - Directly examine your raw data
	 - Understand the limitations
	 - Test
	 - Update and refine

Value of AI summarization. Get everything I need in a small space.

[[Good research questions to improve an AI.]]

Material rewards, symbolic rewards, personal utility, altruism, and intrinsic motivators needs to be considered when receiving feedback. -_-

Heuristics, called responses by the guidebook:
Allow for opting out.
Allow users to give guidance or correct the data or label, which feeds back into the model to improve the dataset or alert the team to the need for additional training data.
Communicate what the system is supposed to do and how it works. Then, explain what it’s missing or its limitations.
Allow users to give feedback about the needs that the system isn’t meeting.
Check the user’s input versus a range of “expected” answers to see if they intended one of those inputs. For example, “Did you mean to search for XYZ?”
Implement AI in ways that don’t break habituation, such as by designating a specific area of the interface for less-predictable AI output. Or, allow users to revert to, choose, or retrain a specific interaction pattern. See more suggestions in [this article](https://design.google/library/predictably-smart/) on habituation from the Google Design blog.
Explain how the system matches inputs to outputs and allow the user to correct the system through feedback.
Explain why a certain result couldn’t be given and provide alternative paths forward. For example, “There’s not enough data to predict prices for flights to Paris next year. Try checking again in a month”.
Allow the user to provide feedback to improve the system’s function.
Explain the multiple systems that are connected, and allow the user to determine priority. Consider visual ways to represent the relationship between multiple AI systems in the product interface, perhaps by mapping them onto different locations.
Allow the user to set independent controls for your AI that don’t overlap with other signals. For example, the watch word for a smart speaker to start listening could be unique. If your team can avoid creating new context errors, the system could attempt to infer which system is the one the user intended to have primacy.
Communicate the product’s capabilities and limitations clearly to set expectations, and do this early.
When appropriate, provide reasons for a given inference, recommendation, suggestion, etc.
Leverage other in-product moments, such as onboarding, to explain AI systems.
Users look for familiar appearance and legibility, which can contribute to initial trust.
Contextualize recommendations with third-party sources.
Explicitly state which data is shared, and which data isn’t.
Make it easy to try the product first.
Engage users and give them some control as they get started.
Progressively increase automation under user guidance.
Continue to communicate clearly about permissions and settings.
Let the users know ahead of time that there is a recovery plan in case something goes wrong, and in the moment, when something doesn’t go as expected.
Give users a way forward, according to the severity of possible outcomes.
Show the output alongside training data, like here's your image and here are some images we have that are similar.
[[]] backlink
three `` to start a query
 query:#tag to produce a list of tags
```query
tag:jupyter
```
https://medium.com/produclivity/3-things-you-didnt-know-you-could-do-with-obsidian-933ae81c51c8
learn markdown: https://facedragons.com/personal-development/obsidian-markdown-cheatsheet/
zettelkasten: https://zettelkasten.de/posts/overview/
![[Screen Shot 2023-04-16 at 2.55.09 PM.png]]
https://www.youtube.com/watch?v=TPmtiglPnEY

Begin with the user need, research, and market fit. Chatbots-only are not the future. The future is the hybrid GUI and prompt. The AI builds the UI.

A blue pop-up helped reveal the AI.

The user is likely using the LLM in a very particular use case for themselves. Study will reveal the prompts and intent so you can create a graphic controller. [[You can generate buttons based on the most common prompts.]]

The design system is more important now if the AI is building the UI. Once you realize the patterns you can build the widgets.

Consider scalability and use cases. Having help writing prompts is beneficial. [[You need to show your references, cite your sources.]]

Use sentiment analysis of NLP to measure AI success.

4 ingredients for UX & AI
Needs research
Usability heuristics & Hybrid interfaces
Personalization
Self-built interfaces
One of the largest challenges any particular person will face is guiding yourself to do something new. It may be more like the challenge is less about doing something new and more about stopping what you’re currently doing. In either case the end result is the same. You’re wanting to form new neural pathways in your brain. That’s really what behaviors are.

A vital point about changing behavior is that you don’t lose the old the behavior. It may go away but neural pathways persist far longer than you might think. Changing an existing behavior is the processes of rerouting electrical activity so that it doesn’t follow the existing pathway but is diverted to the new one instead. Diverting your neural activity needs to happen repeatedly so that it ultimately takes less energy that the old pathways. Behavior change happens in small moments over time.

An easy way to divert your neural activity is to set up an interruption. A common example is freezing a credit card in a block of ice to prevent expenditure. Though that’s not the most beneficial behavior these days since online shopping only requires numbers and ice is transparent. But anyways. Interruptions force attention. They create decision points. Do this or do that. You can’t be lazy and expect to change how you want. Your nature requires a different approach. It’s uncomfortable, sure, but not impossible. Put yourself in your own way. It’s the one and only step to get you to who you want to be.

[[_SVA]]
Dunno much more, is worth looking into.

```query
tag:jupyter
```

#jupyter
![\text{NPV} = \frac{R_{t}}{(1+i)^{t}}](https://www.gstatic.com/education/formulas2/472522532/en/net_present_value.svg)
#ux #ai 


DataVOLO

GenAI will be a feature in existing platforms, alongside RUSTY , Graph, all supporting data is part of one platfrom. Decoders are the generative force. DL only has encoders to learn.

We will do the chunking and high level work.
Chunk overlap is an expert hack.

Ask for 100 chunks back add 1,2,3,4 until we reach the number that we want. Secret sauce of chunk ranking.

Ranking is still a thing.

Vector DB is a common RAG solution though not only.

If you keep your own DB with the latest of domain specific data you'll keep things current.

Conversation design

17k households daily electricity will create a crisis in AI computing. More people need to recognize the seriousness of this.
Two-day seminar #service
 10-step learning workshop with templates and worksheets
One-hour coworking session #service
 Talk is cheap, I'll work through your problem with you over giving you advice as to what to do
Career coaching #service 
```query
tag:service
```
 - Fractional Design Officer #service
 - Fractional Communications Officer #service
  - internal, how employees speak, not external, what it said to customers
 - Fractional Feedback Officer #service
  - runs out of ideas on what, where, and how to improve?
  - let me orient you back and build systems to maintain actionable feedback
 - Fractional Play Officer #service
 - FXO, Fractional Experience Officer #service
 - Meditation coach and accountability #service
 - could sell an eval  
    create a checklist  
    call me after you’ve completed the checklist
maybe creative thinking? AI consult? I dunno.
Some days don’t you just wish that the pie never disappeared? 

https://www.youtube.com/watch?v=JZOxqVl5oP4

This is not a metaphor. I just really miss pie.

[[_SVA]]
#ux #ai 

https://medium.com/ml-ux/machine-learning-and-user-experience-a-few-resources-e7872f1d34ee

https://machinelearning.design/

https://www.youtube.com/@MLUXmeetup/videos

http://www.creativeai.net/

https://medium.com/google-design/human-centered-machine-learning-a770d10562cd

https://www.youtube.com/@MLUXmeetup/videos
Consider that the space between is the only space that matters. The endpoints are fixed. In contrast we don’t make sense of the ends, we make sense of the space in between. Humans experience the world as a relationship between themselves and the environment. Conceptually these can be redefined. I can think of myself as a hero and the environment as unchanging or I can think of myself as a villain and the environment as my clay. The endpoints don’t determine the relationships available but they do prime the pump for certain relationships to be more obtuse.

What am I to this table? It’s a ridiculous question but it forms the basis for our interactions with it. We create meaning from our answer. If I am taller than the table I might see this table as a step to a high location. If I am shorter I might see this table as an immovable mountain. You’re not redefining what the table is, but what it is in relation to what you are.

By all means change the endpoints. There is infinite variety in that. Consider though that the endpoints are less meaningful than the relation between them because the relation is what we create. The relation is often the more subjective factor. You might not find anything when you do change the relation but know that it is within your control. It’s about the only thing within your control.

[[_SVA]]
#ux #ai 

https://futurice.com/ia-design-kit

What AI is good at
 - predict a number
 - predict if this part will fail tomorrow
 - predict which department to route a call to
 - recognize images
 - recognize text
 - recognize sound
 - personalize content
 - target communications
 - discover anamolies
 - discover groups
#ai #RAG 

Yujian Tang - Dev advocate Zilliz

Milvus, Mixtral, OctoAI, Langchain
Milvus is an open source vector database and it allows you to use unstructured data.

LangChain orchestrates LLM conversations with RAG. Indexing is critical for vector search. Vector search allows for a quantitative comparison of qualitative data. You will never have two dimensional data in production and you won't do distance calculations in production.

Mixtral is a Mixture of Experts, specifically 8 experts though only 2 are active at once.

Text generation via Mixtral and OctoAI has 3 hyperparameters:
Temperature - how creative do you want the output to be.
Top p - how varied do you want the output to be.
Max tokens - 32k for Mixtral

LangChain treats LLMs as a function.

code: https://github.com/ytang07/octoai_milvus/blob/main/MMO_RAG_Docker.ipynb

512 characters is about 100 words, maybe one or one and a half paragraphs.

HuggingFace SentenceTransformer can is Yujian's favorite embedding tool as it is free.

Milvus has role based access control so the intern can't see the CFO data.
#ai #RAG 

https://www.youtube.com/watch?v=fo0F-DAum7E

Explainability in AI from MSci
Fairness
Adversarial

LLMs are trained only on stale web data, not fresh or proprietary data. RAG brings in fresh and proprietary data.

Canopy. LangChain, Llamaindex
5 lines of code, the demo is easy
You may overflow the context if your RAG grabs too much response that it maxes out tokens. You need to chunk properly. 

https://github.com/pinecone-io/canopy
The benefit is E2E Rag, Built for scale using Pinecone, Context overflow, No code just a YAML config, FastAPI & Docker

Evaluating a RAG is like evaluating an essay over a multiple choice.

https://github.com/truera/trulens/blob/main/trulens_eval/examples/expositional/frameworks/canopy/canopy_quickstart.ipynb

APIs needed:
Pinecone
OpenAI
Cohere

Controls via a config helps maintenance in production. Eval -> in Trulens
TruEra is a full lifecycle AI
Eval -> Debug -> Monitor
Fine grain logging of the trace.

Fine-tune small models first. By adding data through fine-tuning you may end up with a better model. Use a small model for workflow proof.

Stochastic is asking the same question and getting different responses. Low temp, close to 0, for consistent answers.
The thread is what we grab onto to navigate the chaos unfolding around us. Threads weave more than just stories. Threads weave people, ideas, and movements together. Threads bind us. They are everywhere.

Connecting is what I believe, on a level that is mythically deep, that we show up to do. The world and all its infinities are better for it.

[[_SVA]]
Guilt has a strong negative connotation but it is a profoundly positive emotion. Civilization cannot exist without guilt. Society cannot exist without guilt. Guilt is always pointed at what we did wrong, how we let someone down, and how we went against the grain. Nobody likes to feel guilty which is exactly the point. Guilt keeps up from behaving in certain ways. Encouraging constructive behavior alone will not get you where you want to go. We need guardrails against destructive behaviors. Enter guilt.

I didn’t create guilt. I’m merely pointing out that in its negativity guilt is highly constructive. Cultures are defined as much, if not more, by what they place negative value on than by what they place positive value on. It is possible that we limit ourselves by feeling guilty over actions that we need not feel guilty over. Therein lies the tricky bit. We need guilt to control our actions but that control inhibits us as much as it supports us. If you can find false guilt then by all means remove it. Conversely consider how you can guilt yourself forward, it’s possible.

[[_SVA]]
On a human level it has been stated that the support of a mere 3.5% of the population is necessary to sustain a revolution. From there you’re doing what everyone else is doing and addressing the long work. Overthrowing a government can happen overnight if the atmosphere is charged, people are tense, and then boom goes the dynamite. The atmosphere needs to be charged and as such rarely spontaneously is. Even overthrowing a government overnight takes time and the right conditions. The long work.

Expect to be surrounded on all fronts. You’re buried alive essentially and you gotta bust through the ground. Or you’re surrounded by water and drowning. Government is your environment until you claw to the freedom you desire. It can feel as an endless event. You’re doing necessary work. It can be beneficial to consider your path as ascension. Ascending the constraints. Transcending if that helps.

Maintain your support. Create emissaries, ambassadors, delegates, diplomats, foreign representatives, people relations experts. You’ll get there.

[[_SVA]]
#ux #ai 


#ux #ai 


#ux #ai 


#ux #ai
#ux #ai 

https://www.youtube.com/watch?v=5HgkawZdihU


https://dashtoon.notion.site/Stable-Diffusion-Creative-Technologist-Dashtoon-Full-time-Bengaluru-India-26cc0fcf503a4617b1ac8e60b1b383ad?pvs=25
It is not uncommon knowledge that our individual experiences of the world are highly biased. With our brains acting as self-organizing information systems it cannot be any other way. One such bias worthy of consideration is known as deformation professionelle, which is the tendency to view the world through the distorting lens of your job or training. This shares commonality with the colloquialism that if all you have is a hammer then everything looks like a nail. 

Deformation professionelle can be particularly insidious in the realm of design because design is of such a high order thinking skill, meaning design deals primarily with very fuzzy abstractions. Designers are taught that design is a means to accomplish a goal. Name a situation where a means to accomplish a goal is not applicable and you’ll see the point I’m making.

‘We need more design.’ ‘We need better design.’ ‘Design can help here,’ are all traps of deformation professionelle. It is possible those statements ring true more often than not but nothing can claim applicability in all instances. Be mindful of the ways in which your mind organizes the world to make sense to you. When possible seek alternate perspectives. Ask yourself, ‘how would someone with no design training approach this situation?’

[[_SVA]]
#ux #ai 

Ask what people expect to be able to influence during your feedback sessions.
On this scale, show me how trusting you are of this recommendation.
What questions do you have about how the app came to this recommendation?
What, if anything, would increase your trust in this recommendation?
How satisfied or dissatisfied are you with the explanation written here?
#ux #ai 


So much of how you act and your approach to life is a result of your environment. Probably more than you realize though it’s likely if you are in a toxic environment that you realize it’s toxic. The trick then is to understand that even seemingly benign environments have a profound impact on you. That good life you’re striving for is really a comfortable life inside a supportive environment. It’s time to shift your focus from becoming a better person to creating better environments for yourself. You’ll grow much faster when you do.

[[_SVA]]
Blasphemer! Heretic! Jerk-wad! You cry out against me yet I am not wrong. What you begin with is important, sure, but what you do with your input is what matters. Garbage in-garbage out is a lazy approach that does nothing to create value.

Process is change with intent. If your intent is take a load of nonsense and process it into a different load of nonsense then you are a waste of blood and air. The goal of every process is benefit and value.

Quit spending time finding the right starting point and spend that time finding the right way to make things better.
Ba overlaid with Fa mouth movements with induces hearing Fa instead of Ba despite Ba being the actual sound. This is known as the McGurk effect.

#IxD
DreamBooth is proprietary to Google but there are open-source conceptual versions.
512x512 images and a token. 20-30 high quality images. Use birme.net for cropping.
Images need different contexts (i.e. backgrounds, clothing for people)
The prompt needs to include the token for the images.
FastStableDiffusion on RunPod
Your token needs to be unique. Google your token to see if any images are associated with it.
Try to avoid vowels in your token.
Files need to be named with your token and a variable counter. (e.g. ‘token 01’, ‘token-01’, ‘token_01’,’ token(01)’)
24GB VRAM
Roughly 100 UNet training steps per image unless training on a large data set where 60-80 may be beneficial
350 steps for the text encoder is generally a good idea. 30% of UNet training steps could be advisable.

#dreambooth 
https://arxiv.org/abs/2106.09685 #LoRA 
https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/
https://arxiv.org/abs/2005.07727
https://arxiv.org/abs/2312.04780
https://arxiv.org/abs/2311.17117
https://arxiv.org/abs/2310.04378 #LCM 
https://arxiv.org/abs/2308.00352 #metaGPT
https://arxiv.org/abs/2306.11644
https://arxiv.org/abs/2305.13048
https://arxiv.org/abs/2302.05543 #controlNet
https://arxiv.org/abs/2211.09800
https://arxiv.org/abs/2208.12242 #dreambooth
https://arxiv.org/abs/2205.10770
https://arxiv.org/abs/2012.07805
https://arxiv.org/abs/1706.03762
John Maeda talks about the Emotional Tetrahedron, which is the Iron Triangle with a surprise fourth point of emotion. [[Due to the impact non-determinism has on quality, ie failure is an option, you can only leverage speed, cost, and emotion.]]

 - add AI notices to force the pilot to think critically
 - suggest prompts that leverage the AI's strengths
 - build in feedback loops
 - give AI status updates
 - give more citations
 - add friction
 - don't humanize the AI

[[Collaborative UX via the Copilot stack]]
An incredibly important point to note about any creative endeavor is that the context it will live in is not the same as the context it was created in. This means unless you consider the differences in the contexts then your designs will be insufficient. Context changes at the drop of a note. It is nearly impossible to predict or create a context and your predictions will rarely be spot on. In the same way that planning is more important than the plan, the act of considering the difference in contexts is more important than getting the context right.

A crucial reason for considering contexts is the design of outcomes. We want our designs to catalyze a change for our audience. Every context requires a different approach to create a change. The types of variables which constitute our reality are so noisy that what worked yesterday when the sun was low might not work a month from now when the sun is high. Our designs either need to be bespoke enough to guarantee success in this moment or general enough to work in other moments. The balance is delicate and excruciating, if not impossible, to nail. Once again the act is more important than the result.

No context contains the possibility of every outcome which is precisely why you need to know what outcome you are designing for and which contexts are primed to realize those outcomes. Anything else is painting a target around your shots.

[[_SVA]]
Because you cannot control the speed of the AI due to mathematical constrictions, physical limitations, and power trafficking, you have to make things that are slow feel fast or at least make them feel less slow and ideally make them feel pleasurable regardless of their speed.

A story, considered true by many, witnesses this point.

https://rogerfirestien.com/when-mirrors-and-elevators-got-married/

Disney is a good example for delivering valuable waiting experiences. You can easily turn to the physical world for a metaphorical equivalent to a digital idea.

https://talkingaboutdesign.com/designing-experience-a-case-study-of-disneylands-lines/

Inflating posted wait times is a tricky one but overestimating and delivering early is highly valuable from a recipient's perspective when it comes to time.

Other tactics to make waiting less suck and seem faster are progress bars, streaming text ala ChatGPT, type-ahead ala Google search, and
citations/ads/magazines/waiting room reading.

Microsoft design talks about this as latency. As waiting for the level to load in a video game.
https://build.microsoft.com/en-US/archives/98228450-22d7-4722-bae8-923d116638d4


Are you against providing me with a short intro as to what made you want to speak with me?
Are there any areas you want me to focus on or areas you're least interested in?
What's your situation?
Where are you trying to go?
What are your obstacles?
What are your deal killers?
Who do you expect me to be?
What did you expect to hear from me and didn't?
Is there anything else you want me to know?
#business #intervew-practice-group
#ux #ai 

https://smarterpatterns.com/

The patterns are bucketed into Transparency & Trust, Autonomy & Control, Fairness & Inclusiveness.

These patterns begin with problem statements.

Way too much to hold in your head. A good resource to consult. Highly tactical.
All people are irrational people. All people are rational people. It is highly unlikely that you and the people you design for are the same kind of rational. It’s more likely that you’re the irrational one. The moment you decide to design for someone other than yourself you’ve automatically made yourself the irrational one. This is the burden you must bear. Learn to find the freedom in it.

[[_SVA]]
[[For interviewing to be fair and effective it needs to tolerate culture, discomfort, and biases.]] Our relationship with strange is primal. Social norms can only do so much in removing a programmed aversion to different. Ask yourself from the jump, why am I putting this other person in a category? What do I seek to understand from this designation? Can I not let the difference be irrelevant and move on? Discomfort is not difficult to sense. As soon as you become uncomfortable with your counterpart being different you make them uncomfortable for being different. Or you make them justify their difference and judge them if they fail to impress you. We're not looking for 'fit.' We're looking for competence and effect over comfort and preference. Don't fake sincerity, if you are feeling uncomfortable then remove yourself from the situation, acknowledge your discomfort and remove yourself from the process entirely. Disgust and distain do not a healthy foundation make.
#ai #UX 

[[Beneficial prompts for a UX designer]]
[[Midjourney lighting prompts]]
[[Business ideas]]

DALL-E 2 is built from CLIP, a Prior Neural Network, and a Decorder Neural Network (unCLIP)

prompt weight ::# two colons and a number, can also be negative, all weights must add up to positive

ControlNet is glorified img2img with more control #controlNet 
OpenPose works with people, creating a skeleton
More complex pose - higher weight
Combine pose and edge (canning)
Edge is good for hands
Depth created a B&W depth image
Dreambooth filters(?)
Use edge and depth for pets

UNet encoder and decoder network
 - learn noise distribution, predict it, remove it in steps
 - shrinks image in latent space

Fingers and abs suck because they are semi-repetitive patterns

Diffusion models are more stable and a better approach to training and generating samples over GANs and VAEs and normalizing flows.

Canny edge-detector is a standard edge detector.

[[DreamBooth started with Google allowing you to use your own content in pre-trained text-to-image models.]]

CLIP + VQGAN architecture predates Stable Diffusion and most other diffusion models.
Focus on data that is out of distribution.
Vision inputs have traditionally been camera based but in occluded environments like fog these cameras are insufficient. Shift to incorporating thermal cameras, polarized cameras, event(?) cameras, and depth inputs.
[[OpenCV predicts 2024 as another great year for open source.]]
https://www.meetup.com/data-science-dojo-silicon-valley/events/298895068/?_xtd=gqFyqDQ1OTYzOTUyoXCjYXBp&from=ref

https://code.datasciencedojo.com/iaziz/Building-Simple-and-Efficient-Chatbots-Demo

A good place to start conceptually:
https://www.ibm.com/design/ai/conversation/planning

Chatbots increase availability, decrease wait times, reduce repetition of interactions, and personalize services.

They solve limited availability, long wait time, repetitive interactions, and lack of personalized services.

Chatbot increase customer satisfaction improves brand image and reduces costs overall.

Chatbots can give you sentiment analysis, summarization, translation, and a solid Q&A.

I got this from a customer service industry expert.

LLMs are the fundamental concept of a chatbot. User -> Q/A -> LLM (pretrained) <- Data corpus

'I don't know' is an undesirable response from a chatbot.

Efficient prompting begins with giving the AI a role, then writing clear and specific instructions, giving examples of what the user could ask and what the reply needs to be and ending by asking it clear and precise questions.

#RAG 

The query goes through the external knowledge base (RAG) and appends any relevant info to the user's query before passing that to the LLM which is still pre-trained on a data corpus.

Infer the meaning of the user's query to retrieve from the RAG not a keyword match. This involves a vector search.

Learn more about properly chunking: https://huggingface.co/spaces/m-ric/chunk_visualizer

Prioritize refining and structuring the data you have over adding new data. Good semantic structure will never go out of fashion.

LangChain

Prereqs are Azure OpenAI Service
Jupyter Notebook

You need a starting text doc

https://scrapy.org/
For an open-source python driven way to scrape web content and turn it into a text doc.

https://www.gettingstarted.ai/how-to-use-gemini-pro-api-llamaindex-pinecone-index-to-build-rag-app/

#ai #chatbot

```query
tag:rag
```

https://www.linkedin.com/in/designemissary/

Howard Pinsky, Design Evangelist

Adding provenance to images when exporting

Adobe segments their experience into functions, text-to-image, generative fill (edit), text effects

Have to update functions to new image models

Makes svgs, which are mathematical outlines, maybe canning?

One way to grow is to evangelize the creation.

He doesn't see many interaction designers using AI or these tools.

Content credentials inside of Photoshop will change if you download from Firefly and update in Photoshop. contentauthenticity.org/verify

Provenance is how history has solved the problem of fake news but we've lost sense of it. We've become deluded. Adobe is bringing provenance back. Free speech and all but speak true. Your false narrative, false memories, and revised histories have no place here.
!BUT What if I don't wan't my stuff hijacked with credentials?
 - You gotta use another software.


The Muller Lyer illusion is not applicable to non W(hite)E(ducated)I(ndustrialize)R(ich)D(emocratic) audiences.

#IxD
Life is a cyclical and not a linear process. From perception to action is one model for human interaction. There's a strong argument to begin with action and cycle through the world, perception, cognition, and back into action.

[[Users need visual, audible, and other sensory or perceptive evidence to know they've taken the correct or beneficial action towards their goal.]]

#IxD
OpenAI: https://platform.openai.com/docs/introduction

Lumalabs: https://lumalabs.ai/genie?view=create

Free Twelve Labs credits: https://docs.google.com/forms/d/e/1FAIpQLSfM3Br3-zhZshGbC2lK21uOUSm-ea1xtDRs3DwPd31dHKJ2WQ/viewform

Twelve labs: https://drive.google.com/file/d/1NYqxgAVU-qPPJqOl9lvbbeNGbxluGxmL/view?usp=drive_link

founders@kuratech.com
kp@kuratech.com

#ux #ai 


#ux #ai 


#ux #ai 

AI notices for the user to think critically. Suggesting prompts tells the user what the AI is good at. Citations enforce more work. Status is more information. More information is friction. Not humanizing AI is adding a lot of friction.
Keep the values of fairness, equity, and equality in mind as you are interviewed and interview. Your tenets to fair and effective interviewing are to understand culture and it's impact on a person's life experience, be comfortable with different, learn your biases and implement balances for them.
[[Culture creates a lens through which an individual perceives and interacts with their environment and the people in it.]]
[[Different is uncomfortable.]]
[[Biases are unconscious leanings you have.]]
Most services restrict consumption of model request meaning the result you get back has only spent so much time in the model before it was removed. The general artifacting of images is reduced with more time in the model. I believe this is generally known as steps, but I'm not sure. #ai
It is possible to change your perception. In that aspect, our brains are wonderfully malleable sacks of water. While this change may be seemingly impossible with a basic understanding of the element which shape what we see it will be easier.

The first element is context. In this case context means everything your brain has processed since the first neural connection was made. That’s a lot of processing. Most of the processing has been done without a conscious awareness. All that means is your history has primed you to accept certain perceptions more easily than others. Once bitten, twice shy is an example of context in action. You can’t go back and redo what has already been done but you can remember the past differently. History is written into the wiring of your brain, which as noted before is highly malleable. Rewrite your history. Remember events and change the narrative in your head about the event.

Context is a bit tricky in that it is shaped by cultural and individual differences. Your life is your life. Everything that happened to you is unique to you but you’ve existed inside an environment that we often refer to as culture. Culture is a collective context. It’s the social history, shared beliefs, laws, norms, rights, and roles of the people surrounding you. Culture can be minute or massive. Culture changes over time. One quick way to shift your worldview is to jump cultures. That’s not an invitation to change the culture around you. That’s an invitation to leave your current culture for a new one. Move.

A second element shaping what you see is experience. Context contains and influences experience. Experience is the thread of meaningful moments that have led you to where you are. Context is subtle. Experience is not. That time that one day you felt pure joy is an experience. That time that other day you felt trepidation is an other experience. Experience is unique in that it is a full body thing. Experience lives not only in your mind but in your emotions and in your muscles. Tension is experience. Trauma is experience. Nostalgia is experience. Experiences need to be confronted to be changed. Once again, you can’t go back and redo what you’ve experienced but you can reinterpret and understand your experiences in a different way. If you can integrate the tension and trauma back into your self you release it. You allow the experience to let go of it’s hold on you. Once bitten, twice shy becomes once bitten.

The final element is likely the headiest of them all and that is schemata. Schemata are mental architectures. If all you have known are horses and you see a zebra you will think it an oddly colored horse. Which is not entirely untrue just not nuanced. Perhaps a better example is the common banana. If all you have known are grocery store yellow bananas and you come across a plantain you might be tempted to treat it like a yellow banana. A more nefarious schemata exists around human differences. If all you have known are melatonin deprived humans when you encounter a melatonin rich human you may be tempted to treat that person as less than. Schemata are organized patterns of thought or behavior. They are the boxes with labels that you place things in. They are built up through experience in context. As such schemata are the easiest to change but the least influential. Opening yourself up to being wrong about what you see starts the schemata change. Knowledge can change schemata. But really, change the label and you change the schemata. Switch bad to good, gross to unexplained, harmful to misunderstood, empty to anticipatory. Your architectures or thought aren’t so bad it’s when you misapply them that matters.

With an awareness of the factors that shape how you see the world you can influence them. You can design your worldview to reflect who you want to become. Start now.

[[_SVA]]
Thanks for removing these sliders I didn't know how to use. You can toggle them so they are not in there by default. To hide and show those advanced things.

How pricing works and the massive growth from India but how are they finding you? 2 weeks over 1.5mil new people added to the old people. Which almost killed their product.

New enhancer is benchmarking at 4k better than Tuesday and 4x faster. 85mb of image. 7.6k per 9.6k. Their Macs fail every day. This stuff is nutz with hardware.

You see the base images you use to upscale. Upscale EVERY image I own.

Expand and contract the sidebars with advanced options by hiding what isn't necessary to bring forth the canvas. It is super great to have the thumbnails on the left to prevent scrolling.

$8 is way more than a user can expect from this service. You cannot find a better technology for less money than KREA.

KREA has moved up the early people in pay tiers out of reverence and respect.

KREA was born in Barcelona.
#ux #ai 

Start here
https://www.microsoft.com/en-us/haxtoolkit/library/?content_type%5B1%5D=example
https://www.microsoft.com/en-us/research/uploads/prod/2019/01/Guidelines-for-Human-AI-Interaction-camera-ready.pdf
https://erichorvitz.com/chi99horvitz.pdf

https://www.microsoft.com/en-us/haxtoolkit/ai-guidelines/

Great place to start a project
https://microsoft.github.io/HAXPlaybook/
e.g. https://microsoft.github.io/HAXPlaybook/?state=200002xx

The HAX playbook shows foreseeable failures in NLP scenarios like search. It is extensible but not all inclusive of AI.

Also a helpful place to begin but not a great place to begin.
https://www.microsoft.com/en-us/haxtoolkit/workbook/

I will take away from the HAX that when you are conducting a project the HAX is a good companion item to have. Considering that it is 18 in number there's really no use trying to memorize it all.

https://www.youtube.com/watch?v=JppYmctp0a8&t=16s

The HAX is for supporting AI builders. Human-centered is the core. [[The data for the model needs to be the data of the people using the model.]]

Media and ignorance create unrealistic expectations of AI that need to be tempered by the builders and people who know what the AI can do. Like how CSI influenced the public's expectations of how crimes are solved.

Act when the user benefit outweighs the resource cost but prioritize the patterns across all guidelines. The HAX has research that can be used to justify a design decision.

There are 8 guidelines that present unique challenges for human to AI interactions. These guidelines contain patterns.

[['You have stated your intent is this. With relative confidence this path with yield success. Do you want to act?']]

Responsible AI principles of Microsoft.
 - Fairness
 - Reliability
 - Safety
 - Inclusive
 - Transparency
 - Accountability

Microsoft Research leaders don't require their designers to build an AI to be useful.

The culture these tools/AI are used in needs to be considered with research. [[Culture isn't static therefore the research cannot be static.]]

Cognitive walkthroughs are evaluative. The HAX could be used for evaluation though it is best served as an upfront and along the way tool. Designing for the HAX isn't easy with an AI that is already designed. The HAX is more for planning than recourse.
#ux #ai 

https://build.microsoft.com/en-US/archives/98228450-22d7-4722-bae8-923d116638d4

John Maeda covers most of this and more in his LinkedIn course. [[John Maeda's UX patterns for copilot.]] This content is a nice addition but an addition no less. Don't start here is what I'm saying.

Kurtis Beavers
Rachel Shepard

'Natural language is now the primary interface.'
– PapaBG (Bill Gates)

Copilots are AI like NLP, LLM, GPT-4 to assist people with complex or cognitive tasks. As AI learns it is guessing. It's a complete idiot at the start and needs to know if it got it right. Was that beneficial?

The Copilot experience is working with an idiot savant. The Flowers of Algernon experience before he become a genius. [[Given what an LLM is good at can it be beneficial in this context?]]

Copilot design system is:
 - UX framework
 - Design language
 - Interactions
 - Patterns & components
 - Content design
 - Ops across disciplines

Documents and sentences are different altitudes and may need different Copilots.

AI notice is a pattern to call out the AI. Suggested prompts. Latency is space while AI processes. Adding friction to review output before taking ownership. 'Are you sure you want to continue and not that you want to read the link?'

Be thoughtful about architectures and infrastructure. Can't replace a research but can augment and do a sentiment analysis. AI can't replace the expertise to make a decision. Will the Copilot cannibalize applications?

Given the integration of Copilots you may have made functions, pages, and stories of yore obsolete. You don't need GPT-4 to do a Q&A on top of a data set.

Prompt engineering is an attempt to impose traditional logic on a non-deterministic machine. It cannot solve all problems. Sorta like plugging holes in a dam. Maybe you need a new dam.

Writing longer works better for AI. People who don't know how AI works won't figure out how to make AI work. People who know how AI works say 'I failed,' people who don't know how AI works say 'it failed.' Traditionally it has been the other way.

Fabrication over hallucination.

Design for AI is taking big and framing, not taking nothing and creating. Design for AI is often about restricting and defining what the AI can't or won't do.


Text in the prompt is weighted individually in accordance with the overall context. Tokens don't consider pairings, only weights in context. Thus blue hat is weighted as blue and hat. The likelihood of hat carrying more weight is high as blue on it's own is generally less common. Therefore you get a hat and the likelihood of it being blue is proportional to it's weighting and the model.

[[Processing steps inhibit an AI image generators ability to deal with crowds.]]
https://docs.llamaindex.ai/en/stable/getting_started/starter_example.html

#RAG  #ai 

RAG is a solution to limit context windows. Likely 100ms of tokens of data. Not practical to give all tokens with each query.

RAG gives you the following value: accuracy, faithfulness, recency, and provenance (citations).

Get an LLM to write SQL queries. Vectors are gigantic arrays of numbers. Data is encoded as meaning not words. Embedding is converting words into vector numbers.

LlamaHub has connectors to other software to grab datums. This is useful if your data is all spread across many software stores.

Llama index has their own prompts so you don't have to focus on prompt engineering but you can if you want. Prompting is giving arbitrary text to an LLM to tell it how to answer a question.

Use LLM to break apart complex queries and sends each query to the appropriate data source. 

BM25 search.

Hybrid search runs the same query against tradition and vector search but not all vector DBs support this function.

npx create-llama
npmjs.com/package/create-llama

Pre-processing and post-processing strategies for dealing with off-topic queries.

LLM will have higher latency than traditional keyword search. LLM begins answering a question immediately so stream the results.

Local models can improve latency at reduced cost. Latency is best solved with more hardware. Accuracy is best tuned with a querying strategy. Mess with the size of your retrieve content to improve accuracy, latency, and cost.

PII detector will help you get rid of protected info from your documents. LlamaHub has these preprocessors to help with that.
Preprocessing, ingestion, pre-aggregation, and filtering are key to data cleanliness.

Agents are the hotness in AI right now. Get AIs to use tools and take actions over answering questions. Combine RAG with an agent.

Separate vector stores per data type is recommended because you can query separate stores.

```query
tag:RAG
```


[[Build a circle of mentors with six people.]] Challengers are the reflective force of your energy. Challengers ask the tough questions. They block you. It's not out of hate though it could be, make friends of your enemy, instead challengers seek to push you from good to great.
[[Business processes tend toward optimization not generation.]]
[[All plans are fiction.]]
[[Numbers offer a false assurance.]]
[[Qualitative disciplines are ambiguous by nature.]]
[[Business and design are different cultures and do not benefit from being unified.]]
[[Language to use when taking about design decisions]]
#ux #ai 

https://www.ibm.com/watson/assets/duo/pdf/everydayethics.pdf


Arithmetic symbols are common operators.

[[Relational operators are used to evaluate boolean expressions.]]

#programming #beginner
It is commonly known that cancerous growth will return if every bit is not removed. The model does not apply to ideas. You forget ideas. You can’t remove them. What has happened cannot unhappen. You have to distract yourself away from thoughts for so long that they cease to be relevant and are tucked away. Memories are twitches of the system. They are anticipatory, anxious, and ready to approach what has already happened. This is how songs get stuck in your head. The longer you’ve had the song in your head the harder it is not to hear it all the time.

Machiavelli teaches us how to notice if we are being treated as a cancerous growth and not as beings with ideas. His promise is freedom of ideas not domination. Domination is a weapon of oppression.

[[_SVA]]
https://www.youtube.com/@opencvofficial

The human eye can't see IR so these cameras use IR as their light source. IR doesn't cause your pupils to constrict. You have two cameras, one to see the scene and the other to track the eye.

Apple Vision Pro has 4 IR cameras and 12 cameras overall. 1/3 of the cameras are dedicated to eye tracking. 2 IR cameras per eye for 4 total.

Getting ground truth is matching the environment to the gaze, this can be done by asking to stare at a target or double clicking on a button because you look at a button before clicking on it.

Dark pupil and bright pupil are two ways to to determine pupils. Pupil detection has shifted from edge detection to deep learning neural networks like NVGaze and CNNs.

Use a beam splitter, which is a half-silver mirror, to allow the camera to see the eye front on without the camera.

The FOVEA and not the optical axis determines the gaze. The optical axis is the pole that run through the center of the eye. The FOVEA is offset from the center by a number of degrees which varies per person. This degree difference between the optical axis and visual axis is called the kappa angle. Because of the kappa angle devices need user specific calibration like, look around the screen at these dots.

Pupil center corneal reflection PCCR can determine the center of the pupil but you can use more eye features like iris location and eye contour in addition to corneal reflection and pupil.

There are a lot of synthetic datasets for eye tracking training. Many are from the 2010s. These can be used to train your eye tracking model without training it yourself.
What software do you use on a regular basis? When was the last time you adopted a new software?
Knowing how the eye works helps. Knowing culture and iconography helps. Being able to write a script helps. Knowing your user's capabilities helps as well.
Can’t be a thing. Truth is true. A truth that is not true is not a truth.

Get over it. Truth is not for us to understand. Truth is not for us to accept, acknowledge, or avow. Truth is for us to ignore. Live a better life. Stop concerning yourself with truth.

[[_SVA]]
The space in-between what you imagine and what you see is the space of the artist. Few people dare call that space home. It is an uncomfortable space. We are used to ideas. We find extreme joy in them. Anything that exists in the self-contained universe of our mind is safe from error. As soon as you move an idea towards a concrete vision you start to cause problems. The haze can’t exist. Decisions have to be made. The form must be solidified. 

I’m not saying there is no value in an idea or that execution is all that matters. I think that the people who are willing to journey across the void between idea and reality need to be celebrated more than they are. Art is general considered a leisure pursuit. Obviously in art circles this is predominantly untrue. By and large in the greater culture of society it is. As people we understand the struggle of giving form to vision. This is likely why there are so few people who identify as artists and even fewer who are willing to undertake it as a means of contribution.

I’ll make an assertion that the people who make things, not the people who make things happen, but the hands on artisans should be the wealthiest individuals in any society. They do the most difficult work. Anyone who has ever tried to bring an idea to life will know. If we adopt this posture we’re likely to see greater advancement, socially, culturally, technologically, and emotionally. We’re better off because we go through the discomfort of giving form to vision not in spite of it.

[[_SVA]]
#ux #ai 

Install extensions to work with different languages

Restart with each addition or at the end of a lot of additions

Install an interpreter
cmd + shift + p > "python interpreter"

shift + return runs code selection/line in terminal

right click to get to run in terminal

#programming #beginner
#ux #ai 

https://www.oreilly.com/radar/machine-learning-for-designers/

Unit test are run on the user's machine at installation to ensure the software works as intended.

Identifying faces is easy for people and real hard for computers.

A linearly inseparable problem is a lack of a binary separation or single line upon which delineation can occur.

A Perceptron, invented by Frank Rosenblatt in 1957, is an early example of inductive reasoning in machine learning. It works from distributed representation. Perceptrons do not account for interdependent relationships between attributes and as such are deficient.

The four ways of machine learning are supervised, unsupervised, semi-supervised, and reinforcement learning.

Supervised learning takes inputs and their corresponding outputs and induces the rules that govern the system. They are supervised in that the proof is given, the system substantiates the evidence. Supervised learning best addresses classification and regression problems.

Unsupervised learning takes data and finds patterns generally too complex for humans to discover on their own. This style of learning can produce generative models which can make from the patterns they learn.

Semi-supervised learning uses the patterning of unsupervised learning to improve supervised learning. Data is distilled and cleaned through the unsupervised learning before being passed to the supervised system. This approach is beneficial if only a small portion of the training examples have been associated with a known output.

Reinforcement learning is not trained on existing data but learns from the feedback regarding the consequences of its actions. This is useful when reward is the point like in a game or when success conditions are vague.

Hierarchical feature learning, object recognition.

20 questions is a learning decision tree (classification tree) AI. The 20 questions process could apply to discovering an optimal path through a large number of interrelated decisions.

Hum a song and get a result is a machine learning problem.

Approachability, What can it do, How to interact, the unreliable nature of non-determinism, faulty assumptions like labeling Black people Gorillas, not including a sanity check, poor data

Inductive learning is like a search and any task is a search for the proper operational steps to produce an outcome. ML! Based on historical action this is your intent, did the AI get it right?

Poor training data with a masterful algorithm might give worse results than poor training data in a terrible algorithm. Your four main data considerations are completeness, accuracy, consistency, and timeliness.

Heuristic
Design systems that respond to a user's request and enriches the user's understanding of the domain itself.
Give a small example for the user to complete using AI, like a playground.
Indicate the kind of information you need and what you'll do with it.
Suggestions or a 20Q like interface to come up with what you want.
Provide confidence scores alongside speculations
Have non-ML, maybe human, and possibly code based check on data inputs and ML outputs, to stop the Tay bot and its racist remarks.
Have the system explicitly restate the task.
Provide fallback mechanisms.
Small releases to red teams.
Use confidence scores to assess the validity of included features.
Show the risks of an AI feature.

http://www.wekinator.org/

#ux #ai 

https://miro.com/miroverse/ai-design-toolkit/

Considers bias. Uses service blueprinting for AI architecture. Focuses on before ML and after ML.
https://youtu.be/LlcFkDFYFkk

A challenge is to make the AI actions obvious. A challenge is user comprehension. Explaining what the AI does.

Make sure a user doesn't need to be a prompt engineering genius to use our AI.

Don't let users change input values while the AI is working so the user doesn't think their in process change will be reflected in the AI's output. Provide a cancel or other way to stop AI in process.

Provide a starting point for prompts. Present the most likely actions and allow for exposing more.
#ux #ai 


Designing for teams is a complex process, with a multitude of considerations to keep in mind. From the size of the team to the different types of decision makers, designing for teams requires a nuanced approach. But one of the most crucial aspects of designing for teams is considering user roles, permissions, and account administration.

When do these considerations come into play? According to a collaborative tool designer, it's important to start thinking about them as soon as something becomes collaborative and there's a concept of multiple people being able to access something. Even if the number of roles or permissions isn't that complex at first, it's essential to create a simple, scalable model from the get-go. If the early model doesn't scale well, it can become a technical and UX burden that the team will have to live with for years to come.

So, how can you create a solid foundation for user roles, permissions, and account administration? Start by looking at other tools, such as Google Docs or Dropbox, and see how they handle permissions and roles. Build a table or matrix of their permissions and roles, and see how they work for your own product. Then, decide where you want to deviate or stick with established models.

It's important to note that different teams have different needs when it comes to user roles and permissions. For example, a 10-person team may be more concerned with individual employees who have a say in which tools they use, while a 1,000-person team may be more concerned with decision makers higher up in the organization. Designers need to take these nuances into account when creating user roles and permissions.

Another important consideration is how user roles and permissions affect collaboration. Collaborative tools should make it easy for team members to work together seamlessly, regardless of their roles and permissions. This means that designers need to think about how user roles and permissions affect workflows and processes, and create a system that facilitates collaboration rather than hindering it.

Finally, it's important to create a system that is flexible and adaptable. As teams grow and evolve, their needs for user roles and permissions may change. Designers need to create a system that can accommodate these changes without causing disruption or confusion.

Designing for teams is a complex process, but by considering user roles, permissions, and account administration from the outset, designers can create a system that fosters collaboration, facilitates workflows, and adapts to the changing needs of teams over time.

[[_SVA]]
#design 
https://www.youtube.com/watch?v=Q1Wq028TRoc

One dude has a creative background in music photography and visuals for a band.
Yolo of algorithms to determine objects. Maybe OpenCV
Recognize images of plants, cars, cities, et al & combine then and train a models, it learns shapes, colors, textures. Back in 2017. 7.Years.Ago...

Toy Story was this guy's childhood and driving force. He started with object detection to see if his toys moved in the night. He wanted to be a 3D modeler but got into engineering on the side.
YC $125000/yr to make money.
5k for 6%
125000 in convertible notes
HFZero, Lucy
84 when he was 8 for the older guy

Go through all these programs to express these visual ideas inside. Logic Pro. Cinema 4D. Each one I have all these unnecessary steps to learn them when all I want is immediate access to the output.

You end up with a powerful paintbrush but there is nothing individual to it. AI doesn't propagate the value of your flesh experience.

[[Printed paintings might be possible with highly detailed photos, a topology map, and a 3D printer.]]

Not much use in a business plan, in general in your head it is usually clear what can be clear and about not being clear what cannot be clear and that is what.

Zero Billion Dollar market. NVIDIA bet the future on 3D games and created a zero billion dollar market.

You have to be comfortable living in constant rejection. The entrepreneur life.

Praising in public and criticizing in private. But maybe criticize in public.

The interactions will become semantic. Put a paintbrush on a computer screen. Photoshop will turn into interactions like a painter.
50 AI programmers programming for you.

This one guy uses Photoshop as a benchmark. 99% of Photoshop is obsolete given the new AI interaction pattern of highlighting an area and changing it.

Science advances in funerals. An artist is never valued until after they die.

Asymptotically exponential
The bitter lesson essay. Scale is all you need.
Now I make an app in a weekend even though I don't know how to code.
We are democratizing access to intelligence not just knowledge.

#ai #UX

We desire to fill space, conceptual and physical. Forget for a moment that space is already filled and hollow cannot be as it is conceived. Imagine the space in between here and there. So much of how we operate is grounded in self-defined laws of reality. You can’t get there from here without filling the space between with something, most likely action or movement.

Or can you?

Let’s say you can.

I’m not suggesting that you can place your body in various locations on Earth without some manner of locomotion. That may be possible but highly unlikely. What I am suggesting is that doing nothing is always a valid option. The space between doesn’t need to be filled. It doesn’t desire to be filled. Our own discomfort with inaction is what moves us. Our little biological processes conspires, moment by moment, to move us in some desired direction. Survival is hard-wired and we are grateful for that. For just a moment though let the need to do something go. You can have it back after this. Simply feel what it means to exist. You might find that once you do you’ve gotten where you want to be.

[[_SVA]]
#ux #ai 

https://www3.weforum.org/docs/WEF_Artificial_Intelligence_for_Children_2022.pdf

Ethics, bias, and liability
A11y, neuro-divergences
Audience appropriate
Does not promote bullying or addiction
Is explainable.
[[Compass holders give you direction and inspiration by staying a few steps ahead.]]
[[Yoda keeps you balanced by pointing out what you do that nobody cares about.]]
[[Co-pilots will collaborate with you.]]
[[Connectors bring you to others and others to you.]]
[[Optimizers keep your work from being ineffecient so that one aspect of the work doesn't overwhelm the others.]]
[[Challengers are the immovable objects to your unstoppable force.]]
Look for these people in your life. Find a way to enlist them on your journey. Seek their advice in earnest not out of obligation and heed their advice as you hope they heed yours. Building a circle of mentors is not tough to do.
If you’re ever someplace strange and you don’t think you can connect with the people around you, talk about pizza. Rare is the person who has not experienced pizza. You may disagree on many of the details but the shared ones are what matters. Show up any place with a pizza and you’ll make friends. 

[[_SVA]]

Humans are obsessed with truth. We look for truth in everything. Knowledge can be said to be the pursuit of truth. Americans created a ritual of swearing to tell the whole truth and nothing but the truth so help us God. Scientific inquiry exists to uncover truths about perceivable reality. Deception is a slight against people so severe that we cry for visceral benediction in response. Truth is the foundation we build our lives on. We need a foundation. We’ve called it truth. 

Trust is an expression of truth. With few exceptions humans only trust what we believe to be true. Our challenge to creating trust then is knowing what others need to believe to be true.

If you’re a person trying to gain the trust of another the prevailing theory is that all you need is to convince the other that you will not harm them. Said another way, you will not take anything from them, namely their physical safety and more abstractly their sovereignity.

If you’re designing something which needs to gain the trust of your audience the challenge can seem insurmountable. It’s not.

True, truth, and trust share a root. These concepts are inextricably linked and great insight can be found in that link.

If you want to gain trust determine what needs to be true and make it so.

[[_SVA]]
[[Loose systems encourage appropriation or at least allow for it]]
A prime value of the object-oriented approach is that it reduces the cognitive load of the audience.
The psychological underpinnings of object-oriented UX are gestalt and ecological.
Avoid separating the action from the thing it acts upon by keeping the button and the object close by.
Traditionally UX is verb and flow based not anchored around objects.
Events and articles are example of considering content types as objects.
Don't use a product photo for a category, use a category photo as a category and a product are not the same object.
Different objects need to look different.
Because lifts and trails are connected they need to be connected in the app. Gerry McGovern calls connected objects Twins.
Make sure the actions present are relevant to the object and context.
Use nouns from interviews, branded content, and posted media to create objects.
A useful ChatGPT prompt for pulling objects from language is 'list the nouns from these documents in order of frequency.'
Object-oriented UX teaches the Objects, Relationships, CTAs, and Attributes framework named ORCA.
*not written by me

Launching a new product that competes with existing solutions can be a daunting task. On one hand, you want to offer new and innovative features that differentiate your product from competitors, but on the other hand, you also need to provide important feature parity that meets the basic needs of your users. In this article, we'll explore how to balance innovation and necessity when designing for feature parity.

First and foremost, it's important to understand that users are unlikely to switch to a new tool unless their existing tool is either incredibly painful to use or the new tool is significantly better. Therefore, it's critical to offer enough functionality that users can reasonably use the new tool for simple versions of core use cases, even if it's initially more challenging to use. However, you also need to include features that make your product feel differentiated and appealing, especially at launch.

When launching FigJam, for example, the team actively traded off core functionality like a timer or voting, which other tools had, in order to build features that they didn't. They quickly followed up with those tools to create feature parity, but their initial focus was on providing unique features that would attract users. For example, FigJam offers cursor chat and high-fiving, which are not available in other collaborative design tools.

It's also important to show momentum in building new features. As a new tool, you want users to trust that you will eventually get to feature parity, even if you're not there yet. Therefore, it's critical to have a roadmap that shows users what features are coming in the future and how they will benefit them.

Ultimately, the key to designing for feature parity is to strike a balance between innovation and necessity. You need to provide enough functionality to meet users' basic needs, while also offering unique features that make your product stand out. By doing so, you can create a product that attracts users and keeps them coming back for more.

[[_SVA]]
#ux #ai 

https://adamfard.com/blog/ai-ux-design

https://uxpilot.ai

Breakdown of using AI tools in the UX process. Definitely a good find.

The best practices of AI begin with trust. This author uses Bjorling and Ali's 4 pillars as a framework for these AI behaviors.
 - communicate the AI's capabilities
 - the AI resonates with the users in its communication
 - the AI is flexible
 - the AI is ethical

Designers are more prone to adopt AI as a virtual assistant. People (read: designers) tend to trust AI more when they feel in command.
#ux #ai 


Human beings have developed a remarkable talent called projection. Projection in this instance refers to a mental time jump into the future. As a species at some point we started to become aware of the idea of consequences, that you can thread your current actions with a future result. This is a highly useful realization. It is not without fault. Many enlightened minds will tell you the future doesn’t exist. Regardless, we have come to understand we can control the world around us to create specific outcomes. We could not do this without an understanding of consequences. We could not get better at it without projection.

At all points we carry with us an aim, something we’re trying to accomplish. We work to change what we can in order to see that aim fulfilled. Projection helps us determine how to bridge the space between now and what we want to be different. We project because the variables are too complex to manipulate in the moment. No brain can correctly navigate the now without preparation. It is why we have an aim. A guiding light. The simple truth is that as immense as our conceptual power is we cannot handle reality and our intentions at the same time.

Mitigating that inadequacy is simple. Your tools are planning, rehearsal, and play. Planning sets up the play space. Planning gives you the script. Planning lays out the path. Rehearsal is walking that path. Rehearsal is the execution of that plan. Play is the keystone. Play determines the table stakes. Rehearsal doesn’t happen in the moment so the stakes can’t be the same. You want your play conditions to be as close to the real conditions as you can make them with one crucial difference. Play says it’s okay to get it wrong. Play says your rehearsal can be a failure. Play says try again.

If you want to achieve success your main focus needs to be on planning, rehearsal, and play.

[[_SVA]]
#ux #ai 
‘Does the design meet the goal,’ is the obvious response to the question, ‘is this design effective?’ Does the design create the change it was intended to create? Does it leave a mark?

We often consider designs ineffective when they don’t produce a value, fill a need, improve a life, or if they negatively impact the world. If these conditions aren’t met most humans won’t even bother with the action.

Ineffect is a tactic of subterfuge. You can disrupt a system by making it ineffective. Introduce subtle diversions, add steps, slow it all down, or speed it up. This is how bureaucracy shifts and the DMV becomes a hell space of waiting.

We might do well designing more ineffective things. Instead of thinking about ineffective as the fail state before effective make ineffective the goal and effective the fail state.

[[_SVA]]
I wonder if there is a level of complexity above which something cannot be designed. It seems to me society is an emergent event that catalyzes the working elements into a stable design and not a conscious act of producing an outcome.

Or is it that the boundaries which circumscribe society are designed and the middle is left to figure itself out?

Systems are an increasingly popular consideration amongst designers. Society can be conceptualized as a system. Though the elements of that system may be too numerous to be articulated well enough for design.

Design is tricky. It has limits but can be limitless. In a highly abstract way, life is designed. Yet I’m skeptical the task could be completed if it were a conscious act. Gods can design anything. Nature can design anything. Humans, maybe not so much. I find a certain arrogance in the promise of design which exists in contrast to the hope of design. Is society proof that design is an illusion or merely that myopia is real and design truly is all encompassing?

[[_SVA]]
#ux #ai 

https://uxofai.com/

Begin with human-centered machine learning. Set expectations about what the AI can do. Explain the results means showing the math. [[Communicate confidence with multiple options ordered by rank.]] Design for failure. Know when to bring the human in the loop. Keep the user in control. The AI grows in capability the more you interact with it. Monitor and change your model over time. Personalized AI can become an echo chamber if not planned for, consider including a contrarian AI. Don't give AI a personality outside your brand values. Chatbots are not for single tasks. [[Prototype with real data and fake AI.]] Design with everyone. Be transparent with your users about your data policies and processes. [[Don't collect what you don't need, use on-device ML instead.]]

https://medium.com/google-design/human-centered-machine-learning-a770d10562cd
A bad idea is a highly valuable idea because it reveals to you much about what you consider bad. Prospect theory teaches us outcomes are perceived as gains and losses and that losses feel massively worse than equal gains feel better. Basically that fear of loss drives our decision making. It’s more that fear of loss creates a frame and a biased perception in which the least bad option is the best option. Knowing how much bad you’re willing to bear is a consideration.

Draw a chart or a pie graph or some blob thing and use it to map the relationship of percent good to percent bad of your design. Removing the bad instinctually though erroneously correlates to the addition of good. In actuality, goodness is not a default so the space remains empty. You must also imagine ways to add goodness but it’s easier to convince people of the value of removing something bad. Which is how we get problem solving and not value creation as a key skill of successful industry tycoons.

If you can predict when something will go bad you can mitigate against it. Culturally we have rituals like regular doctor visits. We have spoiled food. Knowing something bad may happen and protecting against it is human nature.

Create a lot of bad ideas. Pull good ideas apart into bad idea. Get all of the bad ideas out. You’ll know where not to go and that will help focus the way.

[[_SVA]]
#ux #ai 

https://girardin.medium.com/experience-design-in-the-machine-learning-era-e16c87f4f2e2

A good heuristic is a profile detox which allows users control over the data. Good recommendation engines have humans cleaning datasets and mitigating the limitations of machine learning.

Algorithms are evaluated on their precision and recall scores.

Variable schedule rewards are a slot machine technique applied to the attention economy.

A good heuristic is to consider the feedback loop. A challenge is understanding.
 - Co-create a tangible vision of the experience and solution with priorities, goals and scope
 - Assess any assumption with insights from quantitative exploration, desk research and field research.
 - Articulate the key questions from the vision and the research. Is the team asking the right questions and are the answers algorithms could give actionable?
 - Understand all the limitations of the data model that gives answers.
 - Specify the success metrics for a desirable experience and define them before the release of a test. The validation phase acts as stopping point and it must be defined as part of the objectives of the project (e.g. improve the recall of the recommendations by 5%, detect 85% of customer who are about to default).
 - Evaluate the impact of the data engine on the user experience. As stated by Neal Lathia, it is particularly hard for data scientists to work “offline” on an algorithm and measure improvements that will correlate with improvements in the actual user experience.

The moment before lightning strikes is a moment few humans are fortunate enough to witness. This miraculous occurrence reveals an incredibly important aspect of energy. You see, the moment immediately before the flash, the release, the thunderous crash of particles, in this moment before, a small part of the Earth reaches up to receive the lightning. Lighting doesn’t happen to the Earth. Lightning happens because of the Earth, because the Earth needs the release, the connection.

Michelangelo got it right. The moment before you act, a small part of the world is reaching out to receive you. It needs you to contribute. It wants you to contribute. There is great power in this moment. Use it.

[[_SVA]]
#unity #programming 
Not a cost benefit of using open-source models in production. The economics are not in favor of small scale AI.
You have not mastered a song when you can play it perfectly, you have mastered a song when you cannot play it imperfectly. What may seem daunting at first becomes effortless through repetition and adaptation. Whatever you’re facing is easy, it just might not be easy yet.

[[_SVA]]
You can’t design the past. That may seems obnoxiously obvious but it points to a crucial notion about design. Design is always about new. You can design something to seem like it could exist in the past but you can’t design backwards. This means design is the domain of a certain type of person. The type of person that continually seeks to create change. The skills and mindsets necessary to be a good designer are about motion. Designers envision a possibility and then work to make that vision a reality. If you live for the way things were you may find designing displeasurable. That’s okay. If you crave exploration and possibility then the world of design could well be your home.

[[_SVA]]
Open a terminal window to find out the version.

Type python3.11
Exit() to exit
cmd + D exits
quit exits

python -c command [arg] ... is another way to start python

python -m module [arg] ... to access modules

Adding -i before a script enter interactive mode after running the script

print(type(var)) prints the type of variable

import keyword > print(keyword.kwlist) will print the full python keyword list

** is exponent 2^3 or 2 x 2 x 2

// is floor division operator for no remainder

% gives remainder

commas aren't for numbers

input() takes an input

hashtags start comments

Python does not treat all numbers the same.

Blocks in python need to be indented.

if and else statements end with a :

if 5 > 6:
 print("nope")
else:
 print("yes")

def {name}(): creates a function

input() types is a string by default

return {var} is how a function returns a value

#code #python
Microsoft conjectures on Sora. 2/27 and 2/28 update.

Core architecture is diffusion model. Peebles at UC Berkeley. Image was extended into video.

More picture frames in each second for realism. 15 seconds at MAX. 60sec with Sora. Did not do any physical simulation.

Emerging properties are 3D consistency, long-range coherence, and interacting with the world. These are built from a larger video model. Emerging properties are not in-built.

Video encoding -> VAE -> Diffusion transformer

Video Latent Diffusion Model compresses videos into latent tokens and that is how video is represented in Diffusion Transformer architecture.

We use the internet data and image caption. System learns. Lots of noise with internet data. Trained an image captioner. Generate a text description, self-trained the caption then trained DALL-E 3. Which is different than MidJourney.

Retrained video captions like training DALL-E3. Before transformers there was U-Net is CNN. Transformer likely to dominate AI architecture.

Loss function is based on diffusion but core architecture is transformer. Measure the loss between the real image and the white noise.

Autoregressive decoder only by Google not a diffusion model. Build a neural network from the diffusion process in order to start from noise and produce and image.

LDMs compress image into latent space of tokens represented by vectors by a VAE. Then reconstruct it through a decoder. Best hidden the best latent space.

Image is an RGB 3D cube and a time cube gets sent to encoder and instead of vectors your get cubes. Then you decode it.

Batch is how many data points you have. No matter how small a batch you still have a time dimension.

Images are compressed into latent tokens by VAE. N model should be massive. The larger models perform better. GPT-4 is estimated to have 128 transformer layers. This is the power source of Sora. at least 48

Token is not for image. Token is for video. Image is a special case of video.

400m text image pairs for DALL-E 2
Find the closest image pairing to guide the conditional diffusion model to create images.

Text to video caption

junlinghu@gmail.com
https://arxiv.org/pdf/2402.17177.pdf

The positional encodings are directly related to the patch. 32 x 32 is all you have for position space. Upsampling to make it bigger. Give a 32 x 32 input and a 32 x 32 output.

Get a hold of a diffusion transformer for Sora. Google has VideoPoet which has audio.
#ux #ai 



[[Statements are made of keywords, expressions, and operators.]]

#programming #beginner 
Play is design in an important way. Play is an unrestricted mindset of possibilities. Play allows us to try and fail without our failures being fatal. Design is about creating pathways to success. When you play you’re continually trying to reach an end goal but you understand there are low/no stake consequences to your actions. This frees you up for experimentation, trial and error. You try more. You probably err more as well but it’s play so who cares?

Play in a social environment is a little more restrictive because the consequences aren’t as low stakes. Now you have to contend with the effects of your actions on others. This is likely why social play comes in the form of games with rules and codes of conduct. Play is no longer freeform but it still carries a low/no stakes quality, provided you play by the rules. Society even forgives transgressions during game play.‘She got caught up in the moment’ is something you might hear or say as an explanation of misconduct during play. Red cards don’t carry over between matches.

Design is learned through play, through the imaginative combinations of disparate elements for no reason other than because. Get better, play more.

[[_SVA]]
I seek to find pleasure in it.

If the end result is expertise then all the better.
Market research leads down the wrong path but with confidence because of numbers. They can say 62% of survey respondents indicated they wanted this feature.
There is an order of operations to your mind. Modern neuroscience teaches us that we have layers to our brain. Not conceptual layers but actual hard-coded meat sack layers of brain that stack on each other. The stacking order goes physical, emotional, intellectual. When you’re making decisions the order goes backwards; intellectual, emotional, physical. Before continuing it must be noted that of all the layers, despite the dominant narrative of our culture, the intellectual is the least powerful. Intellect cannot overpower emotions. This is a logical fallacy that it can. It is clever your intellect.

Rational decisions occur in the intellect. In fact all of reason is the domain of the intellect. A rational decision is one where the path is clear. The stars align. It makes sense. The conditions for a strong rational decision are clearly defined acceptance criteria, an accurate prediction model, considerations of probable alternatives, and no information left unknown. What do you want? Do you know what you need to know to decide? What other options do you have? How will each play out?

With each question considered a brick is laid between where you are and where you want to be. When the bricks line up you have a rational decision. Now you can decide to execute.

Reason exists to create structures to appeal to your emotions for permission to act. In the dominant majority of cases the decider is emotion. In the other instances the decider is your deeper physical nature, your ancient self if you will. No decision is made without the permission of your emotional layer. Which emotion decides is context dependent but every decision carries an emotion.

Rational decisions are the start. Emotional decisions are the end. Move away from the idea that you can logic your way through life and you’ll start to live a better life.

[[_SVA]]

OpenVINO(TM) notebooks on github are jupyter notebooks.
OpenVINO is an API.

```query
tag:#jupyter
```

#jupyter #openvino
The reason you do something in design is to uncover whether it was that thing which yielded results. Design is projective. It is abductive. Abduction is not about the way things are. Abduction is about the way things can be. It’s a form of reasoning to navigate the fog of ambiguity. 

Design is not deductive in that design does not expose when A is B and B is C then A is also C.

Design is not inductive in that does not expose when you do A B occurs

Design is abductive. It exposes when you do A and B happens then Q is the abductive cause. It goes backwards from conclusion to premisses. It deduces cause from effect. 

Design reasoning, abductive reasoning, allows you to move forward. It gives you ground to stand on, logically, to evolve something into existence. Abductive reasoning is human reasoning. Pay attention to when it is being used by others. Find a way to use it more often in your own life.

[[_SVA]]
#ux #ai 

No event or motion occurs without a catalyst. There’s always a cue, a prompt, a reason for something happening. Pressure is one such catalyst. Pressure can be the slow squeeze or the panicked fire. Pressure is an easy concept to understand. Pressure presents itself in obvious ways. Materialistically you see pressure in explosions, cracks, and breaks. It is well known that pressure makes diamonds. Can pressure be a tool for producing outcomes? One could argue it is the only tool that will as no event or motion occurs without a catalyst. The breaking point is a powerful catalyst. 

To understand pressure’s effect on people look to stress. You can see erratic and fearful behavior under pressure. Pressure is what does people in. Look to the weight people bear. Which mountains, which earth rests on the shoulders on an individual? Most likely it is the weight of status, of being seen favorably in another’s eyes. Laws, norms, rights and roles are ways to create pressure. Shame and excision are also ways to create pressure. Competition is a form of pressure. These are the tools for creating pressure. What the outcome is depends on you.

[[_SVA]]
Think about having a control rig that works on a binding rig to allow for the binding rig to only worry about one input.https://threejs.org/docs/#api/en/renderers/WebGLRenderer

#unity 
https://www.linkedin.com/events/futureproof-howaiandmachinelear7169060789000101889/theater/

Dovetail's conference for product people, 4/11 Inside-Out, from Australia

Lead product designer at Dovetail. Introducing AI to the research process.
 - Happiness spikes but returns to the baseline.

Jess, Canva Principle Product Designer
 - Environmental impact of AI is trashfire.
 - Look back 10-15 to trace trajectory on the future. Think about AI in the sense of the iPhone.

Raising the ceiling and lowering the floor. Hard time to imagine that centering people will never not be valuable. Solving problems for users. Design won't be kicked out of the industry. The human input is critical. AI still needs the human.

You bring me in when you get stuck. You can make it on your own. You can grow. If you aren't growing it could be your user experience. You would look to satisfaction, reviews, 

Canva is part of creating a day of love and not about creating great wedding invites and seating placards.

There is value and benefit in AI summarizing and consuming large amounts of data, automating documentation, and automating pixel-perfection in UI files.

[[Text prompts are not a good UI tool.]]

Designers will still act as creative directors and creators not just curators. Designers are still the drivers. Automating the busywork and giving ideas is where AI is most valuable.

Don't think about the output, focus on the human layers of design. Focus on solving real human problems.

Think about the visible and the invisible design. MMMMMMMMMM>>>I DUNNO. This parable seems to me like saying, of all the ways this turned out what could have happened didn't. Think about all of the decisions you could have had to make if you didn't do it this way.

How can you reduce the biases in AI. Bias in AI comes in bias from people. Work on your people biases and your computer biases will follow. Set up people bias tests against AI.

Building systems that improve it's trust over time. Making sure you can opt out of data collection.

[[AI will never completely level the playing field.]]

Designers need to test edge cases.

A quick thumbs up and thumbs down helps prioritize AI features. Ask users whether they were able to accomplish their task with AI or not. The fun is in the learning process.

[[What do you want to automate?]]
An AI that tells you how to fix things
Recycle AI
Upcycle Ai
 - shows you what you can make with your stuff
 - finds what has sold that is similar and how much it has sold for
PartAI
 - a party planning, MC, and day-of-coordinator app
 - OR a dope app that brings the PARTAY!
AI for civic engagement
 - AccelerateSF
Style can't be democratized. Brands won't look the same. Portfolio templates without personalization are obvious. AI without the human touch will be obvious. Never forget the math behind it's eyes.

Stay curious. Be proactive. Talk is cheap. Take action. Apply what you learn. Build, test, repeat.
Time expands to fill the space allotted. If you don’t decide when to stop working you won’t. Space is necessary to be inventive, imaginative, and creative. Time enjoyed is not time wasted. Maybe you feel looking back that the time was wasted. It wasn’t.

Wasted time feels like wasted time in the moment.

Shared time you feel is wasted time is not automatically wasted time. Shared time could be frivolities enjoyed by multiple social members.

Is there not a place within you that would benefit from wasted time?

I propose there is. Wasted time is a feeling that the priority concern is not being given attention. The symptoms are a lack of progress. Over time grievances accumulate. You gain valuable information regarding your urgencies by exploring the feeling of wasted time. If these urgencies recur, waste some time and dive in. Explore what lay beyond their bounds. You may stumble upon a related yet more influential area that will uncork the whole thing.

It could also be that you frustrate yourself into threats. Sometimes it feels that enough is enough and I’m done. It’s unfortunate we’ve arrived here but it’s relatable.

Design can take all kinds. Wasted time is simply a flavor in the stew. It has its time and place. Use as you see fit.

[[_SVA]]
What makes you think you’ll discover anything new if you’re seeing the same thing everyone else is. You have to change your perspective. Be willing to look in ways others aren’t.

[[_SVA]]
#ux #ai 


Pre-work
[[Download these models for Stable Diffusion webUI]]

This Meetup was conceived for all who desire to understand image generation software. We share a journey.

My intent is to expose what is important about AI image generation to an audience that wants to know both how it works and how to work with it.

This technology is multi-faceted and I cover a lot of ground.

I'm curious and I seek the answers to the questions: how does this work and can it do this?

This Meetup is me sharing my path and findings.

I'll be running this in a chat-only lecture format. I'll provide interactions. I'll be off camera and sharing my screen.


WHERE THIS IS GOING
By the end of what I'm doing here, actually, well, hopefully way before the end of what I'm doing here but certainly before the end of your involvement with what I'm doing here, I aim to expose you to the current patterns and functional foundations of AI image generation software,

I'm going to show you how you to design for these softwares

The goal is to give you the knowledge and tools to build up a skill in creating experiences for and with AI image generators.

*Agenda*
Patterns of UX in AI image generators
Challenges of UX for AI image generation
Heuristics to address the challenges of UX for AI image generation
Smash class on UX
Code 😱
Tools
Putting it together
 - [[Using AI for UX]]


PATTERNS
In this section you will get insight into the interface, interactive, and functional patterns many of the AI image generation softwares have in common. We're going to level-set awareness and establish a shared context.

We're going to look for common layouts, interactions, as well as patterns in task flows, error recovery, and overall experiences.

Our goal is 15 to analyze 15. You test with 15 people and you get at least a sigma of security. Or so I'm induced to believe.

Where to find these softwares?
The search term returning the most general results right now is AI image generation.
 - Google
 - Perplexity if you prefer
 - Product Hunt
	 - https://www.producthunt.com/search?q=ai%20image%20generation
 - Meetups
 - Newsfeeds
	 - https://wellfound.com/newsletters
	 - https://alphasignal.ai
	 - https://www.uxforai.com/
 - Social feeds
 - Podcasts
 - Market watches
	 - https://www.marketwatch.com/
	 - national labor statistics
 - VC firms
	 - https://www.ventureloop.com/ventureloop/home.php
 - Discord
	 - Most every company in this space has a Discord server.
 - Job boards
 - Friends
 - WeChat
 - Professional organizations
	 - I'll plug openCV https://opencv.org/
 - Zoom chats
 - Social channels
 - There's an AI for that
	 - https://theresanaiforthat.com/ai/aiart-fm/?ref=search&term=ai%20art#alternatives

The point is not to maintain a constant awareness of what everyone else is doing. Maintain a curiosity in the idea and you'll find your sources of information. Committing to quarterly reviews may be enough to maintain your list. Consider the black swans as best you can.

Let's check in on a few companies in the space.

*Question to the audience, what image generation software have you heard of or worked with or are excited about?*

Daniel's Pix

Microsoft Designer
https://www.youtube.com/watch?v=vCiuBCIBABo
 - What I dig about this is the interface. It is context aware and places the actions close to that which is acted upon rather than using a fixed menu where the actions are far removed from the object.
 - It is solid interaction design with good functionality for free. Adobe Express is a direct parallel, as are other tools.
Learning Playground
https://www.youtube.com/@playgroundai/videos
 - This guy is super cool. He teaches you about the software. In the process he shows you how the technology all these other softwares use works. Great place to go to learn. Great software to work in. It costs your data but you get 1000 generations a day and you get to play with stable diffusion.
Learning Visual Electric
https://www.youtube.com/@visual.electric
 - what Visual Electric is selling are their models, which they occupy as styles
 - They are winning with their eye. They are curated and artistic. For sure a model to back.
Facet
https://www.youtube.com/@facet_ai
 - image generator combined with photo manipulations, mostly levels and saturations and overlays and stuff
 - Facet is great for photo editors and  photographers. It is a low level but streamlined Photoshop and an AI backed Mac PhotoStudio.
 - Facet is selling tools and a workflow.
Krea
https://www.krea.ai/home
 - from https://www.artbreeder.com/ which is the earliest and best example outside of academia for these softwares today
 - I'm likely wrong about this
 - Krea is different. Krea is not selling a model, they are selling functionality, and they are straight winning on all fronts. From my perspective they are the people to beat and bet on.
 Makereal
 https://makereal.tldraw.com/
  - great interface
  - cutting edge of this idea
  - publicly available github (+1000 to the open source)
https://github.com/tldraw/make-real

Now let's talk about the big 4

Midjourney
https://www.midjourney.com/showcase
https://www.youtube.com/watch?v=HYdHNcodsS8
 - Generally considered the best in image quality.
 - Midjourney is, rightly, paywalled, and worth it.
StableDiffusion
https://clipdrop.co/stable-diffusion
https://www.youtube.com/watch?v=_uyAlqFMDlw
 - you'll find much information in the docs and blogs
DALL-E2
https://labs.openai.com/
https://www.youtube.com/watch?v=LZFd0UZbnww
  - DALL-E3 is paywalled by ChatGPT Plus
Firefly
 - is also free but for an account
https://firefly.adobe.com/
https://www.youtube.com/watch?v=zS5qQz81yGU

More models
LAION & LAION-Art
https://labelbox.com/datasets/laion-art/
Civit
https://civitai.com/models
#LoRA https://arxiv.org/abs/2106.09685

Insights
In this section you got a broad spectrum view of the interface, interactive, and functional patterns of the many AI image generation softwares out there and you realized they all have more in common than don't. The insight is that there is a technology that powers all of this and when you discover the patterns you discover its capabilities and you start to see the human intervention on the benefit of a consumer.

SECTION 2 – CHALLENGES
Let's talk about the challenges UX faces
[[Microsoft has pulled together their guide called the HAX.]]
[[IBM has a guide for AI.]]
[[Google Design on the UX of AI.]]
[[UX of AI website on AI.]]
[[Refire Design's take on UX and AI.]]
[[Kirill Lazarev on UX best practices for crafting AI excellence.]]
[[John Maeda's UX patterns for copilot.]]
[[Adam Fard with a new way of designing.]]
[[AI & UX with Hang Xu & Peter Gostev]]
[[UX and AI with Intelligence Briefing.]]
[[The Shape of AI in review.]]
[[Vitaly Friedman's take on UX and AI.]]
[[Ericsson has a guide to UX and AI.]]
[[Machine learning for designers.]]
[[Canva's take on UX for AI.]]
[[UX challenges from that one Meetup.]]
[[5 gotchas in AI.]]
[[Perplexity tells me the main challenges with UX for AI image generation.]]

Here's my hot take on the challenges relevant to UX for AI image generation.

We're going to start where it doesn't matter and end where it does.

The ne plus ultra
[[The main challenge of AI is how to translate subjective human needs, values, and experiences into algorithmic parameters the model can optimize for.]]

Other challenges are to keep the data appropriate to your audience, act ethical, and take accountability for the impact of AI as a whole.

These are lofty challenges like trust, ethics, and value. That's not what I'm about. Those challenges exist and are addressed but are too broad for this audience. This is akin to saying UX is going to change the world. And it will, right after rock and roll does.

6 challenges specific to user experience in particular, in my words.
 - indicating what the AI can do
 - installing ownership, provenance, and authenticity of training data routines
 - designing interactions for non-deterministic outcomes
 - providing feedback loops to improve the AI
 - managing user expectations about what the AI can do
 - keeping the user in control

In this section we took a wide view of the challenges the experts say the field of UX for AI image generation faces. Where I lacked evidence for the specific you were presented with the generic challenges of UX for AI. From this evidence you were given 6 challenges specific to UX for AI image generation

SECTION 3 - HEURISTICS
[[Microsoft has pulled together their guide called the HAX.]]
[[IBM has a guide for AI.]]
[[Google Design on the UX of AI.]]
[[UX of AI website on AI.]]
[[Refire Design's take on UX and AI.]]
[[Kirill Lazarev on UX best practices for crafting AI excellence.]]
[[John Maeda's UX patterns for copilot.]]
[[Adam Fard with a new way of designing.]]
[[AI & UX with Hang Xu & Peter Gostev]]
[[UX and AI with Intelligence Briefing.]]
[[The Shape of AI in review.]]
[[Vitaly Friedman's take on UX and AI.]]
[[Ericsson has a guide to UX and AI.]]
[[Machine learning for designers.]]
[[Canva's take on UX for AI.]]
[[UX challenges from that one Meetup.]]
[[5 gotchas in AI.]]
[[Perplexity tells me the main challenges with UX for AI image generation.]]
[[Check this video out for more UX & AI at Microsoft.]]

In this section you'll be presented with a set of beneficial heuristics for addressing the 6 challenges above.

Perplexity addresses the heuristic themes in three pairs.
Trust & transparency
Feedback & control
Ethical & human-centered

I agree and consider that a useful framework. 

Here is my summation.

Challenge: indicating what the AI can do.
[[You can generate buttons based on the most common prompts.]]
You seem to do this a lot. <- This is the ML part, the predictive part. Would you like to automate it?
[[This leads to the UX patterns of 'hey, this thing is an AI', 'here are some suggested actions', and 'give us your feedback.']]

Challenge: installing routines for ownership, provenance, and authenticity of training data.
[[You need to show your references, cite your sources.]]
[[Don't collect what you don't need, use on-device ML instead.]]
Find a way to attach licenses of use or other provenance data to your images both training and generated but especially your training data.

Challenge: designing interactions for non-deterministic outcomes.
[[Text prompts are not a good UI tool.]]
"Clearly communicate permissions, settings, recovery plans in case of errors, and provide a way forward based on the severity of possible outcomes."

Challenge: providing feedback loops to improve the AI.
[[Culture isn't static therefore the research cannot be static.]]
Design for the labelers.
[[Use user input to improve AI over time via feedback loops like answer ratings or Roman voting.]]

Challenge: managing user expectations about what the AI can do.
[[If a human can't perform the task neither can an AI.]]
[[Communicate confidence with multiple options ordered by rank.]]
[[Make waiting fun is a core UX for AI principle.]]

Challenge: keeping the user in control.
[[Allow people to turn the AI off.]]
[[Give the human the ability to override the AI's decisions at any point.]]
[[AI "here's what I'm going to do, are you good with this?"]]

HEURISTIC PILLARS
[[This leads to the UX patterns of 'hey, this thing is an AI', 'here are some suggested actions', and 'give us your feedback.']]
Find a way to attach licenses of use or other provenance data to your images both training and generated but especially your training data.
[[Culture isn't static therefore the research cannot be static.]]
[[If a human can't perform the task neither can an AI.]]
[[Make waiting fun is a core UX for AI principle.]]
[[Allow people to turn the AI off.]]

Nobody has UX for AI figured out. Jakob Nielsen, of whatever fame and clout you give him, wonders who will be the Jakob Nielsen for the AI generation. He points us to the fact that their aren't established heuristics for this technology.

Make sure you acknowledge and respect old knowledge but feel free to disregard all of it and use exploration and practice as your tools for learning.

Now that we have addressed our challenges and heuristics we can summarize it in:

DANIEL'S UX for AI Definition of done.

No AI can be released until it
 - indicates to the user what the AI can do
 - has routines for ownership, provenance, and authenticity of training data
 - accounts for non-deterministic outcomes
 - has beneficial feedback loops
 - manages user expectations about what the AI can do
 - keeps the user in control

From here on our focus will shift to how we work with the AI image generation software and design for it.

But first a beneficial deviation in the form of a

SMASH CLASS IN UX

This is not an aside, this is a smash class in neuroscience, ecological psychology, gestalt, perception, and human-factors engineering. Consider this a refresher if you're through and done with all the brain stuff in design.

Neuroscience

Ecological psychology
https://youtu.be/k4fKBqu-Ris

Gestalt
Visual illusion museum teaches gestalt on some level. These visual puzzles are core to computer vision. One important aspect of vision to consider is when it fails and lies to you. These computer vision models consider all that stuff.
 - check out a visual illusion museum or 
 - check out a real mirror, you'll realize you're being lied to every time you look in any other mirror
 - https://www.youtube.com/watch?v=4VWrl98KzCE
 - https://www.youtube.com/watch?v=20N53khArXA
 - https://www.youtube.com/watch?v=G-xD1bDoNl4
 - https://www.youtube.com/watch?v=ybLDSAWyEZY
*use chatGPT or perplexity*
 - https://lawsofux.com/

Perception

Human-factors engineering

SMASH CLASS IN UX FOR AI

The titans
[[People + AI by Google]]
[[John Maeda's UX patterns for copilot.]]
[[Ericsson has a guide to UX and AI.]]

Begin here
[[Machine learning for designers.]]

The cover of ethics
[[Designing AI For Children Toolkit (+ Checklist) by World Economic Forum]]

The end of the word on data
[[Designing human data by Thomas Otto.]]

No theory, all practice
[[Canva's take on UX for AI.]]

[[A few resources for machine learning and UX.]]

SMASH CLASS IN UX FOR AI IMAGE GENERATION

https://docs.astria.ai/docs/features/
If I were to build an image generator I would use this list as my starting point for features. I would include and exclude based on competitive positioning. What's cool is that you can dive into the information. You get the API as well as the interface.

https://gooey.ai/docs/guides/
These people give away a lot of detailed information.

https://www.youtube.com/watch?v=jtwl9M-UNQE
Also shows a breakdown and patterns for the dominant AI image generators.

https://youtu.be/ZtRnZHWXYfs?si=WE4FayKTU7SlOc97
Teaches you how to build a DALL-E GPT

https://www.youtube.com/@playgroundai/videos
Outside of Automatic1111 Playground would be the only place I go to use and study UX for AI image generation.

CODE
https://www.derekknox.com/
https://www.youtube.com/@AndrejKarpathy/videos



TOOLS
By function
 - UI
	 - UIzard
 - Persona
	 - https://ai.boardofinnovation.com/personas-maker
 - Persona
	 - https://userpersona.dev/

PRACTICE
At this point you've gotten a general awareness of what AI image generation software can do and we've seen the current experience trends and patterns, we've surmised the challenges and heuristics from expert witnesses, we've gotten a smash class in UX, we've seen the code, we've been introduced to the platforms. We've covered AI powered tools for UX design. Now it is time to put all this nonsense into practice. Let's build!

Good UX begins with the user, here's a discussion to define them.

[[Beneficial curiosities for the field of UX and AI.]]
[[Good research questions to improve an AI.]]

Indulge me in another diatribe, this one on personas. You can call them users, personas, archetypes, audience members, cast and crew. You can call them whatever. They are the people who exist and are human interacting with what you are making. It is generally considered a benefit to know who these people are and what they care about. Call that understanding whatever you want. What is important is that you and your compatriots possess and agree on a physical, emotional, and mental knowledge of the people you hope you benefit. Otherwise you are designing for yourself and your myopia can't sustain your efforts.

Give me places to find people who are into {x}

Who are the users and what are they using it for?
Who woke up this morning wanting to pay money for AI image generation?

*put some users and use cases in the chat, help people get an idea of what AI image generation is good for*

This question in particular is what these businesses are in a mad scramble to figure out.
I know creative agencies are trying to figure out how to leverage it for concept and pitch work. I saw a guy work to make movies and commercials with it.

Marketing is big into AI image generation for product photography. Fashion is into AI image generation for ideas and concept visualization. Canva is trying to keep AI in-house for creating social graphics and banners and the what not, they call it visual communication.
MidJourney gives you dope images but like, what value does it have for your mom or the cab driver or the CEO of Salesforce or your little cousin? These are the questions that will determine your UX.

I personally see these tools as democratizing visual talent so I think they will find their value in social media creation though they will most likely just be ubiquitous in any software, 'turn your quarterly report into a captivating 4 minute video, or turn your Notion database into an epic movie!' kinda thing

I'll create a persona based on that.

[[Using AI for UX]]
Ask perplexity to create a persona
You can get personas
https://userpersona.dev/
https://ai.boardofinnovation.com/personas-maker

Let's talk product ideas, *put a paid link in the chat.*

[[Turn this comment into an action movie. Turn this comment into a comedy staring Will Ferrell. Turn this comment into a hard-boiled detective film.]]

In this section we learned about the users and use cases. We crafted a persona with a value proposition, with a goal, and with a scenario.

SECTION 5
As a designer if you want to go beyond being a user of these tools to a designer of these tools then you won't get there by using them.

https://course.fast.ai/Lessons/part2.html
https://ml5js.org/

[[AI image generators explained]]

[[Artistic control is still missing from generative visual AI for it to usurp traditional methods.]]
To current, what you've been shown are closed environments, paywalled ventures, money-backed guarantees. You can't get in, hack them about, and build for them unless you are invited to. You can thread the softwares together in a narrative fashion but you can't alter them.

None of that is true for Stable Diffusion. Stable Diffusion is open source. A webUI has been provided for branching and download on Github. This webUI gives you access to the functionality, with minor competitive exceptions, of at least 80% and at most 96% of all AI image generator softwares. 

What we're going to do is install the Stable Diffusion webUI so we can hands-on, design our own AI image generation experience.

https://docs.pinokio.computer/download/



The generosity of the open source community and their impact on learning is near unparalleled.

Maybe long ago or at this point you disconnected. You work mostly in Figma. You don't do code so this is too much and not applicable.

You're not wrong. If you want to design
take and remix some of these softwares inside Figma you can do so. You can make prototypes, you can do flows, research, mockups, the works. That's what you'll be doing when you get employed. Maybe that's what you're already doing.

What you gain this way are access to the results. Designing in Figma is designing a dream. All the mockups are imagined until they can be made real, proven they cannot be made real, or abandoned as an effort. Figma can't return the results of a model. Yet. I guess. Because of this you don't consider as well the feasibility of your design. I'm all for dreaming and vision setting work but I find the pragmatic perspective, the one that works with feasible, is where the money is made. If your design is not released because it isn't feasible then it is not valuable to the same degree as a design that is released.

Another benefit of going through this code is a full exposure to the raw tools. This interface has been designed but not by a designer. You're seeing a baser state. The machinations of the experience. The exposed functions of working with a model. This perspective of seeing the raw materials is a better place for learning and growth than the other softwares where a lot of what you need to learn has already been figured out and made rigid.

I'm not saying abandon Figma. I'm a UX designer. I'm not going to not use Figma but we're going to bring it in at a different point.

Now for Stable Diffusion
What I'm so enamored of about the webUI is that it looks like something you'd get from a developer. Super rich and performant and structured but there's like a finesse that's missing, one that UX can create. This seems like the front, save for working in the model.
Using the IDEO vernacular, this is what you have to make desirable. This is what you have to bring the user to. This is the point of capacity, barring inventive deviations and as yet unknown personal revelations.

Code
The only code you need to know is copy and paste CTRL + V.
If you're stubborn, driven, or a savant you could learn brew, cmake, protobuf, rust, python, git, and wget.
Make sure you have a GitHub account
Making sure you are starting from a good base. What old and unnecessary software to remove for a fresh beginning and how to remove it.
We will go through that process.
 - [[To install StableDiffusion WebUI locally you need to look for AUTOMATIC1111.]]

We will start with Stable Diffusion 1.5. It is pretty not that great of a model. It is earlier stage but performant and tuned. I'm not much of a car person but an apt metaphor occurs to me. That of the Toyota Supra's infamous engine. It is bullet-proof. That engine has been tuned and refined as to thrive no matter what you throw at it. My understanding is that Stable Diffusion 1.5 is comparative. A highly tuned performant machine. You're not wrong to change models but if something starts behaving unexpectedly move back to the 1.5 model and see if you don't get the results you expected.

Download the recommended from AUTOMATIC1111 plus these

You may get stuck at this point due to the downloads. If you've got any going and it's wrecking your speed then cancel them. There's a list in the invite. . I want to do this realtime but this part is the worst. Understand there is a certain amount of set it and forget it and you get to carry your models around so you only have to set it up once per model locally. It is an unfortunate result of large file sizes.

What is pruned and emaonly?
What is .ckpt?
What is inpainting and why is there a separate model for inpainting?

Instruct pix2pix
https://huggingface.co/timbrooks/instruct-pix2pix/resolve/main/instruct-pix2pix-00-22000.safetensors'

SDXL Base 1.0
https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0

SDXL Turbo
https://huggingface.co/stabilityai/sdxl-turbo

LCM
https://huggingface.co/latent-consistency/lcm-lora-sdv1-5/tree/main

Now that we're at this point we're going to introduce huggingface and research.

Prompt engineering for Stable Diffusion. What are the qualifiers to produce the best results? Like MidJourney does but for Stable Diffusion?


Extensions you want to download
CIVIT AI from Github
Canvas Zoom
ControlNet github.com/Mikubill/sd-webui-controlnet
With ControlNet you need to download more models.
https://huggingface.co/lllyasviel/ControlNet-v1-1/tree/main
Move them into /extensions/sd-webui-controlnet/models
Pose Editor github.com/huchenlei/sd-webui-openpose-editor
Ultimate SD Upscale

Doing this all on a Jupyter notebook

THE EASY WAY
Doing this the easy way
 - https://docs.pinokio.computer/download/

Where's the gap? AI is terrible at graphic design. It is the worst. AI is terrible at typography. I didn't say text. Typography. It can't explore with letterforms. It doesn't bring the elements of graphic design together like a person can.

Also, ask people to turn their heads. AI has no third dimension so it'll mess up.


RECAP

SALES
If any of this is curious to you and you'd like to speak to me further or if you want someone to walk you through the steps again you can book some time with me through this app. $moneydollarsyall

$moneydollarsyall is also for a weekly breakdown of 5-8 things to know

cashmoney - create a 15 sec ad selling your content, paywall it all charge $4, at the end show most purchased other content, give away for free

$10/mo for class access and the reading group
Also $moneydollarsyall is selling a research reading club for UX researchers.

To UX researchers interested in the research behind AI image generation. Or to anyone really. You pay for the privilege of intellectual discourse.

[[Important AI papers for image generation]]

The books get you the reference texts and resources. The videos show you their greater context.

I've got a bunch of projects I could use a second and third person on. If you want to work on a project with me then e-mail me and I'll send you a list. If we align then we can make something happen.

If you want a career in UX and AI image generation here it is. You don't have to search or piece it together yourself. If y. You can or you can take this smash class in both.

If you want to be positioned at the vanguard of UX for AI image generation you need to follow me. This is my compass. I am alighted to it and though you don't know me, learn that I will see this through.

#ai #ux

```query
tag:ux
tag:ai
```

```query
tag:LoRA
```


https://lu.ma/join/g-H0Fgy36EF7vM1pF

Product-led growth (PLG) & sales led? Not sure.
3-month security review for enterprise when you say the word database.

Startups don't employ marketing agencies. Small to mid-sized business are. Talked to founder's on HackerNews. Found his first client on HackerNews. Knowing the basics of APIs helped understand the audience better and market to them more.

Pinecone created the vector database category. Category ownership is a long-term and risky play. Look for signals early on, like reporters writing about you and Gartner reports.

What do you believe needs to be true for you to hire a designer? What need does a designer fill for you? What situational conditions trigger the need for you to employ a designer?

Developer advocacy is a great growth and marketing tactic. Hire an ML engineer as a developer advocate to teach developers. Find out what your audience wants to learn about and give them the information.

Executive and directors are not likely to want info but the users tend to want the code snippets. Good advocates like to share and teach but don't value money to avoid the sales pitch.

Drive people to the product and get them through the product successfully is growth marketing.

Put up a waitlist to sign-up for a product as you scale from 1k to 10k to 100k. This will help mitigate crashes from capacity spikes.

Be #1 for learning up like DNS and Cloudflare, Git and Atlassian. Over 100 articles in the learning center. Make the content substantive.

This VP of Marketing is watching user's work with the product, identifying workflow problems, and finding confusion points.

What does the audience need to know approach the product? This is divided into three types: aspiring, average, advanced.

Google alerts for relevant keywords.

PLG gets self-serve support through a support chatbot they built. Let's pair up with our customers. Do they offer this service? If so then let's buy it from them.
You have to learn to recognize what you want because now you can get anything but.

https://www.linkedin.com/learning/using-ai-in-the-ux-design-process/

Tools to cover. All are free.
ChatGPT uses Natural Language Processing.
Notion will brainstorm and organize ideas but really it's just another prompting software.

Firefly will generate storyboards.
Figma will create images and text elements.

ChatGPT/Perplexity for research. Give me the value prop and major frustrations for 10 apps in the local market.
I'm a UX designer and I want to discover what motivates and stops users from purchasing comics.
Create a user persona for a local comic book store application.
Feed the model whatever information you have on your users, ideally via RAG.
Give me a list of features for an app beneficial to this persona.
Give me industry trends for similar applications

You can get personas
https://userpersona.dev/
https://ai.boardofinnovation.com/personas-maker

Give me a storyboard breakdown communicating the user's journey through the app

Firefly can give you imagery. I use Stable Diffusion or visual electric.

Use UIzard and chatGPT for flows.

Give me a user flow for this feature which incorporates these values and principles
also give me the principles and values to incorporate. Consider the afore created persona as the user for this flow.

AI plug-ins for FIGMA
Freepik AI
 - a mobile application interface for comic book store owners, keep it artistic but not overwhelming

Find me mobile application user interfaces that are desired by comic book store owners in San Francisco.

Act like an expert in UX and change this thing to make it better without making anything else worse.

A useful usability prompt
Create 10 usability test scenarios and tasks to assess the user-friendliness of a comic book store chatbot feature.
Consider new users, frequent users, and users who are leaving or have left your application.

ChatGPT can help you create surveys and the such for research.

Identify usability challenges for this flow but these are often generic.

Other places to learn about using AI for UX
https://youtu.be/prVP_M0j3uQ
https://youtu.be/vyWFS4DPpqA
https://youtu.be/_LdL1FpvcOg
https://youtu.be/dxfKQvp7DWM
https://www.youtube.com/watch?v=E_96lbbIlXE

[[UX for AI image generation Meetup]]
 - form, voice, and dissemination
	 - dissemination tactics: candy wrappers, food shaped as a flag, Kimonos, window shutters
 - subverting deception
 - sex pistols cover of Queen
 - forcing juxtaposition
	 - Robert E. Lee George Ffloyd projection
 - designers as protestors need to bear witness, religiously
 - [[The strongest form of protest is being ethical in what we bring to form.]]
	 - integrity is hard, money is easy
 - speculative design is exploring what something can be
 - You can augment a space without having to be there #AR
	 - frames help computer vision to recognize objects faster
	 - frames help the human eye to recognize objects faster, in fact, the frame is the only thing that helps human eyes recognize objects
	 - to increase computer vision recognition, train it with video of your artifacts in different lighting and contexts
 - Laws can't touch the alternate reality
	 - Brian Wassom is an #AR attorney
 - Take a moment and make it everything
 - 'Nothing for us, without us' is the #principle of working with people for their benefit instead of acting alone
	 - 'For the benefit of all and harm of none' is the #principle of moral, ethical, and personal guidance
Spending time shoulder-to-shoulder with customers is even more important as you seek to understand what they are trying to generate. It's generally not what they write as prompts but the deeper emotional desire. When I can have this amazing ability to write blogs, create images, do all the things generative AI promises with no inherent talent in any of them I'm seeking something at the top.
Generative AI is scary, complex, and new. The technology hasn't been socialized yet. Questions regarding social issues like authenticity are what drive the field.
Creatives train to have a style then somebody decides to use their work in an AI model and suddenly the creative's style is available to all. This biases datasets and negatively impacts a creative's livelihood. We haven't figured out how generative AI integrates into the lives of artists, it questions core arguments about ownership and compensation.
[[Loose systems encourage appropriation or at least allow for it]]
Is that it is necessary.

As an action design is intentional. Every action by a human is intentional. Action cannot be any other way. As a noun there is nothing about design which must be intentional. An object be it physical, metaphysical, experiential, temporal, or otherwise can possess a design devoid of intent.

Evolution is a viable mechanism for design. The evolution of the natural world is always in response to the moment. There is no future for a tree. There is no future for DNA, RNA, or any other perceived architecture of the natural world. Order has emerged from chaos. The universe and all things in it are the way they are because they are they way they are. Their design has no intention.

It is human nature to impose a design upon our surroundings. We must create an order to navigate our reality. Yet spontaneous order can occur, subsist, and thrive. It could be argued that this type of order is the most stable of all orders because it was born purely from circumstance. The best example to illustrate this point might be the bead spinner. https://www.youtube.com/watch?v=IFirAoh_1xY

In no case is design necessary. Yet, unless you prefer chance to dedicated effort it is often the best path forward.

[[_SVA]]
Syntax, Runtime, and Semantic error are three common errors.

Look up errors you don't understand on StackOverflow.

Semantic errors are unexpected outputs.
[[For interviewing to be fair and effective it needs to tolerate culture, discomfort, and biases.]] Basically everything is culture. Culture impacts what you don't see about someone. Your tendency, unchecked, is to project your own self-worth onto another. With this myopic perspective you'll find it difficult to see the values in experiences outside your own. What would this person's culture value is a back-pocket question for you to understand projecting yourself onto others. Instead, ask your conversation partner about their learnings and ways they see those learnings being effective in this context. Explore what people got out of experiences to understand their values and culture. In cultures with perceived deficiencies, think underserved and oppressed, we mistake not knowing with intellectual capacity & capability. Nobody is deficient merely different. Assume competence and test for incompetence.
#ux #ai 

https://futureoflife.org/open-letter/ai-principles/

An exhaustive set of principles on AI to adopt.
https://www.awwwards.com/AI-driven-design
Chapter 4, pg 29

In all cases you must consider this first and utmost.

Quoted from Nadia Piet, who also created the [[AI x Design toolkit.]]
It’s pretty easy to be myopic when designing for a living. We get caught up in the goals set for us. We focus on our minimum viable audience. We make decisions based on customer satisfaction, corporate returns, and retention rates. Which are all important and keep the design industry thriving. That’s not all there is to design. What you set your sights on is what you achieve. Humans are amazing in that regard. If you’re so focused on the small piece in front of you the bigger piece around you gets ignored. Even more insidious is being blind to the impact the small piece has on the big piece and vice versa. It is beyond the ability of any human entity to solve the biggest problems of our day. There will always be war, famine, starvation, the haves and the have nots. What we can do is design for the link between the small and big. Break free from designing in isolation and start seeing how you can create abundance for everyone. Create twice as much as anticipated so there’s enough to spread around.

[[_SVA]]
#ux #ai 

Consider actions across specialized models instead of the one model for it all. As with people, generality and speciality are beneficial in different situations and you do not expect the one from the other. Begin with the general and move to the specific. Right tool, right job. Right task, right AI.

#ux #ai 

Sometimes I don't want Google to think for me. I want to be in my own thoughts.

- Overhead at CCA event 3/12/2024
Chat GPT prompts
https://www.promptingguide.ai/
https://learnprompting.org/docs/intro

learning
 - "I am currently learning about [insert topic]. Convert the key lessons from this topic into engaging stories and metaphors to aid my memorization."
 - "I am currently learning about [insert topic]. Ask me a series of questions that will test my knowledge. Identify knowledge gaps in my answers and give me better answers to fill those gaps."
 - "I want to learn / get better at [insert desired skill]. I am a complete beginner. Create a 30 day learning plan that will help a beginner like me learn and improve this skill."
 - "I want to learn about [insert topic]. Identify and share the most important 20% of learnings from this topic that will help me understand 80% of it."

jobbing
 - highlight three skills required to be successful at this job description and create a bullet point list from my resume based on those three skills
 - optimize my resume for this job description
 - write resume bullet points for this job description, include metric based achievements

act as
 - Earnest Hemingway
 - Ernest Hemingway
 - linux terminal
 - "position" interviewr
 - javascript console
 - excel sheet
 - english teacher
 - plagiarism checker
 - advertiser
 - relationship coach
 - recruiter
 - archetype
 - Seth Godin
 - a career coach and give me top 5 skills for the following job, explain why
 - a Director of UX and ask me the 10 most likely questions about motivation, behavior, and technical knowledge based on this job description

explain
 - clearly
 - uniquely
 - detailed
 - like I'm five
 - with examples
 - like Elon Musk
 - like I'm in high school

chained prompting
 - write an article about [topic]
 - give me a several headlines, teasers, and subheads for an article about [topic]
 - give me three ideas from the article, and write blogs about those three ideas
 - write different headlines adding in the following concepts

marketing
 - provide me ideas for blog posts about [topic]
 - write a description for [product]
 - suggest inexpensive ways to promote [product] without social media
 - how can I obtain high quality backlinks to raise SEO of [product]
 - write a month of social media posts
 - give me a market analysis for [product]
 - give me research on the market size for [product]

development
 - develop a next.js architecture and code for a [product] website
 - help me find mistakes in this code *paste code*
 - continue writing this code in javascript *paste code*

design
 - how can I design a [product] website in ways that convey trust and authority?
 - what are some micro-interactions to consider for a FinTech app?
 - generate examples of UI design requirements for [product]
 - suggest a wireframe layout for [product] for [audience]
 - suggest ways to optimize [workflow]
 - create a user flow for [product] for [audience]
 - write design system component documentation for the [component], describe when to use, anatomy, placement, content, behaviors, states, and interactions, add three links for best practices of this component
 - As as a user reasearcher for [product] and ask me questions about my experience with [product]
 - generate survey questions to understand [audience] preferences and needs for [product]
 - what are the best practices for [ux pattern]
 - come up with what-if functionality for [product]
 - scenario planning
 - create insights from these notes: *paste notes*
 - create a checklist in table format to ensure [product] meets WCAG 2.1 AA standards
 - give me a competitive feature analysis for [product]

write a script for a story where {x} happens

compare these three articles and write blog posts on their similarities and differences, then pick out the three most important [topic] and write blog posts about those, finally give me video outlines for each of those blog posts and five instagram posts promoting each blogs

give me a video outline for these blog posts
[[Efficiency is measured in effort, think time-on-task.]]

[[Effectiveness is measured in accuracy, think success rate.]]

[[Error tolerance is measured by error rate and recovery options.]]

[[Ease of learning is measured by success rate of new people and new features.]]
#ai

https://ai.google.dev/
https://platform.stability.ai/
https://webapp.engineeringlumalabs.com/api/v1alpha/genie/docs
In the beginning was the Word. The mechanism by which all things were brought into being.

The dream of man to possess the Word is the primordial dream. Yet until now we have not so closely realized that dream.

Think about it. Sora, while a simulated world and in no sense comparable to the world of the Word, is yet still a world into which we will speak and it will change in accord.

The Word was made flesh as only the Word can but now our words will contain, in worlds and echoes indistinguishable from our own, their own preeminence.

The significance is not religious. Only a few know the Word and it's connection. The significance is of human nature. Our dream to posses the Word is protozoic, it needs no label, no language, no vision to be understood.

There's a duality in everything but unity. I imagine the dark side to this reality is corruption of the ego and disassociation. Speak and it shall be so is a powerful and heavy proposition. Once obtained, living in a world devoid of it, the world of the Word, loses flavor.

You may see this as pessimistic. Though I do concern myself with not the things of man, I am excited by the potential of Sora and wish I had a better way to end this narrative.
You have designed your next steps since you the moment you awoke to the world. All of the next steps which don’t come pre-packaged at least. Through testing and feedback, trial and error, you’ve learned the actions and the order of achievement. Many of those actions were constructed as hypotheses and tested against. Have you achieved what you set out to achieve? Yes. WOOT! No. Woot! This is designing.

We need to acknowledge that an element of predisposition exists in our structural makeup. We need to acknowledge that certain people are more likely to do certain things. We form clubs of commonality and call them communities based around our predispositions.

It follows then that certain people are likely to design actions in line with their predispositions. Each of us has an inclination for how to approach a situation.

[[_SVA]]
https://github.com/AUTOMATIC1111/stable-diffusion-webui

#stable-diffusion
#ux #ai 

https://designhumandata.net/

Data privacy
As a designer, I have spent the better part of my career championing the idea that "the interface is the system". This principle holds true across a wide range of design disciplines, from software and hardware to digital and physical products. Essentially, the interface is the point of interaction between the user and the system, and as such, it plays a critical role in shaping the user experience.

The interface is more than just a surface-level design element. It is the embodiment of the underlying system's functionality, and it is where the user's mental model of the system is formed. If the interface is poorly designed, the user's mental model will be flawed, leading to frustration, confusion, and ultimately, a poor user experience.

Therefore, it's essential for designers to approach interface design with the same level of care and attention as they would any other aspect of the system. It's not enough to simply make the interface look good; it must also be designed to be functional, intuitive, and user-friendly.

One of the key principles of good interface design is simplicity. The interface should be designed to be easy to understand and use, with a minimal learning curve. This means minimizing the number of options and actions available to the user, and ensuring that those options and actions are clear and well-organized.

Another important principle is consistency. The interface should be consistent in terms of layout, terminology, and functionality, so that the user can easily navigate through the system and understand how to use it.

Finally, designers must always keep the user in mind when designing the interface. The interface should be designed to meet the needs of the user, rather than the preferences of the designer or the requirements of the system. This means conducting user research, testing, and iterating on the design until it meets the needs and expectations of the user.

In conclusion, the interface is the system, and as such, it plays a crucial role in shaping the user experience. To design a great interface, designers must approach the task with the same level of care and attention as they would any other aspect of the system. They must focus on simplicity, consistency, and user-centered design, and be willing to conduct research, testing, and iteration to ensure that the interface meets the needs and expectations of the user. By doing so, they can create interfaces that are not only functional, but also intuitive, user-friendly, and enjoyable to use.
Nature figured it out a long time ago. Trial and error. Feedback and change. Adaptation. This is how humans learn. This is the only way humans learn. All of life has to do with improving the try to gain more valuable feedback from the error. When you are designing you’re trying and erroring at all points. The feedback loop is constant and multi-layered. Processing the feedback into the next try is what gives importance to processes, the how. An unfortunate truth is that given the nature of complexity success is never guaranteed. Process leads to product easier but process is not perfect.

Consider a shift instead from improving processes to improving inputs. You have to put constraints on your feedback. It is highly beneficial to you when your learnings are pointed in a meaningful direction. That’s a lot of what design is. You want to control the variables to produce the outcome. What you accept in as feedback is as important as what you leave out. There is as much space between trial and error as there is between error and trial. Improve the try by improving the input from the error.

Said in a more simple manner. The lesson you learn from falling down stairs is not that your shoes don’t match your belt.

[[_SVA]]
In cockpits, widgets emit noise when they require interaction or attention.

#IxD 
https://github.com/topics/virtual-try-on

https://github.com/LZHMS/Virtual-Tryon
Python terminal
 - has SDK installed
 - pip install landingai~=0.3.0
10 image minimum to train model
Detection
Segmentation
Classification
Visual Prompting
Make the bounding box tight to the object
Shows you which predictions are not correct
Add metadata tags to help navigate training datasets
Usually better labeling of data changes performance more than adjusting hyper-parameters or models.
Deploy a model to an endpoint in the cloud, you can send images to an endpoint.
To use edge you need a docker container and some sdk calls to run against.
Stream video to a container deployment not the open endpoint due to internet bandwidth.
Add trackers to avoid counting the same thing twice.
Two predictor options, one pointing to recognition the other to classification via sdk. You would split these tasks with two projects.
Redpoint detection architecture.
#ai
Must store variable and data  in the computer memory.

= as an operator assigns the right value to the left value

In python strings data require quotations marks to denote it as a string.

[[Variable names contain letters, numbers, and underscores in python.]]



#programming #beginner 
#IxD
https://youtu.be/k4fKBqu-Ris

The relationship between an organism and its environment is a dynamic relationship.

Properties of environments
 - Environments surround and are extended
 - Environments are structured
 - Environments consist of substances, substances have sufaces, the surfaces are the boundary between the substance and the environment medium

Light is structured characteristic to a surface, texture, color, orientation, shape

Perception fundamentally enables an organism to move through an environment. Perception exists to support action. Action supports perception and reveals structures.

Invariant structure is structure that is constant across changes of orientation. Perceiving objects is perceiving invariant structure.

Retinal image is a two-dimensional projection of an object.

Invariants are revealed through action. What is revealed is a property of the object.

Invariants are not frozen in time but are revealed over time.

Structure is revealed through action.

Information specifies some feature of the environment.

Vistas are that which can be seen from a given observation point. Transitions are movements between vistas.

Transitions are critical for wayfinding in an environment. Distinctive transitions help wayfinding better than non-distinct transitions.

If your body mass is increased the perceived slope of a hill increases and distances seem farther.

Objective and subjective dichotomy is not helpful in psychology.

Roger Barker psychologist, (Ecological psychology, 1968)
Collectively generated structures create opportunities for our lives. Behavior settings occur naturally as the function of the collective actions of individuals. Behavior settings can be specified objectively, are time bound, and are relatively stable. You know when you enter a behavior setting and know what the behavior expectation is.

How can you predict behavior? The best predictor of behavior is location. [[The behavior of different children in the same setting has less variability than the behavior of a single child across settings.]]

Behavior settings and affordances constitute the resources of an environment from an ecological point of view.
Explainability
Showing the math. Humans are accountable to other humans for the actions of the AI they use. Because of this the AI needs to give a rundown of what it will do, the reasons why it will do it, and how it will improve. These are common expectations in learning environments.
 
Model drift
You need feedback loops.

Actions across specialized models
[[Design for workflows not monoliths.]]

Comprehension
AI is technical and many don't know how to work with it.

Implementation
Not only where to use AI but how to get AI to the people.
Names don't start with numbers. Names can't contain spaces. Names are case sensitive. Names can't be keywords.

#programming #python #beginner 
This is going to sound harsh. There's a good chance when I get done saying what I'm going to say that you're not going to like me at all. #communication 

[[If you make a point to talk about integrity there's a good chance you've been betrayed in the past.]] #communication 

"This lady is probably telling her colleagues how lucky this guy is that she's even speaking to me. I was thinking about the positive to that negative and it occurred to me that she probably sees herself as being generous so when she came back I said, 'I want to thank you for being so generous with your time.' #communication 

This is ridiculous. Another random person with a selfish request. Your company is hiring. Are you against connecting over your work experience?  #communication
reach out to chat, talk shop, learn more about each other

It seems like you have a reason for saying that...wanting that...asking that.

Think in terms of influence and not leverage.

People who want to meet you halfway are often a poor judge of distance.
"Yeah, I generally use that to get what I wanted all along. I'll say I want a win/win deal and high anchor. Then I ask them to meet me in the middle which is where I always wanted to be."

It seems like this is important to you and you have a reason for saying that. I'm afraid I have some concerns.

It seems like you're hesitant. It seems like you're skeptical. It seems like I haven't earned your trust yet.

Negotiators with massive egos love flattery. Feed their ego. If anything goes wrong, take full responsibility for it (especially if it is their fault.)

There are so many companies out there with similar products – why are you choosing to do business with us?

What is your vision of this deal moving forward?

It seems like we're one of the top companies you're considering.
add 'high key lighting' to prompt
add 'low key lighting' to prompt
hard light
soft light
bokeh
fill light
rim light
add a spark in the eye
rembrandt lighting
add time of day (noon, sunset, golden hour, night, sunrise)
add atmosphere (cloudy, foggy, hazy, story, sunny, rainy, sunlight rays)
ar 4:5 (aspect ratio 4:5)
when you start describing face details MJ will focus on those
add 'in the style of [x]’ [alphonse mucha] to the prompt
add clothing texture details to prompts
The better idea is How.

How is a question without an assigned direction. How goes up, down, close, wide, out, in, through time. How frees your mind to form connections without predispositions. How is more likely to lead to insights because it comes with less baggage. It is value neutral. How brings the elements of the situation into focus in ways that Why can’t.

Why is a terrible question. Why is a unidirectional vertical question. Why goes down. More Why gets you deeper. The promise of Why is the understanding that seems to come on the other side of it as if Why connects the pieces, provides the clarity, shows the full picture. Why has erroneously been deemed the path to epiphany. Assuming that asking Why will get you there is illustrative of the very reasons it won’t.

Aimed at a person, Why is about intention. Nobody likes to be asked Why. When you ask Why of a person it’s an attack. Typically the only time anyone works to uncover another person’s intent is when they feel corrective action is necessary. As if there is ever something about another person that needs fixing. Why triggers a defensive reaction. Why is a weapon of shame, guilt, and exclusion more than it is a tool for exploration. Understanding intent can be beneficial but using Why to get there is the physical equivalent of beating it out of someone. What you’re likely to get with Why are obfuscated rationales, secondhand truths, or flat out hostility.

When you ask Why of a system you’re seeking causation. You want to know the factors which came together to produce the current state of the system. The popular 5 Why’s approach seeks a root cause as if a system can have a root. No system is so simple as to be able to trace an outcome to one point. Systems are chains of causation impacted by variables too numerous to comprehend. Asking 5 Why’s in a row only gets you five answers loosely linked by virtue of the chronology of your responses. Chances are high those answers have mistakenly created a chain of causation that doesn’t exist.  

How makes you consider the web of influences that conspired to produce an outcome. How causes you to get curious about behaviors and interactions. How creates an information rich environment. How doesn’t assume intention an an overriding force. How exposes context. How invites discussion and collaboration. How protects the sanctity of another’s sovereignity. How respects autonomy. How respects control. An added bonus is you don’t need five Hows to get anywhere meaningful. You only need one.  

Do yourself and the people around you a favor and start asking How more than Why.

[[_SVA]]
If you’ve been through art school, design school, or any liberal arts focused education program in the United States you’re likely familiar with critique. Criticism is something that is tough to swallow. It has a high negative value in most situations and most people tend to avoid it. The popular saying, ‘if you don’t have anything nice to say don’t say anything at all’ is a cultural response to the tendency of people to criticize others. Criticism is human nature though and you’ll receive a lot of it in your life. Rather than avoid criticism the schools mentioned before train you _through_ criticism. For many people this is the civilian equivalent of military hell week, only you get two to five years of it instead of seven days.

The toil is that you have to offer up your work and ask, ‘is it good enough?’ You are forced to receive negative input about the shortcoming’s of your work. You can’t escape critique. You survive it. The sting of criticism doesn’t leave. What eventually happens is a schism between you and your work. You become detached, divorced, desensitized to what you’ve created. You still value what you’ve done but now you’ve learned it’s not about you.

The reward is that you get to offer up your work and ask, “is it good enough?” Will you act? Will you trust? Will you understand and believe? You get to bring people along with you. You get to create for others. You get to listen and care about the concerns of those you seek to help. Critique is rough but it is a worthy pursuit because the other side, the job well done, matters.

[[_SVA]]
What makes it worthwhile is the story we tell ourselves before we act. It’s the hidden narrative describing life on the other side. Everybody has one. If you want to create a change in people you need to know what will make it worthwhile. Not what _you_ think will make it worthwhile, what _they_ think will make it worthwhile. Pay attention, the shift matters.

[[_SVA]]
#ux #ai 


"Because customers reacted in this way we have a theme of {x} that aligns with our company's theme of {x}. We see this as a sign the design resonates and will provide value and benefit to our customers."

Talk about the design decisions which will trigger a customer.
https://designsystem.digital.gov/
Certainty is commonly considered as the opposite of risk. Give people certainty and you will have built trust. Certainty is obtained primarily through the absence of falsity; assertions that don’t hold. If you say something it better be true. At lot is riding on it.

Certainty is a bit of an act of faith in that you create a belief of truth with the faith that the truth holds for you. Any fear you have erodes certainty. Taking away certainty is a possible tactic. You are certain you are going to stay the way you are until you choose to change. Do nothing and that will remain certain. Act differently and you reduce the certainty. Explain how their current way is actually reducing certainty and your new way is increasing it.

You can induce certainty by demonstrating an understanding. Colloquially known as walking a mile in someone else’s shoes. Perhaps the most important certainties to establish in any human interaction are the certainty that you will not harm each other and that you are acting with the other’s interests at heart. Anytime someone feels the certainty of understanding, of empathic connection a bond is formed. I am certain you will help me.

The same goes true for any product we interact with but those come with the certainty of usefulness so pay attention there.

[[_SVA]]
#ux #ai 

https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai.html

Challenges are data, ethics, policy, regulation, bias, fairness, explainability, privacy, robustness in handling errors, secure against attack, safety, governance, compliance, and risk management.
Tell me what you do. 

As a designer it can be difficult to explain the intricacies of design to the uninitiated. As designers we spend a lifetime understanding our profession and what it means to design. Distilling our hard won understanding into something catchy that engages the audience can be difficult. Many prominent designers have their own flavor of what it means to be a designer. You, dear reader, may even have your own or at least your favorite one. The ones I’ve found feel stilted. 

Tell me what you do.
 - I render intent.
 - I make intelligence visible.
 - I make things work well not just look good.
 - I make thinking visual.
 - I create solutions to problems. 
 - I align outcomes with intent

Without a doubt there are lifetimes of wisdom in each of those answers but c’mon. Tell me what you do.

'I give you the optimal path to where you want to go.'

Design is an act of synthesis. It’s an architecture of constraints. Design is a higher-order thinking skill that humans tap into when trying to accomplish a goal. Design considers intent, intelligence, environment, capabilities, consequences, and more. It is something every human does. It is possible that design is an act that everything with an intelligence does. Designers are just better at it because we train to be better at it.

You’re free to stick with your favorite response and understanding. Craft your own if you so desire. However, if you’re looking for a response that’s a bit more universal and approachable now you have it. I give you the best way to get where you’re trying to go.

[[_SVA]]

This all started with play and space as a strategy and a tactic. Boredom can be intentional and it can yield creative results. Growth occurs at the edges of your comfort zone. Boredom can feel highly uncomfortable. It’s an agitator. Boredom forces something to happen. The reaction is action. Do something. The benefit here is the longer you sit agitated the more pronounced the action is. You’re a bow string pulled taut and the more you sink into boredom the more taut you become.

Play is where you give boredom a space to matter, to contribute in a positive way. Play greets boredom. Play brings boredom in and works with it. Play allows the creative agitation of boredom. Play says, ‘I dunno. Let’s find out.’ The notion that you’re outwardly playing might seem awkward so play inwardly. Give yourself permission space on the inside. The playful mind is where playful thoughts and playful behaviors are made.

If anybody challenges your boredom, just say ‘I’m boring myself to action.’

[[_SVA]]
(https://www.linkedin.com/events/casestudy-mitdeployschatbotwith7148338782021287936/theater/)
(https://gaiinsights.com/blog/10-types-of-generative-ai-0)
Alden Do Rosario - CustomGPT creator
Orbit.mit.edu gives you chatMTC (Martin Trust Center)
Chatbots need to cite their sources since most information is unstructured.
A chatbot for each department, HR, Finance, Legal, Design, etc…
Use Zapier to add data or use sitemaps, create sitemaps from YouTube videos and playlists using CustomGPT
Retrieval Augmented Generation
You need to be concerned that your input gets fed to OpenAI
Caught by CustomGPT in the middle
Data gets intercepted and their data using RAG is all their data
CustomGPT gives you metrics on the number of questions you can’t answer.
Add best practices to pages when doing something new.
If you are new to a task, to an anything, but mostly new to a situation it can reduce anxiety to have information on best practices and survival tactics.
CustomGPT works by constructing sentences only from their data source
Hosted SaaS
Need to have system refreshes to note updates and deletions
A multiplicity of resources are available for use, Claude, OpenAI, Google, Perplexity so consider that your ChatBot is the only way.
Installing one of these on an intranet might be beneficial. I’d be concerned whether the tech could support it. Maybe the integration could be done a different way.
Ingestion was less than 2 hours.
They wanted to give chatGPT to non-developers.
Legal assistant GPT in the Dominican Republic. And education.
CustomGPT is not a deep dive into ML, it’s more front-line for the dumb-dumbs, the non-initiates.
Pulls in audio, video, word
(desktof pree?), Pinecone, LLM GPT4, 5k hours on hallucinations
$100/mo for 1k pages
OpenAI is a platform company who will be beneficial for their models.
CustomGPT features autosync, ingesting YouTube, creating Slack integrations, give citations, working with local people, the one person and not the business, and it uses RAG. It is working.
What's your favorite television station? PBS. Nielsen ratings proved this wasn't true. The insight is that this person wanted to be the type of person whose favorite station is PBS.
Better is a powerful tool. Everything you point it at becomes better. How do you decide where to wield better? At which dimensions do you point better? Making that decision easier involves consideration for the people who will benefit from your particular better. Point better at helping who you want to help become who they want to become. If you start here it becomes obvious where to make things better.

Sometimes better is not more of the same. Sometimes better is different. Be willing to go off and explore new directions.

[[_SVA]]
Originality is a highly sought after quality in a work or in a person. We elevate originators. Well, we call people originators only when they are original to us. The truth behind their originality becomes meaningless when they become original to a culture or society. At any rate, originality is something many strive for and few achieve. I posit this is not because originality is difficult to achieve but because the path to originality is uncomfortable.

The quickest path to originality is through error. Mistakes are wholly original and unique to the human experience. It still is that pen marks on paper cannot be un-made. But humans don’t like mistakes. You can call them ‘happy accidents’ if it helps but it rarely does. All most people will see is the missed attempt at realizing their intention. The pen mark that cannot be un-made can be transformed into a new element of the page. Your intention has not failed you, the chaos of the world is giving you a helping hand. The mistakes we make ought to be celebrated and amplified.

[[_SVA]]
*not written by me

Design is a complex process that involves a multitude of skills, including creativity, strategy, and execution. To deliver high-quality designs, you need a team of talented and experienced professionals who can collaborate and work efficiently. However, even the most experienced teams face challenges, and it's essential to develop strategies to overcome them.

Hire Senior Craftspeople

One of the most important things that Dylan emphasizes is hiring senior folks who spike in craft. Many teams tend to expect senior folks to focus more on strategy, but Figma loves to have senior craftspeople on the team, too. They play a crucial role in mentoring, pairing, and giving craft feedback to the rest of the team. When you have experienced designers who are passionate about their craft, they can guide and inspire others to achieve their full potential.

Create a Culture of Riffing

At Figma, they do a thing called "riffing" a lot! It's where folks share their design files, and people pop in to create different iterations of things, visually. It's a great way to provide feedback that's more visual than written. It also encourages designers to be open to feedback and to embrace the idea that their work isn't precious. By having a culture of riffing, you create a safe space for designers to share their work and explore new ideas.

Encourage Constant Focus on Craft

Focusing on the craft is essential to creating high-quality designs. At Figma, they talk a lot about the craft and encourage their team to give visual and interaction feedback. Even early in the process, they don't shy away from providing feedback. Dylan makes a point of giving folks craft feedback himself and explains the rationale behind why it matters. He emphasizes that visual decisions help achieve the goals of the project, or make things easier for users. By focusing on the craft, you can elevate the quality of your designs and ensure that your team is constantly improving.

Facilitate Riffing

If you want to encourage your team to riff, there are some simple rituals or guidelines you can follow. Start by creating a culture of trust, where everyone feels comfortable sharing their work. Encourage team members to share their design files and provide a link to riff on. During crits, designate a "Riff Zone" in the files, so that people can go in and riff on ideas. When asking for feedback on Slack, include a bit that says, "Here's the link if you want to riff!" By facilitating riffing, you can create a collaborative culture that promotes innovation and creativity.

Conclusion

Building a high-performing design team is challenging, but it's achievable if you focus on the right things. By hiring senior craftspeople, creating a culture of riffing, and encouraging a constant focus on craft, you can increase the quality of your team's output. These tips have worked for Figma, and they can work for your team too. By implementing these strategies, you can create a team that is passionate, collaborative, and dedicated to creating high-quality designs.

[[_SVA]]

#programming 
== is the equality operator
!= is not equal operator
< >
<= >=

#python #programming #beginner 
These generative AIs are really good at externalizing the lingual aspects of our brain. They are getting better at externalizing the visual aspects as well. When you're looking to augment yourself with these second brain technologies, don't limit yourself to language alone. Look for a second visual brain as well.

#secondbrain #business #learning #ai #music-app
- WebXR Device API(https://immersiveweb.dev/)(https://immersive-web.github.io/)(https://developer.mozilla.org/en-US/docs/Web/API/WebXR_Device_API)
	- Three.js(https://threejs.org/docs/index.html#manual/en/introduction/Installation)
	- Ammo.js (https://threejs.org/docs/#examples/en/animations/MMDPhysics)(https://medium.com/@bluemagnificent/intro-to-javascript-3d-physics-using-ammo-js-and-three-js-dd48df81f591)
	- WebGL(webglfundamentals.com)(webGL mdn docs)()

- ARCore(https://developers.google.com/ar/develop)on Chrome and Android(https://developer.android.com/studio/publish)
	- Java
	- https://developer.android.com/courses/pathways/android-basics-kotlin-two
	- https://developer.android.com/courses/android-basics-compose/course
	- ARCore Geospatial API(https://www.youtube.com/watch?v=NbSqmZFROIU)(https://developers.google.com/ar/geospatialcreator)

- Unreal
	 - C++

- Unity
	- C#
	- XR Interaction Toolkit
	- AR Foundation

- SteamVR
- Havok
- Freya Holmer

- Python
- Lua
- D3.js (https://d3js.org/)
	- https://data.sfgov.org/City-Infrastructure/Map-of-Public-Bathrooms-and-Water-Fountains/5zvx-hht7
	- https://data.sfgov.org/City-Infrastructure/Map-of-stormwater-inlets-drains-and-catch-basins/xbxd-zkc9
	- https://www.researchdatagov.org/
- Tensorflow

[[How I will put an AR game about the Barbary Coast on my website.]]
WebXR, Three.js, Ammo.js
It will be a website that people can go to. Make it a business on Google for people to access? Or make it a sight you have to tell them about?
(https://codemaker2016.medium.com/develop-your-first-webar-app-using-webxr-and-three-js-7a437cb00a92)

ARCore
Will be Android. Google business can still work but will have to download app. No iPhone support. ARCore Geospatial API

Bringing the skeeze back to the coast

OpenXR, Unity, Meta
PC and console gaming, through Steam. Chance to take the game further. MORE BETTERER!

SteamVR
Steam. The DOPEST!

Unreal
The MOST UPPEREST OF LEVELS!

[[Anybody out there want to help me set up a CI/CD, BDD, TDD environment for an android app I'm developing?]]
Points to a larger idea of emergency protocols, risk mitigation, disaster preparedness

If it hasn’t happened to you then rehearse for if it does

Adopt a “when” not “if” mindset

If it has happened to you and you’re freaking out you need to physically exhaust yourself. You need to go bend steel. A quick way to exhaust yourself is through a series of isometric exercises held to exhaustion. Thinks planks and squat holds. Carrying something heavy up stairs is the most metabolically intensive exercise you can do. Grab a heavy backpack and walk uphill.

Once your body is exhausted your brain doesn’t have energy for freaking out.

If you have experienced failure and are calm you can get to work.

If you are about to go into an experience where you think you’ll experience failure do some hyperventilation exercises to oxygenate your blood. This will regulate your calm and allow you to breathe through stress better.

[[_SVA]]
#ux #ai 

https://design.google/library/ux-ai

The user's understanding of their role in calibrating the system needs to be clear or it's HAL3000 again.

Consider the problem of being your own photographer. Your life becomes taking the photo and not experiencing the moment you're capturing. If you had a photographer to capture those moments you could focus on living them instead of photoing them.

Axioms of HCML (human-centered machine learning)
 - [[If a human can't perform the task neither can an AI.]]
 - [[A deep dive into the methods of an expert separates signal from noise and guides you with data collection, labeling, and component modeling.]]

Early experiments exposed crucial gaps and caused assumptions about quality to be reassessed. At the time of this parable there was not a singular intelligence that understands all things and can transfer knowledge from context to context.

Train the model on what bad looks like to distinguish it from the value in the good. The model also needed to be trained on framing and who to ignore.

This model was trained on social cues like the amount of time people spend in proximity to another. Models need a lot of training data. For this model; time, distinct aesthetic qualities, and familiarity of people where considered when providing data.

Avoiding unwanted redundancy without missing too many moment is a complex UX challenge for this situation.

All of the user's data stays on the camera until the user says otherwise.

Familiarity and control were guiding UI principles. Users got more moments to delete what they didn't want.

[[Fake it with real content over an ML model as the latter is way more costly than the former to get wrong.]] ML affords design logic like 'when something looks sort of like x, do y.'


Don't be the British and enforce a government on a people that never asked for it. Don't force your designs on a people you didn't design with.
#ux #ai 

https://aidesign.tools

Last activity 2023.
Okay Perplexity, I'm starting a brand and don't know what I'm doing. Where do I begin?

#ai
#ux #ai 

Disambiguate before acting.


#ux #ai 

https://medium.com/@refiredesign/ai-design-principles-ux-guide-0e8b285f2b1a

Begin with the audience's need and preferences. Use personas and journey maps to tell stories and reveal touchpoint opportunities for the AI. Make sure the AI does not perpetuate existing biases. Consider the context in which the AI will be used such as at a gym, in a studio, while driving, et al.

Use ML to analyze historical data and predict future actions for the user.
Communicate how the AI is using the user's data to make recommendations. [[Make your privacy policies accessible.]]
[[Use user input to improve AI over time via feedback loops like answer ratings or Roman voting.]] [[Give the human the ability to override the AI's decisions at any point.]] Keep the AI accessible. Onboarding is critical for educating the user on interactions and functions of the AI.
I was inspired and have been reflecting on a challenge for those who have profited off open source efforts to apportion their profits towards the open source effort else they be considered as preying 
https://www.linkedin.com/learning/ux-for-ai-design-practices-for-ai-developers
Taught by John Maeda

There are co-pilots and plug-ins. Co-pilots are agents. [[The new way of doing things is building experiences that use the model.]]

AI orchestrates between models/infrastructure and apps.

Old way, I'm going to build a model. New way is I'm building with a model. This new structure is collaborative.

The user is the boss, AI is not the boss but the AI is only as good as the boss. OpenAI had a sonic boom moment that kicked off the AI craze. Curiosity allows you to be inventive because you're less afraid. Non-tech people who aren't developers will grasp this. Trust must be appropriate that the Copilot understands the intent and purpose.

The three laws that matter in the field of AI
 - emotion
 - trust
 - failure, non-deterministic so there is always a chance of failure, it the actual sense

Computers used to be a command interface but this AI era is not a commanding medium but a collaborative one.

Eliza the first chatbot in 1966 from MIT Joseph Weizenbaum revealed that people put a human behind the AI instead of seeing the dead behind the eyes or that metal glean of distrust. [[This leads to the UX patterns of 'hey, this thing is an AI', 'here are some suggested actions', and 'give us your feedback.']]

AI orchestrates with a kernel. Hardware and GPUs are the infrastructure for maintaining AI. Models are the second layer. The UX is the dashboard. Plug-ins are what you add to the vehicle. [[UX and plug-ins are the places of great leverage. Everything else is non-deterministic.]]

The Iron triangle guides the human and Copilot relationship. Mathematics are non-deterministic, you know mathematically. You gotta lean into it. You can only lean on speed and cost not quality. Quality is governed by speed and cost. Make your UX feel faster and encourage people to pay more.

Progress bars make it feel fast. Think about elevator mirrors and that story. ChatGPT streams out text making it feel faster. Share status updates to why it takes a while. I'm doing this. Showing the number of files increase transparency. There's a UX study on that for an airline or something. You can display reference material for the user to browse while the AI does its thing. [[Make waiting fun is a core UX for AI principle.]]

Now we're getting into code
https://github.com/microsoft/semantic-kernel
This is the AI notice pattern in code, for Microsoft.
https://build.microsoft.com/en-US/sessions/bac1bf0b-7c70-4366-bb86-0abd11b009bc?source=/speakers/ea57976b-5f80-4ad3-9a99-fec904bf107b

The OpenAI API process you need to undergo to use the semantic kernel in VSCode begins with creating an account or logging in if you already have one. ChatGPT can be your login hub to OpenAI. Much like Google if you are logged in there you're logged in here. You may think that's old hat. I find the ecosystem and architecture kinda amazing.

You can create an account with your Google or other platform. I think Facebook and maybe Apple. Or an e-mail. You do you.

[[Working with the OpenAI api.]]

https://platform.openai.com/api-keys
You'll see a prompt to create a secret key.

I know exactly nothing about this so what the heck permissions do I give it? I went with Read on all and Write on Model capabilities. I figure that does the least amount of damage and gets me whatever Model capabilities are.

Perplexity didn't tell me much I didn't already know. I don't know if this will work and I'm concerned too much is at stake and I'm too ignorant to deal with it.

Which is actually pretty true. That I'm doing it anyway may be a testament to my ignorance but I'm doing it anyway. So...

Perplexity says a best practice for securely using API keys is to store them in your ~/.bash_profile

Open your terminal. You can search your Mac or Windows/Linus, I don't know what else, for it. Once it is open then your command string is as follows.

bash
nano ~/.bash_profile

Now you'll find yourself in a text editor you may not have seen before. It is quirky. You don't have to be here long.

Copy and paste the proceeding snippet into the text editor.
export OPENAI_API_KEY='yourkey'

Replace yourkey with your key. The quotation marks matter. You put your key in between them. Don't leave them out.

CRTL+O, confirm the file, and you're out. You can quit terminal.

Almost

Open terminal.

bash
nano ~/.bash_profile

Check for the changes and if they aren't there add them, save, and exit. Check for what was missed. You'll figure it out.

That concludes the adventure in saving our OpenAI API key

Speed is perception and design could be leveraged to work with it. Cost is more expensive.

Ada spawned DaVinci but is much cheaper to use. You gotta make a cocktail of the models. You're doing some strange things to make sure you save cost and need to be celebrated for it.

Cost per token.

Have a conversion to think out loud while it thinks out loud. You can play with most sophisticated models. You can accelerate your slow thinking muscle.

Non-determinism is a thing. The thing. Native code is deterministic. Syntax and Semantic, Precision and Power. Someone who is the lever for both wins. This is quality.

A tetrahedron point is reveal as emotion. The Iron triangle plus one. Paul Eckmen in 1976. I think this is the Lie to Me guy. Only one of his six is positive. 5/6 are negative. Check out the Kubler-Ross grief cycle. You want to design something highly familiar and highly novel. [[Don't humanize the AI so emotions are mitigated when the AI lets you down.]]

[[Adding friction is key to the new UX.]]

Always say 'for example' when you open your mouth because you will always make sense.

[[John Maeda's UX patterns for copilot.]]

Much gratitude @JohnMaeda
#ux #ai 

https://uxdesign.cc/artificial-intelligence-in-ux-design-54ad4aa28762

Use cases
 manager receives countless approval requests,
 up to a certain amount, specified in the software, the budget requests are approved.

Pretty good summation of of the principles
 - put the human first
 - design for trust & transparency
 - make the AI explainable
 - Allow the user to provide feedback and control
 - Everyone who works on AI is accountable for it.
#ux #ai 

https://www.shapeof.ai/
https://www.linkedin.com/in/emmiecampbell/

Shape of AI is aggregation and pattern creation/revelation referred to here as emergent patterns.

Shape of AI is well poised to become a critical part of the modern UX milieu.

Don't be surprised when people expect you to cater your parlance to these ideas and concepts.

These arguments are conclusive, expansive, and well-formatted.

The anti-patterns and abundance of evidence are high points of the argument's integrity. The softwares analyzed are ubiquitous enough to uphold the findings at mass.

This is some next level stuff.

For free.




The prime challenge is distinguishing the AI. Separating it out. Identifiers distinguish the AI. Identifiers give it presence. Signifiers is a sufficient substitute for identifiers. One way to make that distinction is with dress. [[A visual distinction immediately creates separation.]]

Naming is a challenge and is not alone sufficient enough to distinguish the AI. My take is to go with the brand name, not some person name. Dehumanizing, deplorable in all manners, instances, and occurrences aimed at another person, is an active necessity with AI.

The second challenge is presenting how to use the AI to get where you are going. Wayfinding is an ecological perspective transplanted onto a digital environment. Where am I trying to go and how do I get there are basic questions which guide our lives and are beneficial to architect your software around.

[[Suggestions, mad libs, and templates address the bulk of the wayfinding challenge.]] Nudges offer up a chance to engage with the AI.

The text prompt is not the ideal interface but it does have its benefits. The challenge of the prompt remains the challenge of a blank slate.

The third challenge is one of benefit. 
[[Beneficial interaction patterns to aid an AI's utility are auto filling mass data cells, the suggestion enhanced text prompt, collaging from existing sources, and providing synthesis structures.]]

One way to get an output from AI is to remix and blend an existing one. Remixing blends well with collage. Essentially you are exposing someone to a prefilled template and left to figure it our rather than exposing then to a blank slate. This person gets it.

The fourth UX challenge of AI is tuning the model, whether to decrease your sigmas of deviation or personalize the AI to your brand voice or personality. [[Allowing for immediate controls to the AI output like parameters, filters, weighting, negative prompting, sliders, widgets, et al benefit the user with their editing operations.]]

Allowing for long term changes requires a feedback cycle. The feedback cycle is how you address drift. [[Using edge cases as special input into your feedback cycle is a pro level play.]]

These models are like characters in a game. You need a breakdown of their stats to determine the best model for the task. Create a character sheet for each model, benefits, deterrents, excellences, failures, most successful with _blank_ and for _blank_.

The final challenge of UX for AI is trust. Caveats point to transparency, expectations, and confronting reality. Controls like stopping, starting, and continuing actions keep the user in the pilot seat. Footprints keep the AI credible through citations and provenance of statements.

Feedback can help impart ownership of the AI onto the user. The key trust aspect of feedback is accountability. [[Prove the model gets better at what does works and where necessary good at what doesn't work.]]

Data privacy is a consideration and transparent access to it for the user is needed.
Press releases and outreach 6-8 week upfront
Give influencers and bloggers early access
Brief analysts
Leak information on social media
Create announcements constantly
Enlist channel partners and distributors
Offer free trials
Create in-depth usage videos
Make 'how-it-was-made' videos
Give discounts
Start a referral program

#marketing
Roger Barker psychologist, (Ecological psychology, 1968)

https://youtu.be/k4fKBqu-Ris
These words express a truth of most any change, interpreted here as a product, gift, or offering, abstracted though to it's ultimate Saiyen in change. This highly probable reality of not asking for something from you and not benefitting from what you've provided is best acknowledged as to allow the reasoned among the crowd to make their decisions. We want our approach to be positive and only give people what they asked for and what they might benefit from but that's often not the position we can start from. To ensure this scenario doesn't occur it's best to come with proof that someone did indeed ask for what you've provided and therefore will benefit from it. Sometimes though what you benefit most from is not what you asked for and it takes heart and moxie to give to someone what they did not ask for with the promise they will benefit from it.
Generative AI is a maquette. It will "act like" anything and spew you falsehoods. A true con, never to be trusted. I share some of these concerns about quality and credibility. I think the solution is in community. The idea of using each other to correct each other. Iron sharpens iron. Steel sharpens steel. Credibility is approval. You passed the test. Learning courses are just steps to pass a test. Credible sources can publish tests instead of texts. It will be more efficient.

Prompt: Give me a doctorate level test determining my competency in the field of Interaction Design
Prompt: Use this text and give me a 20 question multiple choice exam testing my knowledge of affordances, complete with practical exercises

These prompts are a reality and are useful. Pretty soon we will have a certified IxD bot that provides credible answers to even the toughest questions. 

Using ChatGPT to test yourself. [[The ChatGPT revolution is editing, curation, and taste.]]

Mine literature on the Barbary Coast
for stories, facts, and games.
Connect with Barbary Coast literates
Map the Barbary Coast medallion
-AND-Find the public record of their locations
Build Google Maps directions list
When you check in at the location +- 3ft it creates a list, marks your map with the other medallion locations, and marks your list with where you've checked in at
%completion
Picture match for AR scan
Saves experiences
Execution is how you free yourself from the confines of design.

By nature design is a preemptive act. Design is what you do before you act. In a small twist, design is also the history of what you have done. Though that is of no concern for now.

It seems to me there exists a tendency to conflate creation and design. I believe this is due to the proliferation of the idea of a design process. Of any process really.

Processes are moments of action sequentially linked by time. You can’t design and act simultaneously. Because action is placed under the banner of the design process we consider them one and the same.

You aren’t designing a work of art if you are putting paint to canvas, you are creating.

Does that mean design can’t have a process? Is the act of designing defined as the process of creating a design or is it something else entirely?

Practically, it doesn’t matter. Only the high-mind concerns itself with such distinctions. Which I think is precisely the point.

Somewhere along the way we need to concern ourselves less with design and more with what we’re making.

By all means, go forth and design but someday I expect you to quit and start making instead.

[[_SVA]]
Being that the promise of design is success it only makes sense that it can be pointed at you and your future. Designing your life and your work life are popular topics in modern culture. Something either happens by design or by accident and you don’t want your future self to happen by accident.

I think that’s all nonsense. Design helps you achieve success but cannot guarantee it. What happens next is unknown. That isn’t to say that you can’t design your future self. I am saying though that you need to be a little squiffy with what it means to design at that point. When dealing with timelines that are a generation long the only design you can provide is one that evolves. Design becomes the verb not the noun. When designing your future self you’re continually designing. Which is what most people call living. We don’t unintentionally become who we are. We can’t. Every action by a human is intentional. It cannot be any other way. You’re constantly designing your future self, one moment at a time. Here’s how you get better at it.
 - Interview someone from the oldest generation you have access to, note relevant and irrelevant wisdoms (the past is not guaranteed to carry the future, not everything will be applicable)
 - Set up milestones around qualities you wish to possess not achievements you wish to be known for
 - Write your milestones at least once a month
 - Understand values
 - Form a group with people from generations younger and older than you, change it as generations are born and die
 - Reflect with them on the qualities you possess
 - Seek advice for changing
 - Join a similar group for someone else

[[_SVA]]
[[Loose systems encourage appropriation or at least allow for it]]
Inheritance is a key concept.

[[To add inheritance in Csharp use colon {class} after the variable name.]]

[[If a variable will not be changed from another script then keep the variable as private.]]

#programming 
New world context
How do the modern leaders build products?
How do we remain relevant?
How do we maintain an awareness of the industry?
What are ways to deliver to development teams outside of handing HTML/CSS?
How do we become a better team?
How do we better collaborate amongst each other?

Critique

Craft
 Front-end
 A11y
 Design Sprint Moderation
 Figma
 Social Media
 Storytelling
 Animations
 Prototyping
 Building rapport vs offending during testing, especially now
 CSS/Flexbox
 Inspiration sites like Flash Awards

Business
 Piloting
 PowerBI
 Smarketing
 Who has the funding to do the testing?
 Exposing the need
 Interview practice
 Value to Improving
 Involvement opportunities

Design
 UX vs CX
 User Story Mapping
 UX Strategy O'Reily book
 Strategy
 Robotics
 AI Conversations
 Behavior models
 Service Design Blueprints
 New Tech
 Design thinking in-depth and in practice
 Ideation
 UX Myths
 UX Fake News

Life
 Success
 Failure
 Decision Making
 Data Visualization
 Data Archaeology
 Time & risks
 What's going on in the world
 How to give a talk
 Building relationships
 Managing energy levels

Culture
 More on the mental aspect of the job
 Staying focused
 Remote working
 Balance
 Process enforcement
 Nuance when we are one man wrecking crew
 UX culture

Communication
 For example, if someone attacks you, apologize and flip it back using a Label™: It sounds like you’ve got a reason for saying what you just said. 

User Experience (UX) User Interface (UI)
Product Design
Interaction Design
Wireframing 
Design Thinking 
Human-Centered Design
Usability Testing
User Research
Graphic Design
Visual Design
Software as a Service
Product development
Prototyping
Design Strategy
Branding
Brand loyalty
Software design
Analytics
Innovation
Creative Direction
Problem Solving
Data analysis
Creative thinking
Analytical thinking
Technological literacy
Curiosity and lifelong learning
Resilience, flexibility, agility
Systems thinking
A.I. and big data
Motivation and self-awareness
Team management
Service orientation 
Social influence
Design leadership
Design operations
If you interact there's a 60% chance you'll learn better.

AI mimicks reasoning but cannot actually reason. It looks human but is dead inside. It is filled with the mathematics not the esse.

People will pay to make money or at least feel like they are. #webinars

Chatbot generating sales and appointments. #conversationdesign
for sales. Like an appointment bot for a Dental office. Or sales bot for comic stores.

Show them a demo. The chatbots sell themselves. 1 chatbot a week to sell at $1k. You've made the chatbot. You're selling it to them.

$1-5k v salary

AI Avatars for comic book stores. AI voice, AI virtual avatars, AI costumes, AI writer.

Trends, ride to the middle, for your niche. Visual AI and UX.

5k words. write this from a professional cleaners perspective. Copy and paste, expand on point 500 words. Upsell to an audio book through eleven labs into synthesia or other marketing tool.

sell through chatbots, websites, amazon, ebay

6 months and 30% increase, testimonial
for selling yourself to others

sell and report your results on LinkedIn, don't sell on LinkedIn

Meetups about AI & UX, visual UX
What's good party people? The format of this meeting will be. It will be approximately blank in length and will cover blank topics. You're generous to attend.
 - goana gimme dem e-mailz

I could sell AI UX audits, where I compare your AI against the HAX and other heuristics.
 - make a video of me doing an audit
 - record calls and sell them
 - 90 minute audits for 120 dollars, that's 2.6% of my corporate rate, giving you a total discount of 97.4%.

Sell access to my Figma for $4/mo, $1/wk

Pay for a community Discord, $1000/mo currently open to 1000/new members.
100 people @ $10k/mo
10 people at $100k/mo

Newsletter
An unpredictable publication focused on AI, UX, Interaction Design, and likely other things.
A weekly gateway into the nexus of AI & UX for image generation
Plus whatever else I'm into.
Probably at some point something humorous and hopefully poetic.

A primer on the important tasks for making movies.
All there is to know about UX design.

What gives me the right?
To proclaim as expertise?
This is not an exercise in empathy. 
I submit I was born with a right to experience what I want and through my experience I am made right. Albeit relative to my experience and the credibility of its relation to others' in the field. You may cry I'm a subjective expert and therefore invalidate myself. I might call out a history of evaluation against affirmed experts. My practice has been anchored in UX, IxD, and image generation for the better part of expert hours, often in collaboration with other ascribed experts. Plus I enjoy this stuff so I seek it out and toy with it. Relative to chance do the odds of my involvement matter? I know who improves because of me and I know how they improve because of me. Whether anything I say or do will shift forces relevant to your needs is the conjecture of the ancients.
I proclaim the right of expertise to my experience and testimonials?

[[You could have KREA make movies! ]]

#ux #ai 

https://www.linkedin.com/events/whatdesignersneedtoknowaboutaiw7163223170869628929/theater/

Data Science, Strategy, & Consulting
MoonPig, Bank, Startup
We've got this market we want to enter, how do we think about it? #strategy
How do we get access to LLM in a secure environment and then how do you train it?
How do I incorporate AI into the business. Output validation is difficult.
Message personalization is valuable. Copy to customers would go through layers of reviews. A genAI customer support person is what they want yet have found it doesn't work well especially with layers of reviews.
How do you decide the features that bring benefit and work? ChatGPT is the chatbot of the current era. Everything doesn't have to be a chatbot. It is hard for people to imagine what could be done. You ask them for an image of anything and they ask for a cat or a dog.
Value downstream and data upstream meet in the middle with unstructured data, one-step task instructions, and better leverage of existing documents as the likely opportunity areas.
One step create brand guides, process docs, internal wikis, training materials, HR policies.
The chatbot is a default design pattern. We need to do it this way because this is what we're capable of and we need to launch now. How do you affect change in that environment, in an environment with a Head of AI? ML power is with engineers.
Breaking down a trust pilot review? Is it a positive or negative or classification is the old way. Now you can write a summary, identify issues, identify the sentiment, and guess the NPS. Now, as UX you need to create your own demos and ideas, don't wait on engineering.
The border between UX & AI. The inward pass from UX and outward push of AI. The two meet in a neutral location.
How do you approach AI with a better interface? We don't know the patterns yet. What is beneficial are multiple points of attack at different altitudes and success variabilities. Stay aware of new models and how you can incorporate them.
Setting up a production environment is still in the realm of engineering but prototyping is up for anyone. You can use Replit for production code. Write the code in chatGPT, paste any runtime errors back into chatGPT, and keep going.
Designers are behind. How do you stay at the forefront?
Podcasts, Twitter, LinkedIn, Reddit, Newsletters
Thursday AI is probably way too much but it's good. Latent Space is an interview and also good. The best way to stay ahead is to try with new models and tech.
What is the value of design in a software like MidJourney?
It is still easy to design really bad experiences. As an example with greeting cards, does the UX of AI generated cards make enough sense to be valuable? The chances are low given what customers expect out of a greeting card experience. They aren't coming to make their own cards so why give them a tool to do so?
New approaches to old problems like onboarding are a good way to go or submitting a complaint. Voice interactions that turns the AI into a conversation partner.
Lots of open source models give you common sense answers yet the big players don't. Is it okay to sacrifice 100 grams of pasta for a GPU?
What budget do you have for maintenance?
It's still roughly 90% of public that don't know or care about this stuff. It is still beneficial to temper expectations.
Engagement leads to understanding and is far more valuable than understanding.
[[Character sheet -> genAI model -> 3D model]]
They work in the layer between GPT4 and web.
#ux #ai 

https://www.linkedin.com/feed/update/urn:li:activity:7086602430917791744/

Through these resources you will get way to design responsible AI experiences that put humans first, remove biases and assumptions, provide understanding, explain the decision-making process and give users feedback and control.

Many of these seem not to consider partnership with an ML person and as such become tools of education and vision rather than implementation. Don't read these, find a ML person and build a thing.

Clearly if you want to work for a company it would help to design inside their paradigm so pick your house and run with it.
  
[[AI interface design patterns with Smarter Patterns.]]
[[AI x Design toolkit.]]
[[People + AI by Google]]
[[IBM has a guide for AI.]]
[[Microsoft has pulled together their guide called the HAX.]]
[[AI + design toolkit by Corinne Schillizzi and Tangity.]]
[[AI Design Process Toolkit by Futurice]]
[[Responsible and Ethical AI Practices, by Microsoft.]]
[[Responsible AI Toolkit by PwC.]]
[[Designing human data by Thomas Otto.]]
[[Everyday ethics for AI by IBM.]]
[[Designing AI For Children Toolkit (+ Checklist) by World Economic Forum]]  
[[AI governance principles by Future of Life.]]
[[AI-driven design on Awwwards.]]
[[Designing for AI, a UX approach.]]
[[AI design tools design + AI publication.]]
There’s a TED video somewhere on the internet in which a man discusses his drive behind this large scale knit-the-world initiative he undertook. It begins with him bedridden and bored. Bertrand Russell teaches us, interestingly enough, the same thinking I had. Boredom is a catalyst. It is an activator. There is real human value in anything which helps you stave off boredom.  

“Human beings show their superiority to the brutes by their capacity for boredom, though I have sometimes thought, in examining the apes at the zoo, that they, perhaps, have the rudiments of this tiresome emotion. However that may be, experience shows that escape from boredom is one of the really powerful desires of almost all human beings.” (Bertrand Russell, 1950)  

If your aspirations outpace your capacity to achieve it may be because you’re not bored enough to do anything about it.

[[_SVA]]
To begin you need the capacity to run your AI. If you don't own the equipment or if you want to do this at scale you'll need to rent the capacity. A cheap, though not free, yet quality option is RunPod. A free, yet public and not commercially viable option is Kaggle. You're renting GPU space.

If you want to work locally you'll need a computer with a high-end graphics processing unit. NVIDIA is the leader in this space and most likely will remain so for a while. These GPUs or graphics processing units can work fast and are the only thing capable of handling the immense number of calculations AIs need to run at speed.

The idea is to leverage the innate power of a GPU so the CPU doesn't have to jump in. Your CPU can run a model but you'll get a result back in days rather than minutes and you won't be doing anything else on the computer while it is processing.

RTX A4000, 16GB VRAM, 6 virtual CPUs, 23GB System RAM, 40GB ROM

In both these instances you are creating a new notebook, whatever exactly that means. A notebook seems like an instance of some software setup. These are Python 3. You'll want to go line by line and understand why numpy and pandas are helpful.

You can learn most of what you need to know about the Stable Diffusion or any model through Kaggle's model cards or their GitHub repos.

You'll need to give your phone number to Kaggle to run on their GPUs. It doesn't look like Runpod asks for your phone number.

Once you've uploaded the sample notebook you can see the code required to run stable diffusion. You can execute the code blocks one by one to see what each does or run them all at once.

The process of running through the code takes about 10 minutes on Kaggle and 5 minutes on RunPod.

You need to turn the notebook off so someone else can use it when you're done.

Ollama can help you run an LLM locally.
https://www.youtube.com/watch?v=k4ReYshcA08
[[Cost of hosting Llama is not less than ChatGPT.]]

[[LoRA is a method to fine tune weights from CLIP and Unet.]]

Models are trained on image sizes. Image sizes like 512x512. Any image size outsized of the size the model was trained on will produce unexpected results.

Reproducing the same image means using the same seed.

Use latent noise when adding an object not in the image. Start from the CHAOS! Kafka would be proud!

Denoising strength gives more or less weight to the prompt over the image content.
A low denoising strength favors the image over the prompt.
To overcome this you need low barriers and a high perceived present value.


Jakob Nielsen covers common complaints about the usability of prompt-driven AI tools, such as those used for image generation. Users may find it challenging to articulate their needs effectively through written prompts, particularly if they lack advanced literacy skills.
- https://www.linkedin.com/pulse/prompt-driven-ai-ux-hurts-usability-jakob-nielsen

Manish Agarawal ruminates on the black box nature. He profers a solution of conversational interactions using shared semantics.
https://magrawala.substack.com/p/unpredictable-black-boxes-are-terrible

I'm relieved to find someone other than myself who I can agree with on this matter. His language and interpretation are his and as such are not the way I would put it though in aggregate we've arrived at the same destination.
To understand what I mean, these two assumptions need to be considered true. There is no future. There is only now. 

Design’s promise is an idealized future. Design is useless right now. Design can only be meaningful right now if right now was created by a design.

You’re probably thinking I’m off my rocker. You say, ‘design isn’t useless. Design is, or at least can be considered, the only way forward.’

But design is a historical artifact. It deals exclusively with a moment when whatever was designed did not exist. Design is the precedent. It is the foundation. 

Obviously I’m wrong. This is all high-minded nonsense from someone who has too much time to think about existential crises like the non-existence of the future.

Pragmatically, actions have consequences. Designs lead to future outcomes. We’re here and our world is the way it is because of design. 

There is a tension though. You have to start from where you are to get to where you want to be.

[[_SVA]]
I get that whatever you’re doing is important. It is so important that getting it wrong is not an option. You might fail but you won’t give up until your design succeeds. That’s a lot of pressure. Even if it isn’t it still is. You probably think about your design in the quiet moments of your life. This isn’t a bad thing but the weight of responsibility only grows. The more you’re aware the more you’re pressuring yourself to do better, be better, succeed, don’t fail, die rich and happy.

I’m not saying to let all that go. Imagine for a moment that your design isn’t important enough to think about in the quiet moments. That your design doesn’t matter. That what you’re doing is worth doing simply because you enjoy doing it not because of what you’ll create.

Designing something that is fun and playful can be a serious affair. What requires effort has value and value is something to take seriously. Breathe and let it go. Let the serious facade recede. Let the preposterous center shine. Release the jester. Entertain the court. Crack a joke. Make it inappropriate. Design something absurd. You might find this notion nonsensical, but there is more real estate in the absurd than in the serious. Don’t constrain yourself by taking yourself too seriously.

[[_SVA]]
#ux #ai 


#ux #ai 

Articulation Barrier
Users often struggle with creating the right prompts for AI image generation, leading to cognitive and typing effort, as well as challenges in expressing their visual concepts in writing.
- https://www.nngroup.com/articles/ai-articulation-barrier/
- https://www.linkedin.com/pulse/prompt-driven-ai-ux-hurts-usability-jakob-nielsen

Unreliability of AI in Evaluating UX Screenshots
AI is found to be unreliable in identifying usability problems in screenshots, with a significant percentage of issues being overlooked. This can lead to potential inaccuracies and inefficiencies in the UX evaluation process.
- https://jakobnielsenphd.substack.com/p/ai-ux-evaluation

Impact on Job Market for Designers
There are concerns that generative AI could impact the job market for designers, particularly junior designers, as AI is increasingly capable of automating tasks traditionally assigned to entry-level designers, potentially leading to job displacement.
- https://www.toptal.com/designers/artificial-intelligence/ai-ethics-in-design
- https://www.nngroup.com/articles/ai-articulation-barrier/

Usability Challenges
The usability of prompt-driven AI tools, such as those used for image generation, is a common complaint. Users may find it challenging to articulate their needs effectively through written prompts, particularly if they lack advanced literacy skills.
- https://www.linkedin.com/pulse/prompt-driven-ai-ux-hurts-usability-jakob-nielsen

Hallucinations and Inconsistencies
AI-driven redesign suggestions are reported to be inconsistent and untrustworthy, often leading to inaccurate or misleading recommendations. This can result in wasted time and potential negative impacts on the design process.
- https://jakobnielsenphd.substack.com/p/ai-ux-evaluation
Meaning is a fickle concept. It is not static or constant. It varies per person per context. It is perhaps the most important concept to human development. Meaning is significance to your situation right here, right now.

Information carries no meaning. Our brains construct meaning. In that sense, meaning is the way the brain slots the information into its internal library. If something has no meaning it is ignored and forgotten.

Definitions propose a starting point for meaning but really a definition is information. Meaning needs an emotional component perhaps more so than an intellectual one. If you don’t attach positive emotions to the idea of design it has no meaning.

What then can design mean? Design can mean actualization, hope, faith, control, structure, power, stability, success, et al. There can also be meaning in the act. It is valid to say the point of designing is to design. None of the proposed meanings are universal. It is important to realize that design carries no meaning. You do.

[[_SVA]]

[[Python is a general purpose language whereas Javascript is specifically for webpages.]]

[[Python comes installed on a Mac.]]

[[Instructions for reading and writing code inside an IDE]]

[[Statements are the individual actions your program takes.]]

[[Troubleshooting begins by defining the error.]]

[[Variables and data types store information.]]

[[Strict programming languages require defining your variables and type before using them.]]

[[Java, C#, and C++ are strict languages.]]

[[Strict languages lead to less surprises at runtime.]]

[[Blocks are statements related to an opening condition.]]

[[Python inherits ideas from the programming language C.]]

#programming #beginner #python
#design
Prototype in what the final product will require or close to it. This may mean prototyping in a game engine, WebGL, or other simulator. Be comfortable being bad at this until you're good at it. 
#ux #ai 

[[Given what an LLM is good at can it be beneficial in this context?]]
#ux #ai 

https://www.awwwards.com/AI-driven-design

Chapter 4 is great with examples not just text.
Trust & Transparency
User Autonomy & Control
Value alignment
Ethics

Some specific ethical challenges mentioned are housing of data, privacy, lack of transparency, lack of control, alienation of human capabilities.

Consider how you can use AI to maximize outcomes while minimizing input. Design for failure.

Chapter 2 has a great breakdown of the feedback loop to design for including an example from Google.

Use cases for law enforcement is exploring and linking data, detecting objects, faces, and clues, location evidence with situational awareness or disaster, and effortless data exchange via chatbots.

Heuristics
AI confidence
Source citations
Human-driven recommendations
Feedback

Expectations is a breakdown of trust. Considering failure and provide a way forward.

[[The main challenge of AI is how to translate subjective human needs, values, and experiences into algorithmic parameters the model can optimize for.]]
As a provocation, consider that the best way to wreck your opposition is to help them. If all your opposition wants to do is burn the world down it may seem strange but show up with a can of gasoline and some matches. This is not a tactic of subversion or espionage. This is an attempt to understand how your opposers gains benefit from others. In the process you will gain some practical empathy. Empathy is always valuable.

[[_SVA]]
We have an obligation to do work that moves us forward in significant, meaningful, and humanitarian ways. What you make matters. Money is easy, integrity is hard.
You can think of the brain as a biological device consisting of three layers. From oldest to newest they go motor, emotional, intellectual. From control they go motor, emotional, intellectual. It’s a fact there are certain motor actions you cannot deprogram. Touch a hot stove and don’t pull your hand back. Just sayin’

What we can do with this information is design for each layer.

Designing for the motor layer involved understanding the bio-mechanics of the body. Knees don’t bend backwards. There are other truths about the way the human body is mechanically engineered that can be useful when designing but you really need to spend time to understand the motor capabilities of your audience. We’re all built the same way but we’re not all capable of the same things. Olympic athletes require a different design than couch warriors.

Designing for the intellectual layer seems difficult and is perhaps the most frightening of the layers to explore but it’s not overly complicated. It is true that the intellect is one area where humans diverge the widest. Our experiences make us into different intellectual beings. How I interpret the world may be different than how you interpret the world. Explore context, culture, and history and you’ll have solid ground to start your designs on.

The emotional layer is the trickiest because it is the layer with the largest influence. Your intellect changes based on your emotional state. It is possible that in certain emotional states new areas of your motor ability are activated. The stories of mothers moving cars off their trapped children tell us that humans are capable of more than we generally allow ourselves to be capable of. However, for the vast majority of us, those cases are rare. It is generally supposed that emotions impact our intellectual capabilities much more readily than our physical.

Designing for emotions involves understanding what has to be true for someone to shift states or true for them not to shift states. You seek comfort at least as much as you avoid discomfort. Shifting out of negative states requires a release. The negativity has to be confronted and worked through. Fear dissipates when the fear is labeled and processed. The same goes for sadness, grief, melancholy, and the many other shades of depression we experience. Designing for happiness means giving a feeling of forward motion, satiation, and control.

Follow the rules of your brain and design for the physical first, emotional second, and intellectual third.

[[_SVA]]
Some ideas are unequivocally bad ideas. Some ideas sound bad but are good ideas. Some ideas we call bad because we’re afraid of them but they are actually good ideas. Some ideas are obviously good ideas. The notion of constructive dialogue is beneficial but is a wholly insufficient means of creation. ‘Yes, and’ establishes the past as the truth. That’s the ‘yes’ part. I accept what you said. It is now part of reality. ‘And’ is what I’m doing with that information. The subtext is that ‘and’ does not reverse ‘yes.’ The truth is set, move on.

Piling onto the past helps everyone feel included in the creation process. It does not inherently produce a desirable creation. A common wisdom is that great writing is rewriting. A common phrase illustrating this point is, ‘I could have written a shorter speech if I had more time.’ Creation and curation. Variation and selection. Exploration and evaluation. Writing and editing. The creation part is only half the process. ‘Yes, and’ is creation not curation.

The complement is critical reflection. You need to take a step back from whatever you ‘yes, and’-ed into existence and assess it’s value and merit. Make note of the great ideas, the serendipitous synergies, and the moments of unexpected pleasure. Make note of the bad ideas. Don’t turn a good idea into a bad idea. Realize though that creation produces more failures than successes. You’re stripping what you made down to the irreducible core. This core is now the new truth, the new ‘yes’ that you ‘and’ onto.

I get that in a world of abundant criticism and denigration we need a tool of inclusion and positivity. Understand though that in a world of inclusion and positivity we also need criticism and denigration. Humans and our nature are rarely singular. Yin and yang need each other. ‘Yes, and your idea is not a good one’ is a perfectly valid way to create.

[[_SVA]]


### youtube_LlcFkDFYFkk.txt

[Music]
good afternoon everybody um I am going
to be presenting a talk I did at AI user
group for developers a couple weeks ago
uh because this was extremely last
minute Jackson asked me literally 5
minutes ago uh so please bear with me me
as I try to present on the spot here
it's really a test of my
job but yeah I'm excited to share a
little bit about how to build a great UI
from canvas perspective on AI so if
you're not familiar C with canva it's a
design tool that you can utilize to
create lots of assets from marketing
materials to social media and more this
presentation actually is entirely done
in canva as well and we have an app
store that we launched last year to the
public in June at our canva developers
event called canva extend which is a
sweatshirt I'm wearing and since we've
launched that App Store we've had over
100 apps including over 50 of those
being AI apps live on our app store and
we've reviewed many many many more than
that so we've learned a lot of tips and
tricks to make a really good UI
experience for your AI app through our
experience so I'm going to be talking a
little bit about how to build a great UI
for your AI from a n non-designer at a
design oriented
company so I'll give you some tips that
we've learned from our experience we'll
then go ahead and try to live fix an app
together and then I'll show you some
resources as
well so here are some of the things that
we've learned as a company from
reviewing lots and lots of AI apps from
a lot of thirdparty AI developers out
there how many of you are an AI startup
or starting out on your AI journey and
trying to bring a product to Market
a few of you okay so this could be
really helpful for you as you're
continuing to develop that or if you
even if you already have a product you
might get some information here um that
could be beneficial for your
product so the first tip I want to look
at now you guys are actually designers
this time the developers had no idea
what was wrong with these uis when I
tried this for those designers in the
room any thoughts of what about this UI
could be improved or isn't
ideal no
now okay how many people are familiar
with the canva editor has everyone used
canva a decent amount okay um so for
those of you who aren't familiar with
the canva editor this is a snapshot of
the canva side panel um so if I actually
just like zoom out for a second it's
that real estate here on that black side
panel jump back right right back in So
when we're talking about a limited
amount of pixel width we want to be
really cognizant of how how we're laying
out that page to maximize the amount of
user inputs we're able to accept so by
actually thinking about the vertical
layout a little bit more because we
don't have the entire real estate of the
screen here we're actually able to get a
lot more user input onto that page by
better utilizing our vertical layouts so
here not only are we able to change how
many inputs we have available for our
users to select we're also able to add
additional ones which means that a user
no longer has to be a PR engineering
genius to be able to use our AI we're
able to make them select a couple of
those beforehand so that they are
getting a better result once they're
creating it by allowing re really
thinking about how we're using that real
estate laying it out a little bit better
and allowing users to select more
options as opposed to forcing them to
try to type it into their
prompt our next tip is also about
vertical layout any thoughts on what
could be improved here
now okay let's think about the button
layout right the primary action that we
want a user to do is to actually
generate that image actually use our
technology by putting the amount of
credits you have which really isn't a
foundational component of your app is
just letting users know what they can
continue to do we're taking it away and
we're making users continue to have to
scan the screen to try to find where
that primary action is again let's
utilize that vertical real estate if we
don't need all of it don't use all of it
make sure that you focus in on and
making sure that the primary action your
primary mode that you want a user to
interact with your application is really
easy to find and really obvious to be
able to create a better
app our third
tip
is any ideas
here
around loading how many people have seen
a loading bar that just kind of sits at
like 5% now all of a sudden you jump up
to 70% and then you sit there a while
and then you jump up to
80% it's really arbitrary how like what
does that actually mean to a user it
never actually is um representative of
the amount of time that it actually
takes to loading to load an image so
let's go ahead and remove those
percentages and let's also think about
the loading experience if your AI takes
a while that's okay but don't let users
think that they can change the input
values while that information is loading
if all of these text box are enabled
while my AI is actually loading I as a
user think oh crap maybe I can actually
go ahead and change that input I really
didn't actually want an Australian
accent I wanted an English accent or an
American accent and then when the output
comes back to me and doesn't have that
change I'm going to be really confused
remove all of those options to make sure
that a user doesn't think that they can
change during that loading experience of
your AI to make sure that they are
getting an expected output from their
inputs into your
application so for longer loading we
highly
recommend offloading it to a different
screen to enable users to understand
kind of what's happening in the
application also providing an option to
cancel it if they realize they made a
mistake and want to go back this also
will save you some GPU costs as well
because you're not going to be
processing the entire request only to
have them try it again and try it again
and try it
again our next tip is around user
input how many text boxes do you see on
this screen text
inputs one two three
four four I see four four four you are
wrong there is one text input on
here so let's go ahead and clean that up
and make it more obvious obious what
actually is a text input for users so
those were actually just some
pre-selected example texts that we
wanted to show users because sometimes
it's really helpful to provide them
starting points for their text inputs
let's go ahead and clean that up make it
more obvious what is actually a text
input field where the prompt is actually
going to allow them to make a proper
selection and understand what they are
selecting so by changing the layout of
our pre-selected options it's more
obvious that those are suggestions or
helpful starter inputs and not actually
text inputs that I can
change additionally with our language
selection we're going to go ahead and
change that and make it a little bit
more obvious what uh options there are
for language but let's look at that one
a little bit more in
detail so if we go ahead and look at
that expanded menu of languages that are
available there's a lot of choice here
is that a really good user experience am
I as a user going to be able to make a
choice really easily be able to find
really easily like the language or
dialect that I'm looking
for not
necessarily so by changing this around a
little bit enabling you to filter and
sort and also search a little bit more
obviously it's going to be a much easier
user experience and I'm able to find
what I'm looking for a lot faster and
I'm not going to get frustrated and give
up I'm actually going to be able to get
to the point where I am going to be able
to generate audio from this application
as well also by limiting the amount of
selections that are available to a user
at the very very beginning you're
removing that paralysis of Choice by
making it really easy for them to go
from zero to one and then if they really
want a specific language then they can
go ahead and search for it but go with
those most obvious choices or those most
used choices most popular choices and
only show those before showing
everything that is available
our next tip is
around
buttons how many primary actions should
be on one
screen one how many are on this screen
two so what do I do here is this a
generation page or is this a start a new
or an ad to a design
page really focus in on highlighting
what you want to user to do in this
space so once my image is already
created I really want a user to add that
to a design so that's going to be my
primary action if I want a user to start
over or recreate something separate that
out make it really obvious what the
primary action is that you want a user
to do in that space But if you want to
keep those other options there keep them
separate make sure it's obvious that
this is going to be a net change and
you're creating a net new design here as
well so always always always have just
one primary action on a
page and the last tip I want to talk
about is anyone have any idea what this
app
does no neither did I when I saw it
either this is a caption generation app
not obvious so what we want to do is
actually make it a little bit clearer
what you can do with this app you upload
an image and image will return a caption
in this PCT in this example I uploaded
an image of a cattoon cart it's or sorry
a cartoon cat um and it's much more
obvious that what was returned to me is
a caption that I can now add to my
design if I want to make my design more
accessible I'm also able to see the
original image my primary action is very
clear about adding my caption to the
design and it's very obvious how to
start over here as well so by cleaning
up these little things it really makes
your app so much more usable and so much
more obvious to a user what they're
supposed to be doing what the intent of
your app is and what the value ad of is
and all of these examples that I just
showed you are actual apps from our app
store in their before State then they go
through our app review process and then
this is our end state so we've really
helped a lot of users improve their app
or sorry a lot of developers improve
their app experience through our design
review process and by providing them all
of these tips that we have learned as a
design company in our 10 years of
experience and helping them apply it to
their apps as well and we've Al also
heard from users that they've taken this
and applied it back to their primary app
so they've gone back to their website or
their app or their like desktop app and
modified it to be able to include all of
these tips and tricks that they've
learned from our app review
process now with that let's actually go
ahead and try to fix the UI of an
app so I going to have a fake text to
image AI app I actually haven't tested
this today so I have no idea if it's
going to work so bear with me um but
what we're going to do is we're going to
create a really simple texted image app
that takes a user input and returns an
image that I can then use in my
design so I'm going to go ahead and jump
over here
oops all right so I need to go back a
little
bit I believe it's in
projects what's in here
yes
okay um sorry again I was asked to do
this like 5 minutes before this started
so just need to get things up and
running real
fast all right so I'm G to actually
start at my local development
environment so this is actually going to
be starting the Cana apps SDK starter
kit so this is what you could use if you
were trying to build your app into canva
and when what this will do is it'll
actually start my local server and with
my local server started I can actually
oops go ahead
and I want to go to our canva Dev
portal and I can actually go ahead and
start testing my app live inside of the
canva editor so my app is running on my
local server and then this is a
productive version of canva and my app's
actually running inside of it right now
so in this case I have a button a text
input field and what it's supposed to do
is generate an image for me from um an
inference model that I currently stole
from hugging face and put up here if I
go ahead and generate
image oh apparently I didn't undo all of
the changes that
I guys this is what happens when you
actually have to present on the spot
here
um see oh no okay what app is it
running sorry give me a a second while I
figure out what project I actually have
running
here yeah it's already
open you know what I probably didn't do
save my
changes oops there we go okay
cool all right I'm going to rewind back
out some of those changes that I already
made and now okay let's go ahead and
reload our app so in this case if I I'm
a texted image app and I want users to
input a prompt and then generate a
result if I don't have any sort of
indication about loading state I'm just
going to slam that button as a user
because I don't understand what's
happening until I get a result that's
going to run up your uh GPU charges
immensely you don't want a user kicking
off multiple instances of your AI unless
you really enjoy really high usage costs
does anyone enjoy that probably not um
so one of the really key things to do
here is to make sure that button is
disabled and in a loading State once a
user presses it so they know something
is actually
happened yeah so now we're getting a
couple images being generated because I
just smashed that button and it doesn't
really know what to do with that so um
Cana oops before I jump over there Cana
actually has lot of UI components that
we've created for you to make it really
simple for you to build your app as well
so if I go ahead and look up a button in
our story
book I'll go ahead and zoom in a little
bit better you can see we actually have
a lot of properties already available
from that button so it's really really
easy for me to add uh the state of the
button add a loading action to the
button make sure that it's disabled
stretch it so it fits the entire screen
so a lot of this is going to be
responsive out of the box box so then as
you saw what I did earlier what we're
going to go ahead and do is use that
loading
State and we're going to check to see if
the
state I forget what my state variable is
called sorry pause please loading
state is equal to
loading so by simply setting that
property using a little bit of react
code I'm able to then add that loading
state I'm going to go ahead and save my
changes this time go back to my
app and now when we click generate image
it will automatically add that loading
state so it's really obvious to a user
that there is something happening please
don't smash my button please don't run
out my CPU charges please just wait for
a response to come back from the
AI now the other thing that we might
want to consider here too is um making
sure that we only show
show the image card once the image is
available so if we don't have the value
of the sample URL don't show that so if
you don't show any placeholders until
it's absolutely necessary to show
placeholders so by just going heading
and using our state and wrapping it in
that so we just want to make sure that
loading State equals success in this
case and then we can go ahead and show
our image card
did I do something
wrong no yeah what did I do
wrong
oh y' I backed out all of the change I
backed out all the changes from the
wrong example my bad also
um quotation marks are really critical
here so again we're going to go ahead I
don't know anyone have a good prompt
idea
here okay fine cat doing
yoga so we'll go ahead and G an image we
only want to show that image card once
that image is actually ready we also can
use um we have loading State indicators
as well so if I wanted to have like a
placeholder
[Music]
image
um here we go yeah sorry loading we have
loading indicators we have placeholder
images
oopsies um so you can also create like a
loading State easily with our UI
components to show a progress as well
that like we're trying to generate
something we're going to create it and
by using our progress or our placeholder
images you can also show kind of the
shapes that are going to be coming down
the line
and then once our image actually
resolves it'll actually show up in our
side panel and then we're really easily
able to add it to
our to our application just by clicking
it but another thing that you might want
is to be able to drag that image onto
that page so with our IM oops I keep
going to the wrong place guys sorry um
with our image cards we're also able to
add an on drag start event as well which
enables us to really quickly add the
ability to drag an image from the side
panel into our image as well so making
sure that it's really obvious and
consistent with the design experience
throughout the application so in canva
when you go to add anything to a design
you can always expect to be able to drag
and drop it onto the page making sure
that it's a consistent experience
whether it's an app or even in your own
application of just making sure that
it's a consistent experience of how
users interact with elements and add
them to your your page or create designs
it's going to make it a lot simpler to
create a good user experience where
users want to continue to use your
product also I didn't practice this so I
have no idea how I am on time do I need
to wrap up or okay
cool thank you guys for bearing with me
as I present on the spot here I'm just
going to wrap up real quickly and um
point you to some of the things that we
helped
use today um so our apps SDK is what
enables us to actually interact with the
canva canvas so if you want to bring
your AI Tech into canva we have a lot of
resources to help you actually interact
with the different spaces within canva
we have that UI kit as well which is a
lot of react pre-built components that
are responsive to screen size including
mobile devices because a lot of our Cana
users actually are on mobile and so this
will provide you a lot of tools to help
you get started building your UI even
faster we have plenty of guid again from
our experience of building a design
front forward company um so we have
plenty and plenty of design guides and
common patterns that you will see and
then a little bit about our app review
process so you can learn a lot about how
those apps actually went from the first
page to that second page and improving
their app
experience and you can always learn more
at canva.com
[Music]
integration the entire magic Studio that
we have embedded in canva and then also
take a look at uh the canva developers
experience a little bit more if you're
interested in diving a little bit deeper
on this and getting hands on keyboard
thank you guys all for bearing with me
as I presented this super last minute I
appreciate it and hopefully you learned
a little something about UI
[Music]
today
[Music]

### youtube_ybLDSAWyEZY.txt

thank you
[Music]
let's first start with similarity our
brains like to group objects together
regardless of where they are placed in
this case we group these circles based
on color not by location
the human brain loves to categorize
things when you look at the following
random assortment of squares and
triangles what do you see better yet how
do you see them
there is likely a chance your brain is
deciding to group together the triangles
like in this example or it has decided
to group the squares together like in
this example
your brain is working hard to make sense
of the different shapes presented
the principle of similarity also applies
to color
texture
shape
position orientation and size and
knowing how the brain works here comes
in handy as a designer we can use this
principle to shape how we develop our
layouts
we can bring attention to the most
important elements in the design by
making it different than the rest
we could do that by making it a
different color like this example
we have two layouts each shape
represents a photo text or element in
the layout we are using similar shapes
in our layout this helps everything feel
like it belongs together
this example features different shapes
of photos and content which does not
allow the brain to categorize all the
different information presented causing
confusion
the next principle we're going to go
over is the principle of proximity close
objects are grouped together
your car console uses the idea of
proximity to make it easier for you to
find and locate related controls on the
dashboard you may notice all of the air
conditioning and heater dials located in
close proximity to each other you may
also see the radio controls put tightly
together in relation to the other
unrelated controls in the car this is a
helpful concept to keep in mind when
doing layout design we can group related
items in the layout together so they
feel like a larger cohesive group that
share a similar goal this helps the
human brain organize larger amounts of
information that would otherwise be
overwhelming
in the logo above the logo on the top is
a good example of the principle of
proximity in action the logo on the top
has the words of the company travel and
loop spaced rather closely together
I'm able to read this logo as one
company name travel Loop
in the logo in the middle you see a
wider gap between the two words and they
start to read as separate words
but also start to feel disconnected from
each other
the event name and the descriptor line
are grouped together in the same area
you can also see related date and
location items group close together
this allows the viewer to group related
items together so they can easily
understand the information imagine if we
placed all the information into one area
without any sort of Separation it could
be really messy and intimidating for the
viewer to look at
the next principle is the principle of
simplicity and we break down elements
into the simplest forms possible
we see the image on top as one complex
shape with curves and lines
instead what our brains try to do is
break that complex image down into
something easier to handle and we
suddenly see three simple shapes instead
of just one complex shape
we see the principle of Simplicity
applied to Icon design all the time
icons need to be seen in very small
sizes if we were to have a detailed
illustration for a small icon it would
not always be easy to tell what it was
we instead simplify illustrations down
to icons that could be identified in
many different sizes
so when you take this icon for example
when reduced down to smaller sizes this
simplified icon fares much better than
the more complex illustration
one thing to always ask yourself when
creating a design is can I make this
more simple
you could do this by reducing
unnecessary elements graphics and even
combining texts that are saying the same
thing
simplification can make your message
appear more clean and concise
ask yourself another question is this
graphic or element adding value to my
design
as designers we typically feel we need
to show off our creativity but remember
your Design's overall message is always
the most important make it clear concise
and rewarding to look at
so take this example
the layout to the left is busy and
complex with many different sized
elements and structures
simplifying our layout to focus on our
main photo idea or focal point can help
a viewer cut through the noise so to
speak to have an enjoyable experience
using Simplicity makes complex objects
easier to understand the goal is to
reduce it down to the point where it
still retains its core meaning and use
this clock is still understood as a
clock even though it's just a circle and
one bit line
[Music]

### Untitled 16.txt


What Is the Role of an AI Designer?
How AI designers are bridging the gap between user needs and technological capabilities.
Amanda Linden

Amanda Linden
·

Follow
6 min read
·
Jun 11, 2019

About 4 months ago, I began managing the product design organization for Facebook’s Artificial Intelligence team. We are a central organization that provides AI services for Facebook, Instagram, and other Facebook apps. We also work to develop new experiences, powered by AI.

Before joining the Artificial Intelligence team I had been reading a lot about AI and was really excited about the idea of working in an emerging space. I’d been working on mature mobile and web apps for the last 10 years, so being in a position of learning and ambiguity felt really energizing. I also felt a responsibility knowing that AI technology will be extremely transformative to society, more-so than even the mobile revolution has been. I wanted to use my skills to ensure that AI tools are built in a responsible way.

To be honest though, I wasn’t exactly sure what the role of product design would be on the AI team. We don’t own a consumer product surface of our own, so there isn’t an app for the team to maintain day-to-day. I also had a preconceived bias against designing “technology first” versus “people problem first”, so figuring out how to work effectively in a world where technological capabilities are unfolding real-time (and you are working to apply them in the right way) felt backward and unfamiliar to me.

I thought it might be useful to others to share the approach we are taking to offering design support to our developer & application team partners, and in the creation of new experiences. This information might be useful if you are also building out an AI design team, or if you are curious about pursuing a role designing AI.

Generally speaking, designers on the team are working on the following project types:
Designing AI Prototypes

When an AI tech team needs a prototype, demo, or visualization of their technology, they work with a product designer. AI designers make sure that people see what’s possible with AI. We create prototypes showing how a particular technical capability might be used by people when the AI is working well. As an example, we might create a demo of AI suggesting a possible caption for your Instagram post, or AI helping you know where to buy a pair of shoes you see in a post.

For an AI Demo designer, the creation process is usually to illustrate a set of product ideas as one page briefs with a set of visuals to briefly illustrate the idea. We use the one pager to get buy-in from the broader team that the idea is worth building out further. The finished prototype be used to green light a new research initiative or development project within the AI org.

Designers working on AI Demos are working on a wide variety of ideas, they are highly generative rather than going deep in one technology area. They have a strong understanding of current AI capabilities and keep track of how new capabilities are developing. As a designer working on demos, you might be creating a visual search experience, on a way that users with visual impairment can “see” newsfeed posts by rolling over the photos with their fingers.
Shaping New Technology

AI designers can also work as an embedded part of a technology team, shaping new technology. AI designers work on long-term areas of investment like computer vision, speech, language, video, and AI assistant initiatives. These project teams are developing new AI capabilities (rather than working with existing AI capabilities). The work you do as a designer on a technology team blurs the lines between design, PM and research. You are working to ensure that developer teams understand user needs relating to a particular type of technology and are building the technology to directly solve those needs. You are imagining user experiences that might be seen by users in 3–5 years, and would take significant improvement in AI technology to achieve. AI designers go deep in understanding the long-term vision for AI in their area of focus.
Developing AI Centered Products

Another project an AI designer might work on is to design new AI centered applications, testing them for viability, and (if promising) pitching them for further investment. The time horizon for projects in this space are farther out, so you are working in a world where you imagine people living life 5–10 years from now. You are thinking about how AI can offer better socially powered services to people longer-term. The products you build might be the Facebook or Instagram of the future, or might be a totally new way of engaging with your community.

Designers in this space often have a background in building new hardware or working in a startup space on new app ideas. They are comfortable with ambiguity and have an understanding of how to create the criteria for continuing to pursue or shut down a line of exploration.
Collecting Data for AI to Learn

One of the most important parts of shaping AI technology is giving AI the right data to learn. AI designers work with the engineers who build tools for this data collection and annotation, and design the platforms that enable it, to streamline efficiency and make it intuitive to collect good quality data. In some cases designers help gather datasets when more automated methods won’t work.

Here is an example of how a designer might help with data collection helps AI learn: We may need to teach AI to know when a person is raising their hand. In order to teach the AI, we gather thousands of video examples of people raising their hand, ensuring that examples come from people of various ages, genders, ethnicities and physical differences so that the data set is inclusive. They then gather thousands of examples of people NOT raising their hand to help the AI know when the answer to, “Is the person raising their hand,” should be, “No.” Finally, they show examples of people raising their hand that are potentially harmful (i.e. someone raising their hand in a Nazi salute) so that the AI can learn to flag those examples when identified.

AI designers help to ensure that we are developing data collection systems that are safe, fair, ethical, and apply to real user problems. These designers create frameworks and guidelines where needed to ensure the safe and secure use of AI. They design the libraries that our machine learning systems use to learn, ensuring that they are free of bias, clean and effective.
Designing AI Developer Tools

Designers on the AI team also build applications used by AI engineers, as well as the external developer community through open-source projects. Product designers on this team are building specialized developer applications, ensuring that we are creating a set of tools that work well as a system. Designers in this space need to have a deep understanding of the AI development process and a passion for empowering engineers across the globe. They often have a strong background in engineering or systems thinking.

At a high level, AI designers are bridging the gap between user needs and technological capabilities. Knowing that our goal is to give people the power to build community and bring the world closer together, we want to use current and future capabilities of AI to design the future of how people connect and collaborate.

There are big differences in the role of a typical product designer and an AI designer. Rather than launching a product feature that shows up in an app in an immediate and obvious way, our output is often clarity for engineers on how the technology could be applied. Because AI capabilities might take 2–3 years to develop, it’s important for designers to help developers understand the potential of different solutions and their impact on people’s lives when developing AI. And even more exciting — Beyond using existing AI capabilities to solve problems that exist on our platforms today, these designers get to imagine and imagining how AI will reshape the world tomorrow.

### youtube_4VWrl98KzCE.txt

hello everyone and welcome to mr
simplifies tutorials in this tutorial
we're going to look at gestalt
psychology the concept the principles
and the applications of the same
gestalt is a german word which most
closely equates to patterns
forms or
a unified whole in the simplest of ways
gestalt psychology is a is a school of
thought that believes that the whole of
an object is more important than its
individual parts as simple as that
now over the course of our lives our
minds tend to perceive objects as part
of something larger and something more
complex and this is what just all
psychology elaborates
now in reality there is a lot of chaos
and disorder in the world as we all know
but human beings tend to search for
order
in disorder
and this is also what just all
psychology focuses on
and it therefore helps us understand
human perception and sensation
so who came up with just all psychology
gestalt psychology was founded in
germany by max wertheimer and supported
by kurt kofka and wolfgang koller
now wertheimer observed some lights
switching on and off in a sequence in a
railway station and realized that
they're actually creating an illusion of
movement he called this the phi
phenomena
this refers to our tendency of sensing
movement where there is actually none
and this is what eventually gave birth
to just old psychology
when you see sequential fairy lights
you get an illusion that light is moving
from one corner to the other right it's
however just lights sequentially turning
on and off and there is actually no no
real movement there it's just our brain
interpreting a sequence
of lights turning on and off as a
movement and making it look better and
more satisfying than it actually is
a video game
is a similar but more complex example
what you actually see on the screen is a
complex arrangements of arrangement of
lights
which
gives you a perception of people objects
and motion
and in a similar way when we play some
strings
on a guitar or or some digits on a
keyboard let's say in a sequence our
brain
interprets what we listen to as music
just all psychology is applicable
not just
in the visual context but also in the
auditory context or any other context
in all contexts where there is a
possibility of a pattern
there are some principles of just all
psychology that that govern how human
brains work
when it comes to interpreting movement
and patterns so let's look into some of
them now and after that look into the
applications of gestalt psychology
including gestalt therapy
okay though so the first principle is
the principle of proximity the principle
of proximity states that when objects
are placed close to one another we
perceive them to be related to one
another and to be a part of the same
group
now in the graphic we see a group of
eight dots and we see
that they're grouped into two parts
and we see two groups
and we clearly see two groups even if
the colors are mixed together
and this is the effect of proximity
another example is lettuce coming
together to form words it's essentially
the same alphabets used to produce so
produce so many different words right
and it's the same alphabets that are
being used it's just that they're
clubbed together to form different words
the next principle is the principle of
similarity now this principle states
that we tend to group together
objects which appear similar to one
another
in the graphic below for example we have
an s
formation or a five
clearly visible because the colors make
the the brain group the the red balls
together
another example can be
us grouping people together if they if
they wear the the same colored clothing
to support the the team of their choice
in sport
the next principle is the principle of
figure ground now this principle states
that people tend to
instinctively put objects in the
foreground or in the background
in certain situations we tend to place
prominent objects in the foreground
making them the figure and place other
objects in the background making them
the ground so that's figure ground
now this can vary as per your perception
so what's figure for me can be ground
for you and vice versa
now there are pretty complex visual
examples available to explain this but
in the simplest of examples let's see
the following two block combinations
many in the first image would see the
the small square to be the figure
on a white background and
in the second image many would see the
the black box to be the figure
to be a square donut-like shape and
perceive the the white
box as ground now some could perceive
things completely differently though so
this is
all based on your own perception
now the next principle is the principle
of continuity
this principle states that the human
mind prefers to gauge continuous lines
or curves rather than separate
components that make up the line or the
curve
in other words if several objects are
arranged in a line or a curve and some
objects are not
the objects in the line or the curve
formation are considered to be a unit
for example in the below graphic we have
dots arranged such that we have a smooth
line and a smooth curve
the dots on the half of the curve seem
more related to the dots on the other
half
rather than the second half of the line
the same is true in the case of the line
and this is despite the color
differences
or for example if you if you have leaves
covering your vision of the mcdonald's
logo somewhere
you will complete the the logo in your
own mind and not think of it as a half
logo because there is a pattern and you
recognize that pattern
the next principle is the principle of
closure this principle refers to our
preference to see
complete
and not partial element
we once again look for a single pattern
in our brain in our mind which is
recognizable now the mcdonald's logo
example can be used again as it also
works
on our tendency to close the logo
as as we saw previously or if you look
at
the ibm logo for instance it's been
designed in a way that you actually need
to complete the logo in your mind
it's deliberately designed in that way
the next principle is the principle of
common fate this principle states that
when objects are seen to be in the same
enclosure
or are seen moving together
in a certain direction they can be seen
as grouped together they can be
considered as in the same group army
formations are a good example wherein
people are perceived to be in the same
group due to similar movements and
formations
the next principle is the principle of
symmetry
it's human nature to find a try and find
order in chaos
finding things in symmetry and harmony
gives us solidity and order
if you look at the example below you'll
notice how powerful symmetry is we have
a couple of open and close
opens and closes of brackets
our mind processes the
space in the brackets as groups
despite the brackets being quite close
to one another
so it
kind of is more important than proximity
so it takes precedence over proximity
now look at now let's look at some of
the main
applications of gestalt psychology one
of the most important applications of
gestalt psychology is gestalt therapy
gestalt therapy is essentially a
humanistic
client-centered therapy with a focus on
facing current challenges in life and
taking responsibility
of one's own life
some of the key characteristics of
gestalt therapy are as follows
focusing on the present now focusing on
the present challenges and not delving
too much
or too deeply into the past is one of
the main hallmarks of gestalt therapy
this is because spending too much time
in the past
or going too far into the future as well
can can both create anxiety in a client
a gestalt therapist will therefore focus
on bringing a client's attention back to
the present by building rapport and
being observant about the body language
and basically focusing on the current
challenges in that client's life
the next characteristic is therapist
perception since just all psychology
helps us understand human perception a
gestalt therapist would understand that
his or her
own experience in life and judgment can
actually influence therapy they would
therefore look into not imposing their
own judgment
in the session and keep the therapy
client focused
self-awareness self-awareness is an
important part of gestalt therapy
guided imagery role play and activities
could be used to to to open
with and make a client aware of his or
her abilities and strengths
gestalt therapy is one of the main
applications of just all psychology and
can be used in treating anxiety
depression
low self-esteem and relationship
problems as well
what are some of the other applications
there are various applications in user
interface design and product design as
well
now just all psychology can actually be
used in ui design to strengthen user
experience
for example in designing better quality
websites which engage and educates users
at the same time
the principles we looked at can each be
used from a user interface perspective
to optimize client engagement
for instance the the principle of
similarity can be used to ensure that
similar content blocks on a website and
and calls to action in a website are
placed in a similar color scheme
another good example of of good user
interface design would be to use
symmetry to ensure that web pages are
symmetric to one another so that
the information displayed
is considered orderly and pleasant to
the human brain while serving the
intended purpose because if a person is
unhappy or dissatisfied by the layout
scene
of the imagery and the text on the
screen that person is is likely to click
away from the website or out of the
website or just close it down distal
psychology can also similarly be used in
product design and development so you
can develop better quality products and
designs by using gestalt psychology it
is therefore extremely important
not just
from a therapy point of view
not just from
an understanding of a human brain or a
mind perspective it's also very
important in design
in bridging that gap between
user interface and user experience
design and the actual needs of a
business
okay i hope this tutorial was helpful
for you in terms of understanding
gestalt psychology and distort therapy i
thank you all very much for your
attendance as always and as always
please use the comment section to
recommend topics you want covered in
this channel please use the the
subscribe button and the like buttons
spread the the word about this channel
share this content and as always and
most importantly take
very good care of yourself thank you bye

### Untitled 17.txt

An intro to Machine Learning for designers
The basics of machine learning and how to apply it to the products you are building right now.
Sam Drozdov
UX Collective

Sam Drozdov
·

Follow
Published in

UX Collective
·
6 min read
·
May 30, 2018

Photo by Gertrūda Valasevičiūtė

There is an ongoing debate about whether or not designers should write code. Wherever you fall on this issue, most people would agree that designers should know about code. This helps designers understand constraints and empathize with developers. It also allows designers to think outside of the pixel perfect box when problem solving. For the same reasons, designers should know about machine learning.

Put simply, machine learning is a “field of study that gives computers the ability to learn without being explicitly programmed” (Arthur Samuel, 1959). Even though Arthur Samuel coined the term over fifty years ago, only recently have we seen the most exciting applications of machine learning — digital assistants, autonomous driving, and spam-free email all exist thanks to machine learning.

Over the past decade new algorithms, better hardware, and more data have made machine learning an order of magnitude more effective. Only in the past few years companies like Google, Amazon, and Apple have made some of their powerful machine learning tools available to developers. Now is the best time to learn about machine learning and apply it to the products you are building.
Why Machine Learning Matters to Designers

Since machine learning is now more accessible than ever before, designers today have the opportunity to think about how machine learning can be applied to improve their products. Designers should be able to talk with software developers about what is possible, how to prepare, and what outcomes to expect. Below are a few example applications that should serve as inspiration for these conversations.
Personalize Experiences

Machine learning can help create user-centric products by personalizing experiences to the individuals who use them. This allows us to improve things like recommendations, search results, notifications, and ads.
A basic overview of how video recommendations are influenced.
Identify Anomalies

Machine learning is effective at finding abnormal content. Credit card companies use this to detect fraud, email providers use this to detect spam, and social media companies use this to detect things like hate speech.
Create New Ways to Interact

Machine learning has enabled computers to begin to understand the things we say (natural-language processing) and the things we see (computer vision). This allows Siri to understand “Siri, set a reminder…”, Google Photos to create albums of your dog, and Facebook to describe a photo to those visually impaired.
Provide Insights

Machine learning is also helpful in understanding how users are grouped. This insight can then be used to look at analytics on a group-by-group basis. From here, different features can be evaluated across groups or be rolled out to only a particular group of users.
Prepare Content

Machine learning allows us to make predictions about how a user might behave next. Knowing this, we can help prepare for a user’s next action. For example, if we can predict what content a user is planning on viewing, we can preload that content so it’s immediately ready when they want it.
Types of Machine Learning

Depending on the application and what data is available, there are different types of machine learning algorithms to choose from. I’ll briefly cover each of the following.
Supervised Learning

Supervised learning allows us to make predictions using correctly labeled data. Labeled data is a group of examples that has informative tags or outputs. For example, photos with associated hashtags or a house’s features (eq. number of bedrooms, location) and its price.

By using supervised learning we can fit a line to the labelled data that either splits the data into categories or represents the trend of the data. Using this line we are able to make predictions on new data. For example, we can look at new photos and predict hashtags or look at a new house’s features and predict its price.

If the output we are trying to predict is a list of tags or values we call it classification. If the output we are trying to predict is a number we call it regression.
Unsupervised Learning

Unsupervised learning is helpful when we have unlabeled data or we are not exactly sure what outputs (like an image’s hashtags or a house’s price) are meaningful. Instead we can identify patterns among unlabeled data. For example, we can identify related items on an e-commerce website or recommend items to someone based on others who made similar purchases.

If the pattern is a group we call it a cluster. If the pattern is a rule (e.q. if this, then that) we call it an association.
Reinforcement Learning

Reinforcement learning doesn’t use an existing data set. Instead we create an agent to collect its own data through trial-and-error in an environment where it is reinforced with a reward. For example, an agent can learn to play Mario by receiving a positive reward for collecting coins and a negative reward for walking into a Goomba.

Reinforcement learning is inspired by the way that humans learn and has turned out to be an effective way to teach computers. Specifically, reinforcement has been effective at training computers to play games like Go and Dota.
Things to Consider
What approach is viable?

Understanding the problem you are trying to solve and the available data will constrain the types of machine learning you can use (e.q. identifying objects in an image with supervised learning requires a labeled data set of images). However, constraints are the fruit of creativity. In some cases, you can set out to collect data that is not already available or consider other approaches.
What is the margin of error?

Even though machine learning is a science, it comes with a margin of error. It is important to consider how a user’s experience might be impacted by this margin of error. For example, when an autonomous car fails to recognize its surroundings people can get hurt.
Is it worth it?

Even though machine learning has never been as accessible as it is today, it still requires additional resources (developers and time) to be integrated into a product. This makes it important to think about whether the resulting impact justifies the amount of resources needed to implement.
Closing Thoughts

We have barely covered the tip of the iceberg, but hopefully at this point you feel more comfortable thinking about how machine learning can be applied to your product. If you are interested in learning more about machine learning, here are some helpful resources:

    Machine Learning for Humans — Simple, plain-English explanations accompanied by math, code, and real-world examples.
    Machine Learning Algorithms: Which One to Choose for Your Problem — Tips for developing an intuition for picking a machine learning algorithm to apply to a problem.
    Machine Learning is Fun! — A slightly more technical series that walks through implementing a machine learning example.
    Neural Networks by 3Blue1Brown — A collection of engaging, technical Youtube videos that step through what are neural networks and how they work.
    Andrew Ng’s Machine Learning Course — Highly rated technical course that broadly covers many areas within machine learning.

Thanks for reading. Chat with me on Twitter @samueldrozdov

### youtube_jtwl9M-UNQE.txt

hey I'm Colin I'm one of the founders of
visual electric and I wanted to share a
little bit about the thinking that led
us to uh building this product so I open
up in my browser here the you know three
of the more popular image generation
products today this is mid Journey which
you can access through
Discord this is Dolly which you can
access through chat GPT and staple
diffusion which you can access through a
number of different uh interfaces this
is the one that stability uses sorry
this that stability made called dream
studio and all of these share a pretty
similar interface pattern which is this
conversational view where you send
messages back you s you send messages
and you get images back and it's this
very linear process and you know as a
designer and someone who's been used to
working as out of tools like figma or
illustrator um the thing that felt
obviously wrong about these interfaces
is that it forces the sort of linear
process that doesn't really map to how
the creative process works it the
creative process is not linear uh and
you will often you know go down side
streets and explore ideas only to
discover that they're a dead end and
then at that point you need to back up
and uh find something that you were
looking at before and that might spark a
new idea and and all of this sort of
unfolds
into what becomes this kind of beautiful
mess and this is my mess this is my
visual electric canvas that I was
working in and this represents you know
a couple hours of Flow State of me just
exploring and riffing and pulling and
reference
images uh seeing what ideas it sparked
generating new images from from those
ideas and and there is a logic to how
this all unfolds uh it may seem kind of
overwhelming
to somebody else but to me this is a
this is like a journey that I went on
and uh there's various signposts along
the way and if I need to return to
something or find an old idea that
didn't seem right previously but now
makes sense I know how to get to it and
all of this becomes a kind of instrument
that you play and improvise with and
experiment with and and the goal really
is to have the tool disappear have it
just be about you and your ideas and
exploration and and all this is sort of
made possible by uh having a tool that
that makes sense to designers that works
the way creativity works and that was
the thing that we felt like was missing
uh in the market so I'm going to dive
into specific features and talk about
the various tools and how we design them
um but I just wanted to give that high
level overview of what led us to
building visual Electric in the first
place

### Untitled 15.txt


Designing with AI
What I learned from designing an artificial intelligence–enabled experience
Erica Virtue
Facebook Design: Business Tools

Erica Virtue
·

Follow
Published in

Facebook Design: Business Tools
·
8 min read
·
Sep 26, 2017

At Facebook, AI is everywhere.

Behind the scenes, AI helps make Facebook smarter and easier to use. We use it to help translate text so people can understand each other better, to recognize what’s in images so visually impaired people can “see” the photos their friends post, and to filter out undesirable content like spam. We also use AI to understand the intent behind what people post so we can improve their experience on Facebook.

When I started as a designer at Facebook, I hadn’t thought much about AI or how it could be used as a tool in product design. But then I ended up designing Facebook Recommendations, which uses AI to detect when people are asking for local recommendations, and then to match the places that their friends recommend to Facebook Pages. It’s one way we help connect people and local businesses.
It All Started with a Problem

I’d noticed a lot of posts in my Feed in which people were turning to Facebook to find recommendations for places to go and things to do. These posts got a lot of engagement, but weren’t very useful. You had to scroll through all the comments, then copy and paste the names into Yelp or Google to find out more about the places your friends were recommending — even though over 60 million businesses have Pages on Facebook. The worst part was that it was really easy to lose these posts in your Feed, so they were only useful for as long as you could find them on your Timeline.

I wanted to make it easier and faster to collect and consume the recommendations that people get from their friends — and help them get more recommendations from people they trust.
How We Arrived at AI

People were already asking for recommendations on Facebook, and we didn’t want to get in the way of the behavior that was already happening. Ultimately, AI turned out to be the best approach because it let us make their posts better by turning their unstructured conversations into a helpful shortlist or travel guide. We didn’t reach this solution right away, though. First, I explored a number of possible solutions to our problem, which we validated through user research and live experiments.

One of the first concepts we tested was an approach where you’d have to say up front what you were looking for and where. But we found that people didn’t really understand why they would do this. They didn’t see the value of adding this additional metadata to their post, and it was tough for us to demonstrate the value we could give them when they couldn’t actually see the experience for themselves. We were also fighting against existing behavior, which was to just write a status update with their question.

Another concept we tested was a more educational approach. We thought that by stepping people through a tutorial that explained what was going to happen, we could help people feel more comfortable with the product. We found, again, that it was difficult to explain in words or illustrations how we were going to provide value before letting them experience it for themselves. Once people used the product for themselves, they loved it, but not surprisingly, we saw some drop-off in usage when we added in additional steps before posting.

From testing these more structured approaches, we learned that the less friction we added to the experience, the better it was for people. We decided that the best approach was something “automagical” that would augment the behavior that was already happening, without being too intrusive. In order to trigger the experience in a frictionless way, we relied on artificial intelligence to understand when people were asking for recommendations and what places their friends were recommending when they replied.
How Recommendations Works

With Recommendations, you can post your question on Facebook as you normally would, and when a friend comments with a recommendation, we link to the corresponding Facebook Page and display details like ratings, price range, open hours, and addresses. We also put all the places they recommend on a map so you can find everything easily. We’ve seen people use Recommendations to find everything from water during a hurricane in Florida to the best craft breweries in Australia. There are even Facebook Groups, such as the Tri-State Restaurant Club, where almost every post is a request or offer for Recommendations.
The AI Behind the Product

The Recommendations product seems pretty simple. Making it work is a lot more complex. In order to turn a status update like “Friends! Where’s the best place to get a haircut in Chicago?” into a Recommendations post, we have to first understand: (1) that you’re asking for recommendations, (2) what types of places you’re asking for, and (3) where you’re looking. This is easier said than done, especially considering the way people use slang and casual language on Facebook.

We partnered closely with the Conversational Understanding team at Facebook to use Natural Language Understanding (NLU) to power our experience. This team built AI technology that can understand text posts to accurately detect when someone is asking for a local recommendation, enabling us to automatically trigger the Recommendations experience.

When your friends comment on your post, suggesting all the cool places you should check out, we use AI to understand the text and extract the most likely place(s). AI also gives us a confidence score that indicates the likelihood that it’s the right place. This score shapes the user experience that the commenter receives. If it’s high, we simply attach a place card to their comment (with the ability to remove it). If we have medium confidence, we ask if it’s the right spot before attaching it. When the score is low, we show them an empty card that opens up a search bar that lets them manually search for the place that they want to add.
What I Learned About Designing with AI

The allure of AI is that it can make your product “magically” work. But my experience on Recommendations hammered home that AI’s power doesn’t lessen the need for thoughtful product design — just the opposite, in fact. Of all the lessons from the project, here are the ones I keep coming back to:
Look for existing behavior

AI opens up a lot of opportunities to make existing behaviors faster and easier for people. We didn’t try to invent a completely new behavior; rather, we found an existing one and made it way better! AI made it possible for us to deliver a magical experience while introducing as little friction as possible for people to give or receive recommendations.
If you don’t notice the AI, you’re doing it right

When you use AI in a way that enhances an experience, rather than defining it, it can actually feel almost invisible. AI lets you break free from a traditional user interface and solve problems for people in a seamless and almost magical way.

We purposely decided not to make it feel like you were talking to a robot or like Facebook was interjecting itself into a conversation you were trying to have with your friends. Instead, we used a design that augments the comments you receive from friends with helpful information. This approach feels more natural, and keeps your conversation with your friends at the forefront. In fact, in user research, when we showed the experience to people who said they’d never seen it before, some said “Oh yeah, I’ve used this before! It’s great!”
Test, test, test

As soon as you start introducing “magic” into the experience, people assume that it should work all the time. When we first started testing our experience, our AI got things wrong. A lot. It’s not a great experience when we suggest that you link to a dentist’s Page when you’re trying to recommend a restaurant. Usability testing with real people was very important, especially once we had a working product. We also looked at a lot of public Recommendations posts to get a feel for how well the product was actually meeting people’s needs. By watching people go through our experience early, we uncovered a lot of issues with our AI we wouldn’t have noticed otherwise.
Don’t depend on perfection

Even if your AI works most of the time, there are going to be moments when it completely fails. If people can’t accomplish their goal when this happens, you’re going to end up with a lot of very unhappy users. One thing that makes Recommendations work is that even if our AI didn’t recognize your post, it didn’t stop you from posting your question and getting recommendations from your friends — your post just wouldn’t be as helpful.
Degrade gracefully

By falling back to alternative UI, you ensure that you can provide a good experience for people even when your AI fails. Though it was more challenging to design multiple UI treatments, we were able to provide a less intrusive product by differentiating the experience based on AI confidence. For Recommendations, we experimented with raising and lowering the confidence levels and with a number of different UI treatments at each level, until we found the combination that worked the best.
Feedback is a gift

This is a saying at Facebook, and it’s especially true when designing with AI. It’s important to provide ways for people to give feedback about our guesses and then use it to improve the experience. By letting people x-out our suggestions when we were wrong, we not only provided an escape hatch, we also created a way to collect valuable information about how our AI is doing. Every piece of feedback we receive helps to improve our AI and the overall Recommendations experience.
Influencing AI’s Future

Since launching Recommendations, we’ve continued to improve the experience and I’ve continued to learn a lot about the challenges of AI and the opportunities that it can unlock. Above all, I’ve learned that designing with AI is just like designing anything else. Focus on people problems, test your assumptions, and provide affordances for when things go wrong.

As AI inevitably becomes deeply integrated with the products we build, it becomes more and more essential for product designers to take part in how it evolves. It’s a natural fit — making technology feel human was obsessing product designers long before AI came along. By applying design thinking to AI-enabled products, we can help ensure that those tools truly serve the people who use them.

### Untitled 3.txt

Marielle Lexow

Published in

UX Collective
·
23 min read
·
Aug 17, 2020

The story image shows a photograph of the wave pattern inside Antelope Canyon in North America.

InIn Silicon Valley, automation and artificial systems are present everywhere. For the people living there for years, it might be normal, but it was a new experience when I moved to the San Francisco Bay Area for a UX internship last year. Straight from Germany you probably can imagine how crazy it was to see the big tech companies for the first time but also the typical American things like straight out of Netflix. Just to mention the burgers and burritos but also the traffic and broad streets. I was working in automotive and was surrounded by inspiring people, a fast-moving world and a try and error mentality. You see autonomous driving prototypes from Waymo or Nuro in the real traffic, next to you on the street. It was interesting to look at Waymo’s cameras and sensors outside and inside of the vehicle while waiting at the traffic lights. It measures data from the surrounding environment and every traffic situation. The test driver monitors the live generation of the data, but the evaluation and analysis happen invisibly and deeply confidential in big tech companies and start-ups. Artificial Intelligence is more present than in any place I have ever been to before. Working on future mobility concepts and attending a talk about “Designing for Automation” from the Oracle design team at AIGA in San Francisco, I was so curious about designing for AI products and services, that I wanted to learn more about it. And this is what the article is for, to give an overview of Artificial Intelligence in User Experience Design. We will take a look at questions like which influence does AI have on the creative industry and its UX designers? How can User Experience actively shape the era of Artificial Intelligence and Machine Learning? And how does designing for AI work and what are the most important design principles? Here we go.
Automation vs. Artificial Intelligence

Before we dig deeper into the UX Design for AI, we should first talk about the differences between Automation and Artificial Intelligence, so we are all on the same page. As a designer allocated on an AI project it is crucial to understand at least the basics of how AI works and what goes with it to collaborate well with developers and engineers alike. For both terms Automation and Artificial Intelligence, there is not the one definition, unfortunately. Everybody understands something different, depending on the exact professional field they come from. But the common understanding is, that automation uses structured data as an input. The rules and exceptions the system uses are defined. This means the output the machine gives to the user is predictable. Automation is being used for traditional processes and very task-oriented repetitive workflows. In the previously mentioned talk at AIGA, Oracle shared an interesting example of an automation project. The use case was the budget approval process in large companies. The manager receives countless requests for approval every day, each of which must be processed manually. To simplify this process and make it more efficient for the user, a tool based on automation was developed. Up to a certain financial amount, which the manager determines in the software itself, the budget requests are automatically approved by the system. The manager only reviews the requests from the amount he considers financially relevant. In this use case example, automation has served its purpose.

Artificial Intelligence goes much further. AI uses the input data to find patterns and provide predictions and insights as an output. The AI system uses specific models and algorithms to analyze and interpret data autonomously. It feels “smart” because they are trained with a fair bit of data and are improved continuously. Spotify for example uses Artificial Intelligence for its “Discover Weekly” feature. The user gets a weekly personalized playlist with suggested tracks that fit the own taste of music. Based on the personal playlist for each of the current 286 million monthly listeners the use case is technically too complex for simple automation. Spotify solves the problem with Artificial Intelligence since it is not possible to define concrete rules for the song suggestions in advance because every user has different music preferences and tastes. AI should also not be confused with the term “Machine Learning”. As well as “Natural Language Processing” (NLP), “Computer Vision” and others it is part of the broader bucket AI. They are various algorithms and tools to enable the AI to simulate human intelligence and behavior. In practice, Automation and AI often complement each other. This is also the case in UX Design because there are a lot of similarities when it comes to the current design principles for AI. However, in the following lines of this article, I refer to the influence and design of AI-based systems.
How AI impacts the creative industry …

Due to Corona, many of us are working from home right now. It feels like a new world of work, where the digitalization overruns us very fast and spontaneous talks with colleagues at the coffee machine are over. At least for now. Offices, but also universities are closed and a lot of my fellow students are not able to work on their projects due to closed workshops on the campus. Forrester Magazine writes, that Europe only scoops out 12% of its digital potential. It will probably change after the crisis — studies show, that companies will urgently increase their investments into automation technologies after Corona. These technologies as well as artificial systems have had an impact on the creative industry for several years and will continue to do so. Just to name a few examples: Adobe Photoshop can retouch an image with only one click by using Artificial Intelligence. Logo Makers can create a logo in seconds that fits your brand and design language and suggests you, based on your data, additional colors and fonts. Furthermore, AI-based website generators can throw out a ready-to-rollout-website within a few steps.

During my research for this article, I was struggling to find the right source on how AI will impact especially the UX industry. In the literature, there is currently not much out there. But Adobe has published a major study "Creativity and Technology in the age of AI" in 2018 on the influence of AI on the creative industry, where UX is a part of. The study says that AI is good at doing repetitive tasks like searching for stock images or test different design approaches and find recurring patterns. This might be a big potential for the creative industry to have more time for qualitative and creative processes and outcomes. The good news is that the creativity that characterizes the industry cannot easily be replicated by an AI.

Creativity is such a complex task, even the researchers have not yet fully explored it. It is not only intentional but situational, inspirational and executional. Anthony Brandt and David Eagleman, authors of the book “The Runaway Species”, explain:

    “To achieve a creative artificial intelligence, we would need to build a society of exploratory computers, all striving to surprise and impress each other. That social aspect of computers is completely missing, and this is what makes computer intelligence so mechanical.”.

The authors mentioned the social part of creativity. Probably a lot of my UX folks will agree with me at this point: I better do concept development with coworkers in front of a huge whiteboard, instead of discussing ideas with an AI in a lonely room. The study also predicts that AI, Machine Learning and Neural Networks will have an impact on visual outputs, its perception and its role in society. An example is the computational AI-based art, where artworks and imitational mimics are generated by the system. Another development is the democratization of sophisticated visuals. Non-designers get the tools to create their artifacts without going to a design professional. Look at Instagram: AI mapped rabbit ears on our face to share it in stories and short clips instantly. Everybody can design something. And even for professional designers, AI tools will support the creatives in tasks like data analysis from research, faster testing, or visual outcomes.

We can say, that AI will have an impact on the creative industry. Processes, workflows, tools and probably jobs will change. Most of these are assumptions for now, but we can see some developments going in this direction. As part of the creative industry, most of the mentioned future predictions will also have an impact on the UX industry…
… and its UX designers

Also, we technology-savvy UX designers are afraid, that AI might eat our job. Many jobs will be automated over the next decades. There is a concern, that AI will devaluate the designer’s visual skills or that we will lose control over the design process when smarter intelligence becomes the boss. For now, AI still seems like a black box and we can not predict the exact outcomes from it. It is simply letting go of control, that makes us feel unsafe. Basically, artificial intelligent systems are capable of collecting endless data and interpreting them to predict user behavior. Sounds like our UX job, right? But no worries, it is all good. With very high probability we will not lose our loved job. It will just adapt a bit. Evan Abrams, Motion Designer and Instructor summarizes:

    “AI will shift the designer to be a creative director. That will shift the focus from creating to decision-making — but no AI will supplant decision making.”.

UX designers make sure that the vision as well as the implementation follow the right direction. Our intentions and strategic knowledge are becoming much more important, but also our ability to connect the dots. The CEO of Microsoft, Satya Nadella explained, that humans have the creativity, empathy, emotion, physicality and insight, which can be mixed with powerful AI computation. Instead of working against each other, humans should work together with machines to solve “society’s greatest challenges”. But how would this collaboration look like? The current opinion of people in the industry is, that AI will be an assistant instead of a replacement. AirBnb, for example, is using AI technology to transfer low-fi wireframes into code, almost in real-time. It allows them to quickly test their ideas, because the required testing time should be zero, according to Benjamin Wilkins, former Experience Design Lead at AirBnb. Netflix uses AI to create show thumbnails in different languages based on the locations of the customers.

These products and services should support the user (if it is a customer or an internal design team) and it is the role of the designer to represent the user needs and concerns in the holistic design process. AI can assist UX designers in their daily business. Those of us whoever had to evaluate tons of video material from qualitative user interviews know, that is it very time-consuming. An intelligent assistant can transfer, cluster and point out the highlights from the complex data to help us generate insights. The same applies to quantitative research. Data from millions of people can be used for automatically creating personas. Personally, I am not the biggest fan of using personas in my projects, except it is necessary due to specific use case reasons. Every user is different so I better go with user needs. Another concern of automated personas might be the lack of human equality. AI learns from past data, but it also has to be aware of current cultural and social developments, to name the Black Lives Matter movement for example. We designers define the parameters so the AI can do its job. We will be the curators and make the decisions. Companies but also universities have to invest in the continual and lifelong learning of their designers and students by offering workshops and classes. Doing so, Junior and Senior Creatives can deal with millions of AI design variations and tools while productivity increases in a fast-moving environment. We will work with AI tools in research, idea generation, prototyping, testing and in creating and maintaining design systems. These are very exciting times for UX designers in every career level and we should keep in mind what Simon Sinek always says: Start with WHY.
Let’s start — Resources

AI is a huge topic and you can not learn all of it in only one weekend. If you google “AI” but also in connection with UX Design, you will quickly feel overwhelmed. But instead of giving up directly, it is okay to approach the topic in small steps. To help you get started, I have compiled a few sources below to help a UXer read up on the topic of AI for UX. Even if you are already working on a particular design project, they are still good references.

My first recommendations are the articles from Jennifer Aue Sukis. She is the Design Director for AI Transformation at IBM and says it all starts with becoming a data-driven designer. Including data to the design process helps to better understand user needs and user behavior and to improve the Interaction and UI Design. Therefore it is essential to know the basics about how to integrate and apply data-driven design approaches as well as how Artificial Intelligence and Machine Learning work. IBM published a website about their design for AI practice. You can read about the basics like characteristics of AI, relationship development or the AI/human context model. Since ethics are a very important aspect of AI design and development, IBM handouts a report called “Everyday Ethics for Artificial Intelligence” and it is being updated every year. They also consider information about user data rights and conversation design based on natural language for chatbots and agents. Another big player, Microsoft, also published a website only for AI. Their learning opportunities and resources are mainly intended for developers, but digging deeper into the content, you can find guidelines for Human-AI Interaction and Inclusive Design based on responsibility. Especially the guidelines for Human-AI Interaction have been explained in detail in a paper that you can download here. Since Microsoft approaches AI mainly from a broader business perspective, it is a good resource if you are a (design) manager. Last but not least I warmly recommend the ebook series “AI Driven Design” by Joël van Bodegraven and guest authors, published by awwwards books. In four chapters they are sharing knowledge about ethical challenges, biases, AI design principles and the basics about AI and Machine Learning. As the resources I have shared above, they are also writing about the role of responsibility and situational awareness. Regarding the design challenges of AI-driven applications, they hand out a nice worksheet template to identify UX challenges. View the ebooks here. There are way more resources out there as I shared here in this chapter — for example Google’s People + AI Research Library or the publications from Partnership on AI in cooperation with world-leading companies. Now, that you have a bunch of resources to refer to, let us continue by designing AI products in a valuable way — with the AI design principles.
Do it valuable — AI design principles

    “As a creative community, we are shaping what AI can become in the future.”.

This sounds very exciting, but also like a lot of responsibility for us designers, when we think about what Joël van Bodegraven and Chris Duffey mean with this sentence. We are still at the beginning of the AI era, but Artificial Intelligence is rapidly evolving. In order not to feel lost, there are a lot of AI design principles out there. I have tried to select the most frequently mentioned principles from experts working in the industry. The principles are based on current AI developments and will probably adapt or change over the next couple of years. But for today, here they are:
#1 Putting the human first

Also when it comes to designing for Artificial Intelligence it is the most important thing to be aligned with a real human need. The user’s role, as well as the goal, have to be clear. To deliver good interaction concepts and address user needs, it is all about the insights we have generated and will generate during the design process. Therefore we should keep in mind, that different users might prefer different things, especially when it comes to AI. Not everybody has the same level of experience or trust for this technology. For us designers, it also means to handle the uncertainty, which AI and Machine Learning systems bring. Rachel Been, Design Lead at Google Nest says:

    “As designers, we need to be flexible and ready to react to new questions: What if the user gets an error? What if she wants more transparency into what the AI is doing? How do you onboard her, so she understands it?”

The understanding of what the AI is doing plays an important role, but it does not necessarily mean, that the user has to understand the math behind the algorithm. Instead, the UI could visualize it in a way that makes the AI decision-making process more transparent to the user. No matter which interaction between human and machine, trust is a fundamental part which comes along with building and maintaining the relationship between both parties. Mark Knapp, a professor who researches nonverbal communication, explains the evolution of a relationship in his model. First of all, there is the initiating phase. As the first impression, the AI establishes its presence, personality and tone. User and System explore each other in value and authenticity in the second stage. Through context-aware and multi-step interactions the relationship intensifies. It is discovered, if both parties are interested in continuing the relationship. Fourth, the AI profile is established in the user-system relationship. Last but not least, they reach a high level of trust and appreciation in the bonding phase. His model might sound very romantic due to its transferability to human relationships. But it can also be adapted to humans and machines to understand the psychology of building a relationship.
#2 Design for trust and transparency

Not only designers but also users have to deal with uncertainty and risks by interacting with technology. When there is a lack of control, we need to have a certain level of trust, for example when it comes to storing our data in the cloud. The trust in machines can be influenced by factors like Human Characteristics (personalty, ability), Environment Characteristics (culture, tasks, institutional factors) as well as Technology Characteristics (performance, process, purpose). Applied to our example above it means, that someone with a trusting character is more likely to trust the data storage in a cloud.

The research shows, that the trust in digital contexts (called “e-trust”) is based on four kinds of components:
1. Communication Trust like available network connections, 2. Information Trust as believe in the quality of the information, experiences and uncertainty, 3. Social Trust in the sense of trust in the honesty of relationships e.g. in Social Media and 4. Cognitive Trust as the expected knowledge of reliability and competence.

Whether the user actually trusts the AI also depends on her/his personality, demographics and prior experiences, not to forget influencing factors from the environment like legal aspects or other people. In our UX and UI concept development, we gain trust in showing transparency and honesty. The user should know, which data is coming from where and how it is used. Currently, a Waymo vehicle for example displays what it is seeing in the environment during the ride on the infotainment system. Visually, the UI could show indicators and explanations on the predicted information or different suggestions which can be controlled by the user. Running apps for example can suggest routes which are save and lighted for the evening run. In the end, algorithm-based information are displayed so the user can decide to trust or not.
#3 Explainability

Explainability is a crucial principle to understand the AI decision-making process and setting the right expectations. The user should always know how the system came to this conclusion or recommendation. But how to achieve this? First, the user should be able to ask questions regarding the decisions the AI has made. Secondly, the reasons behind the system recommendation should be reviewable, especially when there is highly sensitive personal data in use. And thirdly, teams of multi-users like medical teams should be given access to the AI decision-making process, when data policies allow it. In cases the user or the team does not have full access to it, they should still know the intent of the AI and its level of transparency. Since AI is based on data, a lot of research has been made on algorithm aversion. Explainability helps averse users to trust the system more, but at the same time protecting them in over-trusting the AI. This could be very important for AI products or services in the medicine or finance sector, where risks might have a high impact. Another hint to consider is showing the explanation right after the user action because people learn better when cause and effect are clear. When the user is looking for café recommendations for example, explain why the system recommends exactly these. Nevertheless, let us stay realistic. Sometimes, explanations might be difficult, especially when the developers and data scientists do not know either, why the AI is doing what it is doing. We designers have to find ways in concept and visual design, how to communicate this to the user. A common solution is to display the AI model confidence level. This helps the users to estimate how much they can trust the AI decision. The UI can show the confidence level as categories, alternatives, numbers, graphs and others. Here it is also highly recommended to test a selection of confidence level visualizations to figure out what works better for this use case and users.
#4 Ability to give feedback and control

Of course, the all-time favorite of all design principles should not be forgotten — the feedback. It is important for all kinds of interactions therefore also for AI, to create a better User Experience, improve the product as well as the technology. User feedback improves the algorithm behind the product and is a supporting part in the communication between users, the product and the team.

For the user, giving feedback does not primarily mean improving the algorithm, but rather, for example, personalizing the content. This comes along with the ability to give them some kind of intervention. Especially when driving with Autopilot or semi-autonomous vehicles, human control should always be given. Controlling things manually or even stopping the process by the user should be considered. To look up, Google figured out three things to look at for feedback and control in their “People + AI Guidebook”:

1. Align feedback with model improvement.
Ask for permission to collect user data and get implicit feedback on interactions and user behavior on the one hand. On the other hand, you can get explicit feedback from the user like comments, ratings, surveys or thumbs up/thumbs down. The given feedback can either go directly into the AI algorithm or be used by the product team.

2. Communicate value and time to impact
Communicate the benefit users will have by giving feedback so it motivates them to share valuable and impactful feedback.

3. Balance control and automation
As designers, we do not have full control of how the users interact with our product in the real world. But what we have in our hands is to let users edit and adapt the output, so it matches their needs. Moreover, we have the responsibility not to automate everything that comes into our hands. It is better to automate unsafe or unnecessary tasks (like setting an automated temperature in Nest or calling an Uber driver) than the ones where people are better than a machine.

Feedback could also be negative, for example in error cases triggered by the AI system. In this case, the designer can approach it with humor or like Netflix does, with like or dislike options on suggested shows. By giving feedback here, the user trains the algorithm in the background and gets a little control of personalized output.
#5 Accountability

As humans create AI interactions and algorithms, every person in the process has the responsibility for the possible impact our decisions can have on the world. Therefore, communicate company policies from the beginning of the project, so everyone is aligned with accountability. Figure out, where which responsibility begins and ends. Document design decisions and see, if the team or the company has any knowledge of the laws regarding artificial intelligent systems. The United Nations, as well as the European Commission, published some guidelines for a trustworthy and ethical AI. Especially for AI concept development, it is even more important to work in interdisciplinary teams with professionals like data scientists, behaviorists and sociologists to build a technically feasible, user-centered and ethical product. From my point of view we should also be honest to ourselves and talk about it when something feels wrong for us and if it does not match our values.
Do it clever — AI design tips

Even if designing for AI takes into account some specialties, it follows a similar design approach as for non-AI projects. We still need to do user research, find the real user needs, define insights, user goals and more. We are also able to use the typical UX design methods like card sorting, mind mapping, ecosystem maps, user journey, sketching, storyboarding or prototyping. The AI/Human ecosystem is described by IBM in their Context Model. The Artificial Intelligence learns from humans, business needs, market goals and external factors from the world. I think it is very helpful to understand how the dots are connected. Like in any other design project, there is a user and/or business intent at the beginning. The following data from the user and the world which is used by the system underlies different policies we have to keep an eye on. In between is the huge machine learning part, where the system gets the data input and tries to find a logic behind it. It learns from the past data and delivers the response to the user who reacts to it. Based on that, the user can improve and continually teach the system. All steps in the AI/Human Context Model will have an impact on the outcome to solve a real user problem. Oracle shared another helpful design tip. Based on the budget approval software for managers I mentioned earlier, they referred to their “Three Tier UI System for Automation”. They differentiate between a highly-automated UI, a semi-automated UI and a manual UI.

By creating the user journey they figured out, which automation potential each step has. By doing so, they were able to identify eliminable and automatable tasks. According to the VP of Design, Fintech and ERP at Oracle, Winston Wang, it is his “[…] version of thinking of the continuum between fully manual vs. fully automatic work and control”. I find it is a really good approach. At this point many thanks to Winston for the support and sharing your thoughts with me. Last but not least, I would like to mention a helpful worksheet called “UX of AI challenges” by Nadia Piet, a design researcher and strategist. She created a table with some questions to think about when it comes to design principles like user trust, transparency and control. It was published in part four of the awwwards e-book series “Artificial Intelligence Driven Design”. In general, you will probably learn most tips and tricks if you are working on a project based on Automation or Artificial Intelligence. Companies like IBM or Oracle have found their ways and approaches to AI and Automation Design in their teams. So I think it will remain very important that these approaches are shared with the design industry to inspire and adapt. For now, we got some starting points on how AI might change our UX jobs, we learned about designing for trust, explainability and other principles as well as looking for helpful models. But in the end, they are all applied as a part of the design process.
The image shows the AI/Human Context Model from IBM. It describes the connections between business, world, machine and human.
IBM AI/Human Context Model
Do it organized — AI design process

When I planned this article I asked myself if designing AI products will lead to a completely different design process? Do we have to change our way of creative thinking? As I was indicating earlier, our common UX process and especially the design thinking tool is quite applicable to AI projects. It supports by dealing with the complexity AI brings along and aligning the project team of developers, engineers, managers and other stakeholders. AI products are built with a multidisciplinary team in an iterative design process. It is about understanding the user and identifying the problem, ideating solutions, iterating prototypes and delivering the concept. Holistically, designers are making sure the team has a clear intent and applies the “putting the human first” principle. Try to make as many decisions as possible based on data, not on assumptions. Even if it is not always possible in real projects with limited time and budget. Another question to discuss with the team is if you really need AI to solve the user problem. People want the best solution which fits their needs, no matter what the technical solution behind it is. So do not build a product based on AI just to build a product based on AI. Identify the user and business needs in a team workshop to stay on the right track (with markers for everyone and a whiteboard!). After that, you can cluster and prioritize the core intents. In co-creation with data experts, you can then figure out, which data you need, which data is available and what is needed to teach the AI. The “Personal Data Canvas” from designhumandata.net is a valuable framework you can download online to figure out some answers.

In the next step of the process, the team can check, which ideas have the potential to be implemented. Crazy ideas are good, but some people actually have to code it so it should be technically feasible. From the concept point of view also think about potential misunderstandings or a repurpose of the product on the one hand, when it is used by the real customers. Thoughts about worst-case scenarios are still a good chance to reveal points that need to be questioned. On the other hand, find out additional benefits on the user or the business, when considering direct as well as indirect effects on the AI. Again, IBM published a helpful toolkit for Enterprise Design Thinking with some approaches on AI.

In the next years, Artificial Intelligence can take over some tasks in the design thinking process, which have a high potential of automation. Examples are competitive analysis, clustering and discovering insights from user interviews or sitemaps and A/B testing methods. AI tools that are capable of analyzing and interpreting a large amount of data can help create better products in the future of design thinking. For now, Craig Nelson, Partner at ISG Research summarizes the design thinking in the context of AI with the following words:

    “Executives who promote design thinking in their organizations can accelerate AI adoption, achieve organizational alignment and drive commitment to their goals while reducing resistance to organizational change.”.

Conclusion

We live in a time which is characterized by both excitement and reorientation at the same time. Who knows what the world will look like after Corona in the long run or how exactly the technology of Artificial Intelligence will develop? In my opinion, it is a great opportunity that UX designers, among others, can contribute to the future development of Artificial Intelligence with our creative and analytical way of thinking but also with our empathy. We are used to dealing with uncertainty. Because let us be honest: In many projects, we do not know on the first day in which direction it will develop and how exactly the final product will feel and look like. Especially here in Germany, I would like to see more courage and openness to the try and error mentality, as I experienced it in Silicon Valley. These do not have to be the Waymos on our streets, but at least a little more visibility of new (AI) solutions. For this to happen, however, they first have to be designed. As designers, we set the parameters that need to be designed and work with other experts to ensure that AI-driven products are not only human-first but also technically feasible, ethical and environmentally responsible. To this end, we should question ideas and concepts or even approaches and be aware of current developments as well as the chances and risks of our AI concepts. This also includes looking at how AI and Machine Learning work and being able to communicate better with developers and engineers. On the other hand, they should also be included in the Design Thinking process. The organizations that still only build technology-oriented products will hardly be able to compete with the organizations that approach products based on the user problem. Tasks that people can do better than an AI should continue to be performed by humans. AI should become like an assistant that takes care of easily repeatable tasks, leaving more time for real thinking and creating. Especially in times of AI, it is more important than ever to work interdisciplinary and iteratively. True to the motto “Do it right or do the right thing” within the scope of AI projects, we can also apply and adapt our well-known UX methods or invent completely new ones that bring us closer to a goal. But this can only work well if the tools and methods are also used to do the right thing. For example to pay attention to possible bias and accountability. Not only in the products we design but also in the products we design with. After all, at the root of possible future innovations, we also have a certain responsibility towards ourselves, the users and our world. AI is still a young topic for creators and users, which will take off in the coming years. As things stand today, Artificial Intelligence will not replace UX Design jobs, but it will certainly change them. What is certain, however, is that new job profiles will emerge and it is essential that we keep learning continuously. There are still no researched forecasts about the impact of AI developments on the UX design industry as such. However, there will probably be more data sets available in the next years. The digital and design industry should continue to exchange and share knowledge. I strongly believe that the best products and services are created in a team of interdisciplinary people. In this sense: Let us exchange ideas, learn from each other and be prepared for the era of Artificial Intelligence!

This article was written as part of the M.A. Design Management class taught by Prof.
Holger Fricke at HAWK Hildesheim, Faculty of Design.



### Untitled 14.txt

AI and Design: why AI is your creative partner
Miklos Philips
UX Collective

Miklos Philips
·

Follow
Published in

UX Collective
·
14 min read
·
Apr 14, 2020

AI and design. AI is your creative partner.

AI and its subset disciplines, such as Machine Learning and Computer Vision are shaping the future. Design tools and designer roles, workflows, and processes will be molded by it. In light of this, we need to start thinking about AI not as “artificial” but as augmented intelligence, and in the ways we can take advantage in order for it to become our creative partner.

It’s time to shift our mindset from a human vs machine to a human plus machine mindset. Becoming familiar with AI will shift our approaches and ignite new thinking. AI in design will be more about designing awesome experiences, not UIs — creating better products, services, and improving people’s lives.
An analogy

Take an isolated tribe in the Amazon rainforest. These people have had no contact with civilization, and have never seen anyone who looked different from them. Imagine — completely cut-off from the 21st century. No TV or electricity, no phones, no Twitter, Instagram, or Netflix.
Photograph by Ricardo Stuckert

This is a photograph of the low-flying helicopter that due to a diversion because of a storm, took the National Geographic photographer Ricardo Stuckert out there, above the tribe. What did the helicopter look like to them? Scary? You bet.

In fact, they shot arrows at the helicopter! Terrified, to them, it seemed like a monstrous flying beast! Were they wondering: “is it a massive metallic dragonfly?”
Photograph by Ricardo Stuckert

Why am I bringing this up?

Because we fear that with which we are unfamiliar. The fear of the unknown.

Do we have the same response to AI?

Remember this guy?

### Untitled 10.txt

#5: Machine Learning is Very Much a UX Problem
Yael Gavish

Yael Gavish
·

Follow
9 min read
·
Jul 25, 2017

This is part 5 of the 6-part tutorial, The Step-By-Step PM Guide to Building Machine Learning Based Products.

We previously discussed how to set up your organization to work effectively— let’s see how to help your users benefit from the results.
ML Models and Results Are Not Easily Explainable

Many ML algorithms are black boxes — you input a lot of data, and get a model that works in mysterious ways, which makes the results difficult-to-impossible to explain. In many algorithms there are interaction effects that makes the models even trickier to explain — these are relationships between various features that explain parts of the behavior that cannot be explained by just adding up the effect of each feature individually. Think about it as a compounding effect between features — the whole is greater than the sum of its parts, in a lot of strange and intricate ways not digestible by a human.

That said, you and your team will need to be convinced that the results make sense, and it’s easier if you can understand the results at a level beyond dry statistical metrics. It also helps to identify cases that are not covered or areas where the results don’t make sense, as we saw in the model building phase. This is even more critical with your users — in many cases they will require an explanation before they trust your results. You won’t have credibility from the get go, even if your results are 100% accurate, so your users may require an explanation to the outcomes you’re showing them. In extreme cases you may even be legally obligated to explain the result, as in the case of rejecting a loan application — by law you have to give the customer a reason for the rejection. To add complexity, your model will not be 100% accurate, as even 80% accuracy is considered quite good, so in some cases users will want to understand results that are actually wrong! In other words, the bar is for your user to see blatant errors once in a while (which they likely will) and still trust your results overall. That’s a high bar to meet.

The challenge is not limited to models used for external customers — the need to earn user trust applies to internal users as well; even though they’re rooting for you, your internal teams are a lot less likely to adopt results they don’t understand or trust. I’ve seen cases where teams preferred using an easy to understand rules engine rather than a ML model that is likely to produce significantly better results, just because a rule engine is explainable — humans write the rules so they can understand them.

This is not a problem you can set aside until after you built the model(s) — it is important to think in advance about the data and components of the model that the user may want to see and how to present results in a way that builds user trust. The answer may actually change your approach to building the model, and will help prevent a situation where you have an answer and no way of explaining the answer to a user. That said, thinking about this in advance will not exempt you from doing so again once you have the results, since model building is inherently an iterative process and extensive changes to your approach may be required if your model has changed.
Modeling for Explainability

The need for explainability may influence the way in which you build your model, including the level of granularity you need to support. Let’s say we’re building a platform for investors to evaluate startups based on Marc Andreessen’s framework, which states that the three core elements of each startup are team, product, and market. Now, Andreessen believes that the market is the most important factor, but let’s say other investors believe that a good team can find ways to grow a small market, therefore the team is more important. You can come up with an overall score or probability of success for companies that combines these 3 dimensions and gives some “absolute truth” you believe is correct, but investors may not necessary buy it. More specifically, investors may want to understand how good the company is on the particular dimension they care the most about. In addition to your model, you may need to be able to give them visibility into that. Here are a couple of different approaches:

    Build 3 separate models for market, product and team, each evaluating the company on a single dimension. Then build an aggregate model which combines all these features (and potentially many others) into an overall result. Investors could both look at the aggregate result and the specific dimension(s) they care the most about.
    Build an aggregate model and find a way to extract the features that are most applicable to each dimension from it and give users a sense of their value and importance, or to show data points that align with each dimension to build confidence in the results.

The right approach depends largely on your problem space, available data, modeling approach etc., but should be explicitly discussed and evaluated before you move on to prototyping the model.
Presenting Results to Users

When deciding how to show results, the goals should be to make them clear, believable and most importantly — actionable. There’s no playbook here — every problem will result in a different presentation of the results. I’ll review a few possible approaches and considerations to give you some ideas.

    Backdating. This is taking historical data and plugging it into the model to produce past predictions that could be verified against known values. For example, if you build a model that predicts values in year N based on data from year N-1, you could plug into the model data from 2 years ago and see if the prediction for a year ago is correct, since that information is known. This is also a potential way to test your models. Depending on the completeness of your historical data, it may be challenging to get enough data coverage to use it fully without some simplifying assumptions and/or model tweaks (e.g. if your model uses data from social networks, you can’t backdate to a time where social networks didn’t exist). This is also not feasible for certain models, such as reinforcement learning models.
    Explaining your methods and inputs. Simply telling the user what the types of data you took into account in your model builds trust by helping them see that the decisions are based on the same types of variables they would consider themselves if they had to make this decision. In the Andreessen startup evaluation example, a brief explanation for the market evaluation piece could be: “The market potential of a startup takes into account the number of companies in the market and their total sales, the growth of that market in the past 5 years worldwide, the number of new product launches over time, M&A activity in the space and macroeconomic trends”. While it’s not a full explanation, it does gives the user a glimpse into the black box. This is definitely necessary if you’re introducing a new score, as previously discussed.
    Exposing some of the underlying data. This approach is the easiest for users to understand and believe since they see the data for themselves, but not always the easiest to design and has several downsides: You need to expose data you may not wish to or be able to expose (e.g. because it’s proprietary, due to legal constraints etc.), the data may not agree with the conclusion in some percentage of the cases (modeling is about probabilities), or the data may not even be there; the algorithm doesn’t need full data coverage for 100% of the entities it evaluates — it can make up for gaps in the data if it has a large enough data sample for similar entities.
    Simplifying and only showing select results to facilitate decision making. Unsurprisingly, Amazon does it well with some of its product recommendations. I searched for a knee sleeve, see below the page I landed on from Google search results.
    Amazon knows for each related product the exact probability that I will buy it, yet instead of giving me 30 sorted options of similar products, I’m presented with a very easy choice between two — either the cheapest or the best selling + top rated product. I know nothing about the criteria they used to pick the comparative set of products and whether it corresponds to what I would pick if given the option, but at this point they made the decision so easy for me that I don’t really care.

Example: Product landing page from search

    Defining a new metric. One question you should consider is whether you’re creating a new metric (a new type of “score”) or predicting a well understood one: You can build your model to predict an existing metric (e.g. revenue of a company, value of a house etc.); alternatively, you can create a score that embodies a certain concept that doesn’t yet have an accepted metric, in order to enable stack ranking of entities by that concept (“the FICO score for <industry X>”). The decision largely boils down to whether there’s a single metric that expresses the business objective you’re trying to reach with your model, or it’s a mix of several factors that need to be weighted somehow. For example, if we’re evaluating the attractiveness of a commercial real estate asset for retail use, we may want to create a “retail fit score”, which will be comprised of several components such as sales per square foot, all in cost per square foot and location brand value contribution (say you believe a location on Fifth Avenue adds brand prestige beyond the pure foot traffic it attracts). In that case, there’s no single metric that encompasses these metrics, so you’ll likely have to model each component individually and then bring them together through some type of relative weighting. An important consideration when choosing to go with a new score is that you will likely have to spend more time and effort to educate your users about it. Think about having to convince the first financial institutions to use the FICO score when it was first introduced…
    Precision doesn’t always matter. A lot of models generate results that are a very precise number — probabilities, values etc. If you show them such precise numbers you risk users taking them more literally than you intend. A home with a predicted value of $583,790 isn’t definitively more valuable than a home with a value of $580,625. The margin for error is probably much greater than the ~$3K difference. Sometimes displaying the results to the customer in those precise terms is counter productive and gets them to read more into the numbers than they should. It may be a good idea to consider giving results in ranges, deciles, grades or some other less precise measure of value rather than showing the customer the exact output of your algorithm.
    Strategically providing access to raw data. In addition to showcasing the results of its own risk models, Lending Club provides access to its raw data for other people to build their own ML models on top of it. Is this approach relevant for you? Could it drive growth in some other part of your business? In addition to providing potential monetization options, this approach also helps the ML research community to accelerate the pace of innovation in the space. As an example, the availability of Microsoft’s COCO and the CIFAR data sets has greatly benefited image classification capabilities.

Again, the choice of user experience highly depends on the subject matter, product and user needs — there’s no “one-size-fits-all”. It’s entirely possible that none of the options above would be remotely relevant for your product. The key takeaway is to not underestimate the amount of thought and effort you need to put into the user experience side of the problem — even the best model is useless if users can’t understand, trust or act upon its output.
An Extra Geeky but Important Note

Explainability is an evolving area of ML research, with researchers actively looking for ways to make models less of a black box. One example is LIME (Local Interpretable Model-Agnostic Explanations, also here): An “explainer” for models that are classifiers (algorithms that map input data into categories or labels) that is used after the model is built to explain the results in a human-digestible way. Whether it’s relevant and/or sufficient for your purposes depends on the specific case and models you use.

Another area of research is Layer-Wise Relevance Propagation (LRP) — a technique to “deconstruct” the prediction of neural networks to visualize and understand the contributions of individual input variables to the prediction.

While the engineering aspects of building an effective machine learning infrastructure are largely outside the scope of this tutorial, keep in mind that product needs can affect engineering decisions and requirements. More on that next.


### Untitled 7.txt


When to book and when to fly? Explaining prices in Google Flights
Slava Polonski, PhD
People + AI Research

Slava Polonski, PhD
·

Follow
Published in

People + AI Research
·
9 min read
·
May 6, 2020

Slava Polonski, UX Researcher
Roxanne Pinto, UX Writer

Editor’s Note — Even though much of the world is currently in lock-down and air travel is drastically reduced, the questions this post addresses are as relevant now as they will be once the people of the world again feel they can travel safely to be in one another’s company.
Illustration by Roman Muradov for Google

Imagine the scene: you’re living your normal busy life, doing the day-to-day grind, and you realize you haven’t booked that flight for that trip you’ve got to take. Oh right, you may think, the holidays are coming up, I still need to book my flights. I bet flights cost a fortune already. We can relate. In fact, millions of people around the world can relate — flight pricing is tough to anticipate, including for many Google Flights users. Flight prices are subject to changes, inconsistent across sites, and hard to understand. As this video from CNN says, “It’s rocket science.”

Identifying patterns in flight prices is tricky. They change a lot. According to some popular blogs, even on a single plane, a type of seat that sells for 100 dollars to one user can easily sell for 500 dollars to another user.

We at Google Flights thought that if we can put some of the data and smartness in the hands of our users, that could help them demystify what they’ll need to pay at a certain time for a certain flight. We hoped we might save our users time, stress, and maybe some money too!

Our first stop was the Explainability + Trust chapter of PAIR’s People + AI Guidebook which provides a useful framework for thinking about these sorts of issues. Here’s what we came up with when we applied it to our unique challenges.
The user need

In user study after user study, the Google Flights team kept hearing the same message: buying a plane ticket is nothing like buying a cappuccino. When searching for flights to new destinations, it’s difficult to estimate the fairness of a price, not to mention that prices can jump up or down in unpredictable ways, sometimes doubling or tripling in a matter of hours. And then you have to figure out the fee for checking your bags.

### Untitled 6.txt


A snapshot of AI-powered reminiscing in Google Photos
People + AI Research @ Google
People + AI Research

People + AI Research @ Google
·

Follow
Published in

People + AI Research
·
7 min read
·
Jun 1, 2021

Illustration for Google by Lukas Egert

By Thryn Shapira

Thryn is a designer who is passionate about building products that work well for everyone. She leads product inclusion efforts on Google Photos and contributed to the People + AI Guidebook.

If you were alive before smartphones and digital cameras, you might remember when your photographic memories were in physical photo albums or a shoebox that you thumbed through when you got the urge to reminisce.

Now that we carry high-quality cameras in our pockets to snap selfies and take videos of our cats, our photo and video libraries are getting huge. It’s great — so many pictures😃; and overwhelming — so many pictures 😩. Special moments that we capture are quickly buried in an overwhelming black hole of digital obscurity, and the majority of photos backed up in Google Photos might never be viewed again.

Still we took them for a reason — to document, to share and to remember those meaningful moments. We on the Google Photos team saw an opportunity to reconnect people with their memories, and we used AI to understand what photos are meaningful and worthy of reminiscing. That said, because a large, diverse group of people use Photos, and because reminiscing is so personal, we knew that we’d need to give individuals control over their experience.
How AI helps us reminisce

In Google Photos we use AI to make your images easier to search and organize by people, places, and things. It also powers features that go beyond search and organization. We use AI to automatically combine photos and videos into a short movie set to music and generate animations from photo bursts. If face grouping is on, AI creates collages featuring a recent photo of someone next to an older photo of them in a similar pose. Personally, I love that these show how someone has grown over time, like this one that shows my daughter at age one and age three.
Google Photos collage; photo credit: Thryn Shapira

A few years ago, we introduced AI-powered reminiscing features. Rediscover This Day resurfaced photos from the same day in previous years, and They Grow Up So Fast compiled photos and videos of a loved one over time into a short movie. These quickly became some of our most loved features; people enjoyed seeing these meaningful moments they might not otherwise revisit. We wanted to build on this and resurface more photos and videos buried in people’s digital libraries.
“Rediscover this day” feature in Google Photos
Make Memories from mountains of pictures

We started working on our Memories feature with the goal to make reminiscing a central and everyday part of the Google Photos experience. With the help of AI, we set out to curate meaningful content from your photo library and display it in an immersive story player.
Memories experience in Google Photos

That said, Memories needed to be enjoyable for everyone — no matter the size of their photo library, whether or not they travel, have kids or pets, or if they take hundreds of pictures a week or a few pictures a month. To create an engaging reminiscing experience that everyone would enjoy we needed to make tough decisions about what types of content to include or filter out.

In addition, reminiscing is personal and not all memories are welcome. Some memories are intensely sad, upsetting, or painful — such as photos of an ex-partner or a loved one that has died. When we expanded our reminiscing features and automatically brought more photos and videos out of obscurity and put them front and center in the Photos app, the impact of getting things wrong became much higher.

With this in mind, we knew that we needed to give each individual some control over their experience. AI-driven products are probabilistic by nature and the experience won’t be perfect for everyone, every time. It’s important to allow people to adapt the output to their needs, edit the experience, or even turn it off.
Curate The Right Photos in Memories

To build Memories, we didn’t just start with AI — we started with people. We conducted research with a diverse set of users and those learnings guided how we defined the AI models that power Memories.

To start, AI curation for Memories takes a set of photos and filters out the bad, boring, and sensitive stuff — from receipts and parking lots to all the blurry photos you took of your fast-moving toddler before you snapped a sharp one. We do this in two ways: non-pixel-based detection models produce signals and labels (i.e. things, people and pets) that determine how likely it is that a photo could be a receipt or picture of your tax forms that shouldn’t be included; and pixel-based models filter out near-duplicates, and score photos on a set of aesthetic qualities like blurriness and lighting.

Then a set of non-machine learning filters based on photo metadata (image resolution, file formats, photo dimensions) filter out things like screenshots and low-resolution photos. We use rule-based filters because AI models simply aren’t needed for this. The camera codes information, like the resolution and whether or not it’s a screenshot, directly into the image file. Because of these filters I’ll never encounter the 64 screenshots of my phone’s lock screen that my daughter took while I’m reminiscing.

Finally, the set of photos is packaged into a memory.
Giving people control

Even if we could accurately predict the significance of each photo, we can’t accurately predict how someone will feel about revisiting a particular moment. And we’d heard from some people that photos surfaced from our earlier Rediscover This Day feature were sometimes unwelcome. In Rediscover This Day, users could turn off the feature or swipe the card away.

For Memories to be positive and meaningful, we needed to continue to include explicit controls so people had the final say over their own reminiscing experience. I understood this need myself. For a while after my dad died it felt too painful to see photos of him resurface unexpectedly. But a year later I was ready to revisit the photos from his funeral where my siblings and I were all together sharing grief and reminiscing about his terrible dad jokes and astonishing life-long devotion to the San Diego Chargers.

With Memories prominently placed at the top of the main app view, we had to be especially sensitive to needs like this. While our AI models do their best to filter out sensitive content, they won’t — and can’t — always get it right. For example, it may seem obvious to automatically detect and filter out photos of funerals. But many photos of funerals and weddings in Western countries share the same objective characteristics: people wearing dark suits, people seated in an assembly or around tables. Funeral traditions are also not universal, and don’t always fit the stereotypical western image. Hindu widows wear white, and at a funeral I attended when I lived in Cameroon, community members wore bright colors and patterns. Even at my Grandma’s funeral, very few people wore black because we knew how disappointed she would be if we treated it like a somber affair. Instead we dressed in bright springtime florals while we celebrated her long and very productive life.

To give people control in Memories, we used existing controls and added new ones. Shortly after we launched Rediscover this Day, Google Photos gave people the ability to hide specific faces in their library. You can hide photos of an ex-partner or an obnoxious in-law, and their face won’t show up in reminiscing features ever again (and you can of course bring those memories back if you change your mind). We felt strongly that the ability to hide dates was also important, and research supported this hypothesis. So we built controls to hide dates and date ranges directly from the memory player. And you can also remove memories all together. The result is key controls for people to adjust and personalize their reminiscing.
User controls in the Memories feature

In the end, it was rewarding to see how AI could be used to power such a personal experience that lets people get more out of their photos: reliving memories and seeing a snapshot into the past. Of course we learned a few things along the way, including how AI shouldn’t be the only tool thrown at every problem, in this case rule-based filters work well, and that there’s room for personal control even with automatic features.


### Untitled 11.txt

UX design in AI
Introduction

Currently, computational capacity is doubling roughly every 18 months. The pace of this development, amplified by rapid improvements in software, has resulted in artificial intelligence (AI) and advanced algorithms that are quickly evolving to understand and interpret some of our most complex natural processes.
At the same time, the ability to access this capacity is multiplying due to sharp increases in bandwidth, improvements in latency and other quality of service parameters with technologies such as 5G. Interfaces are also becoming more seamless due to advances in cloud computing as well as visual, tactile, and verbal interface technologies.

These exponential improvements have brought what, just over a decade ago, were considered industrial-strength processing and communication capabilities into the homes and hands of individuals everywhere. As industries adopt these technologies to modernize and automate their business processes to increase value chain efficiency and effectiveness, a new service-based concept for the technology has emerged. The self-driving or autonomous car is an example of this new concept. Eventually cars will no longer have drivers, a fundamental change in the concept of a car. The passenger of such a vehicle will interact with it on a much higher and abstract level as a service. When we apply this concept to the telecom sector, i.e. creating a “self-driving network”, AI technology will be the brains behind this change. This presents two main challenges for those developing the concept and service:

    The conceptual shift from today’s understanding of what a network is, becoming something more abstract than what it is today, operating on new parameters.
    The fact that a user of such a service will interact with the system on a much higher, more abstract level.

Therefore, the understanding of the business goals and the user of the system is key to success. With the role of users shifting from drivers to passengers and from operators to managers, designers will need to create highly collaborative solutions allowing tangible and reliable interaction between AI technology and the user.

In light of this, the Experience Design team at Ericsson has been researching and developing how to design trustworthy, AI-powered services for telecom operators. Through designing the Cognitive Operation Support System service concept, we have identified four components of human trust that can be applied to AI powered systems. These four pillars - competence, benevolence, integrity and charisma - are the key areas designers and business owners need to address to be successful when it comes to the adoption of AI.

In this paper, we will share our experience of designing a trustworthy, AI-powered Cognitive Operation Support System (OSS) service.
AI today
The current face of AI

AI is an umbrella term encompassing many different methodologies and concepts, referring to any machine developed to perform tasks that would require intelligence if done by a human. Although the media commonly portrays AI capabilities as superior to human capabilities – i.e. as an artificial super intelligence (ASI) – the truth is quite different. Since the earliest explorations into the AI field, the scientists and practitioners have sought to create a computer with a level of intelligence similar to a human. Known as an artificial general intelligence (AGI) – these would be machines with a reasonable degree of self-understanding and autonomous self-control, able to solve a variety of complex problems in a variety of contexts. Despite the huge advancements of AI, especially in the last decade, we are still far away from being able to create an AGI, let alone an ASI.

The current form of AI we are working with is known as an Artificial Narrow Intelligence (ANI), or “weak AI”. ANI systems are created to carry out specific tasks showing specific aspects of intelligence in a specific context. All current applications of AI, whether it is an autonomous car, a chatting app camera filter, or an intelligent OSS, are all considered narrow or “weak” by this definition.

An easier way to describe the role of current AI applications is to call them “agentive technology” - whereby we can think of them as our assistants or agents, handling a discreet task and not the entire job.

In this current context, humans still need to have a view of the bigger picture and are still required to supervise, evaluate, and orchestrate the work of these AI systems.
Levels of AI

Figure 1: Levels of AI
The key to AI success
Trust as a vital component in AI adoption

There is an increasing trend of digital assistants appearing in many different aspects of our lives. Powered by machine learning (ML) models, they analyze data to come up with statistical probabilities that can be used to offer recommendations and make predictions and decisions, from suggesting the optimum route to take on a commute, to adjudicating whether we are viable for a loan or not.

Although they sound less impressive than the idea of the ASI’s superior artificial brain, these recommendations, predictions, and decisions taken by the AI systems can be considered a fundamental change in the way humans are using tools – a paradigm shift in the human-tool relationship. Since the beginning of this relationship, humans have always been in full control not only of what the tool should do, but also exactly how it will work, at least in the design and creation phase. The progression to the current status of AI is an evolution of this relationship in two ways.

First, it is an upgrade of the tool’s status from the role of a “slave” to that of “agent,” giving it agency by having a degree of autonomy with regards to “what” it should be doing. And second, it is a change in that with AI, we no longer entirely decide “how” the tool executes its function. In fact, in many cases, the creators of an AI system cannot entirely describe the criteria that the ML model has used to reach the output. This is known as the “Black Box problem”.

Taking these points into consideration, the following can be said about the current state of AI systems:

    Rather than just executing what the human user wants, AI systems will autonomously come up with predictions, recommendations and decisions.
    We are not always able to fully understand or explain why an AI/ML system has reached its output.
    AI/ML output is based on statistical probabilities just like human decision-making – it judges low or high probability of outcomes, it’s not some kind of ultimate truth or absolute objective correctness.

We can therefore reach the conclusion that a degree of trust is needed, before the user can hand responsibility over to the AI - and give the autonomous car the steering wheel.

The requirements in building this trust-based relationship varies according to the specific task the AI is supposed to handle. Accepting an AI’s recommendation on which movie to watch is much “easier” with a lower trust threshold than, for example, the recommendation on which medicine a doctor should prescribe to their patient.

In a recent survey asking owners of smart voice assistant devices to list the tasks they perform using the device, 84.9 percent reported they use it to set a timer, while only 3.5 percent reported using it to call a cab.

A recent study has shown that when it comes to the application of AI in a business context, 94 percent of business executives understand that AI is essential to business strategy, however a separate study by MIT Solan found that only 18 percent of companies are widely adopting and understanding AI. In designing an OSS AI solution that takes critical decisions affecting the performance of an entire network, we discovered that the success of the system depended on more than building more efficient and accurate models and algorithms. We came to the realization that trust is an essential factor in the human-AI interaction, and if we want the users of our AI solutions to accept handing over more critical tasks and decisions, we need to design them to be trustworthy.
What is trust?
The four components of trust in human relationships

Although the concept of trust in human-AI relationships is a new field, we don’t have to work from scratch.

Our approach at the Experience Design team in Ericsson was human-centric. Humans have been trusting other humans since the beginning of our existence, and once human-human trust relationships were established, we started to putting our trust in entities and organizations; religions, political parties, banks, schools, business and so on. Our approach was to draw on the formula of trust already functioning in these human-human and human-organization relationships, and use it as a base for building trust in human-AI interaction.

The four main factors that contribute to building trust in another person or entity are: competence, benevolence and openness, integrity and charisma. A good example to illustrate these four components in action, is the process of decision making when hiring an employee that will be responsible for a task in an office. When dealing with “digital” assistants in the form of AI systems, exactly the same framework of trust applies.

The following pages examine each of these components in turn, from the perspective of human-AI interaction, along with relevant examples of design-related decision and focus areas that can contribute towards creating a trustworthy AI experience.
The components of trust

Figure 2: The components of trust
Competence
Can you do the job?

In practice within an AI system, the trust component of "competence" essentially means the system is designed to demonstrate that it is capable of fulfilling the user’s needs and that it can deliver what it promises.
Adoption of AI-powered networks requires knowing they’re up to the task.

Here are some practical examples of how UX designers and practitioners can contribute to an AI system’s ability to demonstrate competence:

    Explainability
    Ensuring the system can communicate the reason behind its decisions and its confidence in different results and recommendations in a way that users can easily understand.
    Usefulness
    Making sure the system is employing AI capabilities to fulfil an actual need or solve a real problem for the users in an effective way.

Components of trust – competence

Figure 3: Components of trust – competence
Network performance diagnostics

Network performance diagnostics

    Trialability
    Giving the users the ability to try the AI system or test out its recommendations in a quick, safe and controllable way before they decide to use or approve it.
    Demonstration of results
    Being able to show evidence that using the AI system has resulted in an improved outcome.

Cognitive OSS prototype design demonstrating ”Explainability”

Figure 4: Cognitive OSS prototype design demonstrating ”Explainability”
Demonstration of results

Figure 5: Demonstration of results
Benevolence and openness
Are you on my side?

An AI demonstrating "benevolence" can be defined as a system designed to make decisions in the user's best interest, and to communicate the intentions behind decisions to the human user. It should also show flexibility, acceptance of change and new input – exactly as you would expect from a new human colleague.
Showing a system is open to influence from the user is a big building block of trust.


Some practical examples of how UX designers can contribute to the benevolence and openness of an AI system are:

    Controllability
    Providing an easy way for the user to intervene and change, undo, or dismiss an action or decision taken by the AI, as well as the ability to feed their own recommendations into the system.

Components of trust – benevolence and openness

Figure 6: Components of trust – benevolence and openness
Supervising network performance

Supervising network performance

    Adaptability
    Making the system flexible and dynamic enough to adapt to the user’s explicit or implicit preferences and feedback.

Controllability, enabling users to take a participatory role in the decision-making process

Figure 7: Controllability, enabling users to take a participatory role in the decision-making process
Adaptability, showing the user that their preferences have influence

Figure 8: Adaptability, showing the user that their preferences have influence
Integrity
Do you share my values?

The concept of integrity in an AI system comes down to whether the user feels that the system is honest, and whether it adheres to the same high ethical standards as the user.

There are two ways UX design in AI contributes to the impression of integrity in a system:

    Veracity of promises
    Setting the right expectations for the user by clearly communicating the capabilities and limitations of the AI system - knowing what it can promise to do and follow through on and what it cannot or is not designed to do.
    Transparency on safety, security and permissions
    Making sure the user understands what kind of data is collected, how it is collected, for what reason and how it will be used.

Components of trust – integrity

Figure 9: Components of trust – integrity
Setting the right expectations and showing the user the different possible outcomes of the AI’s recommendations

Figure 10: Setting the right expectations and showing the user the different possible outcomes of the AI’s recommendations
Charisma
Do I like you?

And finally – charisma. Charisma in an AI system comes down to crafting it in way that gives it general charm and appeal, and that the system looks and sounds appropriate to the task it is handling.

UX designers and practitioners can contribute to the attractiveness of an AI system by implementing:

    Visual appeal
    Crafting the system’s look and feel in an aesthetically pleasing and visually organised way, so that the human user perceives it to be more efficient and understandable.
    Tone-of-voice suitability
    Making sure that the style and tone of the copywriting and voice interactions are aligned with the message that you want to convey, the desired personality of the system, and the traits of the targeted user group.

Components of trust – charisma

Figure 11: Components of trust – charisma
Appropriate tone of voice for the scenario

Figure 12: Appropriate tone of voice for the scenario
Clear and organized visual layout contribute to increased perceived trustworthiness

Figure 13: Clear and organized visual layout contribute to increased perceived trustworthiness
Beyond the building blocks
Other factors that can affect trust in AI

All the elements that are mentioned so far in this framework are those that are represented in one way or another in the interaction and the interface of the AI system, and are therefore relevant to the UX design.

There are numerous other factors that can affect trust in an AI system, and although these additional factors cannot be translated into the interface as UX, they are nevertheless essential elements in the building of a trust-based relationship.

For example:

    Accuracy
    If the output results, predictions, recommendations and decisions of the system are not accurate to begin with, then the system will not meet the aforementioned criteria needed to satisfy the "competence" component.

    Bias in AI
    One widely discussed topic in the AI community is the concept of bias - specifically that ML selects incomplete, uninclusive or biased data sets to train the model, whether deliberately or otherwise. This will result in output that is not fair and biased towards a group of users - meaning that the core pillar of "integrity" will not be met.

    Laws and ethics
    Without sufficient and clear laws and a code of ethics that regulates the relationship between the user and the AI system, for example defining who is responsible if the output of the system affects the user in a negative way, then the trust in the human-AI relationship will not survive any potential mistakes the system makes.

AI-powered OSS
With the right design principles in place, AI-powered OSS could open up a more powerful future for network.
Conclusion
The future of human-tool relationships

When introducing AI-powered software like Ericsson's Cognitive Operation Support System (OSS) services, the notions of what a network is, what the owner or network operator’s role is and what a system provider contributes
are changing.

The interaction will be on a much higher and abstract level. Instead of changing gears in the car, the focus will be on the passenger's journey. Instead of having field technicians manually climbing towers to fine-tune the radio, business operators will collaborate with the AI machine to reach the organization’s business intent, impacting the roles of the system providers and the network operator.

A user-centric design process will be even more important when designing AI-powered services than in traditional services. If users and organizations are going to trust the AI-powered system, for example an airplane without a pilot, the trust must be designed into the system and the relationship from the very beginning. Without it, these services will fail.

Designing an OSS AI solution that takes critical decisions that can affect the performance of an entire network is about more than focusing on building better AI models and algorithms. Trust will be the most vital factor in human-AI interaction.
If we want the users of our AI solutions to accept handing over more critical tasks and decisions to AI, we need to design them to be trustworthy.
The essential human in the loop
Designing for trust is a cornerstone of building successful AI systems.
Authors
Mikael Eriksson Björling
Mikael Eriksson Björling

Mikael is Experience Design Line Manager at Ericsson Experience Design Lab and an Ericsson Evangelist. He was previously Director at the Networked Society Lab. His specialty is in understanding how new behavior, emerging technologies and new industry logics are shaping the future society and in the intersection of these areas design great user and customer experiences. Mikael believes that with the ongoing digital transformation we have a great opportunity to shape a better world. Mikael joined Ericsson in 1998.
Ahmed H. Ali
Ahmed H. Ali

Ahmed is visual and user experience designer at Ericsson Experience Design Lab. With over 15 years of experience, his career inside and outside Ericsson was focused on designing digital systems that satisfy users’ needs and help them achieve their goals by bringing design thinking to the product development process, applying human-computer interaction best practices, and delivering UI/UX concepts and insights. Ahmed joined Ericsson in 2018 and he holds an M.A. in visual design from the University of Hertfordshire in the UK.
References

    Minsky, M. (1982). Semantic information processing.
    Goertzel, B. (2007). Artificial general intelligence (Vol. 2). C. Pennachin (Ed.). New York: Springer.
    Gobble, M. M. (2019). The Road to Artificial General Intelligence.
    Noessel, C. (2017). Designing agentive technology: AI that works for people. Rosenfeld Media.
    Bathaee, Y. (2017). The artificial intelligence black box and the failure of intent and causation. Harv. JL & Tech., 31, 889.
    Andras, P., Esterle, L., Guckert, M., Han, T. A., Lewis, P. R., Milanovic, K., & Urquhart, N. (2018). Trusting intelligent machines: Deepening trust within socio - technical systems. IEEE Technology and Society Magazine, 37(4), 76-83.
    Muir, B. M. (1987). Trust between humans and machines, and the design of decision aids. International journal of man-machine studies, 27(5-6), 527-539.
    Siau, K., & Wang, W. (2018). Building trust in artificial intelligence, machine learning, and robotics. Cutter Business Technology Journal, 31(2), 47-53.
    Commerce is a conversation: Survey on Amazon Echo and Voice Assistants - Experian Insights, 2016.
    Intelligent Economies: AI’s transformation of industries and society -The Economist Intelligence Unit, and Microsoft, 2018.
    Ransbotham, S. et all. Artificial Intelligence In Business Gets Real - Pioneering Companies Aim for AI at Scale. MIT Solan, 2018.
    Stern, M. J., & Coleman, K. J. (2015). The multidimensionality of trust: Applications in collaborative natural resource management. Society & Natural Resources, 28(2), 117-132.
    Sanders, K., Schyns, B., Dietz, G., & Den Hartog, D. N. (2006). Measuring trust inside organisations. Personnel review.
    Schoorman, F. D., Mayer, R. C., & Davis, J. H. (2007). An integrative model of organizational trust: Past, present, and future.



### youtube_TPmtiglPnEY.txt

[Music]
hello everyone um my name is KL I'm s
founder of Lazer agency so what we do is
that we do user experience for AI
companies um the short info would be
that we helped our clients raised half
of a billion dollarss uh out into our
design work we also nominated as the
agency of the year last year and uh yeah
we won more than 100 different Design
Awards been doing this for almost 10
years and yeah excited to share you some
of the case studies and thoughts that we
have about the user experience in Ai and
how the future of the interfaces would
look like that you actually can build
right now so um the big biggest problem
in the AI space right now is that uh
yeah 90% of the Alli startups fail with
30% of them uh due to the lack of the
product Market fit and as the user
experience designers uh we believe that
that's one of the biggest problems out
there and it's one of the actually um
easiest things to fix um lots of the
companies you know uh were building the
rubers of the CH gbt and uh in one day
they all dead um the what they should
have been built in the right way is is
if they would do the proper user
resource there wouldn't be that stressed
about the all the you know open AI
openings uh even within the agency we
built like a six different AI startups
and three of them were essentially will
never be able to go to public because of
that um because the VCS and the market
push you to go to the you know to the
life and the demo stage as soon as you
can but the reality is that is that one
month spended the proper user research
can save you can save you months uh in a
development and essentially can help you
to go to achieve your goals instead of
just wasting the time which lots of
people think what the user experience
all about um another thing that I want
to put it out there is that uh in this
space uh even in the chat GPT uh which
got 100 million uh users a week right
now there is very low Traction in daily
uh in the daily usage of a products and
um I think that's the thing to consider
and that's why and and we mainly believe
that it's happening because of the lack
of the user experience and the
personalization and uh thinking of how
to build the product for the users
instead of how to build the product
itself um we believe that in order to
create a successful AI product you need
to differentiate respond to the actual
human needs and desires and but
interface that will stick with you and
that will stick with users that's the
most important part so yeah yeah cool
the crypto was cool well by the way the
crypto might be cool soon too right U if
you are following 30% growth in the last
month so uh let's wait um you know the
next wave of uh crypto I startups coming
next year um but yeah the the whole
thing is that we believe that you need
to be different and you need to
understand the users and to build the
products uh that built exactly for that
uh for that audience how you need to
find the niche uh you need to unlock the
actual user needs and then uh yeah you
need to consider accessibility and
usability especially into the multimodel
LMS that's coming right now you need to
think about the voice you need to think
about the images you need to put it on
top of your uh decision proess and if
you think about the actual use cases how
your audience going to use it not how
you think you going to build the product
itself um so yeah Define the market
Define the target audience and uh rece
seource the problem need and build the
product around
that um yeah do it as much as you can so
yeah um there is a little bit of process
uh that's a d diamond that everyone who
is in design SP seen here but uh we do
believe that research uh rules at all
and uh the more you know about the users
the better product stick and the better
reaction you have and you don't actually
need to be in AI space to do that um so
yeah the good design gives people what
they want and the great design solves
people problems uh in innovative ways uh
I feel that's the case so how to build
the interfaces for AI products out there
the first thing is
that everyone is trying to build the
product using the chat B right so we
have this crazy opening I think and
you're just like oh wow that's a new way
how to interact with the interfaces
that's the future but the reality is
that there is a big problem out there
uh there is a new word that appear right
the new T The Prompt engineering but in
order to be the prompt engineering you
need to be the the engineer you know
there is two parts The Prompt and the
engineer and very few of us are
Engineers out there uh I feel that In
This Crowd it's actually much more
Engineers that you know that's out there
uh in the world and therefore um you
need to design the interfaces that will
help the users to use them and uh this
help to solve this barrier of entering
uh what they actually looking for
because within the chat interface only
you put the user in position in a so
they would have to type and type and
type and type and type till they the end
result instead of just like helping them
to go through through way but how you
can do it well yeah uh the the first
phase of the presentation right you do
use a research to understand what they
actually need and then you tailor the
design uh for that um so we think that
the future is the hybrid yeah there is a
prom base and uh graphic interfaces so
this is one of the products that uh we
design that is in development right now
um the use case here is that we believe
that the interface should be the mix of
the text and the widgets that should be
built through the design system and
should automatically pop up when the
users request for the data that they
need for so for example uh here the user
is looking to set up the know the call
and set up the notification and then we
the llm can understand that intent right
and then based on the intent it can
create the diget for you and then you
can do some interactions in the diget
instead of typing okay can you resle the
reschedule this okay can you do X by
that and you know instead of doing 10 or
I know five or or 10 text prompts you
can do this two clicks um so we believe
that the static interfaces are de where
the designers were creating everything
for the users but the mod interfaces are
the future where you actually using the
text and a vets um out there here is
another one um it's called Pika uh this
product uh was begged by mazilla and
supposed to to go to um the search to to
replace the search all and what we were
doing there is that um you see this um
blue um you know like a popup uh in the
center so this is how we help the user
to navigate and how to chat uh with our
research and this is how we put the
user's attention in in the core of the
app following all other different uh
interfaces and elements of the
interfaces out there um here is some of
the other examples of that but I will
dive deep into this um in a
second so um once the user is starting
to use your chat based product you can
recognize the partners that they have
and and the reality is that the users
are usually using the your uh LMS in a
very particular use cases for themselves
so for example I always uh use improve
uh as the prompt uh because I'm not a
native speaker and I'm just like okay
here is my text can I just improve it
right and I
essentially 50% of the time that I you
charge P you just one prompt and I and
always typing this improved next and uh
this gave us an idea that why don't we
realize the pters of what others users
are doing and put it as the widgets and
put the use cases that the way the users
use the product as the widget so they
can one click it so instead of typing
the summarize ACT test find similar
improve compare wherever you you you sa
you can analyze that and you can put it
as the button in your chat interface and
it will save
uh hours and hours of um users
time so yeah the more you understand the
users you can go even further and you
can uh do it automatically or
semi-automatically if I'm using improve
every single time I can adapt the model
to automatic applies for every promp uh
that I do and how cool would that be
instead of just clicking it it could be
done automatically and I can just
disable it in my settings so the can
essentially analyze the patterns and
create the settings personalized for the
every single users that that they are uh
that they out there and this is how you
create hyper personalized product and
the users will stick to it and will
never go to any of your
competitors um in order to do that you
need to build a modular UI and um yeah
you need to think about the proper
design system so yeah in a design space
everyone's saying the design system is
the key for years but right now I think
that's even uh
more important because um there is
endless amount of the use cases out
there and there that's a beauty and the
scariness of the llms and uh because
there is endless amount of the use cases
the designers should only think in the
way of that is building Design Systems
and the components that then once you
realize the patterns you can build the
vit on top it pretty much right ahead
and it's very easy to track because you
can track all the requests in your AI
product right so once you see that some
of the case is popping up you just build
the visit on top of the design system
but you need to think in advance of
about the scalability and actual use
cases for it um here I here is some
other sorry let me Zoom it out so if you
would for example you could pull the
data from the predit and Twitter and
Facebook and Instagram and wherever and
put it in one nice chat and it could be
as the widget right here on on your
homepage or you can collect the data
about the videos and a post and you can
structure them in a nicely created UI
for the
user there are some other examples how
how I bu it for the source but the core
things here is that the more flexible
you are and the more consistent that
system is the easier for you to be to
scale yeah not going to stick here for
four years but essentially you can pull
there once we know that there is a
person information there is a different
type of the data sets and attributes
that collected to the person and this is
how we can add this tabs uh pretty much
and
listen um the good design is the little
design as possible so you need to think
about the functions um and uh based on
the functions you add the
functionalities not vice
versa um and the design is system that's
a key for it there's another product but
uh that we design but essentially once
the design system is set up you just go
for it
um all right another thing that we
thought as cool is that once you connect
your LM and your product to the uh
through the ipis to a different bunch of
the products so essentially this is what
the this is what we've been doing before
the open AI did it so right now I feel
kind of embarrassed that I'm selling it
out loud but the idea is that the more
Integrations you have in your product
the more your product uh would be useful
for the user therefore they they will
have more usage of it right uh as simple
as that and when you're building it you
need to think in advance and you need to
think what kind of ipis we can connect
uh to and what kind of wigets we can
pull within the context that we have um
and yeah getting back to that prom
engineering part right um I think that
would be this this would be the next
feature of open AI um but before they
did it I think that the co-pilot to help
users find write prompts is one of the
coolest thing out there because you can
help the user to navigate and you can
help the users to write their prompts
easily and you can tailor this to the
use case of the product that you have um
yeah communicate what your product can
and can do U explain how it makes
decisions and always display why AI is
doing important decisions one of the
biggest um threats uh out there from the
users this is was one of the research I
think were done by the Salesforce that
users are afraid where the information
is came from in thei they can trust it
and uh because of that we came up with a
very easy decisions well you just you
know do your thing you just uh show the
call outs where you actually pull the
information from and instead of having
like a 10 different links that you have
ask the your open AI to to create you
can just right ahead okay this is where
I pull the information from and this is
how you start to build the trust to your
AI product and once you build the breach
of the trust the users would love to use
it more another cool part is that um so
is the hot keys right um for this
particular product this one is uh
special specially made for the VCS to do
the market research so if you're in the
VC space you need to go and search for
the companies and competitors and
analyze the market to understand who is
doing what and why and you have the
analytics who are sitting out there um
yeah you can just add this cool little
hot keys that will help you to navigate
through it and essentially reduce the
amount uh of time that the users uh
going to look for certain functions in
your
product um yeah another cool thing that
we recognize is that there is a
different metrix and I think uh this
part works you know the different
lecture uh but essentially you can track
if your product is successful not by
finding the S wordss uh in the chat so
if the user is using extensive amount of
s wordss uh you might you know your AI
might doing something wrong and by this
small uh indicator you can um track
whether the product is going in the
right direction or wrong but another
cool thing is that um yeah uh you can
track response time and quality by
Leading from the user Behavior how many
times do they have to re ask the
question and how fast do the exit
conversation um once they get the answer
or not it's like one of the biggest
challenges out there for all the product
metrics is that if the user enter the
problem six time you are uh you know the
average time spending in the product is
higher but is it actually leading the
user for the success probably not so our
aim as the people who are building eii
product is to reduce the time and to
reduce amount of the requests that
they're creating therefore you need to
create a different metric to measure
your product
success okay so there is four
ingredients for ux fori uh research
research and uh research again um yeah
you need to go through all the classical
usability and uh eristics and also you
need to build the um hybrid interfaces
uh the hyper personalization the more
personalized experienc user would have
the cooler it would be for them and the
more they going to use the product and
all the interfaces starting uh today
right now I'm kidding uh would be
modular uh modular and self-build
interfaces um there is a small case
study that I want to walk you really
quick if you're not yet bored uh so this
is the product uh that I was showing you
before and the whole thing is that we
figure out then once the resarch or in
the VC is doing research on some n or
Market they always do it in a split
screen mode so they're picking
information from a different part of the
web and then they're kind of preparing
it as the separate uh document to to to
show to their senior level management
and once we realize that we're just like
wow why don't we build it as the poor
functionality of the product to be
different and to tell the product to the
user needs and this is the literate
example of how the resource can lead you
to the
um you ask that uh not that common but
tell her to your audience uh your
audience another part is that the if you
are doing the research and if you're a
researcher you would love to um track
the data you can and then convert it
into sheets and a spreadsheet so we
build this um cool tool is that once you
have any statistics you can build a
graph from it right ahead and you can
create a tables uh that are convenable
and exportable right
ahead um and yeah then we try to the
commends and one the users ended to
doing something we suggest them with a
lots of different uh functionalities
that put on top of it so I found this
information say I'm the research and I
found this information about this
company and then and I ended the the
conversation and then uh once I track
track this fet to the second part uh
yeah like I've showed you are here we
can ask you okay what do you want to do
with this you can send the sumary to
email you can download the sumary as the
PDF uh you can create the report from it
and you can track and send updates to
email so one of the functionalities that
that we put as the part of this
interface is that say you're at the VC
and you found this company you liked it
but you ah I'm not sure if they're going
to survive to the precedent series stage
I would love to follow up with them
later so but how do you check it well
now you can do it within the one click
you click the track and then it follows
the company updates on the LinkedIn it
sees if they hire senior level positions
uh from the biggest companies out there
so you it it adds more points uh to the
internal uh document and once you set up
this point system yeah you will be
notified if they're doing good or bad
and it's all done
automatically um and yeah and as I told
you pretty much everything can be
converted in a much easier way and it
helps users with a large amount of text
in their uh research another cool part
is that if you are the researcher uh you
can also apploud the different data sets
to this llm moreover you can set up the
data sets that you want to use during
your search and you don't want to use so
right now uh if you think about the
products you always fit them in a data
sets that you think are needed for the
user but what if the user can decide
what he actually needs to pull the data
from and this is one of the things that
we add there after the resource because
we found out that different people using
the product in a different way and they
need to different type of the data to
rely on and U you know another version
of this product is used by the hedge
funds and the banks to do the research
and predict how the price of the stocks
uh going to look like so they have their
own data that they want to up out uh so
for we created the whole interface of
the selecting of the data sets out
there I guess that's it it's time for
[Music]
Q&A yeah so we are a design agency and
this is how our clients work um so U
this is the company called acern ACC Ern
um yeah they've been in the space since
2015 and we've been helping them since
2015 they working on the AI product uh
is this this product is s for the VCS
but they have another one for the banks
and another one for the Hench funds and
there is a different use cases how you
can how you can use it yeah so I mean if
you are hedge funds or uh hedge fund or
bank or a VC that's the product for you
yeah it's paid yeah I'm not sure about
the pricing though I'm sorry
yeah that's the greatest challenge as
the agency I mean we show the direction
of the user of the clients who made the
research and and the statistics of the
clients who didn't I mean is the you
know at the end of the day we're an
agency and we would follow the
properties that the client would choose
but we always say okay guys here is the
uh product that we scale from the series
C to the series B and uh you know why
because we were doing research all the
time here is another use case is how we
did it but essentially we tell you that
uh you can you can save hours and hours
and hundreds of thousands of up millions
of dollars uh once you are uh building
the product and research can save you
that so resarch is just an Roi on on
your cash on your
[Music]
money I feel that the product should be
tailored to the audience that going to
be using the product and in this
particular case we know the use cases
for for these guys and we tailored their
you know the recommendation engine by
the sour of the markets for the VCS and
we spend a lot of time in doing in doing
that and I think that the more
personalized your product is the the
better it will work so I'm not sure if I
would I mean and maybe that's one of the
reasons why openi is not doing out the
suggestion because you can go as broad
as you can or as short as you can and
that's kind of you know one of the
purposes of the uh uh CH GPT um but for
the most of uh of of of us we are not
building the competitor the shadt we're
building the product for the very nich
use case for the very particular
audience that would use it in a very par
rate and the faster we find it out the
better we can build all the features and
all the little things around and I would
not I mean unless you building the
comparator of the charg PD I would not
go and think in in that Direction I was
just like okay how can we make the most
of these users and how how can we help
them well we generally say that um here
is the cost of the building the MVP and
uh you know here is the cost of the redo
in MVP and here is the price that
associated with that um usually I mean
that's very you can know the ballpark
depending on where your team base if
it's local team or if it's the team over
re You can predict the price of the of
that and on top of that you have the
budget the marketing budget spend to go
to the growth and T the users and you
can ask that client the client about it
right ahead so okay guys how much you
ready to spend to to to track it and
they would probably say well we need
like at least 100K to validate the ideas
to test it out and say well um that's
cool and then you need like a 300K to
500k to build the product out so we're
talking about the you know like a a
million dollars worth of the MVP and how
much are you ready to spend to make sure
that this MVP got all Ed to your user
and that's the moment of the
negotiations uh that's it because if you
would do redo it how big of a Runway you
have would you be able to do do it two
times probably yes right no one you know
nowadays no one raising less than a
million in B at least and but you will
not be able to do it do it three or four
times so that's how we talk to our
clients we say well that's this is what
what you got to invest but I think about
it
together I love the you know that you
can build the model uh you know the
charge model in a in a day so in an
agency we do talk to clients right and
we created our sales agent in a day
before we haded different you know
Outsourcing team who were building this
for us and we build it in a in a day and
we just essentially decided not to
continue this project uh with them so I
think that's one of the coolest thing
out there and yeah the vision is
something uh very interesting I've
talked to one of the researchers uh
through the with with the team of openi
and he said a lot of great things that
how they actually work on this and how
they change the way how the computer
Vision Works within the gbt vision they
essentially recreated it and from a
different perspective I think there is a
lot of opportunity out there
too
[Music]

### Untitled 13.txt


AI Product Management: Research, Requirements and Scope
Nadya Tsech
UX Planet

Nadya Tsech
·

Follow
Published in

UX Planet
·
11 min read
·
Jan 2, 2020

What is AI good at? What questions should you ask during the research phase? How should you prepare business requirements for the development team?

There are several ways companies become interested in AI:

    They talk to users, learn about problems, and gather requirements. And come to the conclusion that AI is the most suitable tool to solve the problem.
    Or they start research with questions such as “How can we use AI to our advantage?” or “How can this technology, everyone is talking about, help our users?”

In both cases, product managers need to answer baseline questions to define requirements.
Part 1. Problems and Opportunities
How Can AI Help Your Clients?

AI can solve a range of problems: optimising repetitive tasks, assisting with decisions and making decisions autonomously. If your users are facing some of the following problems, AI might be the right solution:
1. Is there time-consuming noncreative work that users do repetitively?
Organising scans using AI. Source: Transforming Healthcare With Machine Learning

Every time IDEXX radiologists see a new patient, they spend around 30 seconds rearranging and grouping scans. It’s not only a waste of time but also an irritating task that specialists have to perform many times per day.
2. Are there tasks that need double-checking because of errors?

As I write this post, I’m relying on Grammarly and it’s AI algorithms to assist me.
3. Do your users spend a significant amount of time manually labelling data or creating complex rules for it?

Ataccama’s clients have hundreds of data sources and millions of tables. Usually, the data is unlabeled and hard to find. Data stewards spend a considerable amount of time manually labelling data and writing labelling rules.
Ataccama Metadata Management & Data Catalog

Ataccama AI algorithms spot patterns in data, learn from the users’ actions and assist data stewards with labelling or automate it completely. It saves users from going through data sets one by one and doesn’t require writing rules.
4. Can assistance make users or the whole organisation more efficient?

In 2016, Moorfields Eye Hospital had 7K urgent referrals for people who were in danger of losing their sight. Patients had to wait up to 6 weeks before seeing a specialist because of the huge number of appointments. It turned out that only 800 of the 7K referrals were urgent.
DeepMind Health Research

DeepMind created an algorithm to assist ophthalmologists in analysing scans to diagnose urgent cases and reduce the number of deteriorations. Now it’s working at the level of world experts.
5. Are there extra tasks users have to complete to do their main work?

Data analysts spend up to 60% of their time searching and preparing data before they can start the actual analysis. It’s not only expensive for companies, but it’s also a boring task for analysts. AI can reduce these tasks using NLU and pattern recognition.
6. Does a user have to analyse the data and make decisions over and over again, many times per day?
Tractable AI Estimating

In insurance, AI is used to calculate the price of damage based on images of a car. Trained using a library of photographs from past accidents, AI estimates repair costs. AI minimises the waiting time for payment and reduces work for insurance inspectors.
7. Do clients have rule-based systems?

AI would be overkill for simple rules, but if your users are creating complex rules with dozens of conditions that are changing over time, they would benefit from self-learning algorithms. Examples: Spam detection, segmentation, search, recommendations.
8. Are there systems they have to monitor and check regularly?

Machine learning is good at spotting patterns and anomalies in these patterns. If your users’ job is to make sure everything works (security, fraud, cyber-attacks, system failures, medical results), anomaly detection might help them spot anomalies faster and even find ones not visible to human eyes.
9. Do they have to customise work for their clients?

Customer support, marketing campaigns, chat-bots, reservation systems can be automated if there is enough information about customers and their past interactions with a service.
Source: Blog.edrone.me

Zalando’s marketing content is generated by algorithms. They use information about past purchases and wish-lists of their customers to personalize marketing materials.
10. Is there a middleman between your system and end-users?

It’s the reality in a lot of large organisations. For example, to make business decisions, managers and strategists require access to data. Often they have to request data from their more tech-savvy colleagues in the IT department. It might take weeks or months until the data is available.
Ataccama Metadata Search

Allowing less-technical people to interact with the product in the natural language might change their work experience.
11. Are there problems and tasks that change over time?

Dynamic prices, navigation, logistics, supply chains and stocking are examples of problems that change over time. One of Ataccama’s clients is a large hospital group. They use data to predict how many ambulances they need at any given time and in a given location based on the time of day, week and year, weather, events, air pollution, traffic, and many other changing factors.
12. Is there information that might change your users’ business that is unavailable now?

Danny Lange (ex. Head of Machine Learning at Uber) recommends using the thought process “If we only knew ____” to uncover unexpected business possibilities. “If only we knew how many ambulances we need at any given time”, “If only we knew when to turn on the TV to see the most important moment of the game”.

Example from an Australian cricket broadcaster. Cricket matches can take as long as 5 days. To win, a teams has to take 20 wickets. About half a minute of meaningful moments out of 30 hours. If only fans knew when something interesting was going to happen and could be notified. Foxtel trained their AI algorithm, Monty, on historic videos of cricket and taught it to predict the chance of a wicket. Monty calls users to watch the wicket fall.
Monty’s Wicket Warnings
Is AI the Right Tool for the Problem?

Check-list to spot red flags in the beginning:

1. Do you have access to data? Can you acquire the data you need? Are users willing to share the data? What data are they willing to provide?

2. Do you have permission to use the data? Are there regulations you should contend with?

3. Can you ensure the users’ data is secure?

4. Can you ensure the data is trustworthy and up to date?

5. Is it worth it? Gathering data, keeping it in shape, building a model, and testing and iterating are both time and money consuming. Do you have a team? What is the trade-off? Maybe you need to update the model every day and it’s too expansive.

6. Can you solve the problems with simple rules and logic?
Part 2. Research

Once the problem is defined, it’s time for the research phase. The goal is to gather requirements and learn about constraints.

Answering the following questions will shape the scope and design:
1. Who are the users?

What is their expertise? Are they tech-savvy? What value are they expecting to derive from this product? How familiar are they with AI-based products?
2. Understand user attitudes towards data use

Are users willing to share the data? What data are they willing to provide and what data won’t they provide? Are there company- or industry-wide policies and regulations? What is considered ethical/unethical?
3. Identify the context in which users will use the product

Which environment does the problem occur in? What are they doing before and after? What type of tools do they use? Who do they interact with? What other needs or problems can occur at the same time and in the same environment?
4. What are other tools in their workflow?

If your product is part of a workflow, other tools may affect user habits and expectations. Are they using AI in their work? What type of AI? How are they used to interacting with other AI-based systems. Are there complementing tools you should take into consideration?
5. Who are the competitors?

Are they direct competitors? Would it be possible for your client to switch from one tool to another? How much money and effort would it cost?
6. What are the industry trends?

In the B2B and enterprise world, trends and analytics reports from research and advisory companies have considerable impact. What sources of information do they trust? Are they partnering with any of the advisory companies?
7. What part of the work are users proud of or would be reluctant to automate?

Automation of work can be a sensitive topic. How do we address users’ fears and explain the benefits of AI? Some work is tied to KPIs and bonuses. Your tool might automate or replace this work. How can you help clients to adapt not only to a new tool, but also to the new culture around it?
8. What level of automation should you aim for?

Should you aim for an autonomous system or collaboration between AI and a human? Some task users would outsource to AI, but there are activities people prefer to do to themselves. What are these tasks?

How much time and money would full automation save your clients? Is it worth it? What are the disadvantages of full automation?

📝 More about automation “Human in Control or Automate Everything?”
9. What level of accuracy is required?

How much would the error cost? In terms of money, time, reputation, health, delight, and experience. Are errors acceptable? What are the consequences of false-positive / negative results for the task? Would your clients rather have some errors in the prediction than manually solve tasks? The more accurate the results, the fewer predictions AI makes.
Altoros

In the case where AI was used to calculate the price of damage based on images of a car, what percentage of the time could AI make the wrong estimations but still be profitable? How much would it cost if the AI needed the assistance of people every time it’s unsure?
10. How detailed do the results of interpretability/explainability need to be?

Is full interpretability required by law or policies? For instance, in banking, when a mortgage application is declined a client may request the exact reason.

There are many experiments using AI in radiology. To assist doctors, AI needs to provide all the data and explain the logic behind the prediction.

On the other hand, when Zillow estimates the market value for a property, it doesn’t provide all the data points or explain the algorithms they use. For the user, the explanation is short “We calculate the estimated range based on the current market and the info we have about this house”.
Zillow Zestimate

What information do your clients need to trust the prediction or make a decision based on AI suggestion?

📝 More about explainability “Explaining system intelligence Empower your users, but don’t overwhelm them”
11. How can you ensure the data flow?

The amount of training data is one of the most important components for building a precise system. When working on an AI solution, getting the initial training data and supporting continuous data flow is the product team’s job.

Research whether or not you can enrich your data with public data sets and get new insights. Do your clients have additional data you can use for their benefit?
12. How often should results be updated?

Can the prediction be calculated in advance or should it be updated every time the new information arrives (clicks, likes, photos, scans)? This question is important for technical requirements.
13. Pay attention to users’ communication style

How much jargon is appropriate, how much explanation do they need? Would your users rather have an assistant with a personality or would they trust numbers and percentages more? What terms are considered industry standard and what needs additional explanation? What words are used by experienced people and beginners?
Part 3. Business Requirements Check-list

The design of user flows and the interface depends on business requirements, scope, and a use case that a product management has prioritized. Both design and development teams need the following information to start working on a problem:

✓ Who will be using your product/feature?

✓ What problems do we want to solve?

✓ What type of impact are we aiming for (user satisfaction, reduce cost, minimise time, maximise safety)?

✓ What are the assumptions and hypotheses we want to test?

✓ What are the priorities?

✓ Use cases that are out of scope for this product/feature. Some use cases might be expensive to solve and would have a low impact on clients.

✓ Metrics (money, clicks, conversion rates, manual engagement rate).

✓ Data obtaining strategy and DQ metrics.

✓ User onboarding.

✓ Roadmap. What should the alpha-version look like? How will the feature evolve?

✓ How will the product be tested (monitoring system performance, adoption to change in data or user behaviour, data, model, usability)?

✓ How should we gather and work with user feedback?

✓ Known constraints (legal, data, trust)?

✓ What are the potential risks (biases in data, lack of data or trust, risks for reputation)?

✓ How do we ensure security and safety (from bad data, manipulation, theft)?

📝 More about business requirements for AI features Recommendation Product Driven Machine Learning (and NYC Parking Tickets)
Part 4. Interface Design

When requirements are defined, the design team can start working on the interface. Read about visualisation and prototyping in the next post.

https://medium.com/@nadyatsech/the-design-of-ai-based-products-13-things-to-consider-297ce9c0f0ba
Takeaways

I‘d say the number one thing product managers need to do is to align on the problem and important metrics for users. Changing the problem definition and the scope in ML development is much harder and may cause a lot of trouble. On the other hand, we can be less focused on details because the iterative nature of ML development supports changes and improvements.
Sources
📝 Articles

    Building AI-first products
    Product Driven Machine Learning. How business goals shape the AI building process.
    Machine Learning for Product Managers
    3 Common Problems With Your Machine Learning Product and How to Fix Them
    The Step-By-Step PM Guide to Building Machine Learning Based Products
    How To Create A Successful Artificial Intelligence Strategy

▶ ️Videos

    How to Be a Good Machine Learning PM by Google Product Manager. What problems AI solves, solution examples, processes for managing AI projects.
    What Is Machine Learning for Product Managers Like by Google PM? Basics of AI for PMs

### Untitled 4.txt

Human-Centered Machine Learning
Jess Holbrook
Google Design

Jess Holbrook
·

Follow
Published in

Google Design
·
13 min read
·
Jul 9, 2017

7 steps to stay focused on the user when designing with ML

By Josh Lovejoy and Jess Holbrook

Machine learning (ML) is the science of helping computers discover patterns and relationships in data instead of being manually programmed. It’s a powerful tool for creating personalized and dynamic experiences, and it’s already driving everything from Netflix recommendations to autonomous cars. But as more and more experiences are built with ML, it’s clear that UXers still have a lot to learn about how to make users feel in control of the technology, and not the other way round.

As was the case with the mobile revolution, and the web before that, ML will cause us to rethink, restructure, displace, and consider new possibilities for virtually every experience we build. In the Google UX community, we’ve started an effort called “human-centered machine learning” (HCML) to help focus and guide that conversation. Using this lens, we look across products to see how ML can stay grounded in human needs while solving them in unique ways only possible through ML. Our team at Google works with UXers across the company to bring them up to speed on core ML concepts, understand how to integrate ML into the UX utility belt, and ensure ML and AI are built in inclusive ways.

If you’ve just started working with ML, you may be feeling a little overwhelmed by the complexity of the space and the sheer breadth of opportunity for innovation. Slow down, give yourself time to get acclimated, and don’t panic. You don’t need to reinvent yourself in order to be valuable to your team.

We’ve developed seven points to help designers navigate the new terrain of designing ML-driven products. Born out of our work with UX and AI teams at Google (and a healthy dose of trial and error), these points will help you put the user first, iterate quickly, and understand the unique opportunities ML creates.

Let’s get started.
1. Don’t expect Machine learning to figure out what problems to solve

Machine learning and artificial intelligence have a lot of hype around them right now. Many companies and product teams are jumping right into product strategies that start with ML as a solution and skip over focusing on a meaningful problem to solve.

That’s fine for pure exploration or seeing what a technology can do, and often inspires new product thinking. However, if you aren’t aligned with a human need, you’re just going to build a very powerful system to address a very small — or perhaps nonexistent — problem.

So our first point is that you still need to do all that hard work you’ve always done to find human needs. This is all the ethnography, contextual inquiries, interviews, deep hanging out, surveys, reading customer support tickets, logs analysis, and getting proximate to people to figure out if you’re solving a problem or addressing an unstated need people have. Machine learning won’t figure out what problems to solve. We still need to define that. As UXers, we already have the tools to guide our teams, regardless of the dominant technology paradigm.
2. Ask yourself if ML will address the problem in a unique way

Once you’ve identified the need or needs you want to address, you’ll want to assess whether ML can solve these needs in unique ways. There are plenty of legitimate problems that don’t require ML solutions.

A challenge at this point in product development is determining which experiences require ML, which are meaningfully enhanced by ML, and which do not benefit from ML or are even degraded by it. Plenty of products can feel “smart” or “personal” without ML. Don’t get pulled into thinking those are only possible with ML.
Gmail looks for phrases including words like “attachment” and “attached” to pop a reminder when you may have forgotten an attachment. Heuristics work great here. An ML system would most likely catch more potential mistakes but would be far more costly to build.

We’ve created a set of exercises to help teams understand the value of ML to their use cases. These exercises do so by digging into the details of what mental models and expectations people might bring when interacting with an ML system as well as what data would be needed for that system.

Here are three example exercises we have teams walk through and answer about the use cases they are trying to address with ML:

    Describe the way a theoretical human “expert” might perform the task today.

    If your human expert were to perform this task, how would you respond to them so they improved for the next time? Do this for all four phases of the confusion matrix.

    If a human were to perform this task, what assumptions would the user want them to make?

Spending just a few minutes answering each of these questions reveals the automatic assumptions people will bring to an ML-powered product. They are equally good as prompts for a product team discussion or as stimuli in user research. We’ll also touch on these a bit later when we get into the process of defining labels and training models.

After these exercises and some additional sketching and storyboarding of specific products and features, we then plot out all of the team’s product ideas in a handy 2x2:
Plot ideas in this 2x2. Have the team vote on which ideas would have the biggest user impact and which would be most enhanced by an ML solution.

This allows us to separate impactful ideas from less impactful ones as well as see which ideas depend on ML vs. those that don’t or might only benefit slightly from it. You should already be partnering with Engineering in these conversations, but if you aren’t, this is a great time to pull them in to weigh-in on the ML realities of these ideas. Whatever has the greatest user impact and is uniquely enabled by ML (in the top right corner of the above matrix) is what you’ll want to focus on first.
3. Fake it with personal examples and wizards

A big challenge with ML systems is prototyping. If the whole value of your product is that it uses unique user data to tailor an experience to her, you can’t just prototype that up real quick and have it feel anywhere near authentic. Also, if you wait to have a fully built ML system in place to test the design, it will likely be too late to change it in any meaningful way after testing. However, there are two user research approaches that can help: using personal examples from participants and Wizard of Oz studies.

When doing user research with early mockups, have participants bring in some of their own data — e.g. personal photos, their own contact lists, music or movie recommendations they’ve received — to the sessions. Remember, you’ll need to make sure you fully inform participants about how this data will be used during testing and when it will be deleted. This can even be a kind of fun “homework” for participants before the session (people like to talk about their favorite movies after all).

With these examples, you can then simulate right and wrong responses from the system. For example, you can simulate the system returning the wrong movie recommendation to the user to see how she reacts and what assumptions she makes about why the system returned that result. This helps you assess the cost and benefits of these possibilities with much more validity than using dummy examples or conceptual descriptions.

The second approach that works quite well for testing not-yet-built ML products is conducting Wizard of Oz studies. All the rage at one time, Wizard of Oz studies fell from prominence as a user research method over the past 20 years or so. Well, they’re back.
Chat interfaces are one of the easiest experiences to test with a Wizard of Oz approach. Simply have a team mate ready on the other side of the chat to enter “answers” from the “AI.” (image from: https://research.googleblog.com/2017/04/federated-learning-collaborative.html)

Quick reminder: Wizard of Oz studies have participants interact with what they believe to be an autonomous system, but which is actually being controlled by a human (usually a teammate).

Having a teammate imitate an ML system’s actions like chat responses, suggesting people the participant should call, or movies suggestions can simulate interacting with an “intelligent” system. These interactions are essential to guiding the design because when participants can earnestly engage with what they perceive to be an AI, they will naturally tend to form a mental model of the system and adjust their behavior according to those models. Observing their adaptations and second-order interactions with the system are hugely valuable to informing its design.
4. Weigh the costs of false positives and false negatives

Your ML system will make mistakes. It’s important to understand what these errors look like and how they might affect the user’s experience of the product. In one of the questions in point 2 we mentioned something called the confusion matrix. This is a key concept in ML and describes what it looks like when an ML system gets it right and gets it wrong.
The four states of a confusion matrix and what they likely mean for your users.

While all errors are equal to an ML system, not all errors are equal to all people. For example, if we had a “is this a human or a troll?” classifier, then accidentally classifying a human as a troll is just an error to the system. It has no notion of insulting a user or the cultural context surrounding the classifications it is making. It doesn’t understand that people using the system may be much more offended being accidentally labeled a troll compared to trolls accidentally being labeled as people. But maybe that’s our people-centric bias coming out. :)

In ML terms, you’ll need to make conscious trade-offs between the precision and recall of the system. That is, you need to decide if it is more important to include all of the right answers even if it means letting in more wrong ones (optimizing for recall), or minimizing the number of wrong answers at the cost of leaving out some of the right ones (optimizing for precision). For example, if you are searching Google Photos for “playground”, you might see results like this:

These results include a few scenes of children playing, but not on a playground. In this case, recall is taking priority over precision. It is more important to get all of the playground photos and include a few that are similar but not exactly right than it is to only include playground photos and potentially exclude the photo you were looking for.
5. Plan for co-learning and adaptation

The most valuable ML systems evolve over time in tandem with users’ mental models. When people interact with these systems, they’re influencing and adjusting the kinds of outputs they’ll see in the future. Those adjustments in turn will change how users interact with the system, which will change the models… and so on, in a feedback loop. This can result in “conspiracy theories” where people form incorrect or incomplete mental models of a system and run into problems trying to manipulate the outputs according to these imaginary rules. You want to guide users with clear mental models that encourage them to give feedback that is mutually beneficial to them and the model.
An example of the virtuous cycle is how Gboard continuously evolves to predict the user’s next word. The more someone uses the system’s recommendations, the better those recommendations get. Image from https://research.googleblog.com/2017/05/the-machine-intelligence-behind-gboard.html

While ML systems are trained on existing data sets, they will adapt with new inputs in ways we often can’t predict before they happen. So we need to adapt our user research and feedback strategies accordingly. This means planning ahead in the product cycle for longitudinal, high-touch, as well as broad-reach research together. You’ll need to plan enough time to evaluate the performance of ML systems through quantitative measures of accuracy and errors as users and use cases increase, as well as sit with people while they use these systems to understand how mental models evolve with every success and failure.

Additionally, as UXers we need to think about how we can get in situ feedback from users over the entire product lifecycle to improve the ML systems. Designing interaction patterns that make giving feedback easy as well as showing the benefits of that feedback quickly, will start to differentiate good ML systems from great ones.
The Google app asks every once in awhile if a particular card is useful right now to get feedback on its suggestions.
People can give feedback on Google Search Autocomplete including why predictions may be inappropriate.
6. Teach your algorithm using the right labels

As UXers, we’ve grown accustomed to wireframes, mockups, prototypes, and redlines being our hallmark deliverables. Well, curveball: when it comes to ML-augmented UX, there’s only so much we can specify. That’s where “labels” come in.

Labels are an essential aspect of machine learning. There are people whose job is to look at tons of content and label it, answering questions like “is there a cat in this photo?” And once enough photos have been labeled as “cat” or “not cat”, you’ve got a data set you can use to train a model to be able to recognize cats. Or more accurately, to be able to predict with some confidence level whether or not there’s a cat in a photo it’s never seen before. Simple, right?
Can you pass this quiz?

The challenge comes when you venture into territory where the goal of your model is to predict something that might feel subjective to your users, like whether or not they’ll find an article interesting or a suggested email reply meaningful. But models take a long time to train, and getting a data set fully labeled can be prohibitively expensive, not to mention that getting your labels wrong can have a huge impact on your product’s viability.

So here’s how to proceed: Start by making reasonable assumptions and discussing those assumptions with a diverse array of collaborators. These assumptions should generally take the form of “for ________ users in ________ situations, we assume they’ll prefer ________ and not ________.” Then get these assumptions into the hackiest prototype possible as quickly as possible in order to start gathering feedback and iterating.

Find experts who can be the best possible teachers for your machine learner — people with domain expertise relevant to whatever predictions you’re trying to make. We recommend that you actually hire a handful of them, or as a fallback, transform someone on your team into the role. We call these folks “Content Specialists” on our team.

By this point, you’ll have identified which assumptions are feeling “truthier” than others. But before you go big and start investing in large-scale data collection and labeling, you’ll want to perform a critical second round of validation using examples that have been curated from real user data by Content Specialists. Your users should be testing out a high-fidelity prototype and perceive that they’re interacting with a legit AI (per point #3 above).

With validation in-hand, have your Content Specialists create a broad portfolio of hand-crafted examples of what you want your AI to produce. These examples give you a roadmap for data collection, a strong set of labels to start training models, and a framework for designing large scale labeling protocols.
7. Extend your UX family, ML is a creative process

Think about the worst micro-management “feedback” you’ve ever received as a UXer. Can you picture the person leaning over your shoulder and nit-picking your every move? OK, now keep that image in your mind… and make absolutely certain that you don’t come across like that to your engineers.

There are so many potential ways to approach any ML challenge, so as a UXer, getting too prescriptive too quickly may result in unintentionally anchoring — and thereby diminishing the creativity of — your engineering counterparts. Trust them to use their intuition and encourage them to experiment, even if they might be hesitant to test with users before a full evaluation framework is in place.

Machine learning is a much more creative and expressive engineering process than we’re generally accustomed to. Training a model can be slow-going, and the tools for visualization aren’t great yet, so engineers end up needing to use their imaginations frequently when tuning an algorithm (there’s even a methodology called “Active Learning” where they manually “tune” the model after every iteration). Your job is to help them make great user-centered choices all along the way.
Work together with Engineering, Product, etc. to piece together the right experience.

So inspire them with examples — decks, personal stories, vision videos, prototypes, clips from user research, the works — of what an amazing experience could look and feel like, build up their fluency in user research goals and findings, and gently introduce them to our wonderful world of UX crits, workshops, and design sprints to help manifest a deeper understanding of your product principles and experience goals. The earlier they get comfortable with iteration, the better it will be for the robustness of your ML pipeline, and for your ability to effectively influence the product.
Conclusion

These are the seven points we emphasize with teams in Google. We hope they are useful to you as you think through your own ML-powered product questions. As ML starts to power more and more products and experiences, let’s step up to our responsibility to stay human-centered, find the unique value for people, and make every experience great.
Authors

Josh Lovejoy is a UX Designer in the Research and Machine Intelligence group at Google. He works at the intersection of Interaction Design, Machine Learning, and unconscious bias awareness, leading design and strategy for Google’s ML Fairness efforts.

Jess Holbrook is a UX Manager and UX Researcher in the Research and Machine Intelligence group at Google. He and his team work on multiple products powered by AI and machine learning that take a human-centered approach to these technologies.

Akiko Okazaki did the beautiful illustrations.


### Untitled 5.txt

AI Design Principles: UX Guide
Refire Design

Refire Design
·

Follow
6 min read
·
Oct 23, 2023

Photo by Choong Deng Xiang on Unsplash

The growing field of Artificial Intelligence (AI) has opened up many opportunities to improve user interactions in digital environments. While chatbots are often seen as the face of AI-driven design, the role of AI in user experience (UX) design goes much further. It includes a variety of applications that can enhance user engagement and simplify complex processes.
Understanding the Audience

Getting to the heart of user-centric AI design requires a deep understanding of the audience for whom the AI products are being created. Successful AI design largely depends on aligning the AI’s functionality with the users’ expectations, needs, and preferences. Here’s a closer look at understanding the audience in the context of AI products:
1. Identify User Needs and Preferences

Comprehensive user research is fundamental to identifying user needs and preferences. Employ methods like surveys, interviews, and usability testing to gather insights into user behavior, pain points, and desires. For example, when designing an AI-powered educational platform, understanding the learning preferences, the challenges of traditional learning environments, and the goals of your target audience is crucial. This foundational understanding will guide the design process, ensuring the AI functionalities effectively address the users’ needs.
2. User Personas and Journey Mapping

Creating detailed user personas and journey maps is key to visualizing the user’s interaction with the AI product. User personas summarize the characteristics, goals, and behavior of different user segments. Journey maps provide a visual narrative of the users’ interactions with the AI product, identifying touchpoints, pain points, and opportunities for AI to enhance the experience. For instance, in designing an AI-driven healthcare app, journey mapping can reveal touchpoints where AI can streamline appointment scheduling, offer personalized health advice, or automate medication reminders, thus enhancing the overall user experience.
3. Empathy and Ethical Considerations

Embracing empathy and ethical considerations is vital in understanding the audience for AI products. Given AI’s pervasive nature, being mindful of potential biases, privacy concerns, and ethical implications is critical. Ethical design practices should ensure the AI product respects user privacy, provides value, and promotes inclusivity. For instance, when designing an AI-driven financial advisory app, ensuring the AI does not perpetuate existing biases and provides accurate, unbiased financial advice to a diverse user base is crucial.
4. Contextual Understanding

Understanding the context in which the AI product will be used is essential for designing interfaces and interactions that feel natural and intuitive. Understand the environment, the devices, and the circumstances under which users will interact with the AI product. For example, an AI-driven fitness app used in a gym setting might need to consider offline functionality, integration with gym equipment, and a user interface that is easily accessible during physical activity.

In AI-driven product design, grounding every design decision in a deep understanding of the audience lays the foundation for creating AI interfaces and interactions that are meaningful, intuitive, and highly user-centric.
UX Nuances in AI Design

The realm of AI design is nuanced, requiring a solid grasp of user experience (UX) principles to ensure AI integration enhances rather than hinders user interactions. Here’s a closer look at the UX nuances inherent in AI design:
1. Predictive User Experiences

AI excels at analyzing data to predict future user actions. Designing predictive user experiences involves creating interfaces that anticipate user needs and proactively provide solutions. For example, a weather app might analyze past interactions to predict which weather information a user wants to see first, such as the likelihood of rain if they often check that statistic.

Use machine learning algorithms to analyze historical user data and predict future actions. Conduct user testing to validate the accuracy and usefulness of predictions.
2. Transparency and Trust

Trust is crucial in AI-driven design. Users should know when they are interacting with AI and understand how their data is being used. For instance, if a health app provides personalized workout recommendations, it should clearly communicate how it’s using the user’s health data to make these recommendations.

Employ clear labeling, make privacy policies accessible, and use user-friendly language to explain AI functionalities.
3. Error Handling

Since AI can make mistakes, effective error handling in AI design is about creating intuitive pathways for users to correct or override AI decisions. For instance, if a language translation app provides an incorrect translation, it should allow users to easily correct the translation and learn from that correction.

Provide clear feedback, offer easy-to-access corrective actions, and use user input to improve AI accuracy over time.
4. User Control

Striking a balance between AI automation and user control is essential. Users should feel in control of the interactions, with AI acting as an aid, not a substitute. For instance, an email categorization tool should allow users to easily override the AI’s categorization decisions and categorize emails manually if they wish.

Offer settings or preferences for users to tailor the AI’s behavior, and provide clear options for users to override AI decisions.
5. Accessibility

It’s crucial that AI-driven designs are accessible to all users, including those with disabilities. For example, voice-activated AI should have alternative interaction methods for users unable to speak commands.

Follow accessibility best practices like the Web Content Accessibility Guidelines (WCAG), ensuring AI-driven features are accessible through multiple modalities.
6. Ethical Considerations

Ethical considerations in AI UX design include respecting user privacy, combating bias, and ensuring inclusivity. For instance, ensuring a facial recognition system can accurately recognize faces of all skin tones is a fundamental ethical consideration in AI design.

Use diverse training data, conduct thorough bias testing, and engage in ethical review processes to uphold ethical standards in the AI product.
7. Feedback Loops

Establishing feedback loops for users to provide input helps the AI learn and improve. For example, a recommendation engine should allow users to provide feedback on the relevance of recommendations, which the AI can use to refine its future recommendations.

Implement feedback mechanisms like thumbs up/thumbs down or rating systems, and use this feedback to continuously refine the AI algorithms.
8. Education and Onboarding

Educating users on interacting with AI-driven features and what to expect from the AI is key to a positive user experience. For instance, a clear onboarding tutorial can help users understand how to interact with an AI-driven virtual assistant.
Use onboarding tutorials, tooltips, and help centers to educate users about the AI functionalities and best practices for interaction.

By exploring these UX nuances, designers can navigate the complex landscape of AI design to craft user-centric AI-driven experiences that are intuitive, engaging, and trust-inspiring. Achieving excellence in AI design hinges on paying meticulous attention to these nuances, ensuring AI acts as a powerful ally in enhancing user satisfaction and achieving the desired outcomes.
Wrapping Up

Exploring AI-driven design goes beyond just creating conversational chatbots. It’s about blending AI with a user-centric approach, where AI enhances the user experience instead of replacing human interaction. Paying close attention to understanding the audience, refining the UX nuances, and incorporating design elements that align with AI functionalities helps in crafting digital experiences that are intuitive, engaging, and highly user-centric.

Merging AI with thoughtful design leads to digital products that are not just smart but also intuitive, engaging, and firmly user-centric. This results in a range of AI-driven experiences that meet the varied needs and expectations of users, taking satisfaction and engagement to new levels. It envisions a scenario where AI serves as a strong ally in boosting user satisfaction and achieving the desired outcomes.

At Refire Design, we’re at the forefront of navigating the complex landscape of AI design. Our experienced team of designers and developers excel at creating user interfaces that encapsulate the robust capabilities of AI while ensuring a smooth, enjoyable user experience. We advocate a user-first approach, where every design decision stems from a deep understanding of the user’s needs, preferences, and interactions with AI-driven features.

Whether you’re looking to create intuitive AI-driven apps, engaging conversational interfaces, or robust AI-powered platforms, Refire Design is ready to turn your vision into reality. Our expertise in UX/UI design for AI products, along with a keen understanding of the latest trends in AI and machine learning, makes us a top choice for businesses aiming to create impactful, user-centric AI-driven digital products.

Start your AI design journey with Refire Design as your reliable partner, and experience a well-managed design process that ensures your AI product not only meets the functional needs but also delights users with a seamless and enriching user experience. We are committed to delivering AI design solutions that deeply resonate with your target audience, driving user satisfaction and taking your business success to new heights.



### Untitled 12.txt

The Design of AI-Based Products: 13 Things to Consider
Nadya Tsech
UX Planet

Nadya Tsech
·

Follow
Published in

UX Planet
·
8 min read
·
Jan 2, 2020

Once the problem has been researched and defined, a design team can start working on testable prototypes. There are 13 things that need special consideration.

    You can find information about the research of AI-based products in the first post.

AI Product Management: Research, Requirements and Scope
What is AI good at? What questions should you ask during the research phase? How should you prepare business…

medium.com
1. Designing for Data Acquisition

Collecting training data could be the first design task before you even start building a model. If there are no available sources of data, we need to create a data flow ourselves. Balancing the collection of data and providing the value for users without an AI.

As Andrew Ng mentions in his ML course, The Virtuous Cycle of AI, Better product > attracts more users > they generate more data > and data improves the product.
The Virtuous Cycle of AI. Image

It’s hard to build a recommendation service without views, ratings, stars, reviews or clicks. But it’s possible to collect this information by using polls, gamification or asking users to provide their reviews and stars in exchange for solving their problem.

If your model relies on a specific data format, you need to consider input restrictions, data firewalls and validation.
2. Onboarding

Not every AI feature needs tutorials, but considering the nature of AI, we need to explain to the user how the system works, how the data is collected, set expectations and ask for permissions to collect data.

✓ Ask for permissions to collect data and explain how it will be used. Let the user/company set up the data they want to provide. Explain which data is crucial for the algorithm and how it will affect the work of the tool if the user won’t provide it.

✓ Set up user expectations:

    Explain what the system can do and the benefits for the specific user type.
    Explain what the system can’t do.
    How will it do it?
    What is needed from the user?
    What will happen if the system fails?

✓ If the model becomes smarter over time using the product, explain how it will evolve and how a user can level up the system.

✓ Can it be personalised and set up? Show the user how they can manage collaboration with AI.
Apple iPhone Siri settings

✓ Does the product need training before the company can leverage its potential? Create a flow for trainers/annotations.
Ataccama ONE Master Data Management solution. Users are asked to train the system on a sample of data (20 out of several million). This training is available to users with special qualifications and special permissions.
3. Activation

Design the activation/deactivation process. Is it a button, a word, or a gesture? Should it be on by default or is it an expensive operation that needs user authorization to start? How does the user know it is activated?
Voice activation of Google Assistant
Casetext lets the user switch off/on an AI algorithm for detecting issues in legal documents.
4. Visualisation and Placement

Is it important for a user to differentiate AI content? Would it affect the way they work or make a decision? We should let users decide how they will use algorithm-generated content.

✓ In a special sidebar, tab or a dashboard.
IBM Cognos Analytics AI Assistant in a special sidebar
Google Analytics Insight in a dashboard
Salesforce Einstein AI insights and recommendations in a dashboard
Entelo provides a special sidebar with recommendations.

✓ Put AI suggestions in context.
Luminance shows recommendations right in the text.
Entelo. When analysing a candidate’s CV, Paysa shows the predicted salary range next to the job position.
Wootric analyses customer feedback and labels it with the indication of positive, negative or neutral.

✓ Show predictions and trends in charts.
Konux predicts issue evolution.
Alloy forecasting
Salesforce Einstein AI
5. Communication Style

Communication style and personality are especially important for conversational interfaces. If it’s not a conversational UI, you still need ways to communicate and explain decisions to users. AI features can have the same style as the rest of the product or it can have a personality to highlight its difference.
6. Confidence Visualisation

Is there a well-understood metric among your users (score, colour-code, price) or should you create a new metric to show the prediction confidence?
INK analyses content and gives a user a content relevance metric which is already known among their users.

✓ Group results (high/medium/low, score, colour-code, a/b/c).
Appzen uses the colour-code to show risk score.

✓ Number (0–1, percentage, distance, score).
Firebase Predictions in percentage
Netflix shows match confidence in %s.
Falkonry shows confidence level 0–1.
Amazon Comprehend API provides a number from 0–1.

✓ Sort by relevance or show Top N results.
Google autocomplete suggests top N results.
Spotify. Suggested songs are sorted by relevance.

✓ Chart
Entelo show the probability of a potential candidate leaving their job as a chart.

✓ Mixed approach.
Customer satisfaction prediction in Zendesk is displayed with a colour-code, chart and numerical value at the same time.
Monty’s Wicket Warnings shows the number and a pie chart.
7. Explanation

The bigger the impact of a prediction, the more detailed of an explanation you need to provide. For instance, explaining a credit score can help people to improve it.

✓Explain why a specific outcome was predicted or suggested.
Tableau shows the popup with the information “Why is this recommended?”
Appzen gives a user explanation message and additional information including showing data from external sources.

✓ Explain how AI understands user input or intent.
ThoughtSpot explains why a user sees specific results of a search.

✓ Example-based explanations can be provided when it’s hard to describe the logic behind the prediction.
8. Actions

✓ Accept or reject AI suggestions.
Timelyapp time tracking app

✓ Action for editing and supervising suggestions.
Rossum automated data extraction

✓ Let users create labels to mark found data and patterns.
Falkonry lets users label and track found patterns.

✓ Recommend further action based on the analysis.
Alloy suggests ordering more items based on trends.
Salesforce Einstein AI gives actional advice based on predictions.
Snappr analyses professional photos and gives advice on how to improve the photo.
9. Defaults and Settings

✓ Consider defaults that won’t overwhelm the user while the system learns and gathers data.

✓ Let the user set up a threshold for notifications and suggestions.

✓ Adjust system behaviour according to the number of predictions it makes.
10. Error Handling

✓ Let the user intervene.

✓ Support correction.

✓ Support dismissal.

✓ Let the user provide additional information and reevaluate predictions.

✓ Explain to the user how the system learns based on their corrections.

✓ Consider fallback in case of an AI emergency.
11. Feedback

Design a flow where a user can provide actionable and understandable feedback for the model:

✓ Explain how feedback will benefit the user and improve results.

✓ Let the users provide explicit feedback.
ThoughtSpot
When a user overrides a strong suggestion, you can ask for a reason to learn more. Product Management for AI/ML by TheProductWay
Toutiao learns not only based on implicit feedback from clicks, reads and time spent, but also has a button labelled “not interested”.
In Zendesk, a user can report a wrong score.
The plant identification app, PlantSnap, lets users manually enter information about a plant or send it to a professional.

✓ Use implicit feedback from user interactions (clicks, views, time, share, interactions).
12. Microinteractions

✓ Loading and calculation.
INK analyses the content relevance based on intent and the text.
Snappr analyses professional photos on LinkedIn.

✓ Error messages.

✓ Notifications.
13. Delight

This whole post was focused on user problems. In the B2B world, solving a user’s problem makes a big difference and can delight users more than anything. But as a product team, we should keep an eye on opportunities to give a user more value, surprises and delights. Something that Spotify and Netflix do with their recommendations.
Prototyping and Testing

Testing an AI-based product can be the trickiest part. There are several recommended methods in the design community:

    Human on the back-end or Wizard of Oz method. Helps to understand if this functionality is needed and if it’s trusted.
    Testing many scenarios in different environments to uncover possible faults or inconsistencies.
    Ethical check. Many times in the short history of AI mass usage, we have witnessed how neutral in nature products have caused harm. To avoid it:

    Test the product in different environments.
    Check data for biases.
    Select diverse demographics for testing.

4. Prototype using available AI tools:

    Mathematica to test image recognition, text classification, and classification or regression of generic data. It has an interface and doesn’t require tech skills to use it.
    Wekinator to test musical instruments, gestural game controllers, computer vision or computer listening systems. It’s open-source, no programming required.
    Keras a user-friendly wrapper running on top of TensorFlow, CNTK, or Theano. It is made for prototyping.

📝 More tools Quick Prototyping Tools for Emerging Technologies
Takeaways

When working on interfaces, designers should treat AI as any other technical component. It’s important to understand the constraint, but the technical implementation shouldn’t affect the design process.
Sources
📘 Books

    Machine Learning for Designers by Patrick Hebron.

The first part explains ML fundamentals. The second is about design principles and emerging best practices. The book focuses more on conversational ML and chat-bots, but the principles from the book can be applied anywhere. The chapter about prototyping has a lot of information I haven’t seen anywhere else.
📝 Articles

    People + AI Guidebook is the most comprehensive resource on designing AI interfaces with examples, worksheets and glossary.
    AI UX: 7 Principles of Designing Good AI Products
    UX Design Guide for Data Scientists and AI Products
    UX Design for AI Products. Step by step guide for conversational AI

▶ ️Videos

    Product Design in the Era of the Algorithm by Josh Clark. Design philosophy, ethical questions and practical advice.
    Designing an Artificial Intelligence Interface. Case study

### Untitled 8.txt


Tuning out Toxic Comments, with the Help of AI
Can a machine learning-powered moderation tool make the internet a healthier, safer place?
Quinn Madison
Google Design

Quinn Madison
·

Follow
Published in

Google Design
·
5 min read
·
Nov 21, 2019

Illustration by Niv Bavarsky

This is the second article in a series that shows how the practices and principles of the People + AI Guidebook are reflected in the design and development of human centered AI products at Google. It was written in collaboration with the Jigsaw Team.

There’s so much potential in online interactions. They can be positive — you might learn something fascinating, perhaps meet a remarkable person — or they can be negative, even harmful. According to a Pew Media Research Center study, about 41 percent of American adults have experienced online harassment, most commonly on social media. A significant portion of those people — 23 percent — reported that their most recent experience happened in a comments section.

A single toxic comment can make someone turn away from a discussion. Even seeing toxic comments directed at others can discourage meaningful conversations from unfolding, by making people less likely to join the dialogue in the first place. The Pew Research Center report revealed that 27 percent of Americans decided not to post something after witnessing online harassment.

The power to moderate comment sections — to identify, reduce or eradicate toxic comments — has historically been granted to platform moderators. But what if, instead of relying on moderators, people could control for themselves the comments they see?

We wanted to make it happen, so we designed and built Tune.
Introducing Tune

Tune is an AI-powered Chrome extension that lets users moderate toxicity in their comment threads. It’s designed to give users (not platform moderators) moment-to-moment control over the tenor of comments they see. With Tune, users can turn down the “volume” on toxic comments entirely (zen mode) or allow certain types of toxicity (profanity, for example) to remain visible.

We built Tune on Perspective, an API we developed that uses machine learning to spot abusive language. Tune works on the commenting platform Disqus as well as on Facebook, Twitter, YouTube, and Reddit. It’s open source (find it on Github) and part of the Conversation-AI research project, which aims to help increase participation, quality, and empathy in online conversations at scale.
Tune, in action
Empowering people

Designing Tune required extensive user research, deep empathy for users, and ongoing collaboration between product managers, engineers, and UX designers. From the start, we approached the problem with a user-centered focus by asking:

How might a machine learning-powered moderation tool empower individual users as they read comments?

We thought about how best to build trust, how to design an interface that would offer users control, and how to allow for feedback. Above all, we wanted users to feel empowered to change the toxicity level of the comments seen in their feeds.

Three design goals arose: Build user trust, give users control, and design for transparency.
Finding a metaphor

First: We had to set user expectations and make it easy for each new user to quickly grasp how Tune works. We searched for an easily understandable metaphor.

Our research revealed that users value control. Tune didn’t have to be perceived as something that worked by magic. Being perceived as transparent, we found, would engender user trust. The idea of volume as a metaphor took hold, and with it came the notion of a volume dial. This familiar object reinforced the message we wanted to send: that each user can take control, make “volume” adjustments, and explore what works well for them.
Understanding errors

Perspective was originally developed to enable publishers of all sizes (New York Times, The Economist, and others) to set toxicity thresholds for their platform. But we wanted Tune to serve end users, empowering individuals to set thresholds for themselves.

That said, the output of ML models isn’t always easy for end users to understand. And no matter how rigorous our ML model, we knew errors would still occur. There’s no exact calculus on how to define toxic language, and toxicity isn’t always obvious and universal. We knew our model was likely to classify certain comments in ways that differed from user expectations.

Some comments obviously intend to troll, insult, or provoke the person on the receiving end. But most toxic comments are subtle and ambiguous — not extreme. And in many cases, harmful conversation isn’t caused by the substance of a comment but by the tone in which the ideas are conveyed.

With that in mind, we designed the UI to support transparency: Comments are visible as users turn their “volume” dial to increase or decrease their toxicity thresholds. Users can easily see how the adjustment impacts what types of comments remain visible.
People + AI Guidebook principles

Designing Tune required trial and error and a commitment to human-centered AI design. Our users needed insight into what was happening, so they could trust Tune. They also needed control over toxicity thresholds, so they could adjust in real time.

People and AI Guidebook principles were foundational to the design and are evident in the final product. Those are:

Explainability and trust

Optimize for trust. Explain predictions, recommendations, and other AI output to users. The right level of explanation helps users understand how an ML system works. When users have clear mental models of the system’s capabilities and limits, they can understand how and when it can help accomplish their goals.

Feedback and control

Understand when your users want to maintain control and when they’d appreciate ML automation. We didn’t automate control entirely. We made sure for example, users could minimize toxicity themselves by turning down the dial.

Design to engender feedback — and then align that feedback with model improvement. Ask the right questions at the right level of detail (don’t overwhelm users with questions and avoid wordiness). Ask at the right moment — immediately. When Tune didn’t perform as expected, it was key to enable users to give feedback immediately.

Errors and graceful failure

Set user expectations for “failure” (when the system for example, perceives and classifies a comment as toxic but the user disagrees), and provide paths forward when the system fails. Design and build with the knowledge that errors happen and can help your ML model learn from users. Design an error experience that’s user-centered, because the product needs to provide ways for users to continue their task and help the model improve.
Parting words

We’re proud of what we’ve accomplished so far, but we don’t view Tune as a finished product. We see it instead as an ongoing experiment that empowers users (not platform moderators) to set their own thresholds for what they see. We want Tune to enable a healthier internet — one where toxicity can be dialed down and where people can feel safe.

Quinn Madison leads content strategy for People + AI Research (PAIR) core operations and is a coauthor of People + AI Guidebook.


### Untitled 9.txt

How to Meet User Expectations for Artificial Intelligence
Research-based recommendations to create a human-centered AI experience
Kathy Baxter
Salesforce Designer

Kathy Baxter
·

Follow
Published in

Salesforce Designer
·
9 min read
·
Apr 12, 2017

For those unfamiliar with artificial intelligence (AI), it is the simulation of human intelligence (i.e., learning, reasoning, self-correction) by a computer system or machine. AI has been around since the term was coined by John McCarthy at The Dartmouth Conference in 1956 but it has seen a recent resurgence in interest because there is now more data and computing power available than ever. Neural networks that couldn’t work a few years ago are working overnight and that’s due to greater computing power.
Salesforce Einstein

Salesforce Einstein is applying AI across our CRM products to enable our customers to make better informed decisions and complete tasks faster. We want to make AI accessible to everyone, not just data scientists, because we believe that democratizing AI can improve everyone’s lives.

This is an exciting time for those working in AI but there is a lot we still don’t know. New blog posts, articles, and news stories are published everyday on the topic but much of it is more speculation and opinion than actual empirical research.

To ensure we are making data-driven decisions, the Salesforce User Research and Analytics team conducted a literature review of internal and external user research on AI. Kathy Baxter, Greg Bennett, Yakaira Núñez, and Mru Kodali have combined our own research insights with published research from academia and industry to identify the core expectations users have when interacting with any AI system. Based on those expectations, we have provided recommendations for how AI systems should be designed with users in mind, regardless of tool (e.g., chatbot, case classification) or domain. This is a rapidly evolving field and as such, these expectations and recommendations will continue to evolve with technological advancements and user experiences over time.
1. Know your limits

No AI is perfect, especially when it is learning, so it’s important to know the limits of the system and to stay within the bounds of what it can do to support the user. Don’t allow the user to make errors or force them to remember specific words the system recognizes (Nielsen’s 10 heuristics). Overreach and the user will be disappointed at best, angry at worst.
The Assist chatbot clearly lists the things it can help with.
Recommendations

    Don’t pretend to be human: Not all consumers know what a “chatbot” is so it is especially important to communicate that an artificial assistant isn’t human. Pretending to be a human sets the user’s expectations too high and they may become angry if they feel they have been “duped” by the system.
    Be prescriptive: If you do not have the ability to intelligently support free-text, clearly and concisely communicate what is possible (e.g., “Which model are you referring to? A, B or C?”). Think internationally. You need to know how to respond if the user is trying to communicate in a language you cannot communicate back in.
    Convey level of certainty: Using words like “suggested,” “hint,” or providing confidence scores conveys the level of confidence a user should put into the recommendations and not be overly disappointed when it isn’t correct.
    Take responsibility: Never blame the user when things don’t go as planned. “I’m sorry but I seem to be having difficulty” lets the user know the system realizes it is to blame, not the user.

2. Establish immediate value

Once you know the limits of what you can achieve, you must ensure that you can still provide value to the end user and demonstrate it immediately. The tools/systems cannot be simply usable or entertaining, they must also be useful.
KLM’s chatbot allows customers to manage their travel needs
Recommendations

    Speed is critical: It should go without saying that if the AI can’t help the user complete their task(s) faster and/or more accurately, there is no point in having it. Having to edit suggested responses or repeatedly request information wastes time and the user’s goodwill. Brevity and clarity are also key here. Users should not have to spend additional time trying to understand the recommendation.
    Be accessible: It’s just as important for AI systems/tools to be accessible as any other product. Unfortunately, not all chatbots are accessible. Before launching your smart tool into the world, make sure it is universally accessible. These two posts are great resources to get you started: How to Describe Complex Designs for Users with Disabilities and 7 Things Every Designer Needs to Know about Accessibility.
    Offer an escape hatch: One of Nielsen’s 10 heuristics is “user control and freedom.” When the system fails, user needs a way out. There should always be a way to decline/undo any suggestions or changes the system makes. Chatbots should also offer a way to redirect to humans at any point by asking for one (e.g., submit a case, post to the user community). Sentiment analysis to detect when the user is angry should automatically connect the user to a human. Forcing the user to engage with the AI, especially when it is wrong, will only result in the user avoiding the system (e.g., turning off the suggestions, abandoning the product).

3. Build trust over time

It can take years to build your brand and earn your customers’ trust but in a world where anything can go viral, it can be seriously damaged in days or minutes.
DoNotPay is a lawyer bot that helps people fight unfair parking tickets.
Recommendations

    Don’t be evil: When a group of scientists and technologists were recently asked about grand challenges for the 21st century, concerns around fairness, ethics, and protecting humans in AI systems were frequently cited. Users expect AIs to make the right recommendations in terms of not only accuracy but also based on ethics. A great example is DoNotPay, a lawyer bot that helps users fight unfair parking tickets, gets landlords to repair their tenet’s buildings, and helps refugees apply for asylum.
    Don’t be creepy: You wouldn’t expect nor want a new human administrative assistant rescheduling meetings with your leads or answering emails for you without your direction. The same is true for an AI assistant. Knowing too much is creepy and inserting itself unrequested is annoying, especially when it is wrong. Any AI system should begin by making suggestions and limiting what it offers to do. Demonstrate learning over time and offer to do more as accuracy increases. One example of this is MuseBot which recommends daily activities to enrich your child’s life. It can actually predict lifetime outcomes based on what it learns but does not share that with parents since that could cause more harm than good.
    Be transparent: Users are uncomfortable with a “black box.” They want to understand the inputs that went into making the recommendations and have the ability to edit incorrect information that could negatively influence the accuracy. Amazon’s recommendation system is a great example of showing customers why a particular recommendation was made and allowing them to edit the information to improve recommendations.
    Take feedback: Users will not trust a system it cannot give feedback to. Users should be able to evaluate the accuracy of the AI’s predictions and tell it to course-correct, as well as govern how information is shared between parties (both internally and externally) throughout the auto-sync of information. Netflix allows customers to rate movies, which are then taken into consideration for future recommendations.
    Have a guardian: Although some users will intentionally try to break your AI (e.g., Tay), most users expect companies to have safeguards in place to protect their data and to interact with them legally and ethically. Since AIs are designed to be constantly learning, they may stray considerably from the guidelines their programmers initially gave them. As the complexity increases, they will become “black boxes” to human understanding. It would be virtually impossible for any human to monitor these constant changes, understand, and determine if they are legal or ethical so having an AI guardian will be important to protect users and maintain trust.

4. Respect social norms

Although a chatbot shouldn’t pretend to be a human, it must still respect social norms to avoid being perceived as “rude” or having uncomfortable interactions.
Joy can respond to the user’s mood
Recommendations

    Convey listenership: If the bot is limited to canned responses and isn’t utilizing natural language processing (NLP), it can provide entire sentences instantly in response to a user’s request, but this instant response will feel rude, as if the system isn’t “listening” to the user’s request. Speed is critical, but taking natural pauses and using varied language to show understanding of the request is expected for courtesy. Consider including filler words such as, “Ah, okay. Let me check,” or “I’m still here, just checking,” or “Still getting results” to fill time for long-tailed recall. Consider modeling turn-taking structure and phrasing around best practices for transactional interactions.
    Don’t interrupt: No one likes to be interrupted. AI systems shouldn’t interrupt a user’s task and chatbots shouldn’t interrupt a user mid-speech.
    Detect mood: Responding to a serious customer issue with smiling emoticons or jokes will only anger the user. Bots must detect emotion and respond accordingly, including escalating to a human when the user is angry.
    Context matters: Users expect humans and systems alike to remember previous interactions and content. AIs should also leverage contextual information like location (e.g., airport), time of day (e.g., midnight), and issue types (e.g., flight cancellation) to prioritize and respond accordingly. Is the user looking for an entertaining exchange or is s/he trying to immediately rebooked a cancelled flight? The AI must be able to tell the difference.
    Be polite: Many people say, “Thank you” in response to a bot’s assistance. The bot needs to understand these types of courtesies and how to respond (i.e., “You’re welcome”). Equally, it should respond politely but firmly when the user becomes abusive to avoid normalizing abusive interactions.

5. Have personality

Every system/tool we use should be a pleasure to use.
Starbucks’ bot matches their brand and uses beautiful photos of their products to communicate with customers.
Recommendations

    Be delightful: Chatbots in particular should have a personality. Ideally, a chatbot should be as interesting to interact with as a human. We identify with characters that reflect back to us who we believe we are or who we want to be. The chatbot should be able to adapt to varying conversational styles and preferences and adhere to them. This includes how to respond with the user becomes aggressive or intentionally tries to break it. Ask AmEx gives a variety of options to choose from and goes above and beyond by reminding the user of upcoming holidays.
    Be authentic: The voice and tone of your bot should match your brand. Users will pick up on inconsistencies (e.g., informal slang, jokes and emojis from a very formal financial services company) and can raise alarm bells. Starbucks’ bot matches their brand and uses beautiful photos of their products to communicate with customers.

Einstein teams across Salesforce are levering these guidelines as they design and develop new features. These are living guidelines, meaning that we are constantly evaluating, adding, and fine-tuning them. We’d love to hear what guidelines or insights your team has developed when developing AI tools/systems!

Thank you Ian Schoen and Raymon Sutedjo-The for all of your feedback!


### youtube_ZtRnZHWXYfs.txt

Del 3 is a massive Leap Forward and in
today's comprehensive tutorial we're
going to cover prompting Del Vision
imagery imagination using gpts Del 3 and
so much more prepare to level up and
let's get right into it to get started
open chat.
open.com Del 3 is powered by GPT 4 so
just make sure you're using the latest
GPT 4 model by selecting it in the top
left corner now you can generate images
right here in the regular Chad GPT
window as Chad GPT can automatically
detect when you're looking to get an
image generated or you can head over to
the explore page and launch the Del GPT
from there there's currently no real
difference between using the Chad GPT
window or the Del GPT in terms of
capability and features the only Quirk
I've noticed between the two options is
that when Chad GPT is being buggy the
Del GPT is not and vice versa gpts were
recently just launched so if you're new
to them and would like a bit more
context feel free to bookmark the GPT
build tutorial I've linked below for
today's dily 3 tutorial you'll need a
chat GPT Plus or Enterprise subscription
to use all these features you can see
what plan you're currently on by heading
over to the my plan section and just in
case you're on a plus plan and can't
access Del in your Chad GPT account head
over to settings and beta beta features
and make sure plugins and Advanced Data
analysis are enabled okay let's start
with D 3's most popular use case image
generation we'll enter a basic prompt
asking it to generate a car driving on
the mountain side and voila it turns our
prompt into two image options we can
further edit this is a decent image but
it could definitely be a bit better as
we'll see in a second but before that
let's click into one of the images then
we'll click into the ey icon next to the
download icon clicking the IE icon
reveals a really cool feature you can
view the actual prompt D 3 used in order
to give you an image it deems
satisfactory so why did it change our
prompt well Del 3 is powered by GPT 4
which is the incredibly powerful large
language model that also Powers the
latest version of chat GPT open a
research showed that using very detailed
prompts gives significant better results
when generating images so every time you
type in a prompt D 3 goes through a
process known as prompt rewriting which
Taps into the incredible natural
language processing ability of GPT 4 to
optimize your prompt so it can deliver
what it deems the most visually desired
results and whenever you download an
image the file name will actually
contain the prompt as well pretty cool
and convenient in case you'd like to
come back in the future and regenerate a
similar image okay now that we know that
Del works better with more detailed and
descriptive prompts let's take our first
prompt and add some out of this world's
detail to it the prompt will ask it to
give us an image that is truly out of
this
world now of course art is very
subjective but honestly I much prefer
our second attempt by a country mile
let's pick the second image as you can
see we're now on an alien planet with
beautiful scenery and breathtaking
Landscapes but interestingly even with a
very detailed initial prompt gp4 still
changed it quite a fair bit to produce
this Interstellar result there are ways
to increase the adherance of the final
prompt to your original prompt either by
saying so in the chat window itself or
by using Advanced options such as gpts
and custom instructions which we'll be
taking a look at later in this tutorial
Del 3 is incredibly powerful and as
we've just seen to really unleash its
potential it's important to always work
on and experiment with your prompts
because even though it tweaks your
prompts in the background by giving d a
really good starting place you'll be
able to make your desired images that
much faster however fear not if you
struggle with generating compelling
prompts Chad GPT is an awesome
brainstorming partner let's say I want
help generating an image for a dessert
because food is life
let's get Chad GPT to help with
prompting so enter I'd like to generate
a photograph of a mouth watering dessert
that looks like was taken by
professional foodie can you create a
series of prompts to help me decide what
the final image should look like Chad
GPT then goes on to give us a series of
really delicious looking prompts as it
says each prompt is designed to capture
a different Essence and style of dessert
photography from classic and elegant to
playful and colorful you can choose the
one that reson Ates most with your
vision for the final image this is
awesome there's no way on Earth I would
have thought of any of these
descriptions by myself let's pick option
two you know what this looks pretty good
but the great thing about di 3 and chat
GPT is that you can always ask it to
generate a different option if you
change your mind as it keeps track of
your entire conversation so let's let it
know that I'd actually prefer to go with
option four okay this looks pretty
strange and quickly looking at the
prompt with you can see how it pretty
much used its own fleshed out
descriptions to generate this
deconstructed cheesecake now Del 3
really excels when you give it
instructions a normal human being would
understand so sometimes it is worth
resisting the temptation to get too
complicated and fancy with your prompts
but congrats at this point you now have
a foundational understanding of AI
Generation image prompting there are
tons more interesting prompting
techniques and I will continue to
introduce new ones as we go go along but
fundamentally being detailed and
descriptive in your prompts should get
you that much closer to the results
you're looking for from the get-go just
remember detailed doesn't mean
complicated now let's take a look at
editing and refining our AI generated
images first let's prompt it to give us
a close-up drip painting of an elderly
woman with a hopeful look in her eye
this is a much shorter prompt than I'd
recommend but for the purpose of time
and this tutorial I'll let D 3 do its
magic behind the scenes and would you
look at that our first roow block as I
mentioned before there are hiccups to be
found darly 3 seems to have pretty
strict copyright God rails which I found
often times geted very wrong so if you
run to this sort of error what can you
do you can simply tweak your prompt and
try again so let's try just that you can
either click the little pencil here and
change your first prompt but for
comparison's sake let's tweak our prompt
and then reprompt it in the message box
down below okay so we changed our prompt
to a close-up of an LLY woman with a
hopeful look in her eye the artwork
should embody the drip paint style let's
see if that gives us a better result and
lo and behold it worked now before we
dig into the final prompt D 3 used to
generate the stunning image you will
notice our short but sweet prompt still
includes several key details you should
aim to have in your image generation
prompts depending on what you're making
these are the subject style composition
and emotion I like the first image
better here so let's go with that and
this is our optimized prompt pretty
incredible stuff now let's edit our
image we'll prompt D to add a faint
image of the Rising Sun to the first
image to further convey the feeling of
Hope and see what we get okay the
floating head with the drip painting is
kind of creepy so let's give her and
neck and
shoulders okay this one is much cooler
and much more compelling now supposing
you feel like you're on the right path
but would like to see different
variations you could simply ask it to
generate new variations based on the
updated prompts so let's ask it to
generate new variations that use a
dramatic monochromatic color scheme you
notice my prompt actually has a typo and
is grammatically incorrect but gp4 is
smart enough to use usually pick up on
what the user truly intends I really
really like the first image let's click
into it and briefly look at what the
final prompt was absolutely
brilliant now as you've seen most times
di is going to give you square images
however you actually do have the option
to set the aspect ratio at any time
supported formats are standard which is
square wide which tends to be 16 by9 and
vertical for mobile formats I do
strongly recommend establishing your
aspect ratio right in your initial
prompt as I've seen that it sometimes
struggles to ideate and properly expand
upon images it has already generated
either way let's give it a try with a
hope portrait and see what happens I'll
ask it to convert the first image into a
wide format and as you can see there is
a pretty big dramatic difference from
the first image in square format and the
second image wide format which is why I
mentioned including your aspect ratio in
your very first prompt before we move on
though let's try copy that exact prompt
in the image we did like and see if that
helps so I'll open my preferred image
click copy then paste it as is then the
aspect ratio should be wide and let's
see what happens this time around okay
still a bit different but you know what
we'll take it but I think in this case
it image number one wins yet again and
for good measure let's quickly see what
happens when we convert the first image
into the vertical
format and boom a mobile friendly image
ready to go now of course if you'd like
more creative freedom you could generate
most of your images in the wide format
export them into a tool such as canva or
photoshop and then edit them down to the
size you most prefer now at this point
in time you may have noticed that I'm
actually in my third window we started
with our Mountain car drive the dessert
photo and our hope photo every time you
prompt a d your chat GPT it
automatically names your chat however in
this case since we started with an error
it then named our chat content policy
not mat so you can simply click the
three dots next to chat name click
rename and we'll call it our hope
portrait now apparently you don't have
to start a new chat for New Image ideas
but I do like clean starts when working
with new contexts images and ideas as
sometimes Chad GPT does hallucinate and
might pick context from the wrong piece
of
conversation okay when open AI CEO
tweeted this image earlier this year
this one detail blew everyone's mind
while at first glance it might seem like
a bit of a clumsy font the fact that
perfectly legible text was generated by
Del was incredible for example the exact
same prompt in di 2 yields absolute
gibberish and this applies to current
versions of other well-known and very
capable tools such as mid journey and
stable diffusion so let's try and
generate our own text in Dar 3 we'll
start with this prompt a billboard that
says closing down sale which is located
in an abandoned city that's now overrun
with
vegetation okay image one seems to have
the correct spelling but looking at
image 2 it has a definite typo so let's
click into it and see what its prompt
was interesting how it added details
such as a post-apocalyptic scene with an
abandoned city overrun by lush green
vegetation pretty cool when it comes to
typos you could try overcome them by
employing our prompt fundamentals which
are to provide a clear and detailed
description that avoids ambiguity
especially when it comes to the desire
placement of the text but remember if
you're going to be generating images
containing text in Del 3 do expect for
it to be an iterative process where you
will have to have a back and forth dally
until you land on the Right image
spellings and placement honestly at
least for now it may be best to just
generate your image without text and dly
and then add it in later using a tool
such as canva or Doby Firefly but let's
try correct our typo we'll let it know
that the second image is a typo in the
word closing and it should only have one
eye and would you look at that these
images look much cooler and they have
the correct spellings a job well done
okay crazy thing is we have just
scratched the surface of Del 3 and
things are about to get a whole lot more
interesting first I'm going to upload
this delicious looking breakfast clearly
someone made this Del 3 tutorial hungry
you can upload images by dragging them
directly into the message box or
clicking the the little attachment icon
and selecting the files from there and
for now let's just hit enter and see
what happens incredibly Del has
perfectly described the image right down
to it being in a skillet with a sunny
side up egg with its yolk still intact
it even notices the bread in the corner
and suggests that it's either Rye or
whole grain bread really impressive so
how did it do all of this well this is
because Chad GPT and so by extension
dally is equipped equipped with what's
known as computer vision or more
popularly now ai Vision in a nutshell
computer vision is a field of AI that
enables computers to derive meaningful
information from digital images videos
and other visual inputs we are literally
living in the future so let's take a
look at three practical use cases of di
3's Vision capabilities we'll start with
image recognition first let's pretend
the image we just uploaded is a picture
I took at a restaurant and I'd like to
know how to make it at home we'll ask
you to suggest the recipe I can make at
home to replicate the dish pictured and
just like that we have an awesome recipe
that seems pretty legit and I for one am
a fan as this recipe doesn't come with a
long backstory on why the author happens
to resonate so much with eggs and for
the cherry on top let's get it to
provide us with the nutritional
information for this creation and just
like that we have our key nutritional
info with this dish coming in at about
600 to 800 calories which does sound
pretty legitimate Del also provides a
disclaimer at the very beginning knowing
that it does require precise
measurements for each ingredient as well
as knowing the specific products used as
for example you could use turkey
sausages instead of pork sausages which
would have a difference in calories okay
if your mind isn't blown yet let's use D
for image analysis as our Second Use
case I'm going to upload one of the most
famous pieces of artwork in the world
van Go's star night and I'm going to ask
D to act as a curator at a world renown
Museum and tell us about the piece side
note adding act as to your prompts is
another great prompting technique to
better guide Del in the direction you'd
like it to go and here we now have a
pretty compelling description of this
painting with Dolly letting us know that
it's renowned for its swirling vibrant
Sky filled with dazzling stars that seem
to pulsate with energy and emotion feel
like I'm at the Museum already the third
fun use case of D's Vision AI is
reimagining images this means creating a
new image based on the properties of an
uploaded image how it works is Del when
analyze your image to generate a text
description for itself which it'll then
use as the basis for reimagination let's
take this Skyline View of Copenhagen as
an example and reimagine it in a very
healthy Universe where everything is
made of vegetables and see what we
get and would you look at that it's
transported our image to a world where
everything is made of vegetables now
clearly this looks nothing like
Copenhagen but it did pick up on the key
features such as roadways waterways and
medium rise buildings and looking at the
prompt it seems each vegetable has been
assigned a very important role such as
trees made from broccoli and cauliflower
now there are both tons more fun and
practi iCal use cases for Del's Vision
capabilities so following this tutorial
be sure to take time to experiment and
when in doubt it's okay to ask Del
itself for guidance as we saw before
just a note before we move on Del 3
currently can't directly manipulate or
edit images so for example you can't add
in a vacation pick and tell it to erase
your X for now at least as they're
constantly adding in new features at
this point you now have a really good
grasp of how to prompt and iterate with
Del to achieve your desired outcome
we're now going to build gpts that
leverage di as gpts are a great way to
supercharge your creative workflow gpts
are custom versions of chat GPT that
combine instructions extra knowledge and
any combination of skills so you can
think of them as highly skilled and
talented helpers for very specific tasks
this may sound like it's getting a bit
complicated but as we're about to see
it's very easy to wrap your head around
gpts and you'll become a d 3 power user
in no time as an example for some people
including myself creating or writing
grade starting prompts can be tedious
especially if you find it hard to always
start with a blank canvas so now we'll
be learning how to build a custom di 3
GPT that can not only help us ideate but
also supercharge our AI image generation
workflow to start head over to the
explore tab then click create a GPT
before we get going switch to the
configure Tab and make sure that D image
generation is selected in the capability
section this ensures our GPT will call
upon D when needed back on the create
tab this is where we're going to design
and modify our custom GPT and I'll take
a moment just to appreciate how
incredible this feature is we're
literally going to be doing some
Advanced coding without even writing a
single line of code something like this
just even months ago would have involved
hacking together dozens of different
tools tools okay in the Builder we're
going to let it know we'd like to make a
creative who helps generate visually
stunning images by asking good questions
that help thish out an idea to provide
the key aspects needed to generate an
image next the gbd Builder wants to know
what name would like to give our gbt I
actually like it suggestion visual Muse
so let's go with that following our name
selection it then generates a logo for
us let's tweak the logo to show how you
can easily make changes in GPT Builder
and as you can see see we then get an
updated logo now I should mention again
all of this is in beta so hiccups and
bugs are to be expected for example here
it's asking me how I feel about the
image but it then seems to have jumped
into the next follow-up question before
I could answer the prior One the good
thing is if you answer both questions at
the same time it will still understand
what you're saying though sometimes
you'll find that it will prompt you one
by one and sometimes it will just happen
to give you two questions so your
mileage may vary so we'll let it know we
like the logo and we like it to start
with a specific question about the user
image
idea now the follow-up question here is
asking us what guard rails we like to
put on our D GP te let's let it know
images should always look like they're
from Another Universe just for
laughs and just like that visual Muse is
good to go before we test it out in the
preview pane let's simplify our convers
ation starters by heading over to the
configure page and let's change the two
opening prompts to Let's brainstorm an
image and the second one to be I need
some inspiration for an image and then
we'll get rid of the last two you can
also click into the instructions box to
view how the GPT Builder translated your
input into instructions it'll follow you
can always add and remove instructions
as you desire right in this window or
through the regular GPT Builder click
clicking into our instructions you'll
notice the last paragraph which it added
itself about maintaining a supportive
tone and encouraging creative
exploration guiding uses towards
envisioning scenes or elements that are
surreal ethereal or distinctly unworldly
that is absolutely incredible as I would
have never imagined an instruction so
detailed let's close out of instructions
by clicking close and now let's test out
our Del GPT we'll go with the first
prompt and get it to help us bring
brainstorm I'll go with an alien planet
now the good thing about gpts is you can
be as detailed as you want or let it do
its thing and see what it comes up with
and then edit from there so for example
I'll let it know that the sky will have
multiple Suns and moons but that it can
then decide on everything
else and then it gives me key details of
the image such as the landscape the sky
the inhabitants and the structures for
consideration and I can tweak the before
getting to generate but these look great
so let's see what the actual image looks
like and here's our final work of art
now this is a pretty basic GPT and it's
meant to show you just how capable yet
easily customizable both Chad GPT and d
3r and best part is if you run out of
ideas building your GPT you could simply
ask it to lend a hand for example let's
ask it how else we could improve our GPT
and we'll do that back on the create
page and as you can see it's trying to
guide the GPT to a place where it can
build upon really useful and refined
details that you can then use to
generate an image that the user will
truly be happy with and when all is said
and done remember to save your GPT and
you'll have the option to save it
privately get a sharable link or make it
public for when the GPT store rolls out
before I hit save you notice that even
though we named our GPT visual Muse that
actually didn't get translated to the
GPT name in the top left corner this
again is 50/50 as the gpts I've made
where the name I've given it in the
Builder is the name that the GPT takes
but if this happens that's okay simply
head to the configure page and then type
in your gpt's name there and now once
your GPT has a name you can then proceed
to save it and now look at our shiny new
visual Muse GPT ready to go your newly
created GPT will either live on the left
bar in the recently used gpts or back on
the explore page under your my GPT
section now instead of building gpts you
alternatively could create custom
instructions by clicking on your
username then custom instructions just
like gpts these allow for the
customization of chat gpts and Di's
responses based on your preferences and
can be modified or removed at any time
the first box is where you give Chad GPD
context about yourself you use case and
preferences for example it can be things
such as where you're based what you do
for work your hobbies and so on the
second box is where you set the tone
response style and length of responses
you prefer for example Some people
prefer long detailed responses while
some would much prefer short and
straight to the point answers if your
use cases for Del and Chad GPT don't
change much you may be okay setting
custom instructions here personally I'd
recommend the use of gpts for the
various tasks you'd like to do this is
because custom instructions said here
apply to all your new conversations
whether they started in the chat GPT
chat or dadly chat whereas a GPT can
have very specific instructions that
apply just to itself okay great job
making this far we covered a lot of
ground and before we look at some of our
key takeaways for Del 3 let's talk about
its limitations so that you can save
time from troubleshooting at the time of
recording prompts can be up to 400 100
characters long which should be long
enough in most situations as yes you
want to be detailed but also not
convoluted next it's worth noting both
Chad GPT and D 3 have lots of guard
rails in place particularly when it
comes to avoiding copyright infringement
this means that there'll be times where
it falsely Flags your prompts as
violating their content or copyright
policies as we saw earlier which then
results in no image being generated best
you can do in those scenarios is to
tweak a prompt and try again again as it
did work for us speaking of copyright
Del won't let you replicate any living
artist's work as it is protected by
copyright law though of course some
people very creative prompts seem to be
able to get around this but it does seem
open AI is increasingly clamping down in
those Generations however anything in
the public domain such as star KN is
fair game also beware of Del's limits as
these are constantly evolving and lastly
when Del emerged into the public sphere
hands were its Kryptonite while they've
come a long way if you do generate
images that feat your fingers be sure to
vet them to make sure they look like
human hand so to wrap things up here are
10 key takeaways for your D 3 journey be
specific and detailed in your prompts
take an iterative approach the first
image generator doesn't have to be
perfect and it's okay to have a back and
forth of di set your desired aspect
ratio in your opening prompt if you'd
like to use normal language instead of
aspect ratios you can simply let Del
know you'd like the image in standard or
Square format for 1X one wide for 16x9
or vertical for mobile format be patient
when generating text or better yet add
it in after with an external tool for
more control leverage D's AI Vision
capabilities for both inspiration and
learning do build gpts that each serve a
specific purpose to save time in the
long run as mentioned previously I'd
pick gpts any day over the custom
instructions feature
keep learning this is still a very
rapidly evolving area with many more
advancements to come and last but not
least have fun we're truly living
through a transformative time in history
thanks for making it through the
tutorial I really hope you found it
valuable and that you gain skills that
you'll be able to use both in your
professional and personal lives if you
have any questions or tips you'd like to
share please feel free to leave them in
the comments down below thanks for
watching and catch you in the next one

### merged_output.txt

### youtube_k4fKBqu-Ris.txt

um secondly as as Merrick suggested um
although the the basis of my of the talk
is Gibson's ecological psychology there
are the phrase ecological psychology is
a source of some confusion because there
are in fact three different
psychologists in the United States
who've used that phrase to describe
their work and those are can be easily U
mixed up you know one of them is Gibson
another is Roger Barker who I will talk
about a little bit although I'm going be
mounting Barker's ideas on a gibsonian
foundation which I I take from some
bararan has been okay with them and then
there's Yuri Bron from Brenner's work
who also describes his work as
ecological psychology and I'm not going
to be talking about that at all so
sometimes that phrase is misleading
because you you need to you read it you
don't know which position we're talking
about Unfortunately they they although
they knew one another they never got
together to straighten out who was going
to use which term um um secondly my my
apologies in advance if I if I
misinterpret any of the views of an
action theorists uh I'm not new to an
action Theory I I mean I've been reading
about it periodically over the years I I
I read the aella uh Thompson and rash
book when it came out but I haven't been
keeping up with it it's only been the
last two weeks that I've sort of done a
crash course so I there may be some
things I say that are incorrect and and
please uh Excuse excuse that
also in that regard one of my major
goals is to make sure that Gibson's
understood properly the ecological
approach is understood properly and
um I I I'm not here to convince you that
this is a a good way to go I just want
you to reject it on the grounds in which
it is offering rather than on some other
grounds which it isn't uh pretending to
offer uh the other difference I think is
that Gibson's I think Gibson's um goals
were more modest than what I gather most
inter in action theorists and Gibson was
primarily trying to develop a theory of
perception not a philosophy of life you
know not an approach to life overall um
he certainly thought that his views
about perception could be the basis for
thinking about other things like other
forms of cognition other than perception
but primarily he's focusing on
perception and principally visual
perception although not
solely um
um let me add I I said put something
phrase something in a particular way a
moment ago and let me go back to that
we're not I'm not going to be drawing a
distinction between perception and
cognition rather perception is a form of
cognition the term cognition just refers
to various ways of coming to know and
perceiving is one of those ways and
there are other ways which don't involve
perceiving although I I like I would
like to think they're built on a
foundation of perceiving
um and and then the other thing which I
I think is really great is that um as I
look over the some of the literature it
that an act of an action Theory um the
overlap between it and ecological Psy
psychology is is great so that means the
differences are small and they're
interesting and and we can really
squabble over them so we don't have to
sort of deal with some of the
fundamental assumptions which I think we
we
share um I guess the way I just want to
start out is something a phrase that's
been used a bit over the last couple of
days um in that there have been some
diagrams where we have the organism and
we're talking about the organism as
having autonomy and then there's this
bigger box around it and the phrase is
often used everything
else okay I'm interested in everything
else and or more specifically the focus
that I want to take is is not beginning
with the
organism okay but rather beginning with
the organism involved environment
relationship which which is a dynamic
relationship um so let me Begin by
giving you an outline of where I'm going
to
go I I tried to find something
appropriate I I gather this is the golf
resort in the early moment of a
construction I'm not quite sure um but
here's roughly the outline and it's it's
going to hop a little bit but you so you
at least you'll know first of all I'm
going to talk about some principles of
ecological
psychology and and I want contrast it to
picture perception not so much because
you I think you subscribe to this but
rather I think there are some issues
about the differences between picture
perception and environmental perception
which get dicey between the two
views uh and then I want to illustrate
some of these points with some research
um and uh of mine on navigation then
I'll move to the concept of affordances
which is of course probably gotten more
attention than outside of ecological
psychology than anything else and uh at
that point I'm going to move into the
the positions that I've developed
somewhat in not independent but as an
extension of the gibsonian so kind of up
to here I'm going to be doing chapter in
verse of ecological psychology which
most folks that I um associate with
would agree but then basically move into
how how I've pushed the field a little
bit and that'll be talking about
cultural
historical processes then then the last
two points is I want to root this
theoretical position in a philosophical
Foundation um this has been a problem um
the the point one of the major goals of
my book was to try to do just that many
people read Gibson and they think well
these are interesting ideas but they
don't fit into anything I've ever seen
before where do they come from so what I
want to do is in a very brief um period
of time try to then embed ecological
psychology into a Phil philosophical
foundation and that will be William
James's radic
purism and then lastly to kind of create
some fodder for discussion I want to say
a few things uh about um inaction and
particularly inactive inactive
approaches to perception and ecological
psychology and how I think they're
different and and that may give us some
things to throw
around okay so let let me start as I
said I want to start with everything
else and so that means I want to start
with the environment so I'm going to
just in sort of follow the way that
Gibson sort of introduces his his last
book what's remarkable about his last
book if if you've not seen it his book
is called the ecological approach to
perception but the first you don't get
to anything about the organism until
you're halfway through the book the
entire first half of the book is about
the environment which is kind of
peculiar most books on perception and
psychology begin you know with the
receptors and perhaps a physical
analysis of
stimulation um and and and but but the
receptors come early the brain comes
early Gibson's going to deal with the
perceiver pretty late um so let's first
talk about the environment um by the way
I noticed just that as your steering
wheels are on the wrong side of the car
for me it turns out your toggle switches
are reversed so I may be going backwards
when I want to go forwards on this so
let's see so what are some of the
principles what are some of the things
we need to know about environments first
environments
surround and are extended that is to say
if we take a if we have an organism an
organism situated in an environment
environment is
extended and and and surrounds the
individual and this is the
case um this is a a ubiquitous property
of
environments uh the second property of
environments is that they are
structured um that is to say that
they're not amorphous there's variation
um we the we can spend a lot of time
talking about these structures certainly
there there are textures there are
objects um there's there's Horizon
there's an intrinsic up and down
um and there's a nesting of properties
such you we have sort of smaller
structures nested within larger
structures and so
on so and again this is true of of any
environment this including the one we're
in
okay
so the person situated in an environment
the environment is extended and it
surrounds the individual the environment
has structure now let's talk about the
organism U oh well I'm I'm jumping ahead
now now this is um Gibson considers
these three three terms kind of critical
to his theory um substances surfaces and
medium okay so first of all in the the
environment consists of matter material
substances
and um and sub and substance has
surfaces and a surface is a boundary
between um an object and a medium in
this case you can see that the surface
um is um adjacent to a water medium um
but also the the a surface of an object
uh can interface with with the air as a
medium and so um in in the case of
vision we have a source of of light
which interacts with surfaces and
critically the light is affected by is
structured by the character of the
surface in terms of its texture in terms
of its color in terms of its orientation
relative to the light so what we're
concerned about here is not so much um
the light from the light source but
rather light that's reflected off of
surfaces
so for for so for example and this this
I apologize this is if I if I was more
skilled at PowerPoint you might be able
to see this a little better but but the
idea is what we're interested in is the
way in which light is reflected off of
surfaces and
fills the local environment with
reflected light the reflected light is
going to be structured with reference to
the surfaces
um um that it reflects from again in
terms of in terms of carrying
information about texture color
orientation shape and so
on um
so oh yeah and we could although the
light is reflected in all directions we
could put a perceiver at any place in
that environment and and in this case
just an eye it's not adequate view of a
perceiver it's only part of a proc
receiver obviously um and then that
perceiver will be in a position to begin
to sample the ambient uh structured
light and um if you have any questions
or clarification I please please raise
them um matters of debate I I'd rather
save Until the End John who saying
things about the environment you God I'm
sorry who's who is saying all these
things about the environment you God me
God yeah I tend not to think about
myself in that way
um
we know a lot we know about the a lot
about light and how light interacts with
surfaces and so if we think about the
environment for the moment independent
of the organism we can begin to describe
how light interacts with the features of
the environment independent of the
organism I mean it's not independent of
the organism I what you're saying as
independent of the organism is a
rarefication of the knowledge that human
scientists consist in particular
what I said
was you you didn't hear what I said then
because I said I said for the moment
we're looking at the environment
independent of the organism we're just
we we're going to talk about an organism
environment system but we're going to
first take the environment as the figure
in the organism as the ground and then
we're going to flip it in just a
minute
um it must be I guess let me just follow
up that point with with something else
What in in in traditional approaches to
to perception again if we're looking at
the the information for perceiving
typically it's described in terms of
physical variables like wavelengths of
light for example or wavelengths
intensity of sound what's going on here
is an attempt to develop a an account of
of the physics of the situation not in
terms of um the sources of energy but
rather how the sources of energy
interact with environmental surfaces so
what's going on is an attempt to develop
something that we could call ecological
physics okay and specifically what I'm
talking about here is something that
we'll call ecological Optics as opposed
to
Optics okay Optics refers to how light
interacts with lenses ecological Optics
refers to how light interacts with
surfaces
um and we can talk about how light inter
with lenses independent of people and
that doesn't mean we have a God's eye
view we're just we're just carving out a
part of the
world okay then turning to the organism
what we know about organisms as you all
well know is that organisms are are
active uh they're
mobile and
um and if we put these two pieces
together if we have environments that
extend and Surround and that are
structured and we have organisms that
are mobile then what they're going to be
able to what they're going to need are
ways of guiding themselves through this
structured
world so perceiving
fundamentally uh is a process that
enables organisms to better move through
the
environment sometimes as is in the case
of the earthworm the the detection is of
a very proximal
environment other times in the case of
um other organisms such as us we're
detecting properties at a at at a
greater distance but the main but the
point is that on the one hand perceiving
operate um operates in the service of
action that is to say we perceive in
order to help us better move around get
resources and so
on it's a it's a functional account of
why perceiving um is
exists and so you can see that um
perceiving is guiding the actions of uh
these two individuals these two children
um being able to see the cliff Edge or
the visual Cliff enables the child to
avoid falling off okay so perceiving has
a very functional role and and notice
that I'm not talking about perceiving an
action necessarily as you'll see as two
different processes but really as a
synergistic processes because in fact we
can reverse that and we can say that not
only does perceiving support action but
action also supports perceiving and why
is that the case because there it's it's
really pretty easy to demonstrate that
if you if you grab an object and don't
move your hand with respect to its
surfaces it's often very hard to to
identify what it is you're holding on to
but if you move your hand relative to
the surfaces it's quite easy to identify
what you're holding on to so action
supports perceiving even as perceiving
uh supports action so here we have a
case of of a physician you know
palpating a patient I mean you you may
notice that your physician doesn't just
kind of place his or her hand on your
skin and leave it there as if they're
healers they're pushing and prodding and
probing what they're trying to do is get
information they're trying to understand
about what what um the what structures
they're they're confronted with with the
patient um and in fact people are very
keen on allowing um having experiences
where actions reveal
structures um now let let me talk a bit
about what action one of the things that
action
um provides for perceiving this is an
experiment um done with with young
infants and uh what what they're shown
is um
an object in different
um in different axes okay and what the
baby baby's in a car seat and and it's
and it's goes travels around this Arc
looking at this object and what it gets
is these various transformations of the
object in this case it's oriented on a
different axis and so on two different
objects and and the question that's uh
of Interest here is you know what um
what is the baby perceiving now this is
a terribly difficult question to ask
obviously because babies don't won't
tell you what they're perceiving the
standard procedure which is not without
some criticism is the habituation
Paradigm which many of you know about um
so if the the basic idea of the
habituation Paradigm is um the babies
will continue to look at something until
they and and then we'll lose interest
then you show them something else if
they if they show no interest in the
second thing the presumption is they see
the second thing as being similar to the
first thing if they suddenly you know if
it gets their attention then Pres
assumably they see it as somehow
different so the question is um do do do
babies perceive these different um
projective uh presentations as being
different projections and this is
important for an action theory in terms
of the action Theory perception or do
they perceive it as an object that's a
single object that's perceived from
different points of view in other words
do they detect um the object um with
regard to uh an invariant structure an
invariant structure is is structure that
is constant across changes of
orientation in this
case
okay so um to perceive an object is to
perceive its invariant structure meaning
that you can recognize it from
any uh
position and now we can sort of include
we can get back into why action plays a
role here because action enables you to
engage the object from different angles
in different ways so that you can
extract the invariant yeah
Sor the
baby
no we're just just getting different
viewpoints we're just getting different
viewpoints right right and which is why
this is actually interesting because
this baby's not had prior exper well
other than being carried around by its
mother perhaps has not had experience uh
has Li had limited experience but it but
by through exposure it can presumably
detect something that's common across
all the all the
um um
viewpoints I'm going on a little sleep
so my words will sometimes elude
me what is the result of the study baby
yeah oh yes yeah and and and yes so the
baby has no if you if you present then
the object from a certain particular
point of view and the baby habituates to
it you change the orientation the baby
still it doesn't dishabituate in other
words it recognizes and as best as we
can tell it recognizes the object
independent of any particular viewing
position in other words what it's done
presumably and I'll try to be clearer
about the notion of invariant as I go is
that it's detected a property that um is
common across varying viewing positions
in other words it doesn't perceive a
projection now an important Point here
which I'll come to in a minute this
suggests that
the notion of and and and of of
perceiving as being based on a retinal
image makes no sense at all because the
retinal image of course are projected uh
projections of an object a
two-dimensional projection and this is
exactly what the baby appears not to be
doing just ask you again for
clarification you said an invariant
property but didn't say what is the
property of property an invariant
property
of it's an invariant property of the
object but to anticipate an earlier the
the next point but um that's available
to a perceiver to a moving
perceiver so I mean the in other words
the invariant isn't just and this will
be important for our differences or
agreements or discussion it's the
invariant isn't just sitting out there
it's something that is revealed through
action but it's revealed but what's
revealed is a what's revealed is a
property of the
object so give me well come I'll come
way back I'll come back to that I
promise but just but it's not like the
baby's not moving the baby's eyes are
moving it's not that there's
no but but but the eyes don't really
change the the visual angle very much
well but it's a little bit like the
detecting
so you you need to get you need to vary
to detect the invariance of the object
you you
vary
sad it isn't the cads that make a
difference because the cads you're not
changing your viewing position when you
have catic movement I'm talking about
literally moving to another viewing
position even even a little and I'll
show you some evidence for that later on
but but again if you have any doubts
about this I this is I'll just I
demonstrate this with my introductory
psychology class I mean you just pick a
friend and find some common objects and
then tell them to close their eyes and
put the object in their hand and and
tell them not to move their hand and ask
them to identify the
object they're going to have a hard time
ask them to move it around and it is
easy what's the difference between those
two cases by moving the object in your
hand what you're doing is you're
detecting invariant properties of the
object through action yeah um I would
say that's very different from baby
because also if you move an object
across somebody else's hand yeah it's
also difficult for the person to
identify where you're moving the baby
around I also want to ask what age yeah
I you know I I my memory's crummy but
we're talking about on the order of
three to four weeks um you're right but
but not completely it turns out that
self-produced action does reveal more
information and I'll show I'll try to
show you why but you don't necessarily
have to have self produced action you
can also have passive movement I would
say in the baby case that's not actually
active perception but it's mul in terms
of
vular visual invariance or something
like vestibular information gives you no
vestibular gives you no information
about that and there's no a there's no
Ence going on because the baby's not
doing anything except engaging in cads
but then I wouldn't say sensory motor
I'm not I'd never use the word sensory
motor again can we put in the discuss
and in fact I'm never going to use the
phrase sensory motor in fact I think the
the notion of sensory is is dead wrong
okay but I'll come back to
that okay so if we now instead conveying
a baby around in an arc we have a person
who can can move around what the person
is is able to do is sort of adopt
different Vantage points in the ambient
optic array and actually create
transformations in the ambient optic
array um and here is um since I don't
have the talents of doing any animation
this is a poor man's animation um whoops
to why is this just going on and on um
sorry this is my left right problem
here
okay so as we move what we're it's
essentially what that moving perceiver
is doing is is is essentially what you
do when you move an object in your hand
but in this case the body is moving in
the world and creating and this is the
this is key transformations in the optic
array which enable invariant to be
separated or detected in the array in
other words it's not that you're
perceiving something that's static you
need to introduce change in order to
reveal what's
Constant transformation like invariants
are revealed through
Transformations they're not and for that
reason invariants are not frozen in time
they're only revealed over time and I
can't emphasize that
enough okay that is to say I so I'll say
it again which that invariants are not
these Frozen Source let's say basis of
information but rather they're only
revealed over time and they're revealed
over time because the perceiver produces
Transformations through movements of the
body which reveal invariance so so um it
so it's it's a fully Dynamic process
although Gibson didn't use that
terminology okay so what have I said so
far quick summary I said that
environments surround and are extended
organisms are mobile and that we
develop sensitivities receptor
sensitivities that guide movement in
some cases only ey spots uh vibration
detectors chemical receptors and so on
but they they develop in in the service
of um of action and reciprocally action
uh facilitates perceiving action reveals
structure and perceiving is the
detection of structure over
time so let me slow down in these last
two points perceiving is the detection
of structure over time and this is going
to be a crucial difference between
sensation and perception because
Sensations as classically defined do not
vary over time they're they're they're
patches of light they're pinpoints of
sound of bits of
sound so they they do not support
perception I'll but I'll come back to
that um the next point which has kind of
been implicit in what I've just said but
I I I want to um emphasize it is and
because I think this is a place when I
read the inaction literature where
Gibson's misunderstood frequently
there's this notion that there seems to
be this expression that information is
is out there in the environment and and
in a sense it is but not completely
because in fact information is revealed
through action information is relational
and I'll show you a couple of examples
of that in other words information is is
generated by perceivers actions in
relation to environmental structures now
notice that's not what that's not an
inaction uh consistent phrase I didn't
say that structure is generated through
action
what I said is structure is
revealed through action okay now and
again I may be misreading the literature
and I'll you have you'll have your
chance to tell me that here's a here's a
basic here's a really clear indication
of this and this is this is the notion
of optical flow or Optic flow when you
move through the environment remember
first of all environments are
structured okay we're not moving through
an an unstructured
void there surfaces as we move through
the environment what's happens is we
generate a flow pattern coming from the
reflection of light off of
surfaces okay and it's a very compelling
flow pattern because you you've all
experienced it if you've been to an IMAX
movie um that or you know or there's all
sorts of illusions of movement where you
feel yourself moving and you're not
really moving it's because Optical the
flow of optical information is
information about self-movement
okay
now um a couple of points to make about
this is one that this clearly points to
the fact that the information is
relational because Optical in the case
of self-generated optical flow as I'm
moving through the world and the world
flows around me it only flows around me
if I'm moving it does optic flow does
not exist if I stop the instant I stop
it goes away so in other words Optical
flow information is relational
information because it only is present
when the perceiver is engaging the
environment okay and you could say well
maybe it's an ephant copy but in fact as
you as you know from the example I
offered you a minute ago you can be
sitting still in a movie theater and
still get compelling feelings of of
movement and in fact it's such a subtle
sort of information that there's this
experiment um wonderful experiment done
by David Lee where he he brings people
into into a room um David leaves at
Edinburgh and um and has them stand on a
balance beam okay I mean it's it's it's
just a a plank that's that's narrower
than their their foot length and um
unbeknownst to them the walls of the
room and walls in the ceiling are
independent of the floor and there and
it's suspended on a crane so what David
and his and his colleagues do is shift
the walls just a little bit one way or
the other almost
imperceptibly and what happens that well
you you kind of imagine it so you're
standing on a balance beam and the walls
just shift just a little bit this
way what do you think
happens person falls forward shift it
the other way the person falls backwards
because optic what he's doing by
Shifting the walls is generating optic
flow and optic flow is information about
self-movement in this case it's he's
producing the change but normally and
again this is the important point we are
producing the information now we're not
producing the information in our
heads we're generating the information
through our interaction with the world
yeah I think probably idea if you
explain your term information because
it's yeah in information um what I mean
by that is is is is a characteristic of
the um
the the let's say the light or the sound
the array of it which specifies some
feature of the
environment okay so in this so in this
case if I'm if I'm looking uh it's I'm
manipulating the object in my hand um
this information is that which is
invariant that the enironment that I
discover as I manipulate the object okay
so in so information specifies
properties of the environment why is
that important well go back to one of my
earliest claims that perceiving is a
function that enables organisms to
engage their environment you want to be
able to perceive the environment that
you're moving around in you want to be
able to perceive resources and Hazards
and so on and so
um what you're doing is detecting um
properties that specify these distal
surfaces and these properties are
I it I I can elaborate on this are
somewhat ambiguous in a stationary
array but they're not in a moving
array not computational information no
no it's got nothing to do with
computation in fact I haven't talked
about anything going on in the head I'm
talking about the organism environment
interaction Ezekiel I totly understand
uh I think the main
point uh you know like the importance of
of moving the the you know the ways of
relating and somehow uh connecting to
this in varing structures but I'm very
confused with the language that you use
sometimes because I mean sometimes you
say that things are revealed through
Transformations as if I am you know the
discoverer or something that is out
there and just now you said that through
that Movement we producing information
and and and and and I know that you know
information in this
relational but the the terminology
sometimes seems to imply that actually
is something that is out there and I am
actually the discoverer of something
that is out there as opposed to
something that is actually produced in
that interaction the these are these are
really hard issues um and and and and
but I what I'm trying I and I want to
come back to talking about independent
the notion of independent versus
relational later but but what I want to
say is that the the information is
revealed in the organ organism
environment interaction but it's but the
information the invariant is is a pro is
a potential property given a moving
perceiver so it in in a sense it we have
to get away from the notion of there's
an environment that's independent of us
you know that is this but we also and
what I worry about is the other move of
of talking about the the environment
that we experience in our heads I think
the danger for the ecological
psychologist is being read as saying
that the information is in the world
indep of the organism that isn't true
but I think the the the the the um the
reciprocal danger of the an action
position is being read that everything's
going on in the head and we need to what
we where we need to converge is a clear
sense of what we mean by relational so
so let's we'll have that
conversation um let me see what comes
next oh yeah so this is just a a since I
don't have a movie this is a give you a
sense of what Optical flow Fields look
like and and and again you you readily
use this information just think about if
you're driving how you maintain a
constant distance between the car in
front of
you you could I suppose do a complex
calculation but all you need to do if if
you want to maintain a constant distance
from from the car in front of you is
just to keep the the size of the object
constant of the object in front of you
it starts to get bigger you're getting
closer it just it gets smaller you're
moving away so you you kind of adjust
your movement in order to to achieve
that that
goal uh again and this gets back to um
ezekiel's point I I want to say that
Optical flow environmental information
is relational it emerges from an
organism environment interaction but but
that needs some clarification I
realize but let me just on that point uh
let me I don't want to I don't want to
be accused of cherry picking but I
looked through the inaction literature a
bit to see where Gibson is referred to
and and this is one point and I think it
points out how Gibson's
misunderstood um although Gibson's not
mentioned in this quotation this this
statement is in the context of talking
about ecological
psychology um and there's there's parts
of this that that I would agree with and
parts of it I don't so for the
inactivist sense I haven't identified
the source and I could if you want but
for the inactivist sense is not an
invariance present in the
environment well from an ecological
point of view I I don't even know what
that
means okay because we're not even
talking about senses we're talking about
invariants that emerge in organism
environment
relationships and um and certainly
they're not
retrieved they're
detected okay it's it's not like the
we're fishing out there in the world but
they emerge from the dynamic
interaction um the second sentence I
agree with except the word dialogue
would have to be fleshed out invariances
are instead the outcome of the dialogue
between the active principles of the
organism in action and the structure of
the environment I'm good with that
although we'd have to make sure we both
agree about what we mean by
dialogue um but then the next sentence
gets us gets us back into some dicey
territory the finding of meaning must be
enacted it is it is always a formative
activity well that's where we might
disagree because I want to say that uh
the finding of the discovery of
structure
um is not about the extraction of
information but but really the discovery
of information it's extraction suggest
that it's out there and we're just sort
of pulling it out by moving around we're
actually creating structure
yeah the word sense the does not mean
sensation what does it
mean
un to doation it has to do with
sense
okay that okay I I accept that if that's
then that's a different intention but
but I think it's but I think well I
would also want to say but we can fight
about this later that the phrase sense
making is is is deeply problematic I
agree with the of what's intended by the
phrase but I think the phrase is deeply
problematic for because the distinction
between sensation and perception is
conflated there and I want to separate
them but that's for a few minutes from
now but thank you if I Mis if I misre
that
um then then I apologize but I but
basically the sentiment of
organisms passively receiving
information is just not an ecological
claim um and I want to say that the
notion of the the phrase the world is
brought forth or the world is enacted I
think is is deeply problematic for
reasons which I'll come to and I'm sure
I'm annoying many of you by saying that
let me try to illustrate a few of these
points with some research because I'm
not a philosopher I'm a psychologist so
I have to have some bonafides as a
someone who does data collection okay so
um what prompted This research uh
essentially is is I I mean I come out of
environmental psychology I'm a very I'm
very dissatisfied environmental
psychologist and um environmental
psychologists have historically said
that people find their way around in the
world because they have these mental
representations often called cognitive
Maps which they use to guide themselves
for a bunch of reasons uh that that
seems to be very wrongheaded
particularly if perception occurs over
time so the question I was interested in
is well clearly people can find their
way from point A to point B is there
information in the path of locomotion
that they utilize in finding their way
um and I just wanted to get a start on
this uh question so let me introduce two
terms first of all and these are from
Gibson um the first term is Vista and
and essentially he defines Vista as you
know that which can be seen from here
other words if from a given observation
Point all that you can
see the second term is
transition and a transition is when you
are essentially moving from one Vista to
another so in the course of moving
through a transition you're leaving one
Vista and and and opening up a new
one and um let me see yeah okay and so
what what I want to say here is that um
the hypothesis is that what's critical
in finding your way is learning a path
in terms of a sequence of
Transitions and again a transition is
the revealing of a new Vista and and and
if you will an
exiting uh of of the prior one um and I
can elaborate on that a little bit but
let me just say that what's important
about a transition is that it's
generated again through
action so if you imagine yourself
walking although the reflection is
making it hard to see if you imagine
yourself walking let's say around this
Bend in the
road you can stop transition information
by just stopping
walking okay in other words it's the
kind of relational information akin to
Optical flow information it's
self-generated but it's generated in
relationship to environmental structures
if you don't have an arrangement of
Vistas or maybe put it simply if you
don't have let's say a surface uding
another
surface and when you move you know more
the surface behind is revealed or
concealed but that's a function of your
movement but this but the occlusion is
there in the world
this Bend in the road is in the road you
okay so the experiment quite simply and
this is busy and maybe impossible to see
um what first of all what you have to do
is is is take this and put it up here
this is a continuous time record I I
should have tried to print it in the
landscape but I'm primitive um and um
and what's happening is the perceiver
there a a videotape of a walk 20-minute
walk through a complex environment was
created um and then participants in a
laboratory were just asked to watch it
and just to press a key on the computer
when they saw something that was um
useful for finding their
way okay so basically the the film is
playing this you can't see is is
time this is the number of responses
okay and
um and
what you can see on first viewing um
It's Kind it's a bit all over the place
there's some responses in in certain
places that that are more like um that
are clustered more than others if if you
can see these brackets is that possible
from the
back yeah sorry about that well this
bracket there's brackets here what those
brackets are are independent judges
identified where the transitions were in
the root okay so what we're trying to do
here is see
where the responses are relative to the
transitions in the route the transitions
are def defined independently of the
receivers by some judges and we're just
asking people to to to press the bar key
uh the space bar now this is on first
viewing but this is the record on second
viewing after they've seen it once and
now they're going through it a second
time and we give them the same
instructions you now press the space bar
at at at points that'll be useful for
wayfinding and what you can see in the
change is first of all the variability
gets greatly reduced but also the
responses with a few
exceptions cluster at the
transitions in other words to to put it
in the language I used a minute ago is
that in in traveling through the
environment they've detected information
which it's useful for them to find their
way and that information happens to be
transitional information which is
self-generated in relationship to the
environment
okay it's relational information that's
critical and so it's analogous to the
notion of an invariant specifying an
object through Movement we detect
relational in moving an object or moving
with respect to an object we detect the
structure of the
object um but the structure is revealed
as we move with regard to it similarly
the structure of a path of locomotion is
the discovered As you move through
it um oops wrong
key it's better to work on your own
computer but so be it okay so my point
here is that critical for finding one's
way are transitions and just as in terms
of a design point of view because
designers are interested in these
questions
not as you know not all transitions are
equally distinctive as
others um I don't know about in your
country but in the US I mean hospitals
are notoriously confusing for finding
your way because every hallway every
turn looks like the last one but but if
you if the transitions are
distinctive okay if the new information
that appears at the turn is is is
distinctive each time then then wayf
finding orientation is is far easier and
this is where this kind of work can can
can um dovetail with uh design
questions
and as my students will tell you I say
everything many many times again this
information transitional information is
generated through action it's not in the
environment per
se but it arises from the environment
through action because of the way that
the surfaces are are are are um
established in the environment
okay so summarizing what I just said um
I guess I don't need to go through all
this I get this is mostly as a point of
um to show a break in the flow now let
me contrast this view of perceiving with
the standard view of perceiving um and
um and the standard view of perceiving
is um that of um
assuming that Vision Works as if we're
perceiving
pictures this
um this notion goes back to the idea
that you're assuming that vision is
based on the projection of an image on
the
retina okay uh it has a very old
pedigree it goes back at least as far as
Kepler who who writes I say there is
Vision when a representation of the
whole hemisphere of the world that is
before the eye and a bit more fixes
itself on essentially the
retina theories in visual perception
continue to claim that Vision begins
with a retinal image even some people in
the ecological Camp will use that phrase
and I really don't like that um and one
of the reasons is because a retinal
image is basically
static and it's flat and the world that
we experience is neither of those
things okay so um let me just continue
um and certainly this view becomes
pretty Central in Western culture
particularly in the development of
representational art uh through people
like um Da Vinci and others quite early
um really brought into um becoming a
major idea with the work of people like
vermier and the development of a Comm
obscura which plays a critical role in
the development of representational
painting okay but the the question is
does this the way Vision Works and
um it it it s it suggests that the first
step in vision is static an image on the
perceiver and that results in a
sensation perception distinction this
first level is essentially sensation
which presumably is impoverished or
limited uh in as I'll show at the end of
my talk noi talks about it as
perspectival views
yeah yeah because well for the simple
reason I mean you're certainly right
that that there's movement on the retina
but notice that if if you if you go back
if you think about just photography I
mean one of the first things you have to
learn if you're a child is not to move
the camera because the image blurs you
take a moment in time and
it's but if yeah but you're right except
that to get a clear image you need a
moment of non-movement your shutter will
take care of that but our let me
continue but our experience is of a
continuous world so how do we explain
that the typical view is that the brain
is sent these static images that then
get
assembled
okay yeah that's actually very strange
because uh in order to sample something
you need to deide a window in which you
say within this period we assume
something sta or something like that
file yeah I I don't dispute that at all
I'm I'm just giving you the standard
line I'm not defending this position no
no no but I I don't think that
anyone
they themselves stud
pictur but what what but if you look at
I'm serious if you look at most most
accounts of visual perception in
Psychology today the the first step is
going to be a momentary slice of
information that's frozen in time a cad
and so if we're picking up these
momentary slices we have to assemble
them to perceive a dynamic
World however if we're not detecting
static slices if we're detecting
information over time continuously we've
created a false problem if you see what
I'm saying and so the the the
traditional approach and and I'm
mentioning this because I I I I think
there's some dangers of this in in
action theory is to create this
distinction between sort of the input
which is somehow limited relative to the
experience and some subsequent action of
the organism which which essentially
produces the full-blown experience you
understand what I'm saying there there's
sort of a first step which is somewhat
impoverished relative to the experience
like seeing an seeing an object from a
certain
perspective and there's the experience
of seeing the object you know in the
round in the
full that distinction is is is
only warranted if in fact this
description of sensation is um is valid
but now I'm trying to show you that from
a cultural historical point of view the
notion of a static image come doesn't
come out of the study of vision it comes
out of the study of representational Art
and was incorporated into
Vision people like I I well come to this
person in a minute oh but let me just
elaborate so typically the stories you
get
in in the um mainstream psychological
theory and this comes out of the major
figure in all this is hel 19th century
theorist helmholdt is that so what
happens in perceiving is that you first
get some partial cues and then they need
to be assembled or integrated helmold
said you make an inference based on
partial cues so the difference between
sensation and perception is that
sensation are these these um somewhat
reduced information um let me
say properties that do not fully account
for the experience of the environment
but only
partially and and then we need to enrich
that elaborate that or another way of
saying that in this this is when I'll
come back to the inaction view of
perception is that
um that perspectival views of objects
need to be converted into experience of
the object by the perceiver and I and
and I and I going to dispute
that but that'll be clear at the very
end um but what this leads to is a
position that none of us in the room
want to be in which is this position
here because if the early stages of in
this case Vision are somewhat
impoverished and the organism has to
therefore assemble these various
impoverished uh pieces of information to
experience the world what you have is
experience separated from the world and
we don't want to be there by the way
this come if you'll notice figure one
two this comes from chapter one of a
book on perception undergraduate
textbook this this is essentially
telling students here's how Vision Works
okay Dart could have written this text
book
right and it's not by the way a quirky
one this is a mainstream I mean it's
it's Goldstein Sensational perception
it's one of the biggest selling
perception books in the United States
which is by the way very interesting
it's called sensation and perception and
in index the word sensation doesn't OCC
once huh interesting interesting but but
and and and that doesn't surprise me but
but the entire account of perception
although he's in in Sub in various
additions he's giving more and more uh
space to ecological Theory but the
entire account of visual perception is
based on the assumption that there's a
difference between sensation and
perception and that sensation is the
first step and what Gibson wants to
argue as as I'll hope to make clear a
little bit is that sensation has nothing
to do with perception because sensation
doesn't carry any
information um and so we get to this
this position which you all probably are
quite familiar with starting with lock
it it's evident the Mind knows things
not immediately but only by the
intervention of ideas or dare I say
sensory motor
coordinations it has of them I was
probably a cheap shot but okay but I
want but I'm trying to set up the
argument for later our knowledge is
therefore real only as so far as there
is a Conformity between our ideas in our
heads and the reality out there we're
creating Two
Worlds and as Fred's been saying for the
last couple
days I gather none of us want to create
two
worlds okay whereas what Gibson writes
and it limits perceiving to the now
Gibson argues that traditional theories
of perception take it for granted that
what we see now present experience is
the sensory basis of our perception of
the environment that's just restating
what I just said traditional theories
assume that what we see now is the
sensory basis of perception but he says
that that the perceptual process does
not begin with this momentary pattern
perceiving begins with the pickup of
invariance over
time perceiving is a process that occurs
over
time um sorry for the monologue but I
but I want to lay these things out in a
minute I'll shift to some other things
which are more my contributions one of
the things that the cognitivists hate
about Gibson although I think this
doesn't bother many of you so much is
they'll say but that that means that
memory doesn't play a role in
perceiving
um but if perceiving occurs over
time memory doesn't necessarily play the
the the standard role that it does in
visual perception he writes the theory
of information pickup does not need
memory it does not have to have as a
basic postulate the effect of past
experience on our present way a present
Way by experience by way of memory it
does however and this relates to skill
needs to need to explain learning that
is the Improvement of practice uh of
perceiving with practice and the
education of of attention the state of a
perceptual system is altered when it is
attuned to information of a certain sort
the system has then become sensitized
differences are noticed that were not
previously noticed features become
distinctive that were formally vague so
you're the judge of list data but with
the the memory how would you explain the
baby experience of the rotation without
some sort of like memory placeholder
that's not a skill that is a placeholder
of there's an object in my present
environment that looks something like
this it's it's it's it's the problem
here is is is the problem of the word
memory because it means different things
if you mean the effects of sort of Prior
exposure cumulatively on the present
sure you can't discount what your
history if you mean that there's this
memory Trace in your head that you
therefore used to enrich the moment the
momentary sensory pattern Gibson's going
to say no and and that latter point is
what the standard CLA the cognitivist
claim of perception is so he's going
he's attacking the cognitivists here the
cognitivist use of memory and theories
of
perception um and so as as I want to say
what's happening and and and Gibson
doesn't develop this too far is is that
in the in the course of an individual's
lifetime there's ongoing
atunement so at any given moment you
bring a history of perceptual
attunements sensitivities if you will um
to the situation and and I think that's
part of what we mean by being skilled
except in that case we're talking more
about perception action
processes all right let me um move ahead
in just a second uh but just to
reinforce something so the received view
the traditional view draws a distinction
between sensation and perception
Sensations are sort of impoverished
input perception is the full awareness
of the environment um perception of the
environment is indirect because you
experience the environment in terms of
um the perception that you've created
rather than the detection of the
properties of the environment
immediately uh and what it leads to is
mediation theories and and enrichment
theories the the debate I want to have
with with some of you maybe later is
whether um noi and oran's theory is a
mediation Theory I'm inclined to think
that it is but I might be
wrong um okay well let's move
on here's Now for Something Completely
Different
sorry if you um if you imagine that
you're an 8-year-old child and out in
the
field what what do you experience
there yeah yeah it's it's I mean I would
assume for many of you it's like I'm I'm
on that tree right away right it's it's
a tree um that affords climbing now why
does it afford climbing let's go back to
the
previous photo what makes it a climbable
tree we can I mean it's not hard to
start enumerating the reasons right the
trunks low to the ground um blah blah
blah blah blah you know we can name it
and so in fact we can talk about trees
as a category of objects but trees
differ in their influences this is not a
climbable tree although I mean you can
climb and I and I certainly have done it
as a kid it's not fun and it tends to be
really
messy
um that is not a particularly climbable
tree for a human
being uh that is it affords climbing to
to some extent that's a good that
affords climbing that
doesn't and in other words what the the
point I'm trying to make here is that we
can distinguish objects that might fall
in the same let's say abstract category
the same concept but we can distinguish
them in terms of their affordance
properties okay so it not only are trees
do do trees afford climbing but you can
name all kinds of things that afford
climbing in a child's
environment right so what is it that
makes something climbable well among
other things it has to be properly
scaled to your body you have to be able
to reach you know the the ledge or the
surface and so on so notice that what
makes it climbable is its relationship
to you
so and let's take the notion of a Sit
surface what affords sitting on is
relative to the perceiver this this is a
wall in in front of the Student Union at
my college which begins you know very
low at one point and keeps getting
higher and higher and higher and I just
had my two friends Phil and Joe you know
kind of occupy two positions on this
wall and you can see although I'm
forcing the point Phil could sit on this
but not comfortably it's readly afford
sitting for for Joe at at this point at
redley if we're sitting for Phil but
it's the same wall in other words given
the different sizes relative to the
perceiver the affordance
changes and this case I'm perfectly
happy to say we're talking about
embodied properties of the environment
we're describing the environment with
respect to the body
okay some data um
hopefully many of you know this work
this is Bill Warren's classic and
classic experiment on
affordances um and the um the results
are very
revealing so what you have here is an
experiment where where people are asked
to judge whether they can step up on a
on a on a step on a riser okay and what
the experiment can do is veryy the Riser
height okay so the the the the the
distance between the two step surfaces
can be very small it can be really big
we've experienced steps that vary in
that way so all the perceivers are asked
to do is just say yes or no the step is
climbable and um he he gets participants
who are short short legs participants
who have long legs ask them to make
these
judgments and this line is the is the
50% it's in other words when when
participants are saying half of the time
that they can climb the step and not
surprisingly the shorter participants
are saying yes 50% of the time at a
lower Riser height than the tall
participants
okay right so what what's really cool is
then instead of let me go back to the
previous slide instead of using the
height of the Riser as our metric let's
use a body scaled measure in this case
Riser height relative to leg
length if you take this the height of
the Riser and divide it into the
person's leg length you get a ratio and
a ratio is this is a ratio of the of the
body environment
relationship if you then convert the
obsa to a pi value that is to say to a
relational value
they
meet and what does that say what it says
is that they are
perceiving relational
information that affords stepping up on
a
Surface okay this this experiment has
been replicated in with a lot of
different kinds of materials since then
this was published in '
87 what what I what I think is important
about this
I think it's a fairly convincing
demonstration as have been the
subsequent experiments that information
is
relational okay that is to say the
perceivers regardless of their height
are perceiving relational information
that affords stepping up
on
um if well hesitate I won't go there
another thing that another experiment
which I find really very interesting
it's it's kind of related to this in
this this is experiment by Len Mark at
Miami University of Ohio and he's having
people judge whether a seat affords
sitting on and it's it's a stool that
can be cranked up and cranked down okay
so you can vary the height of the seat
and you're asking people you know can
you sit on it and here's the 50
basically here's here's the the zero and
it's scaled differently here but it's
it's the perceived vers compared to the
actual height and you can see that um
people are overestimating but not by
very much they're relatively accurate in
judging whether a particular seat height
will afford sitting on the overestimates
are an interesting side issue which we
could come back
to so what these are subsequent trials
and and this is if if a person was
judging the height of the seat um
relative to um their height as being the
same then then then their score would be
zero so this would be an
underestimate this would be an
overestimate so they're slightly
overestimating the height of the seat
that's not the that is that's not the
important point now what he does in this
experiment though is he does the same
thing again but he puts blocks on
people's shoes that elevates their
height by a number of inches and and
what you see not surprisingly is now
they're
underestimating okay but the but the
important point is what
happens what have they learned in this
in this experiment so far have they
learned um sort of the absolute height
of the seat or they learning body scaled
information
so what happens in the rest of the
experiment in this case the individuals
are just standing still looking at the
seat in this case they're allowed to
move and so you can you can see that
generally the pattern of overestimates
still obtains but but but roughly these
are pretty accurate judgments we're
talking about minimal differences I mean
these are
centimeters but what's the most
interesting point of these data is is is
are these guys here the ones wearing
blocks on their shoes and that in fact
as they move they
re-calibrate their
judgments okay so movement enables them
to recalibrate what is what affords
sitting on and what doesn't it's a
dynamic
process
hopefully that's the end of that okay
now let's push this a little further is
aordance
Judgment body scaled everything I've set
up to now suggests the answer is
yes um but a new line of research is is
largely by Dennis profit and his
students um is is pushing the boundaries
a little more let's let's say uh we have
an experiment here uh and we want to
know
does altering body mass by wearing a
backpack affect your perception of
environmental
properties now what does that mean if
you're wearing a backpack what we're
we're thinking is that it changes your
relationship to the environment and if
environments are perceived relationally
you ought to perceive them differently
and so in prophet's experiment he has
people wearing backpacks not necessarily
with babies in them weighted backpacks
and uh and he asked them to judge the
the slope of the hill in one case a 5°
slope in another case a 31° slope these
are the judgments with no backpacks
these are the judgments with backpacks
okay there wasn't they had a a ha haptic
measure it was just sort of using a a
board to kind of tilt to make a judgment
that didn't show the effect but Visual
and veral reports show that if your if
your body masses increased the slope of
the Hill seems um more severe both with
5 and 31° slopes this has been
replicated in lots lots of ways uh
here's one replication where people are
judging distance not slope this is
Judgment of distance um estimated
distance to actual distance without a
backpack and and you you see um a fairly
accurate pattern although again what's
peculiar in this work is you get these
Under and Over estimates which we could
talk about later the most important
point though is the relative differences
you're wearing a heavy backpack your
body masses increased distance seem
farther okay does that mean therefore
you're perceiving the world
subjectively no it means you're
perceiving the world in relationship to
your
body okay does it mean you're perceiving
the world independent of your body you
know as as sometimes gibsonian are
accused of saying of course not this
precisely reinforces the gibsonian point
that you're perceiving the world
relationally so it's Not Mere body
scaling but action
possibilities I want to say that a es if
you'd like a definition that I wrote at
6: a.m. this morning so I might
backtrack a little bit uh affordances
are action possibilities of the
environment taken with respect to an
individual uh Gibson
is emphasizes that they're neither
objective nor
subjective you can say they're both or
we'd rather say they're neither that the
objective subjective dichotomy is really
not helpful at all in psychology and
Fred's been making that point over the
last few days it's it rather than being
objective or subjective it's properties
of an organ envir organism environment
relationship and in doing that what
we're adopting is a psychological level
of analysis when we're doing when we're
adopting a relational view rather than a
physical or a mental and well no I say a
physical analysis when we adopt a
psychological level of analysis um we're
we're talking among other things about
functional properties relative to the
perceiver in this case of
affordances okay uh end of part one but
that was a big that was most of the talk
let let me tell you about the ways in
which I've tried to push these ideas a
little
bit
um and uh and it has to do with the way
in which evolutionary biologists have
been thinking about
adaptation um even though and and here
I'll just make a snide remark even
though evolutionary psychologists
haven't figured this out yet
evolutionary biology talks about
adaptation in a way that psychologists
often don't the standard way of talking
about adaptation comes out of Herbert
Spencer Spencer in the 19th century and
it's the notion that an animal adjusts
to the environment Spencer put it we
adjust the adjustment of inner to
Outer in in the 18 1950s William James
wrote a devastating essay on this trying
to indicate why this is so wrongheaded
um but let me just take a simple
approach to this instead we want to say
that adaptation not only involves
organisms adjusting but also changing
their environment to better fit with it
it involves an organism environment
reciprocity and if you start looking for
evidence of this it's all over the place
there's a great book if you haven't read
it called Niche construction that was
published about 10 years ago which is
all about the ways in which organisms
from
microorganisms to humans alter their
environment to better live in it and
here's just a few
examples
um so um I don't know if beavers are
native to this part of the world but but
this is a beaver dam this is constructed
um as a lodge for for beavers to live
with their families and and raise their
young and so on and it's assembled by
creating um these nests uh spider webs
are another example of Niche
Construction in the case of beaver dams
they might last for several months in
the case of a spider's web it might last
for a matter of
hours um termite
Hills um this one is a particularly
interesting one um and Fred mentioned
leaf cutter ants um what with these
chaps do is not only do they create
these huge underground um spaces to live
in but they also transport leaves in to
create essentially agriculture within
their nest that in other words they
produce their own food
supply now what I'm trying to say then
is that it isn't that the organisms are
merely adjusting to the environment but
we're also changing the environment to
better adjust to it this is this ongoing
cycle of Niche construction and um these
are Bower bird nests these huge nests
and here's the strange creatures you
know building you know changing their
environment to to better support their
activities um in the
woods Niche construction is ubiquitous
it's everywhere it's with all species
and and humans have developed it to a
high art what are we doing when we we're
engaging in its construction we're
creating new
affordances we're creating properties
that support action relative to the
individual and um and a great deal of of
um we could look at a sort of a major
slice of cultural Evolution as Niche
construction we're completely in an
artificial setting right now in some
ways artificial not in the sense that
it's NE it isn't made up of there's
probably some organic fibers here or
something right but it's artificial in
the sense that we've created it in order
to better carry out what we hope to do
in
here um and
so just to make make this part short so
these Niche construction and general so
generally social cultural influences are
collective and cumulative and as is is
well known especially in many European
uh much European thinking that each of
us is then born into an environment that
is already structured by sociocultural
activities in other words so if if these
activities produce affordance create
affordances then we each of us are born
into an environment that's filled with
affordances some of which are wholly
produced by human activ ity so this is
another misunderstanding of affordances
affordances is often thought to be
they're just
natural but that's a red herring the
natural social distinction is is phony
human activity produces affordances it
creates affordances out of natural
materials there is no distinction
between the two in fact what I want to
argue but I won't do it here
um but but hopefully in another future
paper is although we often talk about
social affordances what I want to say is
that affordances by and large for humans
are
social because we make
them we create our environments and
these are not environments in our head
they're real environments that we live
in um virtually every object in this
room is has an affordance property
that's been created to support activity
and as children or if you're new to a
culture you have to engage the
environment in order to somehow discover
those properties Fred do you have a
point okay um and so as I said each of
us is born into an environment that's
filled with affording structures I'm I'm
not talking about meaning here because
that'll just send us down a road but I
happy to do that subsequently um and
these are they're very different kinds
of environments I I sort of use these
pictures to contrast this one with these
two as the very different kinds of
Worlds that children enter into that are
um structured to varying degrees have
different types of affordances um the
environments provide different tools for
children um to engage so here's a young
child manipulating a book even though
the child isn't yet at reading age
presumably so the child is familiar with
a book here's a much discussed
photograph um that you would never see
in most western cultures of a of a
barely walking baby holding a machete um
but in this particular culture that's a
perfectly reasonable thing to do uh and
even we we get rather carried away
sometimes in our environments okay now
now let me take one last step what I've
been doing so
far is I said that what I want to talk
about is everything else namely the
environment okay and that's I've been
trying to fill in the everything else um
with affordances
that
um are present due to Natural
circumstances but also designed and and
and Modified by
humans um but there's
another set of environmental structures
that is greatly neglected and so um and
this is the work of Roger Barker Roger
Barker is a psychologist if you haven't
heard of him you're in good company
because in fact many psychologists
trained today have never heard of him
and yet he's some in the in the 60s who
won like the the highest award that APA
gives okay I mean he in his day he he
was incredibly distinguished and um let
me talk about what what he did what
prompted Barker's work is is a very
interesting experience
um at about midcareer when he was fairly
welln his his all of his prior work had
to been had been developmental uh
studies he he was a postto of LaVine he
co-published with Kurt LaVine and uh and
was a very very well-known developmental
psychologist anyway Barker reports in in
his um in his Memoirs that one day he
was driving riding on a train through
these small towns in in
Illinois and um and he realized that
even though at this moment he probably
knew as much about developmental
psychology as most people and he was he
was up to date with the literature he
had no idea what was going on in any of
these small towns he couldn't predict a
thing about what these kids were doing
he was recognizing in fact that what we
don't know is what happens in everyday
life so he did what biologists have long
done and and he proceeded Jane Goodall
by a good decade and a half um
established a research station in the
small town and began studying
Behavior
okay now um I'll have to make a long
story short but one of the most
interesting things that comes out of
this research and it's not anything he
expected it it really surprised him and
I'll I'll try to tell you why is that he
identified that their higher order and
by that I mean collectively
generated and by that I mean generated
by multiple people structures in the
environment that um create
opportunities uh
for our lives and um so let me get right
to the point and I'm going to be really
brief on this because time is short he
calls these environmental structures
these higher order structures Behavior
settings um I'll offer I'll get to more
precise in just a minute he Behavior
settings are Dynamic relatively stabled
Tim limited ecological
entities um and the easiest way to
explain a behavior setting it's actually
quite easy to explain it you're in one
okay a behavior setting is a pattern of
behavior in this case it's the behavior
of you someone lecturing and others you
know attending the lecture or whatever
supported by the mil he called it the
muu I'm going to say I think affordances
really fits in nicely here the the by
the way the the reference if you don't
know about Barker which I is is at the
bottom of the page here are the
properties of behavior settings they
occur natur as a function of the
collective actions of individuals they
pop into existence games pop into
existence um uh classrooms
meetings parades you can kind of go on
and on and on these are collective
activities um but they're structured
they're composed of D of a dynamic
pattern of individuals and
affordances um they are objective in the
sense that and this is in that this
Behavior setting has a specifiable
geographic location anybody have a GPS
on
them you can specify where this Behavior
setting is
objectively it has a temporal
boundary started at 9:25 ends at I'm
going to shoot for
1120 um if I started before 9:30 that
would have been I would have been
talking I would not have been in a
behavior setting at the time
so there's there's a Collective
Agreement about where Behavior settings
are and when they start and when they
end okay so they're relatively stable
structures but have a particular uh life
there this issue is what I'm currently
doing research on um Behavior the the
settings are discriminable you can you
know when you enter a behavior setting
and you can and and you and you and you
know the meaning of the setting you know
what's going on at the place that's an
empirical claim which I hope to have
some some data for in a few
months um they're quasi stable meaning
that they respond to threats to the
Integrity so let's say let's say instead
of a lecture this is a classroom and you
and you have one sort of disruptive
child who's threatening the Integrity of
the setting yeah what what you say Ellen
says to John John Sit Down You're ruin
you're mess you're interrupting the
class and so that leave that to the
debate after and that sort of returns
the this this helps to restore the
setting integrity and if John still
doesn't respond to Ellen then we just
bodily throw them out the door in other
words it's it's a it's a biological
entity we're talking about that's
Collective that operates to maintain its
own
stability um what's and I what I think
is really cool about Barker is he's
thinking at a level that most
psychologists never get to he's thinking
about extra individual environmental
structures
um they exist of any of any independent
of anyone's experience because if you
step out of the room to go to the
bathroom we don't just all flop as you
know mannequins we're we're going on
without you okay
um and and I can say a lot more about
that what led Barker to this discovery
is really pretty interesting um what he
did in his work is he had um he he he
and his research team followed children
throughout their
day and basically just recorded
everything that they did and this and
the setting that they were
in and what he wanted to know is what
could I use to predict the behavior of
children at any given time the
Assumption there there are a couple
assumptions you could make one
assumption is that if you knew about the
kid's
personality you could predict what
they'd be doing at every any given time
or what bar thought if you knew what the
child just immediately experienced like
a stimulus you might be predict what
might immediately occur none of those
things turn out it turns out that the
best predictor of what a child is doing
in that town at any given time is just
knowing where they
are another a nice way of phrasing it is
that the behavior of different children
in the same
setting had less variability than the
behavior of a single child across
settings I don't know about you but what
I think this is like an incredibly cool
idea that and and if we don't work hard
it's going to be
forgotten nobody because no one's doing
this work
anymore so um I'll push on so another so
Behavior settings um are all over the
environment we enter them we help
constru we help uh generate them they
constrain our Behavior they create
possibilities we move through the
environment by entering and leaving
Behavior settings all the time so
getting back to the everything else what
I'm going to say is that part of what's
the everything else outside of the
organism are affordances and behavior
settings generated relationally okay
they're independent but they're not
independent that's a debatable point
obviously um so I would like to say that
behavior settings and affordances
constitute the ecological resources of a
place from a psychological point of view
it they
essentially create opportunities for
doing things and and we can construct
them like we call you know America
organized this so we can this this
Behavior setting has been constructed
but it's not constructed in our heads
it's constructed in the
world so if if um if you can indulge me
for another just few
minutes
um it's it's not good practice to put
maybe the most abstract part of the talk
toward the very end but um but I I want
to try to give you just a general sense
of what sort of philosophical Foundation
all this rests
on let me say that James's radical
empiricism is not the only influence on
Gibson's work he's influenced by a lot
of other ideas including gal psychology
but it's this thread which which I think
is particularly
important because it gets it it provides
grounds for his account of U
realism
um first of all what about the pedigree
uh William James developed the the
philosophy radical empiricism it's in
the principles of psychology published
in 1890 but it's it's embedded in it if
you don't look for it you won't find it
he starts developing the ideas in the
1890s and and and his in his book um and
radicalism publish is appears in 1912
after his death um one of his students
uh who saw himself as the standard
Bearer for radical empiricism in the
subsequent years was Edwin
Holt and Edwin Holt was Gibson's
graduate Mentor so part of what I do in
the book is kind of establish that
lineage so what I want to say basically
say is that the Rel the kinds of
relational claims that I've been making
all along rest on James Z and IAL
empiricism first of all and and and I am
making this very brief first of all what
does James attacking he he with radical
empiricism he's he's attacking the
entire English psychology derived from
locken Hume and the entire German
Psychology from herbart so far as they
treat ideas as separate subjective
entities in the mind that come and go
other words what James is rejecting is
mentalism both the Bri empiricist
tradition and the Continental
tradition not
surprisingly folks who become deeply
influenced by James's writings or huso
and subsequently haiger and meranti you
know so so that that whole you know
alternative you know you know begins
partly uh and and just partly with James
so there are three uh he he lays out
three principles of of radical
empiricism
um by radic he means that um it must be
an empiricism that admits into its
construction its theoretical
construction um it is it neither admits
into it anything that's not directly
experienced
okay or uh and it doesn't exclude
anything that is directly experienced
and the next point is the the point that
separates him from those two traditions
because and this is the most radical
part of radical imp systm because what
James claims is that what is directly
experienced is not only things or
objects but the relations between
them
okay if if you know a bit about Hume I
mean the problem the whole problem with
induction with Hume is that we we see
these separate entities and then we make
inferences from them based
on contiguity of past experience but the
assumtion is that those relations The
Continuous relations are not perceived
they're inferred that's that's hume's
point and James is saying no they're
perceived they're
inexperienced and this this is just
elaborates that point but parts of
experience hold together from next to
nEXt by relations that are themselves
part of
experience so if you know you might be
familiar with James is writing about the
stream of Consciousness right and he
talks about there's resting places and
transition places is that ringabell
right the transitions are the relations
although he doesn't put it that way in
the principles this that's a diff
this um terminology comes later um the
directly apprehended Universe needs in
short no extraneous trans empirical
connective
support that is to say it doesn't need
sort of mental um
functions to connect the
pieces nor does it need a Godlike Force
to connect the pieces that's really what
he's as a as a footnote that's what he's
worried about his major theoretical
adversary at this time was um idealism
which which isn't really much on the
scene now and that's what he's kind of
worried about here um but he wants to
say it's not that God ties the
connections together but they're there
in the world
Okay so so then what is
experienced James begins with the claim
that we we have to we start with the
supposition that there's only one Primal
stuff or material he's notice he's kind
of not sure about which word he wants to
use here in the world rather than two in
other words that we don't start with
matter and mind what we start with is
experience of which everything else is
composed and we call that pure
experience
it's useful to think about it as as sort
of a mathematical limit okay it's it's
it's um for the time being it is is
unqualified actuality it's what's there
it's it's an it has a certain immediacy
and we act on
it um and and it's and the notion of an
object or a subject is only virtually
present in the now it comes about by
differentiating
the structure of immediate experience
everybody with me so
far okay because I'm I'm going to do one
more thing but but but it's I think it's
critical um this is a passage from James
and I'm going to give it to you in in
pieces okay he says let the reader begin
with a perceptual experience that is to
say now the
presentation in the so-called uh
physical object his actual field of
vision the room he sits in so let's be
begin with the room we sit
in the whole Philosophy from democratus
has been one long Wrangle over the
Paradox that what is evidently one
reality the room we live we are
currently situated in can be talked
about in two different ways it can be
talked about as being out there and in
here
okay that's from from a an a pragmatist
point of view that is just a hopeless
sit situation to be
in so then the question becomes how the
puzzle of how one identical room can be
in two places that is to say in the
outer world and in your mind is at
bottom the puzzle of how one identical
Point can be on two
lines and it can be if it's situated at
their inter at their
intersection
and it if it be that pure experience of
the room this sort of immediacy of our
experience this pre-reflective
experience to use a more
phenomenological phrase uh were a place
of intersection of two processes which
connected it with different groups of
Associates
respectively it be it could be counted
twice over I I I'll try to clarify this
although it REM would remain all the
time a numerical single thing so we're
experiencing something that is the
conjoining of two
histories okay that can be traced back
independently of one another but the
experience but experience itself is at
that um moment of
convergence um the experience is a
member of diverse processes that can be
followed away from it along entirely
different lines one of them is the
reader's personal
biography in other words all the things
in your history that have the use a
gibsonian phrase that have attuned you
to the possibilities of this
setting and the other is the history of
the house in which the room is
apart the very same
that um that is to say immediate
experience is the Terminus at quem of a
lot of previous physical operations like
carpentering P papering Furnishing
warming and so on in other words Niche
construction and
of a of a lot of future ones as a room
the experience has occupied that spot
and that environment for 30 years so in
other words what I think he's offering
us here um is experience as not being
separated in terms of environment and
person although that comes subsequently
on
reflection but rather experience that
immediately points both to the
environment and the person
simultaneously like an
affordance one I think nice development
of this idea and hopefully um Kurt
LaVine is getting rediscovered and it's
well it's it's it's really quite
warranted LaVine wouldn't describe
himself as a jamesian but if you if you
know about LaVine he he conceptualized
behavior and that's the term he used is
as being situated in a psychological
field and so this this is the person
these are the various regions of the
psychological field if he were to go on
he would would talk about the valences
that these might have which might draw
or repel the person to these areas and
so behavior is a function of these
multiple forces he's thinking of and
James was just at the beginning of this
notice the Venus talking about field
Theory not Newtonian
physics okay the gal psychologists were
all colleagues of
Einstein what the reason I introduced
LaVine is because I this diagram which I
I really really like so this is that
area that I just showed you a minute ago
which in which is the person and the
environment you know combined okay but
this is it over time and so at this
let's say at any point along here the
character of the person is a function of
its history just as the character of the
environment is a function of its history
as James said and so experience or in
linian terms the life space is a
convergence of these two histories
Gibson didn't particularly like this
because it was a little too
phenomenological for him but but so
summary comments um I won't get to so
what what do I have what's my
beef with um in action theory of
perception and um let me just return to
this diagram
here um to remind you that the
traditional theory which we're all
trying get away from draws a sensation
perception distinction it tends to put
perception in the interior of the
organism and they tend to be mediational
theories and I feel that and I might be
reading it wrong so correct me but I
feel like Ina the inaction theory
perception comes very close to repeating
these same problems let me let me just
try to show you why um let me just show
a couple passages from from Noah's
book uh can you not read that because of
the
color can you see that
okay well well let me I tried to put the
quotations in one color so you could
separate the quotations from my comments
um this quotation and the one that's on
the next slide go together so let me
think take them both together Noah
writes to
encounter its visual potential and that
and the visual potential of of the
object to be perceived
is to encounter its actual shape in
other words when we encounter the
potential we perceive the actual shape
now where do we get the potential when
you experience an object as cubicle
merely on the basis of its perspectival
aspect you do so because you bring to
bear in this experience your sensory
motor knowledge of the relation between
CH changes in the cubes aspect and
movement hopefully this is familiar if
this is unfamiliar then not being able
to read this would have been impossible
to follow I'm sure to experience the
figure as a cube one the basis of how it
looks is to understand how its look
changes as you move Okay now what's
wrong with
this well first of all I think it starts
to reintroduce sensation and per the
sensation perception distinction and let
me show you how um is this at all
visible back
there okay this is this is the again the
Crux is that P perspectival properties
and a perspect perspectival property is
the object seen from a particular
Vantage
Point are not nearly visible qualities
such as shape and size they are looks of
things their visual appearances to see a
circular plate from an angle for example
is to see something with an elliptical
perspectival
shape and to understand how that
perspectival shape would vary as a
function of one's movements with respect
to the perceived object so in other
words you perceive the perspectival
shape and you also see the virtual shape
of the object because you anticipate you
know what would emerge if you did this
that or the other thing um we can do
this because we understand implicitly
that circularity is given in the way how
things look with respect to shape varies
as a result of movement now there's a
couple of things I think are really
wrong with this and and and um first of
all I think it's really bad
phenomenology
because you don't
see elliptical
shapes you see circular
shapes you don't see perspectival you
know appearances you perceive objects in
the full so what I'm afraid and and and
he probably would disagree with me I'm
sure is what we're doing here is we're
kind of slipping back into a per
sensation perception mode again and if
you do that then the sensory motor
coordination that follows
might lead us back into a mentalism that
we don't want to get back into because
it's all happening as you will off stage
instead of happening in the encounter
between the organism and the
environment I'm nearly
finished
um moreover in the way this has been
phrased the idea of an invariant is
missing that is to say if we don't
detect perspectival shapes what we
detect our invariance through action
literally action not anticipated action
not motor schemas but by Bloody moving
around the world okay and um I mean I
could sort of hammer this home I think
but again my experience of circularity
just as my experience of the variation
in its perspectival
shape we don't perceive perspectival
shape unless we're thinking about
picture perception and picture
perception we have to be very concerned
about perspect shape because we're
dealing with a flat surface um I won't I
won't belabor that point but let me take
one statement that comes from Noah's
book action and perception where he
explicitly talks about Gibson and and I
and I can hope to show why he's
misreading Gibson and and I'm I'm and
I'm a little surprised he does because I
also know that he knows Gibson's work
pretty well so I I don't quite
understand what accounts for this uh
Gibson's view can now be usefully
reformulated in the context of the
inactive approach to perceive structure
uh is to perceive structure in sensory
motor
contingencies that is to say in your
anticipation of what something would
look at look like if you moved in
certain ways to see that something is
flat is precisely to see that it has
giving rise to certain possibilities of
sensory motor contingencies and I would
say well first of all you don't perceive
it as flat and secondly what because
what you do is you detect in the
invariant structure in relationship to
your movements in the world so that
takes experience and puts it back at the
kind of in the relationship between the
organism and the environment and what we
can argue about momentarily is what I
think this account does it's a really
slippery slope that heads you back into
mentalism and I don't think that and I
know that's not where you want to
go so if if gibsonian Theory can offer
you anything it might be able to perhaps
fine-tune uh that and um so this kind of
phrase just to re reiterate the E the
ecological notion of structure is
lost what does structure mean in the
context what does structure and sensory
motor contingencies mean I have no idea
but I can tell you what structure means
in an ecological point of view because
in some cases we can specify it
mathematically like in the case of the
Riser height relative to leg
length I can I can talk about it in a
very concrete
way it sort of leaves open and how the
organism is anchored to the world again
it sort of it hearkens back to how I
started the talk it's like there's the
organism and there's everything else
that's not good enough everything else
isn't good enough you know what is the
everything else um and action without
resistance and this was a topic of two
days ago you know that that that's
provided by the task structure or the
environment has no
structure okay so I will conclude an
over long talk at that
point thank
you

### merged.md

What does it take to be good at design? If you follow the increasingly popularized design thinking model you’ll be led to conclude it takes empathy, imagination, experimentation, curiosity, and resilience. While those are virtuous qualities to possess being good at design is much more simple than that.

Design is an act of creating futures. How can that be simple? The act of designing is not simple. The list of what it takes to be good at it is. You can distill design into exploration, abduction, and constriction. You don’t need empathy unless you are designing for someone other than yourself.

Exploration is what sets you on the path. Good explorers enjoy seeing what can be seen. As much as we work to improve the process and inputs of design the truth is that design, just like everything else, is an act of trial and error. Exploration fuels the trials in spite of the errors. Good design is seeing the possible you need an explorers spirit to do that. From a practical standpoint exploration is generating a whole lot of tries. First idea, best idea is the sign of a poor designer. Fifth idea, pretty good idea is the sign of a good designer.

Abduction is a fancy word for sussing causes from the murk of consequences. Good designers need to keep half a mind on the consequences of their choices. This is the essence of design. Realizing a future is coordinating consequences to produce an outcome. Abduction is saying, ‘I did A and saw C. B causes C.’ Abduction is always a guess. If you can’t discover the cause of a consequence you can’t plan around it. The only way to get better at abduction is exploration.

Constriction is a really poor word but it ended in -ion so I’m going with it. Constriction is setting up the bounds of the space. The world may be your oyster but you can’t design without some manner of limiting criteria. Nature supplies you with one in the more of an aim, objective, goal, purpose, or desired outcome. Being good at design is creating a tighter boundary than a goal. SMART goals may work but aren’t quite the direction to go. Think of constriction less of, ‘I’m hungry and want a hamburger’ and more of ,’I’m hungry and want a buffalo burger on wheat with organic tomatoes, arugula, and dijon mustard.’ The boundaries are more tightly defined so now you can go about creating that burger. The design is in the constriction not the creation. Good designers are specific.

Any discussion about literacy and design can be considered splitting hairs. The beauty of concepts is that they are so fuzzy. Exploration is imagination, experimentation, curiosity, and resilience. Abduction is experimentation. Constriction is a terrible word, shame on me, but the idea of defining a space is central to design. Understand these ideas and you’ll be good at design.

[[_SVA]]
https://community.openai.com/t/building-chatbot-for-client-business-using-gpt-3-5-turbo/281411/2

https://stackoverflow.blog/2023/10/18/retrieval-augmented-generation-keeping-llms-relevant-and-current/

https://thesequence.substack.com/p/guest-post-retrieval-augmented-generation
#ux #ai 

AI is different than traditional computation and demands different considerations.

Well defined problems statement are vital in the world of AI with design. AI might not be the solution for the problem you're trying to solve.

AI brings the most value when you need to give recommendations, anticipate disruptions, and detect liabilities. Here's a Spotify playlist of some hits you'll enjoy. Expect that you're going to have X amount of spike in usage. Here are some mitigation strategies for this spike. AI is good at looking across vast interactions and detect fraud.

Comb through topics: help research, personalization through natural language, collect large amounts of information and parse it at scale.

We need to consider how to keep the human in the loop.

Explainability, drift, and fairness are the three pillars of AI trust.

IBM has 10 insurers and 25 retailers on mainframe. They process 90% of all credit card transactions. IBM's mainframes contain 80% of the world's business data.

AI is probabilistic and traditional computing is deterministic. Deterministic is prescriptive and predictable. If the user does this then this happen. Because the data changes over time the AI's output will change over time.

Affordances & Signifiers are still true to AI design. Making the AI evident in the experience builds trust. 'You're about to interact with an AI. Continue?' Track the decisions AI has made in your software. You might denote that this stock has performed well and the AI making a prediction it will continue to perform well otherwise you customers will lose track of what is true and what is fiction, what is real and what is a guess.

The ideal UX for AI ensures the human has control and maintains the final decision. 'Would you like for our system to purchase the stock for you?'

A good UX for AI includes implicit, explicit, or dual feedback loops.

Can use surveys, comments, as feedback mechanisms to improve. You can track how many back and forths were exchanged before the user got the answer they wanted as a quality metric. Did this answer you question is only half the story, what the experience was like getting to the answer is the other half.

Whenever possible explain how the AI predicted the output/outcome.

Explaining your information sources is critical to build trust with LLM specifically since they are trained on the widest data swath. 'I was able to determine this information from these sources.' Citations, even in the text of something it creating from RAG data like a financial report. Like '(1) hyperlinks to the documents.'

A dev and a data scientist are the core AI team.

Rebecca Hemstad
1:39 PM
'Explainability - the method of explainability will likely depend on the nature of the input. There are fundamentally 5 prompt methods: iterative, summarizing, inferring, transforming, expanding. So @Daniel - it sounds like your example was based on summarizing for that specific issue - yeah - probably source for explainability'

Prompt tuning and fine-tuning are how you keep responses relevant to your customers and keep them speaking in their language.

Jocelyne Light
1:49 PM
'I worked on project with a dev/data scientist where we used AI to pull topics out of 1500+ podcast episodes.'

AI still needs the instruction and quality controls to corale its output.
Because so much thinking is about problem solving we believe that more information will reveal the cause and allow us to remove it thereby solving the problem. We’re operating in a deductive manner smattered with induction. We play at Sherlock Holmes thinking ‘if only I knew more, then the solution would be revealed.’ Information is good for mapping context but does little to help you move forward. After all, you can’t know about the future until it happens. Hunting for more information is tactic of fear and avoidance. Creating information through action is the virtuous cycle we all need to set ourselves upon.

[[_SVA]]
That's what Hollywood is wanting. Play a movie for KREA, maybe make the movie a public movie, record the capture, is that illegal?
Find a public script or public shot list to a movie and feed that into a GPT to make a movie.
Find an ancient script and tell GPT to turn it into a script and shot list/screen breakdown for a movie.
https://www.techsmith.com/blog/shot-list/
 Breakdown
  Who, Characters
   Where, Environment
   Colors
   Sounds
   Style
   Lighting
   Dress
   Doing
   Audience vantage
   Scene Composition, Aspect Ratio
Create a shot list from the script above with the columns "scene number, shot number, description, design notes, cinematographer notes". #prompts
https://chatgptaihub.com/chatgpt-prompts-for-filmmakers/#3-storyboarding #prompts
Feed those shot lists into SD, use DP and DC as prompts. Use these images to train a model for interpreting.
Combine those shots with eleven Labs to give you a cinematic. You can sell a cinematic to a movie producer. They're going to take it and run it through their buddies to get whatever works for them. Fine. You've sold the idea. Let 'em run with it.
Even better, the camera to image. Pipe a camera feed in and get animated results.
Maybe you can find public shots or templates. That it can watch. Public stock footage? Stock footage?
Make a Hard Boiled detective movie!
Make a 90-minute movie in less than 90 minutes. Is it possible?
I used AI to turn my interpretation of your post into a movie response. #money
AI made a video based off its reaction to your post. Learn how to do this.
Using information that is open to the public. Most of it for a data and not a monetary exchange.

Turn the Mission comics report into a captivating 1-2 minute video #money

Cost
 - 11/mo elevenLabs - voicing

Footage
 - https://www.gettyimages.com/creative-video
 - https://www.gettyimages.com/editorial-video


#ux 

https://adplist.carrd.co/

88 years old

Why aren't people solving the problem?

Design understands people and the artificial things which we call technology. Design needs to lead the way because it is the ultimate. Designers don't want to leave their skills to understand politics, economics, and that's why they aren't CEOs.

Design is not art and art is not design. Design is sussing out the underlying issues to important problems and pointing the effort towards people.

HCD is wrong. 4 principles. HCD doesn't cover that physical devices destroy the environment through mining and manufacturing of tech. Burning piles of junk in India poisoning the air because of what we design.

We focus too much on craft which comes from art. Brilliant teachings in Singapore. Liberal studies in your design curriculum.

The biggest picture is humanity and all the ecological resources that support humanity. Design can help facilitate solutions from the people who live with the problems. [[Co-creation is anti-colonial.]]

The neural network architecture hasn't changed much since the 70s. There's been no theoretical breakthrough for today's AI only an increase in computing power and capacity. Instead of 3 neural layers there are 100s. Look into Jeff Hinton.

Complexity is in the world. Simplicity is in the head. Adding more buttons might introduce simplicity. Think about bartending interfaces where there are so many categories so everything can be a button or so away.

Mis en pla - everything in its place. Everything was wear it needed to be is what enabled the bus driver to learn this complicated system.

Apple fell in love with aesthetic at the cost of usability. Hired a great industrial designer who wanted it to look simple. Remove the buttons, remove the labels, remove the bevel.

The hard part about of design is making it simple when something goes wrong.

The way you work in industry is very different than the way you work in academia. Going back and forth between industry and academia to understand the principles but driven by industrial desires.

Novelists understand people because they have to to hold interest across time and page count. There's nothing in STEM about people. Bring the humanities into STEM. In the physical sciences if you can't measure it, Lord Kelvin, you can't measure that in the social sciences.

Designers are doers not just thinkers. We have to understand something about everything. Don Norman has never found an instance where a designer could not help.

Good designers always ask, 'is this the right problem?' - a handbook for design

My device would work better if people used them correctly. - If you find yourself saying this, you need a designer.

Don Norman designs designers. Design itself is not where we're getting the answers. What matters is what people do with what you design.

UN has list of 17 sustainable development goals. Pick one of the first 16 goals and design for it.
bool is good for spike traps
int is good for points in a play session
string is good for character names

#unity #programming 
#ux #ai
This means that each variable needs to have its own data type associated with it when it is declared.

#programming 
[[Build a circle of mentors with six people.]] Co-pilots are your long-haul, ride or die, people who expect to be in the suck with you when it happens. Co-pilots are also equals. Co is not a derogatory association. Co means I choose this not I am bound to you.
#ux #ai
#ux #ai 


No two threads can access the same resource. Threads must line up and cannot go until the current thread is finished.

https://medium.com/@magnusram/java-multithreading-what-is-a-blocking-operation-187a7304ccd1#:~:text=When%20we%20say%20that%20a,or%20queue%20is%20not%20empty.

In java, read() method blocks until some input is available for reading.

1) **InputStream.read()** which blocks until input data is available, an exception is thrown or end of Stream is detected.

2) **ServerSocket.accept()** which listens for incoming socket connection in Java and blocks until a connection is made.

3) **InvokeAndWait()** wait until code is executed from [Event Dispatcher thread](http://javarevisited.blogspot.com/2011/09/swing-interview-questions-answers-in.html).

  
  
Read more: [https://javarevisited.blogspot.com/2012/02/what-is-blocking-methods-in-java-and.html#ixzz89GNFl44T](https://javarevisited.blogspot.com/2012/02/what-is-blocking-methods-in-java-and.html#ixzz89GNFl44T)

#code 
When it comes to a successful design there’s only one measure that matters. Do the people you designed for see the value you intended in your design?

It might be useful to understand causation, correlation, leverage, entitlement, or any of the other sophisticated measurement concepts to find out if that statement is true. Like much else in this life I think there’s a simpler way. It’s a much less mathematical way. It’s a much more human way. If you want to know how successful your design is just look at who uses it and how they use it.

[[_SVA]]
Virtual 90min $495 once a week, Monday @ 4
B2B Sales, SPIN selling, analyze an MSA, save time, make more and make more money

Aggregated video content in https://aionlineclassroom.com/

6k videos, CustomGPT trained on all the videos, chatBot recommends video context based on your query

Used Pinterest API to pull out AI infographics and posters. Took about a month to build overall.

It's not about trusting the content, it's about trusting the curator.

Twitter API is 42k/mo at full bore.
Now that you can have anything you have to be good at recognizing what you want. The skill shifts from pure creation from nothing and the act of molding, curating, and edit what you're given into what you want. This skill is based on vision so the people with taste and discernment will be the more successful one. 
It is genuinely rare to find someone that can be considered good at dealing with disagreement. For reasons beyond my comprehension the fight or flight response is triggered by a disagreement. I think that a lot of energy is required to remake thoughts. The brain is inherently lazy. The brain protects the energy resource it has by triggering emotions of combat or retreat. Thoughts are not a physical threat but we feel them as such.

Dealing with disagreement is the act of making space inside your mind for a conflicting perspective. Dealing with disagreement is not the same as arguing well. Shouting matches are not dealing with disagreement. Dealing with disagreement is not the same as someone who doesn’t back down from conflict. Bullies don’t deal with disagreement. Dealing with disagreement is not the same as debate though the decorum may look similar. Debate is an academic practice for intellectuals. Disagreement happens between all people and rarely carries a formal structure.

Making space inside your mind is surprisingly easy. We do it all the time when we like someone we meet. We make concession for our friends at an alarming rate. There is a danger here, friend or enemy are not useful constructs when dealing with disagreement. You won’t be successful trying to see someone with whom you disagree as a friend if they weren’t a friend before you disagreed. You cultivate your better nature before your interactions not during them. Abandon the whole friend/enemy dichotomy and stick with person. Don’t assign a value. A blank slate is a perfectly acceptable starting point.

From this blank slate agree to adopt a posture of exploration and compassion. Persuasion is not the goal. Understanding is. When it arises, channel your rage into bridging the gap instead of reinforcing your side or assaulting theirs. Disagreement is a powerful chance to establish shared purposes and values. Deal with it well and we all benefit.

[[_SVA]]
#ux #ai 


You spew truth at me with the vitriol of a raving dog and say you care about me. You hate behind the safety of your truth. ‘Truth has no sides’, you say. ‘It is truth therefore it is always the right side.’ Your arrogance betrays you, you small-minded infant. Truth has infinite sides. There may only be one truth but it is not for us to grasp. You misunderstand facts for truths. You cry, ‘objective truth!’ As if facts dictate reality. In the equation of existence reality produces facts. Perspective is what you strive for but you hate instead. You refuse to see from my perspective the things which I hold to be self-evident, the truths of my world, the facts of my reality. You want to care, you want to love, you want to foster a better society? If you did you wouldn’t think your truth matters more than mine.

[[_SVA]]
If you need to design a system, map a system, understand a system, create a system, overturn a system, basically do anything but ignore a system here are the conversational prompts to get you the information you need. 

What are the tasks for our audience? What’s the core, repeatable behavior our audience is looking to engage in? What is the change our audience seeks? What outcome is our audience expecting? What do they want accomplished? What are the variables involved in making that happen? How do the variables interact? What outcomes do they produce? What’s their environment like? What contexts do the variables create? How do the variables change? What flows between them? What value does the system create, reinforce, neglect, remove? Where are the beneficial redundancies? Where are the beneficial synergies? Where are leverage points? Who is involved in organizing, maintaining, and controlling this system? What does their communication flow look like? Who can kill a deal? Who do we need for implementation, release, funding? Where are the landmines to changing the system? Short, mid, and long-term? Do we have a complete list of who we’re doing this for and the changes we’re going to make? Have we listed the benefits our changes will bring about? Is everyone on board? Do we need to convince anyone else? How will we run this? Are we agile? What’s our process? What are the odds of success? The odds of failure?

[[_SVA]]
#ux #ai 

Research input must be continual and collected data must be refreshed from time to time.
Sensation is raw input and perception is neural interpretation. Our perceptions sometimes fool us.

#IxD 
#ux #ai 

https://www.youtube.com/watch?v=5HgkawZdihU

Help. I need some info. Help. Not just any info.

When you go to do a thing you'll go to AI like the way when you go to the internet you go to a browser. [[The processing of converting applications into interfaces is the domain of UX.]]

ChatGPT EXPLODED because we simplified the interface to a text prompt. More simplified the interaction with AI at large. You no longer need to build the AI to work with the AI.

Removes the fear of approaching certain tasks, namely a person without art skills making beautiful images. You can use ChatGPT to help you make better prompts for ChatGPT.

Cellphones. Text is primary means of communication for inter-office comms. AI at its core is texting to an intelligent computer.

No patent generated by AI will be accepted by the copyright office. Stop calling things that aren't AI, AI. We don't need AI in our toasters.

Logistic regression, logic trees are some terms to talk about.

Fraud detection, response analysis, and email open rate are good return for your investment.

Brainstorming tool not final
Don't ban it
Researching interest and need

In making decisions under conditions of uncertainty consequences must dominate the probabilities. 

In all instances where there are more unknown variables than know variables your design must be driven by the probable consequences of your decisions. If you can't trace your design forward through time then stop until you can. 

A few tactics that can help you improve your clairvoyance.
 - Ask everyone for advice on how to improve your design based on the defined goals and constraints
 - Find an entity that is analogous to your situation and trace it's path through history. Learn the successes and failures from similar efforts by others.
 - Construct or purchase a predictive model. Take advantage of math's concreteness by plugging your data into established formulae. Judge the results.
 - Consult a psychic. It may and or may not provide insight. Consider this an extension of the first point about asking everyone for advice.

[[_SVA]]
John Maeda shows us how UX has shifted because the prototyping is not UX related. What is being prototyped are models, not experiences. Can we do this is the first answer we need becuase we figure out the experience of it. The people working on models are metaphorically equivalent to engine builders. What's the UX of an engine? What's the UX of a model?
Make me a website for this product
Make me a survey to assess the value and desirability of this product
search the web and give me keywords for top search results
create an image for my youtube's thumbnail showcasing these trends
Give me a list of the most common UX tasks
 - search IxDF/ Coursera/ Reddit/ etc
 - describe what you do on a daily basis
Act like Daniel Kahneman and give me an analysis(?)
Give me a base rate for {x}
Create a designer GPT for ToLoPoSoGo, TEC, Design Thinking
Distilling a decade of experience into the design essentials
Beyond technique: People skills for succeeding as a UX designer
CustomGPT sentiment analysis as a lead generation tool, if the sentiment is correct then drive them to book a call
[[Build a circle of mentors with six people.]] You study compass holders. You're looking for successful behaviors in relevant situations to emulate. Compass holders are beacons that call you forward.
Complicated data reaching out to the internet for the complicated things. Maybe you want a fine-tuned Llama.

https://www.linkedin.com/in/bradley-surkamer-13973774/
https://www.linkedin.com/in/kevinferguson1/
https://www.linkedin.com/in/chernst/
https://www.linkedin.com/in/aafricawala/

7B data points being multiplied over and over and over again. 7B takes 7x4 GB memory. 70x4 is 280GB memory.

Mixture of Experts (MoE) use a lot of memory too, mixtral 7bx8 use 40GB of RAM in my laptop even when it is 7b, but it runs faster even on cpu

Pick an expert part is mixture of experts methodology. One big model delegating to smaller models.

24GB for NVidia, H100 is 10+k
RTX4090 only has 30GB of memory.
Mac can run bigger models because of unified memory.

Ollama and Ollama webUI. Ollama is just the storage. You still need a RAG implementation. NVidia has Chat w/RTX. AnythingLLM point to Ollama for RAG.

You'll need to train a model or wrap it with guardrails if you want the model the behavior differently than it currently does. Like don't talk politics or religion.


It has been known since the advent of weaponized aircrafts that during warfare the side which controls the skies has the advantage. It has also been known for a while that the first predators of humankind were large birds of prey. If you get a chill whenever a shadow passes overhead then you can thank your evolved neurology. The high ground as the upper hand is common knowledge. 

Given the extreme susceptibility to harm humans have from anything coming from above you’d think we’d be more concerned with looking up. Instead, being the eyeballs in the front of the head creatures we are, we are focused the most on what is in front of us. It makes sense, you can’t look in all directions at once.

Looking up is a competitive advantage. Up is a dimension few people consider yet it contains the potential for impact greater than any other dimension. It might not make sense in the world of metaphor and analogy to look up but in the world of physics it does. What you pay attention to alters how you navigate life. Pay attention to what others won’t and you see things others can’t.

Point of fact. If you ever want to win a game of hide and seek, find a spot that is up.

[[_SVA]]
Roboflow, tools for computer vision developers
Roboflow has stuff for plant health
Can help you learn how to train models without learning code
Good for students
roboflow.com/opencv
Transformer based architecture has proved beneficial across task types.
CLIP + VQGAN architecture predates Stable Diffusion and most other diffusion models.
Focus on data that is out of distribution.
Vision inputs have traditionally been camera based but in occluded environments like fog these cameras are insufficient. Shift to incorporating thermal cameras, polarized cameras, event(?) cameras, and depth inputs.
  
Splats use historical inputs and fill in the blanks with generative AI.
Regulations to force forgetting, maybe after 3 years of storage. Search was limited by regulations to avoid forever memory.
Splat results are compressed into a neural network.
If I get this level of quality then do this.
Execution engine to check quality steps and write to production systems.
How do I know which generation is best for my context, then you have this validation engine.
We may be moving too fast and will have a lot of false starts in 2024 especially as it relates to interacting with the physical world.
$200 subscription in Tesla per month for 8 hours of full-cell driving.
[[Artistic control is still missing from generative visual AI for it to usurp traditional methods.]]
[[Cost of hosting Llama is not less than ChatGPT.]]
Meta might be open sourcing their tech to prevent vendor lock for people using OpenAI. Meta could change to closed-sourcing on a dime, which would monetarily bone everyone using their tech.
EU AI Act Cheat sheet by Oliver Patel
Regulate the use, not the tech. Regulate the outcomes not the process.
#ux #ai 


What benefit can we draw from adopting a stereotype? Stereotypes are expectations. The stereotype is a shared understanding. When you know the stereotype you fall under then you gain the advantage. You immediately understand the shared expectations. You know the stereotype. You know the rules. You can see yourself through a communal lens.

Of course stereotypes have a negative value. They lend to false and often threatening assumptions and you are assigned a stereotype. These rules are forced upon you. These expectations indeterminate of your being.

Consider instead adopting a stereotype. Pick your favorite one. One that gives you the most of what you currently feel you lack. You can pick one that gives you less of what you’re gaining if what you’re gaining isn’t what you wanted. You’re adopting a role. Playing a part. I suppose this thinking can lead to mocking if you adopt a stereotype as a form of denigration.

What can you gain from playing into expectations that force people to see you in a different stereotype? Choose the stereotype you want to be known as and act accordingly.

[[_SVA]]
Working agreement
 - what do you want approval over?
 - Feedback, how to give, get, and when
 - How do you want your project to go?
 - Non-negotiables?
	 - absence forfeits your rights
	 - no work-for-hire, license or buy-out
payment for Sprints, 50% to start
35% after first review, 15% to close


Start with project goals and success measures
Require content in advance.
Set and remind deadlines
Make consequences matter
 - what happens when deadlines aren't met
	 - if you miss deadline we get to make the decision
	 - if you miss the deadline we cancel the project
Backup the project

Written approval
Don't revisit approved work
Send invoices at best moments
Keep track of revisions on closed work as future work
Two revisions tends to be the sweet spot

Begin on the designated start date not before, includes communication
5% increase in time and cost to cover surprises - contingency fee

Call out favors
Creating tension requires you to see the other person as stuck in a state which is not beneficial, does not generate value, maybe generates negative value, and could be harmful. This person is blind to what you have to bring. What you have to bring removes them from the non-beneficial state into the utopia you provide. If only they would move. Tension is the force to get them to move. You genuinely want these people to experience the better you are providing. You need to make them tense enough that they seek resolution in what you're offering. Hacking this for a quick dollar corrodes your integrity and makes it harder to succeed multiple times. Bring your generosity to your people and show them a reason to be uncomfortable with their current state.
#ux #ai 

From that online Meetup.

Do not try to replace your user
- the operator needs to know what the AI is doing
- being held accountable for the results of AI
Understand the problem, clarify the scenario
- we help you with capacity planning, issues with queries
Do not forget a feedback loop
- model may drift
AI is all about context
- How do you know the user needs?
- [[Do not have the AI guess what the user already knows.]]
UX for AI is not well defined
- reverse engineering problem with AI code, why did the AI write the code the way it did?
- what makes this code good code for my situation and task?
- [[AI "here's what I'm going to do, are you good with this?"]]
Start small
- before adding your AI feature, build your data foundation
[[Don't build a single model to solve them all, have multiple AIs.]]
In the beginning there is joy, elation, surprise. Then routine sets in. Habits form. Dull and drab become the colors we use to paint the world around us. Discontent overtakes joy. Grey. Everything is grey.

Get weird with it. Too often we wait for new to happen to us. What if we create it instead? Maybe not new to everyone but new to us. You have permission. Go!

[[_SVA]]
Here are a few questions to help you make better decisions.
 - Have I done this before? If so, what has changed since last time? How likely are those changes to affect the outcome?
 - Who has done something similar? How likely is it my results will mirror theirs?
 - Given everything I know I don’t know and everything I don’t know I don’t know, how afraid am I that I am wrong?
 - What can I do to prove myself incompetent to make this decision?

Decisions are about balancing need, risk, and benefit in an uncertain environment. Improving decisions means improving the accuracy of your prediction model. The more you can uncover the factors at play and decrease the likelihood of them changing the more likely your predictions will be accurate.

[[_SVA]]
There's a general hierarchy to design and it goes; make it work then make it look good. Or, in design vernacular, make it useful and usable before you make it beautiful. This is a fair stance to take. It is sensible and logical. Nobody wants a beautiful brick when they ask for a tea kettle.

This stance does not acknowledge that when your audience experiences your design they experience it from the outside in. They see beauty and form first. Those imply use. Aesthetics signal affordances. This is a basic postulate of perception. Considering this it is wise to stop positioning aesthetics as the undeserving bastard child of your product conception. Aesthetics is not a second-class citizen. Aesthetics is the ambassador to your product experience.

If adding functionality disrupts the overall design aesthetic you're compromising your user's experience so stop it.
#ux #ai 


The endpoints are always more clearly defined than the space between. One point is here and now, the other is there and then. You’ll know the endpoints because it’s how you operate. You imagine a change and seek to make that change happen. You’re rarely unclear on the change and rarely clear how to get there. This is by design. If the pathways were known it would limit the endpoints. You would only be able to do what you already knew how to do. You could only go places you’d already been.

You’re not like that.

You have dreams and desires, aspirations and future expectations. You define the destination then set about the difficult task of getting there.

The space between is where you show what makes you you.

Get comfortable in the in-between. It’s where all the good stuff is.

[[_SVA]]
[[Build a circle of mentors with six people.]] Connectors are the people you see who like to introduce people they know to other people they know. Connectors get a thrill out of finding commonalities and then bringing those in common together. They generally have a wide social network though it's not a requirement. The best way to meet them is to show up where you think they'll be and show up with something in common.
https://www.youtube.com/watch?v=PaCmpygFfXo

Links: - makemore on github: [https://github.com/karpathy/makemore](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbFh5QWN1dExpWWpQcWVqaURYZjNwdHpuREQ1UXxBQ3Jtc0tsSUk5QXZSVWZSSGcyYkxZUmszXzlqdlY2MWI1X1hHYUpObjlBYnpVVVM2cEdSUXdDS0xjbnpqeUdqQkU0dEE5eEhURW9EMmVzekNlTV9wblpmT2dnWkc3Q2xobHdRWVN5NHAyZHpmMjBzMTZqRkxHNA&q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fmakemore&v=PaCmpygFfXo) - jupyter notebook I built in this video: [https://github.com/karpathy/nn-zero-t...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbmVKODI0R0RqOXA1Uy10dDJ3OWUzRjZMbXZVZ3xBQ3Jtc0tsWlNkbDJkLXY3M1Q1NzBJRmJrR1BJemZqZG1HRFFZVHdoNEtwdk1NNHBDOUpWUFJCSlg3dVNUQXJQOHVPaTYwei1xZjk4RXA3cGstSFFGWGZVUzdINnlhUGliUVI3b3F3cXVfZmc1bGtrclF0M2JoRQ&q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fnn-zero-to-hero%2Fblob%2Fmaster%2Flectures%2Fmakemore%2Fmakemore_part1_bigrams.ipynb&v=PaCmpygFfXo) - my website: [https://karpathy.ai](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbHZ4QmlUUHJBMFA1Y0REU0wyQ044emtiV3JrUXxBQ3Jtc0trZmtaeUVYOWlaaUVNclNfQ0UxdWN3X0xfU2otSUJhdWxMQ095bFhudFZjRkNYV3FxaHVaY3BndWdEdHVYX1dkaHRfdE9QdWNiWkJzU01vSFJjMkxta1VXbHZaMU91cnhnSzdmeVJhcm9kOVNucDNxcw&q=https%3A%2F%2Fkarpathy.ai%2F&v=PaCmpygFfXo) - my twitter:   [![](https://www.gstatic.com/youtube/img/watch/social_media/twitter_1x_v2.png) / karpathy](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbkQwWDlPd0lwMldOV0pfeFFHWUF0dllCQkE4d3xBQ3Jtc0trY2R1bl9faHVSMWMxR0JQX3Q1VDVuVXo2ZDFfU3dMakpxQ0JCWllqOFJnaVZ2ejNPZjFqUHFyUTR6UzZPcTBDNVFNTEp2TDZyT3ZObjdmc3BuSS1pckNFLVJDaXNHc0VSYTU0Z2pKb0JCajAzS3kzcw&q=https%3A%2F%2Ftwitter.com%2Fkarpathy&v=PaCmpygFfXo)   - (new) Neural Networks: Zero to Hero series Discord channel:   [![](https://www.gstatic.com/youtube/img/watch/social_media/discord_1x.png) / discord](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqblZOV241ZWtySE96VDBoSU5mMmZOTGYyUVlUd3xBQ3Jtc0tsR1BNVWowVDJOd0RYZksxQlBoZ3lTa3FkWGpYRk84YjBnVi1kck1uTlFkYjNkRWdJUVQzcmY4ZXZRNVJKa2ZvMTMxNzdYZ3ZoUnltLXA1aERwc3lxRWZBSkUwdjhhd0RvOE8xVmJFcFZMbkx2X3VPbw&q=https%3A%2F%2Fdiscord.gg%2F3zy8kqD9Cp&v=PaCmpygFfXo)   , for people who'd like to chat more and go beyond youtube comments

Useful links for practice: - Python + Numpy tutorial from CS231n [https://cs231n.github.io/python-numpy...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbEtOMXJEUUV0V1gyZkh5UlEzY1NNMlV4STMtQXxBQ3Jtc0trenJ4Unp4enQxakUwcXBoaGx5aUlNUXRnWnZRalV3R3dmZ0kyY2pjMUlWcVh1MmtYaVRSaU5mdVhNR2l2TExyeEd4RTIyQVkyOGVkd0M2Z3lYZFh2cDF1bGJfRDJWSzNUWng2S3ZVX1J4aURkTXUxWQ&q=https%3A%2F%2Fcs231n.github.io%2Fpython-numpy-tutorial%2F&v=PaCmpygFfXo) . We use torch.tensor instead of numpy.array in this video. Their design (e.g. broadcasting, data types, etc.) is so similar that practicing one is basically practicing the other, just be careful with some of the APIs - how various functions are named, what arguments they take, etc. - these details can vary. - PyTorch tutorial on Tensor [https://pytorch.org/tutorials/beginne...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbW55ZG9yOFB5eFR6R0FPNXhqaERoQk1LU1lQZ3xBQ3Jtc0trQXlwdHNDeEtfWnpCampScC1nMjFLVlNudlpVOWxwcWNTVXhqaFZGQWRKM25PMzhaWmpjQmNjWUVuQTFNQUk1c21zRkVwOGxWY0JhbWo3UDVJdGVpRXlUbW1xZExsTVRBYXZJdllUMFFCal9faTJkVQ&q=https%3A%2F%2Fpytorch.org%2Ftutorials%2Fbeginner%2Fbasics%2Ftensorqs_tutorial.html&v=PaCmpygFfXo) - Another PyTorch intro to Tensor [https://pytorch.org/tutorials/beginne...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbUFtR3d1akdpZ2RTS2VkN3E1SlJHVUxROWF6QXxBQ3Jtc0ttUTAzaVBhYlNtamJnMnltdGdQcmRsaWxUZ0FxY3FEem1QaThpc1ZtVUQ0bnhtZXBidjRGV0ktSDRMbHJCMThxSUNNd1RuZ05oc193Z3pxNU80YThwUU4xN2RpTHdLUWp4VVd3QlZBSnROQ2V1cmtGSQ&q=https%3A%2F%2Fpytorch.org%2Ftutorials%2Fbeginner%2Fnlp%2Fpytorch_tutorial.html&v=PaCmpygFfXo) 

E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?
E02: split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?
E03: use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?
E04: we saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?
E05: look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead? 
E06: meta-exercise! Think of a fun/interesting exercise and complete it. 

Will make more that are alike, i.e. Baby names.
A sequence of characters

NLP uses <> brackets to denote special tokens.

Take them through a softmax, normalize, then gradiate the learning.

For the latter parts of the series
https://www.youtube.com/@AndrejKarpathy/videos

My file
https://www.kaggle.com/code/ntoned/makemore-project
Still not able to build applications on top of multimodal models.
F Jazz Blues
| F9//// | Bb7//// | F9//// | F9//F7#9// | Bb7//// | Bbdim//// | F9//Eb9// | D7#9//// | Gm7//// | C7//// | F9//D7#9// | Gm7//C7// |

Scales
F7 : F blues (country)
F7 : F7 bebop, F mix
Bb7 : Fm blues (gospel), Bb mix, Bb7 bebop
D7#9: Fm blues, F7 bebop, G harm min
Gm7/C7: G dorian, C7 bebop

Theory
Tritones on Dom7 because of guide tones
D7 = V7 of ii (Gm)
D7 in key of F is secondary dominant
V7alt = V7#9, V7b9, V7#5, V7b5, et al

Practice
Aural (10 mins)
  - Sing up to La and back
  - Sing thirds up to La and back
Shapes (25 mins)
 - F Major
 - F7 Bebop
 - F Major Pent
 - F Minor Pent
 - F Major Blues
 - F Minor Blues
Bebop (25 mins)
 - Flex 1: 1,1-2,1-3,1-4,1-5,1
 - Flex 2: Alternating 1, 3, 5
 - Flex 2b: 1-2,3-4,5-6
 - Flex 3: Climb the scale down to 5 (say the notes)
 - Flex #4: alternate start from 9 down to root, start from 9 up to three
 - 3 to 3
 - 5 to 5
 - b7 to b7
 - Start on 9
 - Start on 9 chromatically down to root
 - Start on 4
 - Start on 6
 - 2 up to 3 chromatically (the major blues/mixolydian)
 - Bebop lick
 - Bebop lick up 2
 - Bebop lick up 3
 - Bebop lick up 4
 - Bebop lick up 5
Pieces (25 mins)
 - Etude 1 (in position)
 - Etude 2 (in position)
 - Groove blues (in position)
 - Country blues n’ bebop
 - Walk the bass
 **- All the things you are**
 - Straight no chaser
 - White Christmas
[[For interviewing to be fair and effective it needs to tolerate culture, discomfort, and biases.]]Biases sway decisions long before you become aware a decision needs to be made. Biases are formed when we compare a new experience to a previous one. These create grooves in your brain patterns. Grooves are desirable because they are a path towards effortless. Descriptive bias is picture matching. In something new you only see what you've seen before. Skepticism about your intuitions is healthy. The person you need to be most skeptical about is yourself. You need to be curious to see beyond your first impression. Dig deep and talk about past behaviors and growth. Diversity doesn't mean compromising on quality. Bias shifts standards leading to you being tough on one person and soft on another. Remember, 'fit' is not the point.
[https://meetu.ps/e/MMn4n/6gTv8/i](https://meetu.ps/e/MMn4n/6gTv8/i)

Channel for posted recording
https://www.youtube.com/channel/UCp7pR7BJNnRueEuLSau0TzA

Generative models learn the data distribution in their data set. the 1940s gave rise to the dream of AI. 1960s gave us deep learning. 1970s gave us neural networks. 1980s got backpropagation.
1990 is LSTM. 2000s gave us GANs. 2010s gave us transformers. 2020s is the OpenAI decade.

OpenAI was founded in 2015.

Contrastive language image pretraining CLIP
Language is a remarkable phenomena. Sounds strung together to communicate electrical pulses in our brain. Language has added immense nuance to human communication and has enabled a lot of humanity’s progress. While it may be true that it’s not what you said but how you said there can be no denying that what you said matters. Imagine someone screaming positive sentiments at you or crying while professing love. You’ll experience a fair amount of cognitive dissonance as a result and you won’t have confidence in your ability to respond appropriately.

Given that language is important for aligning on understanding what might be the language of design? What are the words designers can use to make sure they are talking about the same thing? Does design even have a language?

Jargon and lingo are variations on this idea that I won’t talk about right now. Design has core ideas such as audience, constraints, context, culture, semantics, logic, emotions, decisions, value, benefit, outcomes, need, use, and aesthetic. This is the language of design. These aren’t foreign ideas or made up terms. These words aren’t unique to design but they are at the center of the practice of design. Listen for how often you use these words and then use them more. Encourage others to use them. If you want to be a good designer learn this language. Language matters.

[[_SVA]]
#ux #ai 

https://www.ericsson.com/en/ai/ux-design-in-ai

Four main components of trust are competence, benevolence, integrity, and charisma. An AI solution needs to consider them all.

Heuristics
Make sure the AI solves an actual need. Make the AI explainable. Show evidence the AI is learning. Give a way to trial an AI. Keep the user in control. Make the system adapt to explicit and implicit feedback. Set appropriate expectations. Be transparent with data storage, collection, and handling. Give the AI an appeal to be understandable.
Good. Quit trying to rationalize it and just accept it. Whatever it is doesn’t owe you sense. Your insecurities about rational thought are your problem. The ideas which form the foundation of our existence didn’t make sense when they were proposed. Not to the people who didn’t allow them the opportunity to make sense.

Mental friction is uncomfortable. I get it. Comporting your mental state with non-sensical ideas sucks. You’ve got willpower. You can avoid that discomfort but don’t drag anyone else or the idea along with you. We need ideas that don’t make sense. Logic is the slowest, clumsiest, and most energy intensive way of progressing. It’s the safest so we default to it. It may seem paradoxical that in order for new ideas to make sense they have to be accepted as non-sensical. You don’t change the idea, you let the idea change you. Or you don’t. That’s on you.

The next time you come across something that doesn’t make sense just let it.

[[_SVA]]
#ux #ai 

Nothing for us without us.
#ai #ux

https://5754110.fs1.hubspotusercontent-na1.net/hubfs/5754110/CG%20_%20How%20to%20Build%20Your%20Computer%20Vision%20System.pdf

https://5754110.fs1.hubspotusercontent-na1.net/hubfs/5754110/2_27%20Capgemini%20AI%20Dev%20Day.pdf

https://www.linkedin.com/posts/capgemini-aie-sf_aideveloperday-computervision-largevisualmodels-activity-7170873906818396160-bUoL

Roboflow, tools for computer vision developers
Roboflow has stuff for plant health
Can help you learn how to train models without learning code
Good for students
roboflow.com/opencv
[[OpenCV predicts 2024 as another great year for open source.]]


A team would survey power lines and power towers. Then classify each image. Now you've got a drone.

Inspection time reduction
Accuracy Increase
Visible and thermal camera to look at heat signatures.
Vigilance
This is how we got Amazon Go.

Quinn Killough
Manufacturing
SAM
SegGPT
DINO v2
GPT-4(Vision)
LVM and visual prompting

What's the weird thing to do with this?
What doesn't make sense to use this tech for?

Defect detection, image classification, scene analysis, assembly verification, object location & guidance, counting/sorting are all identified use cases, retail store shelf analysis. How many times you look at the Zoom camera vs looking elsewhere. Detecting boats in satellite images.

Mise en pla, making sure the right things are in the right spot.
Is it organized? Marie Kondo method.

Domain LVM understands the space and can use unlabeled image data. Used to train downstream models but is not the one you use. Created bottom up instead of default to refined. Can be used to generate synthetic data.

HIPPA for imagery in medical field. Synthetic data is a stopgap solution. Synthetic data is also a great way to make money.

Base subscription and cloud usage determine the price. Large models are handled financially separately.

Can you take it with you? Yes.

100k unlabeled images to train LVM.

Is it mold?

Dillon Laird
Scope -> Collect -> Train -> Deploy -> Collect -> Train -> Deploy loop.
Classification, object detection, and semantic segmentation are project types.
Will an 80% accuracy model work? How many sigmas do you need?

Image classification maybe not great for picking out scratches on an advil pill. Object detection is a tight box and might be a better model. Semantic segmentation is the most information.

Image classification needs a lot of images and labeling in easy. Object detection takes fewer images but the labeling effort is high. Semantic segmentation requires the least images but the labeling is the highest.

If a human can only identify an object 80% of the time the computer vision model likely won't exceed that. Be sure the give the humans and the computer the same images. I would feel the scratch to see if it is deep before discarding it.

Some pills may be scratched, some chipped, and some poked with a needle. This is high variability. You need to simulate or provide images on the various contexts the image will be present in.

Standardized lighting and image capture process reduces variability and thus problem difficulty.

Do you have enough data samples for your sigmas? Maybe your current defect count is 60% and you know this can get you to 80%.

If you can reduce it to a 3D tensor we can work with that otherwise you only have access to RGB.

If you give labeling software mixed results they won't get it right that often. Do we label paths in the parking lot as roads or no?

More important than hyperparameters is the data you give the model. Iterate on data as the primary mechanism for model improvement. Evaluate models on a fixed data set. Deploy early to figure out the performance and deploy in shadow mode to minimize the impact of the deployment.

Default augmentations like changing the orientation, flipping the image, rotating it, changing the lighting is a way to give you cheap synthetic data.

Andrej Karpathy talks about Tesla production AI iteration on edge case data.

36 megapixel max then the image gets sized down.

Consistent separate hold outet. Add no class.
 
Anchor free detection. Semi-supervised learning.

You'll get a good breakdown of LandingAI and how it works in their community.
https://community.landing.ai/c/landinglens-fundamentals
LoRA is the method developed and used by Stable Diffusion. LoRA is Low-Rank Adaptations. 

#LoRA 

```query
tag:LoRA
```

#ux #ai 

[[Build a circle of mentors with six people.]] If you've ever thought about paying someone to watch you work for a day and suggest effeciencies for your workflow then you know what an optimizer is. Sometimes we are trying too hard and going nowhere. Optimizers will point that out and help you move from it.
This is what keeps it fast.

#LoRA 
Everything will decay. Ruin is inevitable. Immortality is a curse. The end is part of the design yet it is rarely considered. There’s also a tremendous negative value to the idea of the end. Fear dictates that we keep what we have regardless of its continued worth or benefit to us. For that reason we accumulate much more readily than we discard. Certain physical objects are designed to decay specifically to promote the cycle of repurchase. This is called designed obsolescence and it has virtue thought not always.

What I mean here by designing ruin is a similar practice. The near term is only one of many timeframes to design for. It is likely that your design will outlast your involvement so the mid, far, and eternal terms need consideration. Designing ruin is focusing on the latter. Consider how the design will wear, break down, and be repaired. Give your designs a life and a death. Design by the human hand is control over the process. Don’t leave the end to chance.

[[_SVA]]
No story of design starts with now. Now is not a destination. Now is alive with potential but stagnant with change. Design is a means to realize what can be. This means that you have to start with where you want to go and end with where you are. Design fills the space between.

This isn’t revelatory. The operating model for human motion is reaching a destination. We’re all driven towards something other than what we have. The trick is to develop an awareness of the insignificance of where you are compared to where you want to go. The driving question of design is not ‘how do we get there from here’ it is instead ‘how do we get here from there?’

[[_SVA]]
#marketing
In some sense the entirety of design exists to satisfy our own and other people’s values. In fact, it’d be difficult to argue against the idea that all action, all motion, all human effort exists to satisfy our own and other people’s values. What makes anybody do anything? Even the act of acting has value. Kinesthetic pleasure is pleasure. The notion that design creates value is somewhat of a moot revelation but worth being reminded of at points. It’s possible the manner in which design satisfies our values is novel to design. If you find yourself looking at the biggest picture you might see that everything is design. 

The important takeaway from this is that design exists to serve value so start there.

[[_SVA]]
In certain cultures, outside the box is a valuable place to think. Paradoxically, outside the norm is rarely a valued place to live. People…*shakes head*

Thinking outside the box can’t happen without the box. Aristotle revealed to us that we naturally create boxes. Modern nomenclature refers to that as classification or labeling. Like and dislike are boxes. Up and down are boxes. Beautiful and ugly are boxes. You get the idea.

The mind cannot deal with the infinite. The whole architecture of our mind is there to create form from chaos. Without ‘is’ and ‘is not’ we would blob about until our inevitable demise.

Whether you rail against the box or conform to it you still are reacting to the box. The box gives you freedom to decide, to choose, to act, to be. The box is about as close to a truism as an idea can get. Celebrate the box. The box is not a bad thing.

[[_SVA]]
[[Keywords are words the programming language reserves for their needs, like and/or/if/else.]]

[[Operators tell the computer to perform an action.]]

[[Expressions are strings of arguments like 10/2 + 3 and 2 + 3 * 6.]]

#programming #beginner 
Think of the long view. The thousand-yard stare. You can lift your head up and find longer arcs. You see the arc of seasons, suns, planets, and aeons. You see the arc of the archetypes, the arc of the watchers, the arc of the ink black waters of eternity. If you look back you can see the arc of human intention, human storytelling, the human experience. You desire to know where it’s all going. What’s next? yet it is not for you to know. We must content ourselves with our reactions to the moment. The long dark arc is for none to see save the archetypes, watchers, and mystery inhabitants of the ink dark deep.

[[_SVA]]
#ux #ai 

[[Design for workflows not monoliths.]]
Hero
 [[We know that we value certainty]]
 [[Giving form to vision]]
 [[Deformation professionelle]]
 [[End with the beginning]]
 [[Designing for complexity]]
 [[Beneficial pressure]]
 [[What makes it worthwhile]]
 [[You can't optimize yourself in the moment]]
 [[The arc of human intention]]
 [[Designing better]]
 [[Value in the context of design]]
 [[The toil and reward of critique]]
 [[Literacy and design]]
 [[Style, curation, editing, and MML training are the tools of the GPT world.]]
Sage
 [[Design for feature parity]]
 [[Improving outputs]]
 [[Designing for teams]]
 [[What needs to be true?]]
 [[Making better decisions]]
 [[Rational decisions]]
 [[Explaining design]]
 [[The design of learning]]
 [[Analyzing motivations]]
 [[Designing society]]
 [[Designing for context and outcome]]
 [[Designing for irrational people]]
 [[Design's purpose is predictable change]]
 [[Language matters]]
 [[The space between]]
 [[Designing a worldview]]
 [[Brain architecture]]
 [[Relationships are the final frontier]]
 [[System stress benefits from being designed]]
 [[Design reasoning is abductive]]
 [[Insight comes from odd angles]]
 [[A system design conversation]]
 [[Surviving failure]]
 [[The meaning of design]]
 [[When work is resolved it feels natural]]
 [[The interface is the system]]
 [[Design is meant to trigger your audience]]
 [[Business processes tend toward optimization]]
 [[Acceptance is what we crave in order to belong]]
 [[If you make a point to talk about integrity there's a good chance you've been betrayed in the past.]]
Explorer
 [[Design for the greatest good]]
 [[The environment is a factor]]
 [[Old design]]
 [[Escaping design]]
 [[The freedom of the box]]
 [[Instinctual exploration]]
 [[Designing your future self]]
 [[The thread keeps the story together]]
 [[People are the beginning and end of design]]
Jester
 [[When in doubt talk about pizza]]
 [[You design your behaviors based on your goals]]
 [[Don't hit them where it hurts, hit them where it helps]]
 [[Design for wasted time]]
 [[You may need to bore yourself into climbing the mountain]]
 [['Yes, and' only gets you halfway]]
 [[Boredom is a generative force]]
 [[Design's great paradox]]
 [[Design doesn't have to be serious]]
 [[Playing a stereotype]]
 [[Designing measures]]
 [[More about the space between]]
 [[What happened to all the fun?]]
 [[Play is design]]
 [[Infinite pie]]
 [[The ease of mastery]]
 [[Nobody looks up]]
Outlaw
 [[Die to your self-righteousness]]
 [[Conflicting truths are not a thing]]
 [[Overthrowing a government]]
 [[Designing bad ideas]]
 [[Interruption as a design decision]]
 [[Ineffective design]]
 [[Innocence as a tactic]]
 [[Machiavelli's promise]]
 [[Momentous energy]]
 [[But it doesn't make sense]]
 [[Dealing with disagreement]]
 [[Guilt is a profoundly positive emotion]]
 [[Mistakes and originality]]
 [[The design of ruin]]
 [[The information trap]]
 [[The great deception of design]]
 [[Why is a bad idea]]
 [[Stop wielding your truth as a weapon]]
 [[Input matters less than your process]]
 [[Stop sacrificing aesthetics for functionality]]
 [[Plans are works of fiction]]
 [[Numbes offer a false assurance]]
 [[You can lie with data]]



Operating agreements
LPR industry
AI legal outsourcing
Expensive celebrity talent & humor for the ads
$500/mo for customGPT
Entertainment in the crucible due to WINS, words, images, numbers, sounds.
Give me 5-8 important things to look at for AI each week #money
Self-discover with self-compose reasoning structures may be important
Shorten the time to value
People want to know how to use AI to get money from people.
90mins for $495, get people into a room sharing their actual questions, value prop to CEO, how do I learn top insurance pain points in three minutes? - chatGPT with RAG #money
AWS Tableau is Quicksite, Q is their AI for AWS.
The largest cloud war dwarves dinky LLMs even the 2B ones.
Microsoft generates 2B in cash weekly, without prompt or attention.

Corners present opportunities to discover what is around them. The possibility of seeing what you don’t see propels you forward. The unknown excites you. For reasons ancient and unknowable you seek what can be sought. Not for greed. For the pleasures of the journey. You are an explorer.

Exploration is an act to be highly valued in the field of design. Exploration defines the design space. You’re tracing the edges within which you create. You’re supplying the inputs. You’re refining the model.

Exploration leads us forward. Let yourself be entranced by the unknown. The next corner beckons.

[[_SVA]]
Fear is a known motivator. Fear itself is the six hundred pound guerrilla of the group. Generally fear is an expression of an avoidance of loss. Fear shows up when you imagine yourself losing something of value. Maslow postulates that the needs of shelter, sustenance, and positive social interactions carry the most value. By extension imaging the loss of any one of those needs will induce the greatest fear. Fear is not rational and will motivate us in irrational ways. Behaviors during a frightened state need to be considered in isolation. Let’s be pedantic about it. The behavior is not irrational but contextually rational to a frightened state.

Greed is the growth side of fear. Fear is loss. Greed is gain. Fear drives when it wants. Greed takes over in-between. Greed has a strong negative stigma in many religious-based modern cultures. Greed begins as a selfish desire. Much in the way that fear of individual loss is felt greater than fear of collective loss, so too does greed concern itself to the individual before the collective. Greed can be pointed at a gain for many.

Laziness as a motivator is tied to the conservation of life on the anatomical level. Life energy is abundant but finite. We all die. Living bodies have inherited an understanding of this fact over the course of evolution. Laziness is a built in mechanism for conserving energy and prolonging existence. Laziness is the mechanism that causes you to evaluate a decision on the basis of effort required. All things being equal alternatives requiring the least effort are the ones we choose. Desiring not to extend unnecessary effort is not a character flaw, it is instead a virtue of smart people.

Purposes motivate people. Purposes are an inner state linked to an outer goal. Inner states are drive. Outer results are goals. Emotions are neural memories of body states. Desire to change our inner states produces an inner vision of outer results. The value in that combination gives purpose and once purpose is attained the body acts. The plan is set, execute. Purposes can be conflicting, false, and redefined. Action doesn’t guarantee results. Try and err. The drive continues until the purpose is dissolved or the drive is overcome by another more urgent drive.

Fear, greed, and laziness motivate a change of inner state away from loss of value and energy or towards gain. The change is conceived of internally as an outer result. You’ve now formed an image of your desired state and a plan to move there. Once formed you set about trying to find the least effortful way to get there.

[[_SVA]]
Rubber Ducking AI
Legal Eagle Courtroom drama by AI
 - How do you return the blood?

#ai 
#ux #ai 


#ux #ai 

You share this in common with ## other people.

You are %likely to benefit from {x}.
#ux #ai #ml


Grocery shopping, cooking, driving, pushing text to a blog
It's best not to know you can't do something before you go do it. You'll create your own way and that will be your greatest advantage. Great chess masters lose to beginners because the beginners don't know how to play the game. The chess masters never see them coming.

[[_SVA]]
All creative solutions must be logical in hindsight. Of course we were going to end up here. The general sentiment is one of obvious resolution. That's not the process to create the solution. That part is unnatural, meandering, manic, and frightful. You need the faith that the resolution will come but don't think you can avoid the discomfort. It's the reward that makes the effort worthwile.
[[Build a circle of mentors with six people.]] Yoda is good at what you are not. The thinking isn't above you. Yoda may be an equal in an area of your weakness.
#ux #ai 

[Nadia Piet](https://www.linkedin.com/in/ACoAAAgsQl8B9ZOTT6tUAzqeR_udMdUGlr-K1AY)  
https://aixdesign.co/toolkit
https://raindrop.io/aixdesign/a-ix-design-library-18077843/theme=light&sort=-created

UX of AI challenges
Trust & transparency
Autonomy & control
Value alignment
#ux #ai 

https://www.microsoft.com/en-us/ai/responsible-ai

Is a guide from 2022 that talks about how Microsoft will evaluate their AI systems.


Your pedantic semantics of challenge people over users is painfully idiotic. The idea of current users and future users has value
Obviously. Everything benefits from being designed. Well, everything that has been designed benefits the people and situations for which it was designed. What was excluded from consideration may gain benefit from design or it may not. System stress is certainly something we cannot let happen by accident. All systems contain stress points. These occur only within the confines of the system. System’s are isolated ecologies. Any stress will result from the design, intentionally or not. Since stress will happen it’s better for designers to work with it up front. If you wait to deal with stress when it emerges you may have to make drastic changes to your design to accommodate the effects of the stress.

An example, however basic and archaic, is a keystone in an arch. Physics prevents us from creating an arch without some manner of keystone, even a conceptual one. The arch contains stress from gravity. The keystone distributes that stress. Buckminster Fuller created a geodesic dome based on the principles of stress distributions. He designed a system that understood how to handle the stress it would encounter and generate. He intentionally designed, or discovered, the stress points of the geodesic dome system.

Consider the systems you’ve built for yourself. Perhaps you have a routine you’ve designed. If you’ve ever encounter a moment where it’s burdensome to complete your routine then you’ve encountered system stress. Perhaps you adapted your routine accordingly. Maybe you pulled some elements out, rearranged others, or abandoned your routine entirely. If you have then you’re designing. I postulate you would receive more benefit from your routine if you had accommodated for the stresses earlier in your design process. Perhaps you couldn’t because attention is limited and humans can’t consider the infinite factors which contribute to the current moment. That’s fine but now you know and you can use that knowledge going forward.

Give yourself some slack. You may find you’ll have a better life because of it.

[[_SVA]]
#ux #ai 

https://www.ibm.com/design/ai/
https://www.ibm.com/design/ai/ethics/everyday-ethics

Designers must account for a system that can understand, reason, learn, and interact. IBM states the value of design is to improve lives and leave the world better than we found it.

AI has four characteristics: it understands context through structured and unstructured data, it makes considered arguments, AI is trained and not programmed, AI interactions are natural and unobtrusive.

AI NEEDS context, which in IBM's way is defined as the holistic view of a complete human experience, including emotional, physical, system, and domain knowledge.

Insights in what AI gets us. There is still a need to solve for users and not be constrained by technical capabilities or requirements.

Guidelines
 - Establish a fully-realized AI profile shared between the system and user.
 - Deliver multi-step context-aware interactions.
 - [[Display provable authenticity of the system's interactions.]]
 - Establish the system's tone, personality, and presence.
These guidelines are based on Mark Knapp's relationship model considering only the first phases of Initiating through Bonding.

AI Essentials framework for building an AI:
 - Intent: Align on the business and user intent(s) for your solution.
 - Data: Document the data you could use to make your idea a reality.
 - Understanding: Determine what you will need to teach your AI.
 - Reasoning: Bring your ideas down to earth.
 - Knowledge: Brainstorm the direct and indirect effects of your AI.

AI is capable of achieving higher quality outcomes faster than humanly possible. AI is expected to aid our pursuit of knowledge and improve the human condition.

Common AI use cases.
 - Accelerate research and discovery
 - Enrich your interactions
 - Anticipate and preempt disruptions
 - Recommend with confidence
 - Scale expertise and learning
 - Detect liabilities and mitigate risk
Generally looking for patterns in heaps of data.

AI works either through an algorithm or mathematically sequenced events or AI works through a model ala machine learning. Models are helpful when specifying rigid rules in hard or abundant e.g. stock trading, identifying cancer, predicting preferences, etc.

Machine learning has three general subcategories: supervised, unsupervised, and reinforcement. Supervised learning requires examples for accuracy. Unsupervised learning is good for finding hidden connections in oceans of data. 

The ingredients of a reinforcement learning problem are: 
 - an agent, 
 - its environment, 
 - a way for the agent to interact with its environment, and 
 - a way for the agent to get feedback on its actions within the environment (called a reward function or feedback function).

ML can detect patterns of abandonment in your product and classify a user as at risk of leaving.

You data needs to be of representative sample size. Your data needs to be as free of missing and incomplete information as possible. Related data sources need to be consolidated in the same location. Your data needs to be consistent and offer up as few conflicts as possible. Don't conflate correlation and causation. Consider the famous ice cream sales and murder rate correlation where the missing variable was temperature.

ML is always, by construction, a form of statistical discrimination. It cannot function without bias.

A note of caveat: [[Imperceptible AI is not ethical AI.]]
https://www.ethicscanvas.org/
https://standards.ieee.org/initiatives/autonomous-intelligence-systems/
https://www.ibm.com/design/research/

IBM sees 5 main focus areas for designers and AI.
 - Accountability is on everyone for considering the AI's impact in the world. You must know the policies governing your AI.
 - Align your AI with the norms and values of your audience. I add culture. Your AI learns and needs to align on the values as well.
 - Explainability is providing detail from the AI about its decision process.
 - Fairness means ongoing research and data collection which is representative of a diverse population. 
 - User Data Rights is radical transparency into what data, when, how and how to turn it off.

IBM embraces five pillars of AI.
 - Explainability
 - Fairness
 - Robustness
 - Transparency
 - Privacy
Design is a feature of humanity’s ability to project. It’s a meta act similar to orchestration. What design allows us to do is be proactive. We know humans continually seek to change their state and status. Design is what allows us to do that. Well, design is the name we’ve attached to the activity. The way of the universe is what allows us to do that.

Your actions are what produce outcomes. Design guides your actions. Design puts elements together. When they line up in our mind we execute.

You can design on the fly. In some sense design is always momentary. The more traditional view of design is as a precursor, completed before action is taken. Insecurities drive the traditional view. We refuse to handle chaos. We’re biologically built to create meaning from chaos but that act is energy intensive so we avoid it. We avoid paying attention to the thought. We’re always creating meaning from chaos. We can’t avoid it but we can refuse to consciously acknowledge that fact.

With design, we’re continually imagining the outcomes of our actions. How do the actions build on each other? I do this then this will happen and because this happened then I do this. Or you can come at it backwards. I need this to happen so I will do this which needs this to happen so I will do this.

You’re tracing a path through anticipated consequences to realize the change you seek. You can consider design as forethought but it’s not just thinking about the chain of causation, it is actively manipulating the elements until the end of the chain gets you what you want.

Design is uncomfortably human but that means everyone does it. Every person seeks change. Design is how we’re able to achieve it.

[[_SVA]]

Rendition(TM) will make code from a Figam file -> Feed Rendition code -> AI summarizes code -> AI guesses which component to use -> AI rewrites the code
#ux #ai 


#ux #ai 

https://pair.withgoogle.com
Ho!, man. So much to go through. 
Would take 7 days to go through at 2 a day.

https://pair.withgoogle.com/guidebook/
Legitimately more than you can hold in working memory. Not you, you savant, but you, like me, standard in memory.

Challenges are getting started
  - aim for using AI to create valuable personalized experience while avoiding using AI because you can as that may lead to poor and lower quality experiences
  - what is our knowledge graph structure that will support this AI feature.
  - aim for setting the right expectations about the AI especially if the AI is used in high stakes situations and avoid overselling the capabilities.
  - aim to explain the benefit and avoid emphasizing the underlying technology
  - Consider false positives, false negatives, and ways to provide a way forward and change the product to accommodate them. False negatives are more impactful on moral than false positives.
  - Be data conscious and partner with a data person.
  - Expect play and experimentation as AI is added to more and more software.
Use cases
 - read mass amounts of text and make it presentable
 - make your images easier to search and organize by people, places, and things
 - create meaningful content from your photo library via an immersive story player
 - tuning out toxic comments aka spot abusive language https://conversationai.github.io/
 - [[A precision x recall matrix can help prioritize AI features and design.]]
Onboarding
 - point out what you get right and that you are getting more right i.e. progressing will lead to more engagement
 - Create a test drive situation, a playground of sorts to test features, like with a toggle.
 - Aim for using familiar concepts and avoid novelty when familiarity is the solution.
 - Slowly give the AI more control the more the user uses it.
Explaining the system
 - Give examples of what the AI might be better at and also where the user might be better to step in
 - Aim to show the model confidence if possible in a way that is easy to interpret and avoid using numbers in ambiguous situations i.e. 'most likely' can be better than '82%.'
 - Aim to explain the AI decisions that impact trust and avoid explaining complex rationale.
 - Explaining the complex is beneficial if pushed to a separate area like during onboarding or as marketing materials or a help center.
 - Provide specific and general output explanations, i.e. 'this plant is most likely poison oak because of YXA features' and 'this app uses color, shape et al to identify plants.'
Responsible dataset building
 - Dig deep into labeler variations as the different ways people describe the same thing offer beneficial data quality insights.
 - Get help from domain experts throughout the development lifecycle.
 - Clean, clear, and declutter your dataset at regular intervals.
 - Co-create the labels with the data labelers when doing supervised learning.
 - Make sure the data you train on is representative of the data you'll get from your users, i.e. people likely won't take professional level photos so don't train on those.
 - Attach dataset meta on authorship ala https://sites.research.google/datacardsplaybook/
Trust
 - At all times communicate what data is being collected, how it is being used, and how to turn it off.
 - Bolster responses with third-party confirmation, citations, and/or social proof.
 - Allow users to provide feedback through roman voting, hiding, flagging, and standard communication channels.
 - Aim to reveal and allow approval for options and avoid automating too much too fast without proper undos or decision trees.
 - Automate more when the risk is low or failure tolerance is high or both.
 - When the AI fails prove context, next steps, and actionable links to the user.
Feedback
 - Always tell people what information you need from them, what you are going to do with it, and what they get out of it.
 - Implicit feedback are logging data like time of day usage and the number of accept or reject recommendations.
 - Explicit feedback is audience commentary and must be aligned with ways the model can be improved.
 - Communicate specifically how the feedback will change their individual experience.
Control
 - control over your data at all times
 - you need to allow people to adapt their outputs, edit the experience, and even turn the AI off
 - [[People want control when they enjoy what they do, feel personally responsible for the outcome, are in a high-stakes situation, or find it difficult to communicate preference.]]
Automation balance
 - People will give up control when they are unable or the task is unpleasant or unsafe.
 - A framework to determine what to automate: https://ieeexplore.ieee.org/abstract/document/844354
Support for failure AKA Error handling 
 - Defining "errors" and "failures", identifying their sources whether user, system, or context ala breakfast at night and providing ways forward.
 - Inform the user the system improves over time. Failure now is not failure forever.
 - Context errors often present as true positives. Failstates often present as true negatives.
 - Look for errors the user doesn't perceive.
 - Make failure safe, boring, and a natural part of the product.
 - Avoid making dangerous failures interesting or over-explaining your system vulnerabilities.
 - Be cautious of compounding errors from other ML models.
Data ethics, governance, and other matters
 - source responsibly
 - prepare and document your data
 - design for labelers and labeling
 - make your data high-quality from the get
 - The most important data considerations for quality are predictive power, relevance, fairness, privacy, and security.
 - Google's call to responsible AI: https://ai.google/responsibility/responsible-ai-practices/
	 - Be human-centered
	 - Have training and monitoring metrics
	 - Directly examine your raw data
	 - Understand the limitations
	 - Test
	 - Update and refine

Value of AI summarization. Get everything I need in a small space.

[[Good research questions to improve an AI.]]

Material rewards, symbolic rewards, personal utility, altruism, and intrinsic motivators needs to be considered when receiving feedback. -_-

Heuristics, called responses by the guidebook:
Allow for opting out.
Allow users to give guidance or correct the data or label, which feeds back into the model to improve the dataset or alert the team to the need for additional training data.
Communicate what the system is supposed to do and how it works. Then, explain what it’s missing or its limitations.
Allow users to give feedback about the needs that the system isn’t meeting.
Check the user’s input versus a range of “expected” answers to see if they intended one of those inputs. For example, “Did you mean to search for XYZ?”
Implement AI in ways that don’t break habituation, such as by designating a specific area of the interface for less-predictable AI output. Or, allow users to revert to, choose, or retrain a specific interaction pattern. See more suggestions in [this article](https://design.google/library/predictably-smart/) on habituation from the Google Design blog.
Explain how the system matches inputs to outputs and allow the user to correct the system through feedback.
Explain why a certain result couldn’t be given and provide alternative paths forward. For example, “There’s not enough data to predict prices for flights to Paris next year. Try checking again in a month”.
Allow the user to provide feedback to improve the system’s function.
Explain the multiple systems that are connected, and allow the user to determine priority. Consider visual ways to represent the relationship between multiple AI systems in the product interface, perhaps by mapping them onto different locations.
Allow the user to set independent controls for your AI that don’t overlap with other signals. For example, the watch word for a smart speaker to start listening could be unique. If your team can avoid creating new context errors, the system could attempt to infer which system is the one the user intended to have primacy.
Communicate the product’s capabilities and limitations clearly to set expectations, and do this early.
When appropriate, provide reasons for a given inference, recommendation, suggestion, etc.
Leverage other in-product moments, such as onboarding, to explain AI systems.
Users look for familiar appearance and legibility, which can contribute to initial trust.
Contextualize recommendations with third-party sources.
Explicitly state which data is shared, and which data isn’t.
Make it easy to try the product first.
Engage users and give them some control as they get started.
Progressively increase automation under user guidance.
Continue to communicate clearly about permissions and settings.
Let the users know ahead of time that there is a recovery plan in case something goes wrong, and in the moment, when something doesn’t go as expected.
Give users a way forward, according to the severity of possible outcomes.
Show the output alongside training data, like here's your image and here are some images we have that are similar.
[[]] backlink
three `` to start a query
 query:#tag to produce a list of tags
```query
tag:jupyter
```
https://medium.com/produclivity/3-things-you-didnt-know-you-could-do-with-obsidian-933ae81c51c8
learn markdown: https://facedragons.com/personal-development/obsidian-markdown-cheatsheet/
zettelkasten: https://zettelkasten.de/posts/overview/
![[Screen Shot 2023-04-16 at 2.55.09 PM.png]]
https://www.youtube.com/watch?v=TPmtiglPnEY

Begin with the user need, research, and market fit. Chatbots-only are not the future. The future is the hybrid GUI and prompt. The AI builds the UI.

A blue pop-up helped reveal the AI.

The user is likely using the LLM in a very particular use case for themselves. Study will reveal the prompts and intent so you can create a graphic controller. [[You can generate buttons based on the most common prompts.]]

The design system is more important now if the AI is building the UI. Once you realize the patterns you can build the widgets.

Consider scalability and use cases. Having help writing prompts is beneficial. [[You need to show your references, cite your sources.]]

Use sentiment analysis of NLP to measure AI success.

4 ingredients for UX & AI
Needs research
Usability heuristics & Hybrid interfaces
Personalization
Self-built interfaces
One of the largest challenges any particular person will face is guiding yourself to do something new. It may be more like the challenge is less about doing something new and more about stopping what you’re currently doing. In either case the end result is the same. You’re wanting to form new neural pathways in your brain. That’s really what behaviors are.

A vital point about changing behavior is that you don’t lose the old the behavior. It may go away but neural pathways persist far longer than you might think. Changing an existing behavior is the processes of rerouting electrical activity so that it doesn’t follow the existing pathway but is diverted to the new one instead. Diverting your neural activity needs to happen repeatedly so that it ultimately takes less energy that the old pathways. Behavior change happens in small moments over time.

An easy way to divert your neural activity is to set up an interruption. A common example is freezing a credit card in a block of ice to prevent expenditure. Though that’s not the most beneficial behavior these days since online shopping only requires numbers and ice is transparent. But anyways. Interruptions force attention. They create decision points. Do this or do that. You can’t be lazy and expect to change how you want. Your nature requires a different approach. It’s uncomfortable, sure, but not impossible. Put yourself in your own way. It’s the one and only step to get you to who you want to be.

[[_SVA]]
Dunno much more, is worth looking into.

```query
tag:jupyter
```

#jupyter
![\text{NPV} = \frac{R_{t}}{(1+i)^{t}}](https://www.gstatic.com/education/formulas2/472522532/en/net_present_value.svg)
#ux #ai 


DataVOLO

GenAI will be a feature in existing platforms, alongside RUSTY , Graph, all supporting data is part of one platfrom. Decoders are the generative force. DL only has encoders to learn.

We will do the chunking and high level work.
Chunk overlap is an expert hack.

Ask for 100 chunks back add 1,2,3,4 until we reach the number that we want. Secret sauce of chunk ranking.

Ranking is still a thing.

Vector DB is a common RAG solution though not only.

If you keep your own DB with the latest of domain specific data you'll keep things current.

Conversation design

17k households daily electricity will create a crisis in AI computing. More people need to recognize the seriousness of this.
Two-day seminar #service
 10-step learning workshop with templates and worksheets
One-hour coworking session #service
 Talk is cheap, I'll work through your problem with you over giving you advice as to what to do
Career coaching #service 
```query
tag:service
```
 - Fractional Design Officer #service
 - Fractional Communications Officer #service
  - internal, how employees speak, not external, what it said to customers
 - Fractional Feedback Officer #service
  - runs out of ideas on what, where, and how to improve?
  - let me orient you back and build systems to maintain actionable feedback
 - Fractional Play Officer #service
 - FXO, Fractional Experience Officer #service
 - Meditation coach and accountability #service
 - could sell an eval  
    create a checklist  
    call me after you’ve completed the checklist
maybe creative thinking? AI consult? I dunno.
Some days don’t you just wish that the pie never disappeared? 

https://www.youtube.com/watch?v=JZOxqVl5oP4

This is not a metaphor. I just really miss pie.

[[_SVA]]
#ux #ai 

https://medium.com/ml-ux/machine-learning-and-user-experience-a-few-resources-e7872f1d34ee

https://machinelearning.design/

https://www.youtube.com/@MLUXmeetup/videos

http://www.creativeai.net/

https://medium.com/google-design/human-centered-machine-learning-a770d10562cd

https://www.youtube.com/@MLUXmeetup/videos
Consider that the space between is the only space that matters. The endpoints are fixed. In contrast we don’t make sense of the ends, we make sense of the space in between. Humans experience the world as a relationship between themselves and the environment. Conceptually these can be redefined. I can think of myself as a hero and the environment as unchanging or I can think of myself as a villain and the environment as my clay. The endpoints don’t determine the relationships available but they do prime the pump for certain relationships to be more obtuse.

What am I to this table? It’s a ridiculous question but it forms the basis for our interactions with it. We create meaning from our answer. If I am taller than the table I might see this table as a step to a high location. If I am shorter I might see this table as an immovable mountain. You’re not redefining what the table is, but what it is in relation to what you are.

By all means change the endpoints. There is infinite variety in that. Consider though that the endpoints are less meaningful than the relation between them because the relation is what we create. The relation is often the more subjective factor. You might not find anything when you do change the relation but know that it is within your control. It’s about the only thing within your control.

[[_SVA]]
#ux #ai 

https://futurice.com/ia-design-kit

What AI is good at
 - predict a number
 - predict if this part will fail tomorrow
 - predict which department to route a call to
 - recognize images
 - recognize text
 - recognize sound
 - personalize content
 - target communications
 - discover anamolies
 - discover groups
#ai #RAG 

Yujian Tang - Dev advocate Zilliz

Milvus, Mixtral, OctoAI, Langchain
Milvus is an open source vector database and it allows you to use unstructured data.

LangChain orchestrates LLM conversations with RAG. Indexing is critical for vector search. Vector search allows for a quantitative comparison of qualitative data. You will never have two dimensional data in production and you won't do distance calculations in production.

Mixtral is a Mixture of Experts, specifically 8 experts though only 2 are active at once.

Text generation via Mixtral and OctoAI has 3 hyperparameters:
Temperature - how creative do you want the output to be.
Top p - how varied do you want the output to be.
Max tokens - 32k for Mixtral

LangChain treats LLMs as a function.

code: https://github.com/ytang07/octoai_milvus/blob/main/MMO_RAG_Docker.ipynb

512 characters is about 100 words, maybe one or one and a half paragraphs.

HuggingFace SentenceTransformer can is Yujian's favorite embedding tool as it is free.

Milvus has role based access control so the intern can't see the CFO data.
#ai #RAG 

https://www.youtube.com/watch?v=fo0F-DAum7E

Explainability in AI from MSci
Fairness
Adversarial

LLMs are trained only on stale web data, not fresh or proprietary data. RAG brings in fresh and proprietary data.

Canopy. LangChain, Llamaindex
5 lines of code, the demo is easy
You may overflow the context if your RAG grabs too much response that it maxes out tokens. You need to chunk properly. 

https://github.com/pinecone-io/canopy
The benefit is E2E Rag, Built for scale using Pinecone, Context overflow, No code just a YAML config, FastAPI & Docker

Evaluating a RAG is like evaluating an essay over a multiple choice.

https://github.com/truera/trulens/blob/main/trulens_eval/examples/expositional/frameworks/canopy/canopy_quickstart.ipynb

APIs needed:
Pinecone
OpenAI
Cohere

Controls via a config helps maintenance in production. Eval -> in Trulens
TruEra is a full lifecycle AI
Eval -> Debug -> Monitor
Fine grain logging of the trace.

Fine-tune small models first. By adding data through fine-tuning you may end up with a better model. Use a small model for workflow proof.

Stochastic is asking the same question and getting different responses. Low temp, close to 0, for consistent answers.
The thread is what we grab onto to navigate the chaos unfolding around us. Threads weave more than just stories. Threads weave people, ideas, and movements together. Threads bind us. They are everywhere.

Connecting is what I believe, on a level that is mythically deep, that we show up to do. The world and all its infinities are better for it.

[[_SVA]]
Guilt has a strong negative connotation but it is a profoundly positive emotion. Civilization cannot exist without guilt. Society cannot exist without guilt. Guilt is always pointed at what we did wrong, how we let someone down, and how we went against the grain. Nobody likes to feel guilty which is exactly the point. Guilt keeps up from behaving in certain ways. Encouraging constructive behavior alone will not get you where you want to go. We need guardrails against destructive behaviors. Enter guilt.

I didn’t create guilt. I’m merely pointing out that in its negativity guilt is highly constructive. Cultures are defined as much, if not more, by what they place negative value on than by what they place positive value on. It is possible that we limit ourselves by feeling guilty over actions that we need not feel guilty over. Therein lies the tricky bit. We need guilt to control our actions but that control inhibits us as much as it supports us. If you can find false guilt then by all means remove it. Conversely consider how you can guilt yourself forward, it’s possible.

[[_SVA]]
On a human level it has been stated that the support of a mere 3.5% of the population is necessary to sustain a revolution. From there you’re doing what everyone else is doing and addressing the long work. Overthrowing a government can happen overnight if the atmosphere is charged, people are tense, and then boom goes the dynamite. The atmosphere needs to be charged and as such rarely spontaneously is. Even overthrowing a government overnight takes time and the right conditions. The long work.

Expect to be surrounded on all fronts. You’re buried alive essentially and you gotta bust through the ground. Or you’re surrounded by water and drowning. Government is your environment until you claw to the freedom you desire. It can feel as an endless event. You’re doing necessary work. It can be beneficial to consider your path as ascension. Ascending the constraints. Transcending if that helps.

Maintain your support. Create emissaries, ambassadors, delegates, diplomats, foreign representatives, people relations experts. You’ll get there.

[[_SVA]]
#ux #ai 


#ux #ai 


#ux #ai 


#ux #ai
#ux #ai 

https://www.youtube.com/watch?v=5HgkawZdihU


https://dashtoon.notion.site/Stable-Diffusion-Creative-Technologist-Dashtoon-Full-time-Bengaluru-India-26cc0fcf503a4617b1ac8e60b1b383ad?pvs=25
It is not uncommon knowledge that our individual experiences of the world are highly biased. With our brains acting as self-organizing information systems it cannot be any other way. One such bias worthy of consideration is known as deformation professionelle, which is the tendency to view the world through the distorting lens of your job or training. This shares commonality with the colloquialism that if all you have is a hammer then everything looks like a nail. 

Deformation professionelle can be particularly insidious in the realm of design because design is of such a high order thinking skill, meaning design deals primarily with very fuzzy abstractions. Designers are taught that design is a means to accomplish a goal. Name a situation where a means to accomplish a goal is not applicable and you’ll see the point I’m making.

‘We need more design.’ ‘We need better design.’ ‘Design can help here,’ are all traps of deformation professionelle. It is possible those statements ring true more often than not but nothing can claim applicability in all instances. Be mindful of the ways in which your mind organizes the world to make sense to you. When possible seek alternate perspectives. Ask yourself, ‘how would someone with no design training approach this situation?’

[[_SVA]]
#ux #ai 

Ask what people expect to be able to influence during your feedback sessions.
On this scale, show me how trusting you are of this recommendation.
What questions do you have about how the app came to this recommendation?
What, if anything, would increase your trust in this recommendation?
How satisfied or dissatisfied are you with the explanation written here?
#ux #ai 


So much of how you act and your approach to life is a result of your environment. Probably more than you realize though it’s likely if you are in a toxic environment that you realize it’s toxic. The trick then is to understand that even seemingly benign environments have a profound impact on you. That good life you’re striving for is really a comfortable life inside a supportive environment. It’s time to shift your focus from becoming a better person to creating better environments for yourself. You’ll grow much faster when you do.

[[_SVA]]
Blasphemer! Heretic! Jerk-wad! You cry out against me yet I am not wrong. What you begin with is important, sure, but what you do with your input is what matters. Garbage in-garbage out is a lazy approach that does nothing to create value.

Process is change with intent. If your intent is take a load of nonsense and process it into a different load of nonsense then you are a waste of blood and air. The goal of every process is benefit and value.

Quit spending time finding the right starting point and spend that time finding the right way to make things better.
Ba overlaid with Fa mouth movements with induces hearing Fa instead of Ba despite Ba being the actual sound. This is known as the McGurk effect.

#IxD
DreamBooth is proprietary to Google but there are open-source conceptual versions.
512x512 images and a token. 20-30 high quality images. Use birme.net for cropping.
Images need different contexts (i.e. backgrounds, clothing for people)
The prompt needs to include the token for the images.
FastStableDiffusion on RunPod
Your token needs to be unique. Google your token to see if any images are associated with it.
Try to avoid vowels in your token.
Files need to be named with your token and a variable counter. (e.g. ‘token 01’, ‘token-01’, ‘token_01’,’ token(01)’)
24GB VRAM
Roughly 100 UNet training steps per image unless training on a large data set where 60-80 may be beneficial
350 steps for the text encoder is generally a good idea. 30% of UNet training steps could be advisable.

#dreambooth 
https://arxiv.org/abs/2106.09685 #LoRA 
https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/
https://arxiv.org/abs/2005.07727
https://arxiv.org/abs/2312.04780
https://arxiv.org/abs/2311.17117
https://arxiv.org/abs/2310.04378 #LCM 
https://arxiv.org/abs/2308.00352 #metaGPT
https://arxiv.org/abs/2306.11644
https://arxiv.org/abs/2305.13048
https://arxiv.org/abs/2302.05543 #controlNet
https://arxiv.org/abs/2211.09800
https://arxiv.org/abs/2208.12242 #dreambooth
https://arxiv.org/abs/2205.10770
https://arxiv.org/abs/2012.07805
https://arxiv.org/abs/1706.03762
John Maeda talks about the Emotional Tetrahedron, which is the Iron Triangle with a surprise fourth point of emotion. [[Due to the impact non-determinism has on quality, ie failure is an option, you can only leverage speed, cost, and emotion.]]

 - add AI notices to force the pilot to think critically
 - suggest prompts that leverage the AI's strengths
 - build in feedback loops
 - give AI status updates
 - give more citations
 - add friction
 - don't humanize the AI

[[Collaborative UX via the Copilot stack]]
An incredibly important point to note about any creative endeavor is that the context it will live in is not the same as the context it was created in. This means unless you consider the differences in the contexts then your designs will be insufficient. Context changes at the drop of a note. It is nearly impossible to predict or create a context and your predictions will rarely be spot on. In the same way that planning is more important than the plan, the act of considering the difference in contexts is more important than getting the context right.

A crucial reason for considering contexts is the design of outcomes. We want our designs to catalyze a change for our audience. Every context requires a different approach to create a change. The types of variables which constitute our reality are so noisy that what worked yesterday when the sun was low might not work a month from now when the sun is high. Our designs either need to be bespoke enough to guarantee success in this moment or general enough to work in other moments. The balance is delicate and excruciating, if not impossible, to nail. Once again the act is more important than the result.

No context contains the possibility of every outcome which is precisely why you need to know what outcome you are designing for and which contexts are primed to realize those outcomes. Anything else is painting a target around your shots.

[[_SVA]]
Because you cannot control the speed of the AI due to mathematical constrictions, physical limitations, and power trafficking, you have to make things that are slow feel fast or at least make them feel less slow and ideally make them feel pleasurable regardless of their speed.

A story, considered true by many, witnesses this point.

https://rogerfirestien.com/when-mirrors-and-elevators-got-married/

Disney is a good example for delivering valuable waiting experiences. You can easily turn to the physical world for a metaphorical equivalent to a digital idea.

https://talkingaboutdesign.com/designing-experience-a-case-study-of-disneylands-lines/

Inflating posted wait times is a tricky one but overestimating and delivering early is highly valuable from a recipient's perspective when it comes to time.

Other tactics to make waiting less suck and seem faster are progress bars, streaming text ala ChatGPT, type-ahead ala Google search, and
citations/ads/magazines/waiting room reading.

Microsoft design talks about this as latency. As waiting for the level to load in a video game.
https://build.microsoft.com/en-US/archives/98228450-22d7-4722-bae8-923d116638d4


Are you against providing me with a short intro as to what made you want to speak with me?
Are there any areas you want me to focus on or areas you're least interested in?
What's your situation?
Where are you trying to go?
What are your obstacles?
What are your deal killers?
Who do you expect me to be?
What did you expect to hear from me and didn't?
Is there anything else you want me to know?
#business #intervew-practice-group
#ux #ai 

https://smarterpatterns.com/

The patterns are bucketed into Transparency & Trust, Autonomy & Control, Fairness & Inclusiveness.

These patterns begin with problem statements.

Way too much to hold in your head. A good resource to consult. Highly tactical.
All people are irrational people. All people are rational people. It is highly unlikely that you and the people you design for are the same kind of rational. It’s more likely that you’re the irrational one. The moment you decide to design for someone other than yourself you’ve automatically made yourself the irrational one. This is the burden you must bear. Learn to find the freedom in it.

[[_SVA]]
[[For interviewing to be fair and effective it needs to tolerate culture, discomfort, and biases.]] Our relationship with strange is primal. Social norms can only do so much in removing a programmed aversion to different. Ask yourself from the jump, why am I putting this other person in a category? What do I seek to understand from this designation? Can I not let the difference be irrelevant and move on? Discomfort is not difficult to sense. As soon as you become uncomfortable with your counterpart being different you make them uncomfortable for being different. Or you make them justify their difference and judge them if they fail to impress you. We're not looking for 'fit.' We're looking for competence and effect over comfort and preference. Don't fake sincerity, if you are feeling uncomfortable then remove yourself from the situation, acknowledge your discomfort and remove yourself from the process entirely. Disgust and distain do not a healthy foundation make.
#ai #UX 

[[Beneficial prompts for a UX designer]]
[[Midjourney lighting prompts]]
[[Business ideas]]

DALL-E 2 is built from CLIP, a Prior Neural Network, and a Decorder Neural Network (unCLIP)

prompt weight ::# two colons and a number, can also be negative, all weights must add up to positive

ControlNet is glorified img2img with more control #controlNet 
OpenPose works with people, creating a skeleton
More complex pose - higher weight
Combine pose and edge (canning)
Edge is good for hands
Depth created a B&W depth image
Dreambooth filters(?)
Use edge and depth for pets

UNet encoder and decoder network
 - learn noise distribution, predict it, remove it in steps
 - shrinks image in latent space

Fingers and abs suck because they are semi-repetitive patterns

Diffusion models are more stable and a better approach to training and generating samples over GANs and VAEs and normalizing flows.

Canny edge-detector is a standard edge detector.

[[DreamBooth started with Google allowing you to use your own content in pre-trained text-to-image models.]]

CLIP + VQGAN architecture predates Stable Diffusion and most other diffusion models.
Focus on data that is out of distribution.
Vision inputs have traditionally been camera based but in occluded environments like fog these cameras are insufficient. Shift to incorporating thermal cameras, polarized cameras, event(?) cameras, and depth inputs.
[[OpenCV predicts 2024 as another great year for open source.]]
https://www.meetup.com/data-science-dojo-silicon-valley/events/298895068/?_xtd=gqFyqDQ1OTYzOTUyoXCjYXBp&from=ref

https://code.datasciencedojo.com/iaziz/Building-Simple-and-Efficient-Chatbots-Demo

A good place to start conceptually:
https://www.ibm.com/design/ai/conversation/planning

Chatbots increase availability, decrease wait times, reduce repetition of interactions, and personalize services.

They solve limited availability, long wait time, repetitive interactions, and lack of personalized services.

Chatbot increase customer satisfaction improves brand image and reduces costs overall.

Chatbots can give you sentiment analysis, summarization, translation, and a solid Q&A.

I got this from a customer service industry expert.

LLMs are the fundamental concept of a chatbot. User -> Q/A -> LLM (pretrained) <- Data corpus

'I don't know' is an undesirable response from a chatbot.

Efficient prompting begins with giving the AI a role, then writing clear and specific instructions, giving examples of what the user could ask and what the reply needs to be and ending by asking it clear and precise questions.

#RAG 

The query goes through the external knowledge base (RAG) and appends any relevant info to the user's query before passing that to the LLM which is still pre-trained on a data corpus.

Infer the meaning of the user's query to retrieve from the RAG not a keyword match. This involves a vector search.

Learn more about properly chunking: https://huggingface.co/spaces/m-ric/chunk_visualizer

Prioritize refining and structuring the data you have over adding new data. Good semantic structure will never go out of fashion.

LangChain

Prereqs are Azure OpenAI Service
Jupyter Notebook

You need a starting text doc

https://scrapy.org/
For an open-source python driven way to scrape web content and turn it into a text doc.

https://www.gettingstarted.ai/how-to-use-gemini-pro-api-llamaindex-pinecone-index-to-build-rag-app/

#ai #chatbot

```query
tag:rag
```

https://www.linkedin.com/in/designemissary/

Howard Pinsky, Design Evangelist

Adding provenance to images when exporting

Adobe segments their experience into functions, text-to-image, generative fill (edit), text effects

Have to update functions to new image models

Makes svgs, which are mathematical outlines, maybe canning?

One way to grow is to evangelize the creation.

He doesn't see many interaction designers using AI or these tools.

Content credentials inside of Photoshop will change if you download from Firefly and update in Photoshop. contentauthenticity.org/verify

Provenance is how history has solved the problem of fake news but we've lost sense of it. We've become deluded. Adobe is bringing provenance back. Free speech and all but speak true. Your false narrative, false memories, and revised histories have no place here.
!BUT What if I don't wan't my stuff hijacked with credentials?
 - You gotta use another software.


The Muller Lyer illusion is not applicable to non W(hite)E(ducated)I(ndustrialize)R(ich)D(emocratic) audiences.

#IxD
Life is a cyclical and not a linear process. From perception to action is one model for human interaction. There's a strong argument to begin with action and cycle through the world, perception, cognition, and back into action.

[[Users need visual, audible, and other sensory or perceptive evidence to know they've taken the correct or beneficial action towards their goal.]]

#IxD
OpenAI: https://platform.openai.com/docs/introduction

Lumalabs: https://lumalabs.ai/genie?view=create

Free Twelve Labs credits: https://docs.google.com/forms/d/e/1FAIpQLSfM3Br3-zhZshGbC2lK21uOUSm-ea1xtDRs3DwPd31dHKJ2WQ/viewform

Twelve labs: https://drive.google.com/file/d/1NYqxgAVU-qPPJqOl9lvbbeNGbxluGxmL/view?usp=drive_link

founders@kuratech.com
kp@kuratech.com

#ux #ai 


#ux #ai 


#ux #ai 

AI notices for the user to think critically. Suggesting prompts tells the user what the AI is good at. Citations enforce more work. Status is more information. More information is friction. Not humanizing AI is adding a lot of friction.
Keep the values of fairness, equity, and equality in mind as you are interviewed and interview. Your tenets to fair and effective interviewing are to understand culture and it's impact on a person's life experience, be comfortable with different, learn your biases and implement balances for them.
[[Culture creates a lens through which an individual perceives and interacts with their environment and the people in it.]]
[[Different is uncomfortable.]]
[[Biases are unconscious leanings you have.]]
Most services restrict consumption of model request meaning the result you get back has only spent so much time in the model before it was removed. The general artifacting of images is reduced with more time in the model. I believe this is generally known as steps, but I'm not sure. #ai
It is possible to change your perception. In that aspect, our brains are wonderfully malleable sacks of water. While this change may be seemingly impossible with a basic understanding of the element which shape what we see it will be easier.

The first element is context. In this case context means everything your brain has processed since the first neural connection was made. That’s a lot of processing. Most of the processing has been done without a conscious awareness. All that means is your history has primed you to accept certain perceptions more easily than others. Once bitten, twice shy is an example of context in action. You can’t go back and redo what has already been done but you can remember the past differently. History is written into the wiring of your brain, which as noted before is highly malleable. Rewrite your history. Remember events and change the narrative in your head about the event.

Context is a bit tricky in that it is shaped by cultural and individual differences. Your life is your life. Everything that happened to you is unique to you but you’ve existed inside an environment that we often refer to as culture. Culture is a collective context. It’s the social history, shared beliefs, laws, norms, rights, and roles of the people surrounding you. Culture can be minute or massive. Culture changes over time. One quick way to shift your worldview is to jump cultures. That’s not an invitation to change the culture around you. That’s an invitation to leave your current culture for a new one. Move.

A second element shaping what you see is experience. Context contains and influences experience. Experience is the thread of meaningful moments that have led you to where you are. Context is subtle. Experience is not. That time that one day you felt pure joy is an experience. That time that other day you felt trepidation is an other experience. Experience is unique in that it is a full body thing. Experience lives not only in your mind but in your emotions and in your muscles. Tension is experience. Trauma is experience. Nostalgia is experience. Experiences need to be confronted to be changed. Once again, you can’t go back and redo what you’ve experienced but you can reinterpret and understand your experiences in a different way. If you can integrate the tension and trauma back into your self you release it. You allow the experience to let go of it’s hold on you. Once bitten, twice shy becomes once bitten.

The final element is likely the headiest of them all and that is schemata. Schemata are mental architectures. If all you have known are horses and you see a zebra you will think it an oddly colored horse. Which is not entirely untrue just not nuanced. Perhaps a better example is the common banana. If all you have known are grocery store yellow bananas and you come across a plantain you might be tempted to treat it like a yellow banana. A more nefarious schemata exists around human differences. If all you have known are melatonin deprived humans when you encounter a melatonin rich human you may be tempted to treat that person as less than. Schemata are organized patterns of thought or behavior. They are the boxes with labels that you place things in. They are built up through experience in context. As such schemata are the easiest to change but the least influential. Opening yourself up to being wrong about what you see starts the schemata change. Knowledge can change schemata. But really, change the label and you change the schemata. Switch bad to good, gross to unexplained, harmful to misunderstood, empty to anticipatory. Your architectures or thought aren’t so bad it’s when you misapply them that matters.

With an awareness of the factors that shape how you see the world you can influence them. You can design your worldview to reflect who you want to become. Start now.

[[_SVA]]
Thanks for removing these sliders I didn't know how to use. You can toggle them so they are not in there by default. To hide and show those advanced things.

How pricing works and the massive growth from India but how are they finding you? 2 weeks over 1.5mil new people added to the old people. Which almost killed their product.

New enhancer is benchmarking at 4k better than Tuesday and 4x faster. 85mb of image. 7.6k per 9.6k. Their Macs fail every day. This stuff is nutz with hardware.

You see the base images you use to upscale. Upscale EVERY image I own.

Expand and contract the sidebars with advanced options by hiding what isn't necessary to bring forth the canvas. It is super great to have the thumbnails on the left to prevent scrolling.

$8 is way more than a user can expect from this service. You cannot find a better technology for less money than KREA.

KREA has moved up the early people in pay tiers out of reverence and respect.

KREA was born in Barcelona.
#ux #ai 

Start here
https://www.microsoft.com/en-us/haxtoolkit/library/?content_type%5B1%5D=example
https://www.microsoft.com/en-us/research/uploads/prod/2019/01/Guidelines-for-Human-AI-Interaction-camera-ready.pdf
https://erichorvitz.com/chi99horvitz.pdf

https://www.microsoft.com/en-us/haxtoolkit/ai-guidelines/

Great place to start a project
https://microsoft.github.io/HAXPlaybook/
e.g. https://microsoft.github.io/HAXPlaybook/?state=200002xx

The HAX playbook shows foreseeable failures in NLP scenarios like search. It is extensible but not all inclusive of AI.

Also a helpful place to begin but not a great place to begin.
https://www.microsoft.com/en-us/haxtoolkit/workbook/

I will take away from the HAX that when you are conducting a project the HAX is a good companion item to have. Considering that it is 18 in number there's really no use trying to memorize it all.

https://www.youtube.com/watch?v=JppYmctp0a8&t=16s

The HAX is for supporting AI builders. Human-centered is the core. [[The data for the model needs to be the data of the people using the model.]]

Media and ignorance create unrealistic expectations of AI that need to be tempered by the builders and people who know what the AI can do. Like how CSI influenced the public's expectations of how crimes are solved.

Act when the user benefit outweighs the resource cost but prioritize the patterns across all guidelines. The HAX has research that can be used to justify a design decision.

There are 8 guidelines that present unique challenges for human to AI interactions. These guidelines contain patterns.

[['You have stated your intent is this. With relative confidence this path with yield success. Do you want to act?']]

Responsible AI principles of Microsoft.
 - Fairness
 - Reliability
 - Safety
 - Inclusive
 - Transparency
 - Accountability

Microsoft Research leaders don't require their designers to build an AI to be useful.

The culture these tools/AI are used in needs to be considered with research. [[Culture isn't static therefore the research cannot be static.]]

Cognitive walkthroughs are evaluative. The HAX could be used for evaluation though it is best served as an upfront and along the way tool. Designing for the HAX isn't easy with an AI that is already designed. The HAX is more for planning than recourse.
#ux #ai 

https://build.microsoft.com/en-US/archives/98228450-22d7-4722-bae8-923d116638d4

John Maeda covers most of this and more in his LinkedIn course. [[John Maeda's UX patterns for copilot.]] This content is a nice addition but an addition no less. Don't start here is what I'm saying.

Kurtis Beavers
Rachel Shepard

'Natural language is now the primary interface.'
– PapaBG (Bill Gates)

Copilots are AI like NLP, LLM, GPT-4 to assist people with complex or cognitive tasks. As AI learns it is guessing. It's a complete idiot at the start and needs to know if it got it right. Was that beneficial?

The Copilot experience is working with an idiot savant. The Flowers of Algernon experience before he become a genius. [[Given what an LLM is good at can it be beneficial in this context?]]

Copilot design system is:
 - UX framework
 - Design language
 - Interactions
 - Patterns & components
 - Content design
 - Ops across disciplines

Documents and sentences are different altitudes and may need different Copilots.

AI notice is a pattern to call out the AI. Suggested prompts. Latency is space while AI processes. Adding friction to review output before taking ownership. 'Are you sure you want to continue and not that you want to read the link?'

Be thoughtful about architectures and infrastructure. Can't replace a research but can augment and do a sentiment analysis. AI can't replace the expertise to make a decision. Will the Copilot cannibalize applications?

Given the integration of Copilots you may have made functions, pages, and stories of yore obsolete. You don't need GPT-4 to do a Q&A on top of a data set.

Prompt engineering is an attempt to impose traditional logic on a non-deterministic machine. It cannot solve all problems. Sorta like plugging holes in a dam. Maybe you need a new dam.

Writing longer works better for AI. People who don't know how AI works won't figure out how to make AI work. People who know how AI works say 'I failed,' people who don't know how AI works say 'it failed.' Traditionally it has been the other way.

Fabrication over hallucination.

Design for AI is taking big and framing, not taking nothing and creating. Design for AI is often about restricting and defining what the AI can't or won't do.


Text in the prompt is weighted individually in accordance with the overall context. Tokens don't consider pairings, only weights in context. Thus blue hat is weighted as blue and hat. The likelihood of hat carrying more weight is high as blue on it's own is generally less common. Therefore you get a hat and the likelihood of it being blue is proportional to it's weighting and the model.

[[Processing steps inhibit an AI image generators ability to deal with crowds.]]
https://docs.llamaindex.ai/en/stable/getting_started/starter_example.html

#RAG  #ai 

RAG is a solution to limit context windows. Likely 100ms of tokens of data. Not practical to give all tokens with each query.

RAG gives you the following value: accuracy, faithfulness, recency, and provenance (citations).

Get an LLM to write SQL queries. Vectors are gigantic arrays of numbers. Data is encoded as meaning not words. Embedding is converting words into vector numbers.

LlamaHub has connectors to other software to grab datums. This is useful if your data is all spread across many software stores.

Llama index has their own prompts so you don't have to focus on prompt engineering but you can if you want. Prompting is giving arbitrary text to an LLM to tell it how to answer a question.

Use LLM to break apart complex queries and sends each query to the appropriate data source. 

BM25 search.

Hybrid search runs the same query against tradition and vector search but not all vector DBs support this function.

npx create-llama
npmjs.com/package/create-llama

Pre-processing and post-processing strategies for dealing with off-topic queries.

LLM will have higher latency than traditional keyword search. LLM begins answering a question immediately so stream the results.

Local models can improve latency at reduced cost. Latency is best solved with more hardware. Accuracy is best tuned with a querying strategy. Mess with the size of your retrieve content to improve accuracy, latency, and cost.

PII detector will help you get rid of protected info from your documents. LlamaHub has these preprocessors to help with that.
Preprocessing, ingestion, pre-aggregation, and filtering are key to data cleanliness.

Agents are the hotness in AI right now. Get AIs to use tools and take actions over answering questions. Combine RAG with an agent.

Separate vector stores per data type is recommended because you can query separate stores.

```query
tag:RAG
```


[[Build a circle of mentors with six people.]] Challengers are the reflective force of your energy. Challengers ask the tough questions. They block you. It's not out of hate though it could be, make friends of your enemy, instead challengers seek to push you from good to great.
[[Business processes tend toward optimization not generation.]]
[[All plans are fiction.]]
[[Numbers offer a false assurance.]]
[[Qualitative disciplines are ambiguous by nature.]]
[[Business and design are different cultures and do not benefit from being unified.]]
[[Language to use when taking about design decisions]]
#ux #ai 

https://www.ibm.com/watson/assets/duo/pdf/everydayethics.pdf


Arithmetic symbols are common operators.

[[Relational operators are used to evaluate boolean expressions.]]

#programming #beginner
It is commonly known that cancerous growth will return if every bit is not removed. The model does not apply to ideas. You forget ideas. You can’t remove them. What has happened cannot unhappen. You have to distract yourself away from thoughts for so long that they cease to be relevant and are tucked away. Memories are twitches of the system. They are anticipatory, anxious, and ready to approach what has already happened. This is how songs get stuck in your head. The longer you’ve had the song in your head the harder it is not to hear it all the time.

Machiavelli teaches us how to notice if we are being treated as a cancerous growth and not as beings with ideas. His promise is freedom of ideas not domination. Domination is a weapon of oppression.

[[_SVA]]
https://www.youtube.com/@opencvofficial

The human eye can't see IR so these cameras use IR as their light source. IR doesn't cause your pupils to constrict. You have two cameras, one to see the scene and the other to track the eye.

Apple Vision Pro has 4 IR cameras and 12 cameras overall. 1/3 of the cameras are dedicated to eye tracking. 2 IR cameras per eye for 4 total.

Getting ground truth is matching the environment to the gaze, this can be done by asking to stare at a target or double clicking on a button because you look at a button before clicking on it.

Dark pupil and bright pupil are two ways to to determine pupils. Pupil detection has shifted from edge detection to deep learning neural networks like NVGaze and CNNs.

Use a beam splitter, which is a half-silver mirror, to allow the camera to see the eye front on without the camera.

The FOVEA and not the optical axis determines the gaze. The optical axis is the pole that run through the center of the eye. The FOVEA is offset from the center by a number of degrees which varies per person. This degree difference between the optical axis and visual axis is called the kappa angle. Because of the kappa angle devices need user specific calibration like, look around the screen at these dots.

Pupil center corneal reflection PCCR can determine the center of the pupil but you can use more eye features like iris location and eye contour in addition to corneal reflection and pupil.

There are a lot of synthetic datasets for eye tracking training. Many are from the 2010s. These can be used to train your eye tracking model without training it yourself.
What software do you use on a regular basis? When was the last time you adopted a new software?
Knowing how the eye works helps. Knowing culture and iconography helps. Being able to write a script helps. Knowing your user's capabilities helps as well.
Can’t be a thing. Truth is true. A truth that is not true is not a truth.

Get over it. Truth is not for us to understand. Truth is not for us to accept, acknowledge, or avow. Truth is for us to ignore. Live a better life. Stop concerning yourself with truth.

[[_SVA]]
The space in-between what you imagine and what you see is the space of the artist. Few people dare call that space home. It is an uncomfortable space. We are used to ideas. We find extreme joy in them. Anything that exists in the self-contained universe of our mind is safe from error. As soon as you move an idea towards a concrete vision you start to cause problems. The haze can’t exist. Decisions have to be made. The form must be solidified. 

I’m not saying there is no value in an idea or that execution is all that matters. I think that the people who are willing to journey across the void between idea and reality need to be celebrated more than they are. Art is general considered a leisure pursuit. Obviously in art circles this is predominantly untrue. By and large in the greater culture of society it is. As people we understand the struggle of giving form to vision. This is likely why there are so few people who identify as artists and even fewer who are willing to undertake it as a means of contribution.

I’ll make an assertion that the people who make things, not the people who make things happen, but the hands on artisans should be the wealthiest individuals in any society. They do the most difficult work. Anyone who has ever tried to bring an idea to life will know. If we adopt this posture we’re likely to see greater advancement, socially, culturally, technologically, and emotionally. We’re better off because we go through the discomfort of giving form to vision not in spite of it.

[[_SVA]]
#ux #ai 

Install extensions to work with different languages

Restart with each addition or at the end of a lot of additions

Install an interpreter
cmd + shift + p > "python interpreter"

shift + return runs code selection/line in terminal

right click to get to run in terminal

#programming #beginner
#ux #ai 

https://www.oreilly.com/radar/machine-learning-for-designers/

Unit test are run on the user's machine at installation to ensure the software works as intended.

Identifying faces is easy for people and real hard for computers.

A linearly inseparable problem is a lack of a binary separation or single line upon which delineation can occur.

A Perceptron, invented by Frank Rosenblatt in 1957, is an early example of inductive reasoning in machine learning. It works from distributed representation. Perceptrons do not account for interdependent relationships between attributes and as such are deficient.

The four ways of machine learning are supervised, unsupervised, semi-supervised, and reinforcement learning.

Supervised learning takes inputs and their corresponding outputs and induces the rules that govern the system. They are supervised in that the proof is given, the system substantiates the evidence. Supervised learning best addresses classification and regression problems.

Unsupervised learning takes data and finds patterns generally too complex for humans to discover on their own. This style of learning can produce generative models which can make from the patterns they learn.

Semi-supervised learning uses the patterning of unsupervised learning to improve supervised learning. Data is distilled and cleaned through the unsupervised learning before being passed to the supervised system. This approach is beneficial if only a small portion of the training examples have been associated with a known output.

Reinforcement learning is not trained on existing data but learns from the feedback regarding the consequences of its actions. This is useful when reward is the point like in a game or when success conditions are vague.

Hierarchical feature learning, object recognition.

20 questions is a learning decision tree (classification tree) AI. The 20 questions process could apply to discovering an optimal path through a large number of interrelated decisions.

Hum a song and get a result is a machine learning problem.

Approachability, What can it do, How to interact, the unreliable nature of non-determinism, faulty assumptions like labeling Black people Gorillas, not including a sanity check, poor data

Inductive learning is like a search and any task is a search for the proper operational steps to produce an outcome. ML! Based on historical action this is your intent, did the AI get it right?

Poor training data with a masterful algorithm might give worse results than poor training data in a terrible algorithm. Your four main data considerations are completeness, accuracy, consistency, and timeliness.

Heuristic
Design systems that respond to a user's request and enriches the user's understanding of the domain itself.
Give a small example for the user to complete using AI, like a playground.
Indicate the kind of information you need and what you'll do with it.
Suggestions or a 20Q like interface to come up with what you want.
Provide confidence scores alongside speculations
Have non-ML, maybe human, and possibly code based check on data inputs and ML outputs, to stop the Tay bot and its racist remarks.
Have the system explicitly restate the task.
Provide fallback mechanisms.
Small releases to red teams.
Use confidence scores to assess the validity of included features.
Show the risks of an AI feature.

http://www.wekinator.org/

#ux #ai 

https://miro.com/miroverse/ai-design-toolkit/

Considers bias. Uses service blueprinting for AI architecture. Focuses on before ML and after ML.
https://youtu.be/LlcFkDFYFkk

A challenge is to make the AI actions obvious. A challenge is user comprehension. Explaining what the AI does.

Make sure a user doesn't need to be a prompt engineering genius to use our AI.

Don't let users change input values while the AI is working so the user doesn't think their in process change will be reflected in the AI's output. Provide a cancel or other way to stop AI in process.

Provide a starting point for prompts. Present the most likely actions and allow for exposing more.
#ux #ai 


Designing for teams is a complex process, with a multitude of considerations to keep in mind. From the size of the team to the different types of decision makers, designing for teams requires a nuanced approach. But one of the most crucial aspects of designing for teams is considering user roles, permissions, and account administration.

When do these considerations come into play? According to a collaborative tool designer, it's important to start thinking about them as soon as something becomes collaborative and there's a concept of multiple people being able to access something. Even if the number of roles or permissions isn't that complex at first, it's essential to create a simple, scalable model from the get-go. If the early model doesn't scale well, it can become a technical and UX burden that the team will have to live with for years to come.

So, how can you create a solid foundation for user roles, permissions, and account administration? Start by looking at other tools, such as Google Docs or Dropbox, and see how they handle permissions and roles. Build a table or matrix of their permissions and roles, and see how they work for your own product. Then, decide where you want to deviate or stick with established models.

It's important to note that different teams have different needs when it comes to user roles and permissions. For example, a 10-person team may be more concerned with individual employees who have a say in which tools they use, while a 1,000-person team may be more concerned with decision makers higher up in the organization. Designers need to take these nuances into account when creating user roles and permissions.

Another important consideration is how user roles and permissions affect collaboration. Collaborative tools should make it easy for team members to work together seamlessly, regardless of their roles and permissions. This means that designers need to think about how user roles and permissions affect workflows and processes, and create a system that facilitates collaboration rather than hindering it.

Finally, it's important to create a system that is flexible and adaptable. As teams grow and evolve, their needs for user roles and permissions may change. Designers need to create a system that can accommodate these changes without causing disruption or confusion.

Designing for teams is a complex process, but by considering user roles, permissions, and account administration from the outset, designers can create a system that fosters collaboration, facilitates workflows, and adapts to the changing needs of teams over time.

[[_SVA]]
#design 
https://www.youtube.com/watch?v=Q1Wq028TRoc

One dude has a creative background in music photography and visuals for a band.
Yolo of algorithms to determine objects. Maybe OpenCV
Recognize images of plants, cars, cities, et al & combine then and train a models, it learns shapes, colors, textures. Back in 2017. 7.Years.Ago...

Toy Story was this guy's childhood and driving force. He started with object detection to see if his toys moved in the night. He wanted to be a 3D modeler but got into engineering on the side.
YC $125000/yr to make money.
5k for 6%
125000 in convertible notes
HFZero, Lucy
84 when he was 8 for the older guy

Go through all these programs to express these visual ideas inside. Logic Pro. Cinema 4D. Each one I have all these unnecessary steps to learn them when all I want is immediate access to the output.

You end up with a powerful paintbrush but there is nothing individual to it. AI doesn't propagate the value of your flesh experience.

[[Printed paintings might be possible with highly detailed photos, a topology map, and a 3D printer.]]

Not much use in a business plan, in general in your head it is usually clear what can be clear and about not being clear what cannot be clear and that is what.

Zero Billion Dollar market. NVIDIA bet the future on 3D games and created a zero billion dollar market.

You have to be comfortable living in constant rejection. The entrepreneur life.

Praising in public and criticizing in private. But maybe criticize in public.

The interactions will become semantic. Put a paintbrush on a computer screen. Photoshop will turn into interactions like a painter.
50 AI programmers programming for you.

This one guy uses Photoshop as a benchmark. 99% of Photoshop is obsolete given the new AI interaction pattern of highlighting an area and changing it.

Science advances in funerals. An artist is never valued until after they die.

Asymptotically exponential
The bitter lesson essay. Scale is all you need.
Now I make an app in a weekend even though I don't know how to code.
We are democratizing access to intelligence not just knowledge.

#ai #UX

We desire to fill space, conceptual and physical. Forget for a moment that space is already filled and hollow cannot be as it is conceived. Imagine the space in between here and there. So much of how we operate is grounded in self-defined laws of reality. You can’t get there from here without filling the space between with something, most likely action or movement.

Or can you?

Let’s say you can.

I’m not suggesting that you can place your body in various locations on Earth without some manner of locomotion. That may be possible but highly unlikely. What I am suggesting is that doing nothing is always a valid option. The space between doesn’t need to be filled. It doesn’t desire to be filled. Our own discomfort with inaction is what moves us. Our little biological processes conspires, moment by moment, to move us in some desired direction. Survival is hard-wired and we are grateful for that. For just a moment though let the need to do something go. You can have it back after this. Simply feel what it means to exist. You might find that once you do you’ve gotten where you want to be.

[[_SVA]]
#ux #ai 

https://www3.weforum.org/docs/WEF_Artificial_Intelligence_for_Children_2022.pdf

Ethics, bias, and liability
A11y, neuro-divergences
Audience appropriate
Does not promote bullying or addiction
Is explainable.
[[Compass holders give you direction and inspiration by staying a few steps ahead.]]
[[Yoda keeps you balanced by pointing out what you do that nobody cares about.]]
[[Co-pilots will collaborate with you.]]
[[Connectors bring you to others and others to you.]]
[[Optimizers keep your work from being ineffecient so that one aspect of the work doesn't overwhelm the others.]]
[[Challengers are the immovable objects to your unstoppable force.]]
Look for these people in your life. Find a way to enlist them on your journey. Seek their advice in earnest not out of obligation and heed their advice as you hope they heed yours. Building a circle of mentors is not tough to do.
If you’re ever someplace strange and you don’t think you can connect with the people around you, talk about pizza. Rare is the person who has not experienced pizza. You may disagree on many of the details but the shared ones are what matters. Show up any place with a pizza and you’ll make friends. 

[[_SVA]]

Humans are obsessed with truth. We look for truth in everything. Knowledge can be said to be the pursuit of truth. Americans created a ritual of swearing to tell the whole truth and nothing but the truth so help us God. Scientific inquiry exists to uncover truths about perceivable reality. Deception is a slight against people so severe that we cry for visceral benediction in response. Truth is the foundation we build our lives on. We need a foundation. We’ve called it truth. 

Trust is an expression of truth. With few exceptions humans only trust what we believe to be true. Our challenge to creating trust then is knowing what others need to believe to be true.

If you’re a person trying to gain the trust of another the prevailing theory is that all you need is to convince the other that you will not harm them. Said another way, you will not take anything from them, namely their physical safety and more abstractly their sovereignity.

If you’re designing something which needs to gain the trust of your audience the challenge can seem insurmountable. It’s not.

True, truth, and trust share a root. These concepts are inextricably linked and great insight can be found in that link.

If you want to gain trust determine what needs to be true and make it so.

[[_SVA]]
[[Loose systems encourage appropriation or at least allow for it]]
A prime value of the object-oriented approach is that it reduces the cognitive load of the audience.
The psychological underpinnings of object-oriented UX are gestalt and ecological.
Avoid separating the action from the thing it acts upon by keeping the button and the object close by.
Traditionally UX is verb and flow based not anchored around objects.
Events and articles are example of considering content types as objects.
Don't use a product photo for a category, use a category photo as a category and a product are not the same object.
Different objects need to look different.
Because lifts and trails are connected they need to be connected in the app. Gerry McGovern calls connected objects Twins.
Make sure the actions present are relevant to the object and context.
Use nouns from interviews, branded content, and posted media to create objects.
A useful ChatGPT prompt for pulling objects from language is 'list the nouns from these documents in order of frequency.'
Object-oriented UX teaches the Objects, Relationships, CTAs, and Attributes framework named ORCA.
*not written by me

Launching a new product that competes with existing solutions can be a daunting task. On one hand, you want to offer new and innovative features that differentiate your product from competitors, but on the other hand, you also need to provide important feature parity that meets the basic needs of your users. In this article, we'll explore how to balance innovation and necessity when designing for feature parity.

First and foremost, it's important to understand that users are unlikely to switch to a new tool unless their existing tool is either incredibly painful to use or the new tool is significantly better. Therefore, it's critical to offer enough functionality that users can reasonably use the new tool for simple versions of core use cases, even if it's initially more challenging to use. However, you also need to include features that make your product feel differentiated and appealing, especially at launch.

When launching FigJam, for example, the team actively traded off core functionality like a timer or voting, which other tools had, in order to build features that they didn't. They quickly followed up with those tools to create feature parity, but their initial focus was on providing unique features that would attract users. For example, FigJam offers cursor chat and high-fiving, which are not available in other collaborative design tools.

It's also important to show momentum in building new features. As a new tool, you want users to trust that you will eventually get to feature parity, even if you're not there yet. Therefore, it's critical to have a roadmap that shows users what features are coming in the future and how they will benefit them.

Ultimately, the key to designing for feature parity is to strike a balance between innovation and necessity. You need to provide enough functionality to meet users' basic needs, while also offering unique features that make your product stand out. By doing so, you can create a product that attracts users and keeps them coming back for more.

[[_SVA]]
#ux #ai 

https://adamfard.com/blog/ai-ux-design

https://uxpilot.ai

Breakdown of using AI tools in the UX process. Definitely a good find.

The best practices of AI begin with trust. This author uses Bjorling and Ali's 4 pillars as a framework for these AI behaviors.
 - communicate the AI's capabilities
 - the AI resonates with the users in its communication
 - the AI is flexible
 - the AI is ethical

Designers are more prone to adopt AI as a virtual assistant. People (read: designers) tend to trust AI more when they feel in command.
#ux #ai 


Human beings have developed a remarkable talent called projection. Projection in this instance refers to a mental time jump into the future. As a species at some point we started to become aware of the idea of consequences, that you can thread your current actions with a future result. This is a highly useful realization. It is not without fault. Many enlightened minds will tell you the future doesn’t exist. Regardless, we have come to understand we can control the world around us to create specific outcomes. We could not do this without an understanding of consequences. We could not get better at it without projection.

At all points we carry with us an aim, something we’re trying to accomplish. We work to change what we can in order to see that aim fulfilled. Projection helps us determine how to bridge the space between now and what we want to be different. We project because the variables are too complex to manipulate in the moment. No brain can correctly navigate the now without preparation. It is why we have an aim. A guiding light. The simple truth is that as immense as our conceptual power is we cannot handle reality and our intentions at the same time.

Mitigating that inadequacy is simple. Your tools are planning, rehearsal, and play. Planning sets up the play space. Planning gives you the script. Planning lays out the path. Rehearsal is walking that path. Rehearsal is the execution of that plan. Play is the keystone. Play determines the table stakes. Rehearsal doesn’t happen in the moment so the stakes can’t be the same. You want your play conditions to be as close to the real conditions as you can make them with one crucial difference. Play says it’s okay to get it wrong. Play says your rehearsal can be a failure. Play says try again.

If you want to achieve success your main focus needs to be on planning, rehearsal, and play.

[[_SVA]]
#ux #ai 
‘Does the design meet the goal,’ is the obvious response to the question, ‘is this design effective?’ Does the design create the change it was intended to create? Does it leave a mark?

We often consider designs ineffective when they don’t produce a value, fill a need, improve a life, or if they negatively impact the world. If these conditions aren’t met most humans won’t even bother with the action.

Ineffect is a tactic of subterfuge. You can disrupt a system by making it ineffective. Introduce subtle diversions, add steps, slow it all down, or speed it up. This is how bureaucracy shifts and the DMV becomes a hell space of waiting.

We might do well designing more ineffective things. Instead of thinking about ineffective as the fail state before effective make ineffective the goal and effective the fail state.

[[_SVA]]
I wonder if there is a level of complexity above which something cannot be designed. It seems to me society is an emergent event that catalyzes the working elements into a stable design and not a conscious act of producing an outcome.

Or is it that the boundaries which circumscribe society are designed and the middle is left to figure itself out?

Systems are an increasingly popular consideration amongst designers. Society can be conceptualized as a system. Though the elements of that system may be too numerous to be articulated well enough for design.

Design is tricky. It has limits but can be limitless. In a highly abstract way, life is designed. Yet I’m skeptical the task could be completed if it were a conscious act. Gods can design anything. Nature can design anything. Humans, maybe not so much. I find a certain arrogance in the promise of design which exists in contrast to the hope of design. Is society proof that design is an illusion or merely that myopia is real and design truly is all encompassing?

[[_SVA]]
#ux #ai 

https://uxofai.com/

Begin with human-centered machine learning. Set expectations about what the AI can do. Explain the results means showing the math. [[Communicate confidence with multiple options ordered by rank.]] Design for failure. Know when to bring the human in the loop. Keep the user in control. The AI grows in capability the more you interact with it. Monitor and change your model over time. Personalized AI can become an echo chamber if not planned for, consider including a contrarian AI. Don't give AI a personality outside your brand values. Chatbots are not for single tasks. [[Prototype with real data and fake AI.]] Design with everyone. Be transparent with your users about your data policies and processes. [[Don't collect what you don't need, use on-device ML instead.]]

https://medium.com/google-design/human-centered-machine-learning-a770d10562cd
A bad idea is a highly valuable idea because it reveals to you much about what you consider bad. Prospect theory teaches us outcomes are perceived as gains and losses and that losses feel massively worse than equal gains feel better. Basically that fear of loss drives our decision making. It’s more that fear of loss creates a frame and a biased perception in which the least bad option is the best option. Knowing how much bad you’re willing to bear is a consideration.

Draw a chart or a pie graph or some blob thing and use it to map the relationship of percent good to percent bad of your design. Removing the bad instinctually though erroneously correlates to the addition of good. In actuality, goodness is not a default so the space remains empty. You must also imagine ways to add goodness but it’s easier to convince people of the value of removing something bad. Which is how we get problem solving and not value creation as a key skill of successful industry tycoons.

If you can predict when something will go bad you can mitigate against it. Culturally we have rituals like regular doctor visits. We have spoiled food. Knowing something bad may happen and protecting against it is human nature.

Create a lot of bad ideas. Pull good ideas apart into bad idea. Get all of the bad ideas out. You’ll know where not to go and that will help focus the way.

[[_SVA]]
#ux #ai 

https://girardin.medium.com/experience-design-in-the-machine-learning-era-e16c87f4f2e2

A good heuristic is a profile detox which allows users control over the data. Good recommendation engines have humans cleaning datasets and mitigating the limitations of machine learning.

Algorithms are evaluated on their precision and recall scores.

Variable schedule rewards are a slot machine technique applied to the attention economy.

A good heuristic is to consider the feedback loop. A challenge is understanding.
 - Co-create a tangible vision of the experience and solution with priorities, goals and scope
 - Assess any assumption with insights from quantitative exploration, desk research and field research.
 - Articulate the key questions from the vision and the research. Is the team asking the right questions and are the answers algorithms could give actionable?
 - Understand all the limitations of the data model that gives answers.
 - Specify the success metrics for a desirable experience and define them before the release of a test. The validation phase acts as stopping point and it must be defined as part of the objectives of the project (e.g. improve the recall of the recommendations by 5%, detect 85% of customer who are about to default).
 - Evaluate the impact of the data engine on the user experience. As stated by Neal Lathia, it is particularly hard for data scientists to work “offline” on an algorithm and measure improvements that will correlate with improvements in the actual user experience.

The moment before lightning strikes is a moment few humans are fortunate enough to witness. This miraculous occurrence reveals an incredibly important aspect of energy. You see, the moment immediately before the flash, the release, the thunderous crash of particles, in this moment before, a small part of the Earth reaches up to receive the lightning. Lighting doesn’t happen to the Earth. Lightning happens because of the Earth, because the Earth needs the release, the connection.

Michelangelo got it right. The moment before you act, a small part of the world is reaching out to receive you. It needs you to contribute. It wants you to contribute. There is great power in this moment. Use it.

[[_SVA]]
#unity #programming 
Not a cost benefit of using open-source models in production. The economics are not in favor of small scale AI.
You have not mastered a song when you can play it perfectly, you have mastered a song when you cannot play it imperfectly. What may seem daunting at first becomes effortless through repetition and adaptation. Whatever you’re facing is easy, it just might not be easy yet.

[[_SVA]]
You can’t design the past. That may seems obnoxiously obvious but it points to a crucial notion about design. Design is always about new. You can design something to seem like it could exist in the past but you can’t design backwards. This means design is the domain of a certain type of person. The type of person that continually seeks to create change. The skills and mindsets necessary to be a good designer are about motion. Designers envision a possibility and then work to make that vision a reality. If you live for the way things were you may find designing displeasurable. That’s okay. If you crave exploration and possibility then the world of design could well be your home.

[[_SVA]]
Open a terminal window to find out the version.

Type python3.11
Exit() to exit
cmd + D exits
quit exits

python -c command [arg] ... is another way to start python

python -m module [arg] ... to access modules

Adding -i before a script enter interactive mode after running the script

print(type(var)) prints the type of variable

import keyword > print(keyword.kwlist) will print the full python keyword list

** is exponent 2^3 or 2 x 2 x 2

// is floor division operator for no remainder

% gives remainder

commas aren't for numbers

input() takes an input

hashtags start comments

Python does not treat all numbers the same.

Blocks in python need to be indented.

if and else statements end with a :

if 5 > 6:
 print("nope")
else:
 print("yes")

def {name}(): creates a function

input() types is a string by default

return {var} is how a function returns a value

#code #python
Microsoft conjectures on Sora. 2/27 and 2/28 update.

Core architecture is diffusion model. Peebles at UC Berkeley. Image was extended into video.

More picture frames in each second for realism. 15 seconds at MAX. 60sec with Sora. Did not do any physical simulation.

Emerging properties are 3D consistency, long-range coherence, and interacting with the world. These are built from a larger video model. Emerging properties are not in-built.

Video encoding -> VAE -> Diffusion transformer

Video Latent Diffusion Model compresses videos into latent tokens and that is how video is represented in Diffusion Transformer architecture.

We use the internet data and image caption. System learns. Lots of noise with internet data. Trained an image captioner. Generate a text description, self-trained the caption then trained DALL-E 3. Which is different than MidJourney.

Retrained video captions like training DALL-E3. Before transformers there was U-Net is CNN. Transformer likely to dominate AI architecture.

Loss function is based on diffusion but core architecture is transformer. Measure the loss between the real image and the white noise.

Autoregressive decoder only by Google not a diffusion model. Build a neural network from the diffusion process in order to start from noise and produce and image.

LDMs compress image into latent space of tokens represented by vectors by a VAE. Then reconstruct it through a decoder. Best hidden the best latent space.

Image is an RGB 3D cube and a time cube gets sent to encoder and instead of vectors your get cubes. Then you decode it.

Batch is how many data points you have. No matter how small a batch you still have a time dimension.

Images are compressed into latent tokens by VAE. N model should be massive. The larger models perform better. GPT-4 is estimated to have 128 transformer layers. This is the power source of Sora. at least 48

Token is not for image. Token is for video. Image is a special case of video.

400m text image pairs for DALL-E 2
Find the closest image pairing to guide the conditional diffusion model to create images.

Text to video caption

junlinghu@gmail.com
https://arxiv.org/pdf/2402.17177.pdf

The positional encodings are directly related to the patch. 32 x 32 is all you have for position space. Upsampling to make it bigger. Give a 32 x 32 input and a 32 x 32 output.

Get a hold of a diffusion transformer for Sora. Google has VideoPoet which has audio.
#ux #ai 



[[Statements are made of keywords, expressions, and operators.]]

#programming #beginner 
Play is design in an important way. Play is an unrestricted mindset of possibilities. Play allows us to try and fail without our failures being fatal. Design is about creating pathways to success. When you play you’re continually trying to reach an end goal but you understand there are low/no stake consequences to your actions. This frees you up for experimentation, trial and error. You try more. You probably err more as well but it’s play so who cares?

Play in a social environment is a little more restrictive because the consequences aren’t as low stakes. Now you have to contend with the effects of your actions on others. This is likely why social play comes in the form of games with rules and codes of conduct. Play is no longer freeform but it still carries a low/no stakes quality, provided you play by the rules. Society even forgives transgressions during game play.‘She got caught up in the moment’ is something you might hear or say as an explanation of misconduct during play. Red cards don’t carry over between matches.

Design is learned through play, through the imaginative combinations of disparate elements for no reason other than because. Get better, play more.

[[_SVA]]
I seek to find pleasure in it.

If the end result is expertise then all the better.
Market research leads down the wrong path but with confidence because of numbers. They can say 62% of survey respondents indicated they wanted this feature.
There is an order of operations to your mind. Modern neuroscience teaches us that we have layers to our brain. Not conceptual layers but actual hard-coded meat sack layers of brain that stack on each other. The stacking order goes physical, emotional, intellectual. When you’re making decisions the order goes backwards; intellectual, emotional, physical. Before continuing it must be noted that of all the layers, despite the dominant narrative of our culture, the intellectual is the least powerful. Intellect cannot overpower emotions. This is a logical fallacy that it can. It is clever your intellect.

Rational decisions occur in the intellect. In fact all of reason is the domain of the intellect. A rational decision is one where the path is clear. The stars align. It makes sense. The conditions for a strong rational decision are clearly defined acceptance criteria, an accurate prediction model, considerations of probable alternatives, and no information left unknown. What do you want? Do you know what you need to know to decide? What other options do you have? How will each play out?

With each question considered a brick is laid between where you are and where you want to be. When the bricks line up you have a rational decision. Now you can decide to execute.

Reason exists to create structures to appeal to your emotions for permission to act. In the dominant majority of cases the decider is emotion. In the other instances the decider is your deeper physical nature, your ancient self if you will. No decision is made without the permission of your emotional layer. Which emotion decides is context dependent but every decision carries an emotion.

Rational decisions are the start. Emotional decisions are the end. Move away from the idea that you can logic your way through life and you’ll start to live a better life.

[[_SVA]]

OpenVINO(TM) notebooks on github are jupyter notebooks.
OpenVINO is an API.

```query
tag:#jupyter
```

#jupyter #openvino
The reason you do something in design is to uncover whether it was that thing which yielded results. Design is projective. It is abductive. Abduction is not about the way things are. Abduction is about the way things can be. It’s a form of reasoning to navigate the fog of ambiguity. 

Design is not deductive in that design does not expose when A is B and B is C then A is also C.

Design is not inductive in that does not expose when you do A B occurs

Design is abductive. It exposes when you do A and B happens then Q is the abductive cause. It goes backwards from conclusion to premisses. It deduces cause from effect. 

Design reasoning, abductive reasoning, allows you to move forward. It gives you ground to stand on, logically, to evolve something into existence. Abductive reasoning is human reasoning. Pay attention to when it is being used by others. Find a way to use it more often in your own life.

[[_SVA]]
#ux #ai 

No event or motion occurs without a catalyst. There’s always a cue, a prompt, a reason for something happening. Pressure is one such catalyst. Pressure can be the slow squeeze or the panicked fire. Pressure is an easy concept to understand. Pressure presents itself in obvious ways. Materialistically you see pressure in explosions, cracks, and breaks. It is well known that pressure makes diamonds. Can pressure be a tool for producing outcomes? One could argue it is the only tool that will as no event or motion occurs without a catalyst. The breaking point is a powerful catalyst. 

To understand pressure’s effect on people look to stress. You can see erratic and fearful behavior under pressure. Pressure is what does people in. Look to the weight people bear. Which mountains, which earth rests on the shoulders on an individual? Most likely it is the weight of status, of being seen favorably in another’s eyes. Laws, norms, rights and roles are ways to create pressure. Shame and excision are also ways to create pressure. Competition is a form of pressure. These are the tools for creating pressure. What the outcome is depends on you.

[[_SVA]]
Think about having a control rig that works on a binding rig to allow for the binding rig to only worry about one input.https://threejs.org/docs/#api/en/renderers/WebGLRenderer

#unity 
https://www.linkedin.com/events/futureproof-howaiandmachinelear7169060789000101889/theater/

Dovetail's conference for product people, 4/11 Inside-Out, from Australia

Lead product designer at Dovetail. Introducing AI to the research process.
 - Happiness spikes but returns to the baseline.

Jess, Canva Principle Product Designer
 - Environmental impact of AI is trashfire.
 - Look back 10-15 to trace trajectory on the future. Think about AI in the sense of the iPhone.

Raising the ceiling and lowering the floor. Hard time to imagine that centering people will never not be valuable. Solving problems for users. Design won't be kicked out of the industry. The human input is critical. AI still needs the human.

You bring me in when you get stuck. You can make it on your own. You can grow. If you aren't growing it could be your user experience. You would look to satisfaction, reviews, 

Canva is part of creating a day of love and not about creating great wedding invites and seating placards.

There is value and benefit in AI summarizing and consuming large amounts of data, automating documentation, and automating pixel-perfection in UI files.

[[Text prompts are not a good UI tool.]]

Designers will still act as creative directors and creators not just curators. Designers are still the drivers. Automating the busywork and giving ideas is where AI is most valuable.

Don't think about the output, focus on the human layers of design. Focus on solving real human problems.

Think about the visible and the invisible design. MMMMMMMMMM>>>I DUNNO. This parable seems to me like saying, of all the ways this turned out what could have happened didn't. Think about all of the decisions you could have had to make if you didn't do it this way.

How can you reduce the biases in AI. Bias in AI comes in bias from people. Work on your people biases and your computer biases will follow. Set up people bias tests against AI.

Building systems that improve it's trust over time. Making sure you can opt out of data collection.

[[AI will never completely level the playing field.]]

Designers need to test edge cases.

A quick thumbs up and thumbs down helps prioritize AI features. Ask users whether they were able to accomplish their task with AI or not. The fun is in the learning process.

[[What do you want to automate?]]
An AI that tells you how to fix things
Recycle AI
Upcycle Ai
 - shows you what you can make with your stuff
 - finds what has sold that is similar and how much it has sold for
PartAI
 - a party planning, MC, and day-of-coordinator app
 - OR a dope app that brings the PARTAY!
AI for civic engagement
 - AccelerateSF
Style can't be democratized. Brands won't look the same. Portfolio templates without personalization are obvious. AI without the human touch will be obvious. Never forget the math behind it's eyes.

Stay curious. Be proactive. Talk is cheap. Take action. Apply what you learn. Build, test, repeat.
Time expands to fill the space allotted. If you don’t decide when to stop working you won’t. Space is necessary to be inventive, imaginative, and creative. Time enjoyed is not time wasted. Maybe you feel looking back that the time was wasted. It wasn’t.

Wasted time feels like wasted time in the moment.

Shared time you feel is wasted time is not automatically wasted time. Shared time could be frivolities enjoyed by multiple social members.

Is there not a place within you that would benefit from wasted time?

I propose there is. Wasted time is a feeling that the priority concern is not being given attention. The symptoms are a lack of progress. Over time grievances accumulate. You gain valuable information regarding your urgencies by exploring the feeling of wasted time. If these urgencies recur, waste some time and dive in. Explore what lay beyond their bounds. You may stumble upon a related yet more influential area that will uncork the whole thing.

It could also be that you frustrate yourself into threats. Sometimes it feels that enough is enough and I’m done. It’s unfortunate we’ve arrived here but it’s relatable.

Design can take all kinds. Wasted time is simply a flavor in the stew. It has its time and place. Use as you see fit.

[[_SVA]]
What makes you think you’ll discover anything new if you’re seeing the same thing everyone else is. You have to change your perspective. Be willing to look in ways others aren’t.

[[_SVA]]
#ux #ai 


Pre-work
[[Download these models for Stable Diffusion webUI]]

This Meetup was conceived for all who desire to understand image generation software. We share a journey.

My intent is to expose what is important about AI image generation to an audience that wants to know both how it works and how to work with it.

This technology is multi-faceted and I cover a lot of ground.

I'm curious and I seek the answers to the questions: how does this work and can it do this?

This Meetup is me sharing my path and findings.

I'll be running this in a chat-only lecture format. I'll provide interactions. I'll be off camera and sharing my screen.


WHERE THIS IS GOING
By the end of what I'm doing here, actually, well, hopefully way before the end of what I'm doing here but certainly before the end of your involvement with what I'm doing here, I aim to expose you to the current patterns and functional foundations of AI image generation software,

I'm going to show you how you to design for these softwares

The goal is to give you the knowledge and tools to build up a skill in creating experiences for and with AI image generators.

*Agenda*
Patterns of UX in AI image generators
Challenges of UX for AI image generation
Heuristics to address the challenges of UX for AI image generation
Smash class on UX
Code 😱
Tools
Putting it together
 - [[Using AI for UX]]


PATTERNS
In this section you will get insight into the interface, interactive, and functional patterns many of the AI image generation softwares have in common. We're going to level-set awareness and establish a shared context.

We're going to look for common layouts, interactions, as well as patterns in task flows, error recovery, and overall experiences.

Our goal is 15 to analyze 15. You test with 15 people and you get at least a sigma of security. Or so I'm induced to believe.

Where to find these softwares?
The search term returning the most general results right now is AI image generation.
 - Google
 - Perplexity if you prefer
 - Product Hunt
	 - https://www.producthunt.com/search?q=ai%20image%20generation
 - Meetups
 - Newsfeeds
	 - https://wellfound.com/newsletters
	 - https://alphasignal.ai
	 - https://www.uxforai.com/
 - Social feeds
 - Podcasts
 - Market watches
	 - https://www.marketwatch.com/
	 - national labor statistics
 - VC firms
	 - https://www.ventureloop.com/ventureloop/home.php
 - Discord
	 - Most every company in this space has a Discord server.
 - Job boards
 - Friends
 - WeChat
 - Professional organizations
	 - I'll plug openCV https://opencv.org/
 - Zoom chats
 - Social channels
 - There's an AI for that
	 - https://theresanaiforthat.com/ai/aiart-fm/?ref=search&term=ai%20art#alternatives

The point is not to maintain a constant awareness of what everyone else is doing. Maintain a curiosity in the idea and you'll find your sources of information. Committing to quarterly reviews may be enough to maintain your list. Consider the black swans as best you can.

Let's check in on a few companies in the space.

*Question to the audience, what image generation software have you heard of or worked with or are excited about?*

Daniel's Pix

Microsoft Designer
https://www.youtube.com/watch?v=vCiuBCIBABo
 - What I dig about this is the interface. It is context aware and places the actions close to that which is acted upon rather than using a fixed menu where the actions are far removed from the object.
 - It is solid interaction design with good functionality for free. Adobe Express is a direct parallel, as are other tools.
Learning Playground
https://www.youtube.com/@playgroundai/videos
 - This guy is super cool. He teaches you about the software. In the process he shows you how the technology all these other softwares use works. Great place to go to learn. Great software to work in. It costs your data but you get 1000 generations a day and you get to play with stable diffusion.
Learning Visual Electric
https://www.youtube.com/@visual.electric
 - what Visual Electric is selling are their models, which they occupy as styles
 - They are winning with their eye. They are curated and artistic. For sure a model to back.
Facet
https://www.youtube.com/@facet_ai
 - image generator combined with photo manipulations, mostly levels and saturations and overlays and stuff
 - Facet is great for photo editors and  photographers. It is a low level but streamlined Photoshop and an AI backed Mac PhotoStudio.
 - Facet is selling tools and a workflow.
Krea
https://www.krea.ai/home
 - from https://www.artbreeder.com/ which is the earliest and best example outside of academia for these softwares today
 - I'm likely wrong about this
 - Krea is different. Krea is not selling a model, they are selling functionality, and they are straight winning on all fronts. From my perspective they are the people to beat and bet on.
 Makereal
 https://makereal.tldraw.com/
  - great interface
  - cutting edge of this idea
  - publicly available github (+1000 to the open source)
https://github.com/tldraw/make-real

Now let's talk about the big 4

Midjourney
https://www.midjourney.com/showcase
https://www.youtube.com/watch?v=HYdHNcodsS8
 - Generally considered the best in image quality.
 - Midjourney is, rightly, paywalled, and worth it.
StableDiffusion
https://clipdrop.co/stable-diffusion
https://www.youtube.com/watch?v=_uyAlqFMDlw
 - you'll find much information in the docs and blogs
DALL-E2
https://labs.openai.com/
https://www.youtube.com/watch?v=LZFd0UZbnww
  - DALL-E3 is paywalled by ChatGPT Plus
Firefly
 - is also free but for an account
https://firefly.adobe.com/
https://www.youtube.com/watch?v=zS5qQz81yGU

More models
LAION & LAION-Art
https://labelbox.com/datasets/laion-art/
Civit
https://civitai.com/models
#LoRA https://arxiv.org/abs/2106.09685

Insights
In this section you got a broad spectrum view of the interface, interactive, and functional patterns of the many AI image generation softwares out there and you realized they all have more in common than don't. The insight is that there is a technology that powers all of this and when you discover the patterns you discover its capabilities and you start to see the human intervention on the benefit of a consumer.

SECTION 2 – CHALLENGES
Let's talk about the challenges UX faces
[[Microsoft has pulled together their guide called the HAX.]]
[[IBM has a guide for AI.]]
[[Google Design on the UX of AI.]]
[[UX of AI website on AI.]]
[[Refire Design's take on UX and AI.]]
[[Kirill Lazarev on UX best practices for crafting AI excellence.]]
[[John Maeda's UX patterns for copilot.]]
[[Adam Fard with a new way of designing.]]
[[AI & UX with Hang Xu & Peter Gostev]]
[[UX and AI with Intelligence Briefing.]]
[[The Shape of AI in review.]]
[[Vitaly Friedman's take on UX and AI.]]
[[Ericsson has a guide to UX and AI.]]
[[Machine learning for designers.]]
[[Canva's take on UX for AI.]]
[[UX challenges from that one Meetup.]]
[[5 gotchas in AI.]]
[[Perplexity tells me the main challenges with UX for AI image generation.]]

Here's my hot take on the challenges relevant to UX for AI image generation.

We're going to start where it doesn't matter and end where it does.

The ne plus ultra
[[The main challenge of AI is how to translate subjective human needs, values, and experiences into algorithmic parameters the model can optimize for.]]

Other challenges are to keep the data appropriate to your audience, act ethical, and take accountability for the impact of AI as a whole.

These are lofty challenges like trust, ethics, and value. That's not what I'm about. Those challenges exist and are addressed but are too broad for this audience. This is akin to saying UX is going to change the world. And it will, right after rock and roll does.

6 challenges specific to user experience in particular, in my words.
 - indicating what the AI can do
 - installing ownership, provenance, and authenticity of training data routines
 - designing interactions for non-deterministic outcomes
 - providing feedback loops to improve the AI
 - managing user expectations about what the AI can do
 - keeping the user in control

In this section we took a wide view of the challenges the experts say the field of UX for AI image generation faces. Where I lacked evidence for the specific you were presented with the generic challenges of UX for AI. From this evidence you were given 6 challenges specific to UX for AI image generation

SECTION 3 - HEURISTICS
[[Microsoft has pulled together their guide called the HAX.]]
[[IBM has a guide for AI.]]
[[Google Design on the UX of AI.]]
[[UX of AI website on AI.]]
[[Refire Design's take on UX and AI.]]
[[Kirill Lazarev on UX best practices for crafting AI excellence.]]
[[John Maeda's UX patterns for copilot.]]
[[Adam Fard with a new way of designing.]]
[[AI & UX with Hang Xu & Peter Gostev]]
[[UX and AI with Intelligence Briefing.]]
[[The Shape of AI in review.]]
[[Vitaly Friedman's take on UX and AI.]]
[[Ericsson has a guide to UX and AI.]]
[[Machine learning for designers.]]
[[Canva's take on UX for AI.]]
[[UX challenges from that one Meetup.]]
[[5 gotchas in AI.]]
[[Perplexity tells me the main challenges with UX for AI image generation.]]
[[Check this video out for more UX & AI at Microsoft.]]

In this section you'll be presented with a set of beneficial heuristics for addressing the 6 challenges above.

Perplexity addresses the heuristic themes in three pairs.
Trust & transparency
Feedback & control
Ethical & human-centered

I agree and consider that a useful framework. 

Here is my summation.

Challenge: indicating what the AI can do.
[[You can generate buttons based on the most common prompts.]]
You seem to do this a lot. <- This is the ML part, the predictive part. Would you like to automate it?
[[This leads to the UX patterns of 'hey, this thing is an AI', 'here are some suggested actions', and 'give us your feedback.']]

Challenge: installing routines for ownership, provenance, and authenticity of training data.
[[You need to show your references, cite your sources.]]
[[Don't collect what you don't need, use on-device ML instead.]]
Find a way to attach licenses of use or other provenance data to your images both training and generated but especially your training data.

Challenge: designing interactions for non-deterministic outcomes.
[[Text prompts are not a good UI tool.]]
"Clearly communicate permissions, settings, recovery plans in case of errors, and provide a way forward based on the severity of possible outcomes."

Challenge: providing feedback loops to improve the AI.
[[Culture isn't static therefore the research cannot be static.]]
Design for the labelers.
[[Use user input to improve AI over time via feedback loops like answer ratings or Roman voting.]]

Challenge: managing user expectations about what the AI can do.
[[If a human can't perform the task neither can an AI.]]
[[Communicate confidence with multiple options ordered by rank.]]
[[Make waiting fun is a core UX for AI principle.]]

Challenge: keeping the user in control.
[[Allow people to turn the AI off.]]
[[Give the human the ability to override the AI's decisions at any point.]]
[[AI "here's what I'm going to do, are you good with this?"]]

HEURISTIC PILLARS
[[This leads to the UX patterns of 'hey, this thing is an AI', 'here are some suggested actions', and 'give us your feedback.']]
Find a way to attach licenses of use or other provenance data to your images both training and generated but especially your training data.
[[Culture isn't static therefore the research cannot be static.]]
[[If a human can't perform the task neither can an AI.]]
[[Make waiting fun is a core UX for AI principle.]]
[[Allow people to turn the AI off.]]

Nobody has UX for AI figured out. Jakob Nielsen, of whatever fame and clout you give him, wonders who will be the Jakob Nielsen for the AI generation. He points us to the fact that their aren't established heuristics for this technology.

Make sure you acknowledge and respect old knowledge but feel free to disregard all of it and use exploration and practice as your tools for learning.

Now that we have addressed our challenges and heuristics we can summarize it in:

DANIEL'S UX for AI Definition of done.

No AI can be released until it
 - indicates to the user what the AI can do
 - has routines for ownership, provenance, and authenticity of training data
 - accounts for non-deterministic outcomes
 - has beneficial feedback loops
 - manages user expectations about what the AI can do
 - keeps the user in control

From here on our focus will shift to how we work with the AI image generation software and design for it.

But first a beneficial deviation in the form of a

SMASH CLASS IN UX

This is not an aside, this is a smash class in neuroscience, ecological psychology, gestalt, perception, and human-factors engineering. Consider this a refresher if you're through and done with all the brain stuff in design.

Neuroscience

Ecological psychology
https://youtu.be/k4fKBqu-Ris

Gestalt
Visual illusion museum teaches gestalt on some level. These visual puzzles are core to computer vision. One important aspect of vision to consider is when it fails and lies to you. These computer vision models consider all that stuff.
 - check out a visual illusion museum or 
 - check out a real mirror, you'll realize you're being lied to every time you look in any other mirror
 - https://www.youtube.com/watch?v=4VWrl98KzCE
 - https://www.youtube.com/watch?v=20N53khArXA
 - https://www.youtube.com/watch?v=G-xD1bDoNl4
 - https://www.youtube.com/watch?v=ybLDSAWyEZY
*use chatGPT or perplexity*
 - https://lawsofux.com/

Perception

Human-factors engineering

SMASH CLASS IN UX FOR AI

The titans
[[People + AI by Google]]
[[John Maeda's UX patterns for copilot.]]
[[Ericsson has a guide to UX and AI.]]

Begin here
[[Machine learning for designers.]]

The cover of ethics
[[Designing AI For Children Toolkit (+ Checklist) by World Economic Forum]]

The end of the word on data
[[Designing human data by Thomas Otto.]]

No theory, all practice
[[Canva's take on UX for AI.]]

[[A few resources for machine learning and UX.]]

SMASH CLASS IN UX FOR AI IMAGE GENERATION

https://docs.astria.ai/docs/features/
If I were to build an image generator I would use this list as my starting point for features. I would include and exclude based on competitive positioning. What's cool is that you can dive into the information. You get the API as well as the interface.

https://gooey.ai/docs/guides/
These people give away a lot of detailed information.

https://www.youtube.com/watch?v=jtwl9M-UNQE
Also shows a breakdown and patterns for the dominant AI image generators.

https://youtu.be/ZtRnZHWXYfs?si=WE4FayKTU7SlOc97
Teaches you how to build a DALL-E GPT

https://www.youtube.com/@playgroundai/videos
Outside of Automatic1111 Playground would be the only place I go to use and study UX for AI image generation.

CODE
https://www.derekknox.com/
https://www.youtube.com/@AndrejKarpathy/videos



TOOLS
By function
 - UI
	 - UIzard
 - Persona
	 - https://ai.boardofinnovation.com/personas-maker
 - Persona
	 - https://userpersona.dev/

PRACTICE
At this point you've gotten a general awareness of what AI image generation software can do and we've seen the current experience trends and patterns, we've surmised the challenges and heuristics from expert witnesses, we've gotten a smash class in UX, we've seen the code, we've been introduced to the platforms. We've covered AI powered tools for UX design. Now it is time to put all this nonsense into practice. Let's build!

Good UX begins with the user, here's a discussion to define them.

[[Beneficial curiosities for the field of UX and AI.]]
[[Good research questions to improve an AI.]]

Indulge me in another diatribe, this one on personas. You can call them users, personas, archetypes, audience members, cast and crew. You can call them whatever. They are the people who exist and are human interacting with what you are making. It is generally considered a benefit to know who these people are and what they care about. Call that understanding whatever you want. What is important is that you and your compatriots possess and agree on a physical, emotional, and mental knowledge of the people you hope you benefit. Otherwise you are designing for yourself and your myopia can't sustain your efforts.

Give me places to find people who are into {x}

Who are the users and what are they using it for?
Who woke up this morning wanting to pay money for AI image generation?

*put some users and use cases in the chat, help people get an idea of what AI image generation is good for*

This question in particular is what these businesses are in a mad scramble to figure out.
I know creative agencies are trying to figure out how to leverage it for concept and pitch work. I saw a guy work to make movies and commercials with it.

Marketing is big into AI image generation for product photography. Fashion is into AI image generation for ideas and concept visualization. Canva is trying to keep AI in-house for creating social graphics and banners and the what not, they call it visual communication.
MidJourney gives you dope images but like, what value does it have for your mom or the cab driver or the CEO of Salesforce or your little cousin? These are the questions that will determine your UX.

I personally see these tools as democratizing visual talent so I think they will find their value in social media creation though they will most likely just be ubiquitous in any software, 'turn your quarterly report into a captivating 4 minute video, or turn your Notion database into an epic movie!' kinda thing

I'll create a persona based on that.

[[Using AI for UX]]
Ask perplexity to create a persona
You can get personas
https://userpersona.dev/
https://ai.boardofinnovation.com/personas-maker

Let's talk product ideas, *put a paid link in the chat.*

[[Turn this comment into an action movie. Turn this comment into a comedy staring Will Ferrell. Turn this comment into a hard-boiled detective film.]]

In this section we learned about the users and use cases. We crafted a persona with a value proposition, with a goal, and with a scenario.

SECTION 5
As a designer if you want to go beyond being a user of these tools to a designer of these tools then you won't get there by using them.

https://course.fast.ai/Lessons/part2.html
https://ml5js.org/

[[AI image generators explained]]

[[Artistic control is still missing from generative visual AI for it to usurp traditional methods.]]
To current, what you've been shown are closed environments, paywalled ventures, money-backed guarantees. You can't get in, hack them about, and build for them unless you are invited to. You can thread the softwares together in a narrative fashion but you can't alter them.

None of that is true for Stable Diffusion. Stable Diffusion is open source. A webUI has been provided for branching and download on Github. This webUI gives you access to the functionality, with minor competitive exceptions, of at least 80% and at most 96% of all AI image generator softwares. 

What we're going to do is install the Stable Diffusion webUI so we can hands-on, design our own AI image generation experience.

https://docs.pinokio.computer/download/



The generosity of the open source community and their impact on learning is near unparalleled.

Maybe long ago or at this point you disconnected. You work mostly in Figma. You don't do code so this is too much and not applicable.

You're not wrong. If you want to design
take and remix some of these softwares inside Figma you can do so. You can make prototypes, you can do flows, research, mockups, the works. That's what you'll be doing when you get employed. Maybe that's what you're already doing.

What you gain this way are access to the results. Designing in Figma is designing a dream. All the mockups are imagined until they can be made real, proven they cannot be made real, or abandoned as an effort. Figma can't return the results of a model. Yet. I guess. Because of this you don't consider as well the feasibility of your design. I'm all for dreaming and vision setting work but I find the pragmatic perspective, the one that works with feasible, is where the money is made. If your design is not released because it isn't feasible then it is not valuable to the same degree as a design that is released.

Another benefit of going through this code is a full exposure to the raw tools. This interface has been designed but not by a designer. You're seeing a baser state. The machinations of the experience. The exposed functions of working with a model. This perspective of seeing the raw materials is a better place for learning and growth than the other softwares where a lot of what you need to learn has already been figured out and made rigid.

I'm not saying abandon Figma. I'm a UX designer. I'm not going to not use Figma but we're going to bring it in at a different point.

Now for Stable Diffusion
What I'm so enamored of about the webUI is that it looks like something you'd get from a developer. Super rich and performant and structured but there's like a finesse that's missing, one that UX can create. This seems like the front, save for working in the model.
Using the IDEO vernacular, this is what you have to make desirable. This is what you have to bring the user to. This is the point of capacity, barring inventive deviations and as yet unknown personal revelations.

Code
The only code you need to know is copy and paste CTRL + V.
If you're stubborn, driven, or a savant you could learn brew, cmake, protobuf, rust, python, git, and wget.
Make sure you have a GitHub account
Making sure you are starting from a good base. What old and unnecessary software to remove for a fresh beginning and how to remove it.
We will go through that process.
 - [[To install StableDiffusion WebUI locally you need to look for AUTOMATIC1111.]]

We will start with Stable Diffusion 1.5. It is pretty not that great of a model. It is earlier stage but performant and tuned. I'm not much of a car person but an apt metaphor occurs to me. That of the Toyota Supra's infamous engine. It is bullet-proof. That engine has been tuned and refined as to thrive no matter what you throw at it. My understanding is that Stable Diffusion 1.5 is comparative. A highly tuned performant machine. You're not wrong to change models but if something starts behaving unexpectedly move back to the 1.5 model and see if you don't get the results you expected.

Download the recommended from AUTOMATIC1111 plus these

You may get stuck at this point due to the downloads. If you've got any going and it's wrecking your speed then cancel them. There's a list in the invite. . I want to do this realtime but this part is the worst. Understand there is a certain amount of set it and forget it and you get to carry your models around so you only have to set it up once per model locally. It is an unfortunate result of large file sizes.

What is pruned and emaonly?
What is .ckpt?
What is inpainting and why is there a separate model for inpainting?

Instruct pix2pix
https://huggingface.co/timbrooks/instruct-pix2pix/resolve/main/instruct-pix2pix-00-22000.safetensors'

SDXL Base 1.0
https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0

SDXL Turbo
https://huggingface.co/stabilityai/sdxl-turbo

LCM
https://huggingface.co/latent-consistency/lcm-lora-sdv1-5/tree/main

Now that we're at this point we're going to introduce huggingface and research.

Prompt engineering for Stable Diffusion. What are the qualifiers to produce the best results? Like MidJourney does but for Stable Diffusion?


Extensions you want to download
CIVIT AI from Github
Canvas Zoom
ControlNet github.com/Mikubill/sd-webui-controlnet
With ControlNet you need to download more models.
https://huggingface.co/lllyasviel/ControlNet-v1-1/tree/main
Move them into /extensions/sd-webui-controlnet/models
Pose Editor github.com/huchenlei/sd-webui-openpose-editor
Ultimate SD Upscale

Doing this all on a Jupyter notebook

THE EASY WAY
Doing this the easy way
 - https://docs.pinokio.computer/download/

Where's the gap? AI is terrible at graphic design. It is the worst. AI is terrible at typography. I didn't say text. Typography. It can't explore with letterforms. It doesn't bring the elements of graphic design together like a person can.

Also, ask people to turn their heads. AI has no third dimension so it'll mess up.


RECAP

SALES
If any of this is curious to you and you'd like to speak to me further or if you want someone to walk you through the steps again you can book some time with me through this app. $moneydollarsyall

$moneydollarsyall is also for a weekly breakdown of 5-8 things to know

cashmoney - create a 15 sec ad selling your content, paywall it all charge $4, at the end show most purchased other content, give away for free

$10/mo for class access and the reading group
Also $moneydollarsyall is selling a research reading club for UX researchers.

To UX researchers interested in the research behind AI image generation. Or to anyone really. You pay for the privilege of intellectual discourse.

[[Important AI papers for image generation]]

The books get you the reference texts and resources. The videos show you their greater context.

I've got a bunch of projects I could use a second and third person on. If you want to work on a project with me then e-mail me and I'll send you a list. If we align then we can make something happen.

If you want a career in UX and AI image generation here it is. You don't have to search or piece it together yourself. If y. You can or you can take this smash class in both.

If you want to be positioned at the vanguard of UX for AI image generation you need to follow me. This is my compass. I am alighted to it and though you don't know me, learn that I will see this through.

#ai #ux

```query
tag:ux
tag:ai
```

```query
tag:LoRA
```


https://lu.ma/join/g-H0Fgy36EF7vM1pF

Product-led growth (PLG) & sales led? Not sure.
3-month security review for enterprise when you say the word database.

Startups don't employ marketing agencies. Small to mid-sized business are. Talked to founder's on HackerNews. Found his first client on HackerNews. Knowing the basics of APIs helped understand the audience better and market to them more.

Pinecone created the vector database category. Category ownership is a long-term and risky play. Look for signals early on, like reporters writing about you and Gartner reports.

What do you believe needs to be true for you to hire a designer? What need does a designer fill for you? What situational conditions trigger the need for you to employ a designer?

Developer advocacy is a great growth and marketing tactic. Hire an ML engineer as a developer advocate to teach developers. Find out what your audience wants to learn about and give them the information.

Executive and directors are not likely to want info but the users tend to want the code snippets. Good advocates like to share and teach but don't value money to avoid the sales pitch.

Drive people to the product and get them through the product successfully is growth marketing.

Put up a waitlist to sign-up for a product as you scale from 1k to 10k to 100k. This will help mitigate crashes from capacity spikes.

Be #1 for learning up like DNS and Cloudflare, Git and Atlassian. Over 100 articles in the learning center. Make the content substantive.

This VP of Marketing is watching user's work with the product, identifying workflow problems, and finding confusion points.

What does the audience need to know approach the product? This is divided into three types: aspiring, average, advanced.

Google alerts for relevant keywords.

PLG gets self-serve support through a support chatbot they built. Let's pair up with our customers. Do they offer this service? If so then let's buy it from them.
You have to learn to recognize what you want because now you can get anything but.

https://www.linkedin.com/learning/using-ai-in-the-ux-design-process/

Tools to cover. All are free.
ChatGPT uses Natural Language Processing.
Notion will brainstorm and organize ideas but really it's just another prompting software.

Firefly will generate storyboards.
Figma will create images and text elements.

ChatGPT/Perplexity for research. Give me the value prop and major frustrations for 10 apps in the local market.
I'm a UX designer and I want to discover what motivates and stops users from purchasing comics.
Create a user persona for a local comic book store application.
Feed the model whatever information you have on your users, ideally via RAG.
Give me a list of features for an app beneficial to this persona.
Give me industry trends for similar applications

You can get personas
https://userpersona.dev/
https://ai.boardofinnovation.com/personas-maker

Give me a storyboard breakdown communicating the user's journey through the app

Firefly can give you imagery. I use Stable Diffusion or visual electric.

Use UIzard and chatGPT for flows.

Give me a user flow for this feature which incorporates these values and principles
also give me the principles and values to incorporate. Consider the afore created persona as the user for this flow.

AI plug-ins for FIGMA
Freepik AI
 - a mobile application interface for comic book store owners, keep it artistic but not overwhelming

Find me mobile application user interfaces that are desired by comic book store owners in San Francisco.

Act like an expert in UX and change this thing to make it better without making anything else worse.

A useful usability prompt
Create 10 usability test scenarios and tasks to assess the user-friendliness of a comic book store chatbot feature.
Consider new users, frequent users, and users who are leaving or have left your application.

ChatGPT can help you create surveys and the such for research.

Identify usability challenges for this flow but these are often generic.

Other places to learn about using AI for UX
https://youtu.be/prVP_M0j3uQ
https://youtu.be/vyWFS4DPpqA
https://youtu.be/_LdL1FpvcOg
https://youtu.be/dxfKQvp7DWM
https://www.youtube.com/watch?v=E_96lbbIlXE

[[UX for AI image generation Meetup]]
 - form, voice, and dissemination
	 - dissemination tactics: candy wrappers, food shaped as a flag, Kimonos, window shutters
 - subverting deception
 - sex pistols cover of Queen
 - forcing juxtaposition
	 - Robert E. Lee George Ffloyd projection
 - designers as protestors need to bear witness, religiously
 - [[The strongest form of protest is being ethical in what we bring to form.]]
	 - integrity is hard, money is easy
 - speculative design is exploring what something can be
 - You can augment a space without having to be there #AR
	 - frames help computer vision to recognize objects faster
	 - frames help the human eye to recognize objects faster, in fact, the frame is the only thing that helps human eyes recognize objects
	 - to increase computer vision recognition, train it with video of your artifacts in different lighting and contexts
 - Laws can't touch the alternate reality
	 - Brian Wassom is an #AR attorney
 - Take a moment and make it everything
 - 'Nothing for us, without us' is the #principle of working with people for their benefit instead of acting alone
	 - 'For the benefit of all and harm of none' is the #principle of moral, ethical, and personal guidance
Spending time shoulder-to-shoulder with customers is even more important as you seek to understand what they are trying to generate. It's generally not what they write as prompts but the deeper emotional desire. When I can have this amazing ability to write blogs, create images, do all the things generative AI promises with no inherent talent in any of them I'm seeking something at the top.
Generative AI is scary, complex, and new. The technology hasn't been socialized yet. Questions regarding social issues like authenticity are what drive the field.
Creatives train to have a style then somebody decides to use their work in an AI model and suddenly the creative's style is available to all. This biases datasets and negatively impacts a creative's livelihood. We haven't figured out how generative AI integrates into the lives of artists, it questions core arguments about ownership and compensation.
[[Loose systems encourage appropriation or at least allow for it]]
Is that it is necessary.

As an action design is intentional. Every action by a human is intentional. Action cannot be any other way. As a noun there is nothing about design which must be intentional. An object be it physical, metaphysical, experiential, temporal, or otherwise can possess a design devoid of intent.

Evolution is a viable mechanism for design. The evolution of the natural world is always in response to the moment. There is no future for a tree. There is no future for DNA, RNA, or any other perceived architecture of the natural world. Order has emerged from chaos. The universe and all things in it are the way they are because they are they way they are. Their design has no intention.

It is human nature to impose a design upon our surroundings. We must create an order to navigate our reality. Yet spontaneous order can occur, subsist, and thrive. It could be argued that this type of order is the most stable of all orders because it was born purely from circumstance. The best example to illustrate this point might be the bead spinner. https://www.youtube.com/watch?v=IFirAoh_1xY

In no case is design necessary. Yet, unless you prefer chance to dedicated effort it is often the best path forward.

[[_SVA]]
Syntax, Runtime, and Semantic error are three common errors.

Look up errors you don't understand on StackOverflow.

Semantic errors are unexpected outputs.
[[For interviewing to be fair and effective it needs to tolerate culture, discomfort, and biases.]] Basically everything is culture. Culture impacts what you don't see about someone. Your tendency, unchecked, is to project your own self-worth onto another. With this myopic perspective you'll find it difficult to see the values in experiences outside your own. What would this person's culture value is a back-pocket question for you to understand projecting yourself onto others. Instead, ask your conversation partner about their learnings and ways they see those learnings being effective in this context. Explore what people got out of experiences to understand their values and culture. In cultures with perceived deficiencies, think underserved and oppressed, we mistake not knowing with intellectual capacity & capability. Nobody is deficient merely different. Assume competence and test for incompetence.
#ux #ai 

https://futureoflife.org/open-letter/ai-principles/

An exhaustive set of principles on AI to adopt.
https://www.awwwards.com/AI-driven-design
Chapter 4, pg 29

In all cases you must consider this first and utmost.

Quoted from Nadia Piet, who also created the [[AI x Design toolkit.]]
It’s pretty easy to be myopic when designing for a living. We get caught up in the goals set for us. We focus on our minimum viable audience. We make decisions based on customer satisfaction, corporate returns, and retention rates. Which are all important and keep the design industry thriving. That’s not all there is to design. What you set your sights on is what you achieve. Humans are amazing in that regard. If you’re so focused on the small piece in front of you the bigger piece around you gets ignored. Even more insidious is being blind to the impact the small piece has on the big piece and vice versa. It is beyond the ability of any human entity to solve the biggest problems of our day. There will always be war, famine, starvation, the haves and the have nots. What we can do is design for the link between the small and big. Break free from designing in isolation and start seeing how you can create abundance for everyone. Create twice as much as anticipated so there’s enough to spread around.

[[_SVA]]
#ux #ai 

Consider actions across specialized models instead of the one model for it all. As with people, generality and speciality are beneficial in different situations and you do not expect the one from the other. Begin with the general and move to the specific. Right tool, right job. Right task, right AI.

#ux #ai 

Sometimes I don't want Google to think for me. I want to be in my own thoughts.

- Overhead at CCA event 3/12/2024
Chat GPT prompts
https://www.promptingguide.ai/
https://learnprompting.org/docs/intro

learning
 - "I am currently learning about [insert topic]. Convert the key lessons from this topic into engaging stories and metaphors to aid my memorization."
 - "I am currently learning about [insert topic]. Ask me a series of questions that will test my knowledge. Identify knowledge gaps in my answers and give me better answers to fill those gaps."
 - "I want to learn / get better at [insert desired skill]. I am a complete beginner. Create a 30 day learning plan that will help a beginner like me learn and improve this skill."
 - "I want to learn about [insert topic]. Identify and share the most important 20% of learnings from this topic that will help me understand 80% of it."

jobbing
 - highlight three skills required to be successful at this job description and create a bullet point list from my resume based on those three skills
 - optimize my resume for this job description
 - write resume bullet points for this job description, include metric based achievements

act as
 - Earnest Hemingway
 - Ernest Hemingway
 - linux terminal
 - "position" interviewr
 - javascript console
 - excel sheet
 - english teacher
 - plagiarism checker
 - advertiser
 - relationship coach
 - recruiter
 - archetype
 - Seth Godin
 - a career coach and give me top 5 skills for the following job, explain why
 - a Director of UX and ask me the 10 most likely questions about motivation, behavior, and technical knowledge based on this job description

explain
 - clearly
 - uniquely
 - detailed
 - like I'm five
 - with examples
 - like Elon Musk
 - like I'm in high school

chained prompting
 - write an article about [topic]
 - give me a several headlines, teasers, and subheads for an article about [topic]
 - give me three ideas from the article, and write blogs about those three ideas
 - write different headlines adding in the following concepts

marketing
 - provide me ideas for blog posts about [topic]
 - write a description for [product]
 - suggest inexpensive ways to promote [product] without social media
 - how can I obtain high quality backlinks to raise SEO of [product]
 - write a month of social media posts
 - give me a market analysis for [product]
 - give me research on the market size for [product]

development
 - develop a next.js architecture and code for a [product] website
 - help me find mistakes in this code *paste code*
 - continue writing this code in javascript *paste code*

design
 - how can I design a [product] website in ways that convey trust and authority?
 - what are some micro-interactions to consider for a FinTech app?
 - generate examples of UI design requirements for [product]
 - suggest a wireframe layout for [product] for [audience]
 - suggest ways to optimize [workflow]
 - create a user flow for [product] for [audience]
 - write design system component documentation for the [component], describe when to use, anatomy, placement, content, behaviors, states, and interactions, add three links for best practices of this component
 - As as a user reasearcher for [product] and ask me questions about my experience with [product]
 - generate survey questions to understand [audience] preferences and needs for [product]
 - what are the best practices for [ux pattern]
 - come up with what-if functionality for [product]
 - scenario planning
 - create insights from these notes: *paste notes*
 - create a checklist in table format to ensure [product] meets WCAG 2.1 AA standards
 - give me a competitive feature analysis for [product]

write a script for a story where {x} happens

compare these three articles and write blog posts on their similarities and differences, then pick out the three most important [topic] and write blog posts about those, finally give me video outlines for each of those blog posts and five instagram posts promoting each blogs

give me a video outline for these blog posts
[[Efficiency is measured in effort, think time-on-task.]]

[[Effectiveness is measured in accuracy, think success rate.]]

[[Error tolerance is measured by error rate and recovery options.]]

[[Ease of learning is measured by success rate of new people and new features.]]
#ai

https://ai.google.dev/
https://platform.stability.ai/
https://webapp.engineeringlumalabs.com/api/v1alpha/genie/docs
In the beginning was the Word. The mechanism by which all things were brought into being.

The dream of man to possess the Word is the primordial dream. Yet until now we have not so closely realized that dream.

Think about it. Sora, while a simulated world and in no sense comparable to the world of the Word, is yet still a world into which we will speak and it will change in accord.

The Word was made flesh as only the Word can but now our words will contain, in worlds and echoes indistinguishable from our own, their own preeminence.

The significance is not religious. Only a few know the Word and it's connection. The significance is of human nature. Our dream to posses the Word is protozoic, it needs no label, no language, no vision to be understood.

There's a duality in everything but unity. I imagine the dark side to this reality is corruption of the ego and disassociation. Speak and it shall be so is a powerful and heavy proposition. Once obtained, living in a world devoid of it, the world of the Word, loses flavor.

You may see this as pessimistic. Though I do concern myself with not the things of man, I am excited by the potential of Sora and wish I had a better way to end this narrative.
You have designed your next steps since you the moment you awoke to the world. All of the next steps which don’t come pre-packaged at least. Through testing and feedback, trial and error, you’ve learned the actions and the order of achievement. Many of those actions were constructed as hypotheses and tested against. Have you achieved what you set out to achieve? Yes. WOOT! No. Woot! This is designing.

We need to acknowledge that an element of predisposition exists in our structural makeup. We need to acknowledge that certain people are more likely to do certain things. We form clubs of commonality and call them communities based around our predispositions.

It follows then that certain people are likely to design actions in line with their predispositions. Each of us has an inclination for how to approach a situation.

[[_SVA]]
https://github.com/AUTOMATIC1111/stable-diffusion-webui

#stable-diffusion
#ux #ai 

https://designhumandata.net/

Data privacy
As a designer, I have spent the better part of my career championing the idea that "the interface is the system". This principle holds true across a wide range of design disciplines, from software and hardware to digital and physical products. Essentially, the interface is the point of interaction between the user and the system, and as such, it plays a critical role in shaping the user experience.

The interface is more than just a surface-level design element. It is the embodiment of the underlying system's functionality, and it is where the user's mental model of the system is formed. If the interface is poorly designed, the user's mental model will be flawed, leading to frustration, confusion, and ultimately, a poor user experience.

Therefore, it's essential for designers to approach interface design with the same level of care and attention as they would any other aspect of the system. It's not enough to simply make the interface look good; it must also be designed to be functional, intuitive, and user-friendly.

One of the key principles of good interface design is simplicity. The interface should be designed to be easy to understand and use, with a minimal learning curve. This means minimizing the number of options and actions available to the user, and ensuring that those options and actions are clear and well-organized.

Another important principle is consistency. The interface should be consistent in terms of layout, terminology, and functionality, so that the user can easily navigate through the system and understand how to use it.

Finally, designers must always keep the user in mind when designing the interface. The interface should be designed to meet the needs of the user, rather than the preferences of the designer or the requirements of the system. This means conducting user research, testing, and iterating on the design until it meets the needs and expectations of the user.

In conclusion, the interface is the system, and as such, it plays a crucial role in shaping the user experience. To design a great interface, designers must approach the task with the same level of care and attention as they would any other aspect of the system. They must focus on simplicity, consistency, and user-centered design, and be willing to conduct research, testing, and iteration to ensure that the interface meets the needs and expectations of the user. By doing so, they can create interfaces that are not only functional, but also intuitive, user-friendly, and enjoyable to use.
Nature figured it out a long time ago. Trial and error. Feedback and change. Adaptation. This is how humans learn. This is the only way humans learn. All of life has to do with improving the try to gain more valuable feedback from the error. When you are designing you’re trying and erroring at all points. The feedback loop is constant and multi-layered. Processing the feedback into the next try is what gives importance to processes, the how. An unfortunate truth is that given the nature of complexity success is never guaranteed. Process leads to product easier but process is not perfect.

Consider a shift instead from improving processes to improving inputs. You have to put constraints on your feedback. It is highly beneficial to you when your learnings are pointed in a meaningful direction. That’s a lot of what design is. You want to control the variables to produce the outcome. What you accept in as feedback is as important as what you leave out. There is as much space between trial and error as there is between error and trial. Improve the try by improving the input from the error.

Said in a more simple manner. The lesson you learn from falling down stairs is not that your shoes don’t match your belt.

[[_SVA]]
In cockpits, widgets emit noise when they require interaction or attention.

#IxD 
https://github.com/topics/virtual-try-on

https://github.com/LZHMS/Virtual-Tryon
Python terminal
 - has SDK installed
 - pip install landingai~=0.3.0
10 image minimum to train model
Detection
Segmentation
Classification
Visual Prompting
Make the bounding box tight to the object
Shows you which predictions are not correct
Add metadata tags to help navigate training datasets
Usually better labeling of data changes performance more than adjusting hyper-parameters or models.
Deploy a model to an endpoint in the cloud, you can send images to an endpoint.
To use edge you need a docker container and some sdk calls to run against.
Stream video to a container deployment not the open endpoint due to internet bandwidth.
Add trackers to avoid counting the same thing twice.
Two predictor options, one pointing to recognition the other to classification via sdk. You would split these tasks with two projects.
Redpoint detection architecture.
#ai
Must store variable and data  in the computer memory.

= as an operator assigns the right value to the left value

In python strings data require quotations marks to denote it as a string.

[[Variable names contain letters, numbers, and underscores in python.]]



#programming #beginner 
#IxD
https://youtu.be/k4fKBqu-Ris

The relationship between an organism and its environment is a dynamic relationship.

Properties of environments
 - Environments surround and are extended
 - Environments are structured
 - Environments consist of substances, substances have sufaces, the surfaces are the boundary between the substance and the environment medium

Light is structured characteristic to a surface, texture, color, orientation, shape

Perception fundamentally enables an organism to move through an environment. Perception exists to support action. Action supports perception and reveals structures.

Invariant structure is structure that is constant across changes of orientation. Perceiving objects is perceiving invariant structure.

Retinal image is a two-dimensional projection of an object.

Invariants are revealed through action. What is revealed is a property of the object.

Invariants are not frozen in time but are revealed over time.

Structure is revealed through action.

Information specifies some feature of the environment.

Vistas are that which can be seen from a given observation point. Transitions are movements between vistas.

Transitions are critical for wayfinding in an environment. Distinctive transitions help wayfinding better than non-distinct transitions.

If your body mass is increased the perceived slope of a hill increases and distances seem farther.

Objective and subjective dichotomy is not helpful in psychology.

Roger Barker psychologist, (Ecological psychology, 1968)
Collectively generated structures create opportunities for our lives. Behavior settings occur naturally as the function of the collective actions of individuals. Behavior settings can be specified objectively, are time bound, and are relatively stable. You know when you enter a behavior setting and know what the behavior expectation is.

How can you predict behavior? The best predictor of behavior is location. [[The behavior of different children in the same setting has less variability than the behavior of a single child across settings.]]

Behavior settings and affordances constitute the resources of an environment from an ecological point of view.
Explainability
Showing the math. Humans are accountable to other humans for the actions of the AI they use. Because of this the AI needs to give a rundown of what it will do, the reasons why it will do it, and how it will improve. These are common expectations in learning environments.
 
Model drift
You need feedback loops.

Actions across specialized models
[[Design for workflows not monoliths.]]

Comprehension
AI is technical and many don't know how to work with it.

Implementation
Not only where to use AI but how to get AI to the people.
Names don't start with numbers. Names can't contain spaces. Names are case sensitive. Names can't be keywords.

#programming #python #beginner 
This is going to sound harsh. There's a good chance when I get done saying what I'm going to say that you're not going to like me at all. #communication 

[[If you make a point to talk about integrity there's a good chance you've been betrayed in the past.]] #communication 

"This lady is probably telling her colleagues how lucky this guy is that she's even speaking to me. I was thinking about the positive to that negative and it occurred to me that she probably sees herself as being generous so when she came back I said, 'I want to thank you for being so generous with your time.' #communication 

This is ridiculous. Another random person with a selfish request. Your company is hiring. Are you against connecting over your work experience?  #communication
reach out to chat, talk shop, learn more about each other

It seems like you have a reason for saying that...wanting that...asking that.

Think in terms of influence and not leverage.

People who want to meet you halfway are often a poor judge of distance.
"Yeah, I generally use that to get what I wanted all along. I'll say I want a win/win deal and high anchor. Then I ask them to meet me in the middle which is where I always wanted to be."

It seems like this is important to you and you have a reason for saying that. I'm afraid I have some concerns.

It seems like you're hesitant. It seems like you're skeptical. It seems like I haven't earned your trust yet.

Negotiators with massive egos love flattery. Feed their ego. If anything goes wrong, take full responsibility for it (especially if it is their fault.)

There are so many companies out there with similar products – why are you choosing to do business with us?

What is your vision of this deal moving forward?

It seems like we're one of the top companies you're considering.
add 'high key lighting' to prompt
add 'low key lighting' to prompt
hard light
soft light
bokeh
fill light
rim light
add a spark in the eye
rembrandt lighting
add time of day (noon, sunset, golden hour, night, sunrise)
add atmosphere (cloudy, foggy, hazy, story, sunny, rainy, sunlight rays)
ar 4:5 (aspect ratio 4:5)
when you start describing face details MJ will focus on those
add 'in the style of [x]’ [alphonse mucha] to the prompt
add clothing texture details to prompts
The better idea is How.

How is a question without an assigned direction. How goes up, down, close, wide, out, in, through time. How frees your mind to form connections without predispositions. How is more likely to lead to insights because it comes with less baggage. It is value neutral. How brings the elements of the situation into focus in ways that Why can’t.

Why is a terrible question. Why is a unidirectional vertical question. Why goes down. More Why gets you deeper. The promise of Why is the understanding that seems to come on the other side of it as if Why connects the pieces, provides the clarity, shows the full picture. Why has erroneously been deemed the path to epiphany. Assuming that asking Why will get you there is illustrative of the very reasons it won’t.

Aimed at a person, Why is about intention. Nobody likes to be asked Why. When you ask Why of a person it’s an attack. Typically the only time anyone works to uncover another person’s intent is when they feel corrective action is necessary. As if there is ever something about another person that needs fixing. Why triggers a defensive reaction. Why is a weapon of shame, guilt, and exclusion more than it is a tool for exploration. Understanding intent can be beneficial but using Why to get there is the physical equivalent of beating it out of someone. What you’re likely to get with Why are obfuscated rationales, secondhand truths, or flat out hostility.

When you ask Why of a system you’re seeking causation. You want to know the factors which came together to produce the current state of the system. The popular 5 Why’s approach seeks a root cause as if a system can have a root. No system is so simple as to be able to trace an outcome to one point. Systems are chains of causation impacted by variables too numerous to comprehend. Asking 5 Why’s in a row only gets you five answers loosely linked by virtue of the chronology of your responses. Chances are high those answers have mistakenly created a chain of causation that doesn’t exist.  

How makes you consider the web of influences that conspired to produce an outcome. How causes you to get curious about behaviors and interactions. How creates an information rich environment. How doesn’t assume intention an an overriding force. How exposes context. How invites discussion and collaboration. How protects the sanctity of another’s sovereignity. How respects autonomy. How respects control. An added bonus is you don’t need five Hows to get anywhere meaningful. You only need one.  

Do yourself and the people around you a favor and start asking How more than Why.

[[_SVA]]
If you’ve been through art school, design school, or any liberal arts focused education program in the United States you’re likely familiar with critique. Criticism is something that is tough to swallow. It has a high negative value in most situations and most people tend to avoid it. The popular saying, ‘if you don’t have anything nice to say don’t say anything at all’ is a cultural response to the tendency of people to criticize others. Criticism is human nature though and you’ll receive a lot of it in your life. Rather than avoid criticism the schools mentioned before train you _through_ criticism. For many people this is the civilian equivalent of military hell week, only you get two to five years of it instead of seven days.

The toil is that you have to offer up your work and ask, ‘is it good enough?’ You are forced to receive negative input about the shortcoming’s of your work. You can’t escape critique. You survive it. The sting of criticism doesn’t leave. What eventually happens is a schism between you and your work. You become detached, divorced, desensitized to what you’ve created. You still value what you’ve done but now you’ve learned it’s not about you.

The reward is that you get to offer up your work and ask, “is it good enough?” Will you act? Will you trust? Will you understand and believe? You get to bring people along with you. You get to create for others. You get to listen and care about the concerns of those you seek to help. Critique is rough but it is a worthy pursuit because the other side, the job well done, matters.

[[_SVA]]
What makes it worthwhile is the story we tell ourselves before we act. It’s the hidden narrative describing life on the other side. Everybody has one. If you want to create a change in people you need to know what will make it worthwhile. Not what _you_ think will make it worthwhile, what _they_ think will make it worthwhile. Pay attention, the shift matters.

[[_SVA]]
#ux #ai 


"Because customers reacted in this way we have a theme of {x} that aligns with our company's theme of {x}. We see this as a sign the design resonates and will provide value and benefit to our customers."

Talk about the design decisions which will trigger a customer.
https://designsystem.digital.gov/
Certainty is commonly considered as the opposite of risk. Give people certainty and you will have built trust. Certainty is obtained primarily through the absence of falsity; assertions that don’t hold. If you say something it better be true. At lot is riding on it.

Certainty is a bit of an act of faith in that you create a belief of truth with the faith that the truth holds for you. Any fear you have erodes certainty. Taking away certainty is a possible tactic. You are certain you are going to stay the way you are until you choose to change. Do nothing and that will remain certain. Act differently and you reduce the certainty. Explain how their current way is actually reducing certainty and your new way is increasing it.

You can induce certainty by demonstrating an understanding. Colloquially known as walking a mile in someone else’s shoes. Perhaps the most important certainties to establish in any human interaction are the certainty that you will not harm each other and that you are acting with the other’s interests at heart. Anytime someone feels the certainty of understanding, of empathic connection a bond is formed. I am certain you will help me.

The same goes true for any product we interact with but those come with the certainty of usefulness so pay attention there.

[[_SVA]]
#ux #ai 

https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai.html

Challenges are data, ethics, policy, regulation, bias, fairness, explainability, privacy, robustness in handling errors, secure against attack, safety, governance, compliance, and risk management.
Tell me what you do. 

As a designer it can be difficult to explain the intricacies of design to the uninitiated. As designers we spend a lifetime understanding our profession and what it means to design. Distilling our hard won understanding into something catchy that engages the audience can be difficult. Many prominent designers have their own flavor of what it means to be a designer. You, dear reader, may even have your own or at least your favorite one. The ones I’ve found feel stilted. 

Tell me what you do.
 - I render intent.
 - I make intelligence visible.
 - I make things work well not just look good.
 - I make thinking visual.
 - I create solutions to problems. 
 - I align outcomes with intent

Without a doubt there are lifetimes of wisdom in each of those answers but c’mon. Tell me what you do.

'I give you the optimal path to where you want to go.'

Design is an act of synthesis. It’s an architecture of constraints. Design is a higher-order thinking skill that humans tap into when trying to accomplish a goal. Design considers intent, intelligence, environment, capabilities, consequences, and more. It is something every human does. It is possible that design is an act that everything with an intelligence does. Designers are just better at it because we train to be better at it.

You’re free to stick with your favorite response and understanding. Craft your own if you so desire. However, if you’re looking for a response that’s a bit more universal and approachable now you have it. I give you the best way to get where you’re trying to go.

[[_SVA]]

This all started with play and space as a strategy and a tactic. Boredom can be intentional and it can yield creative results. Growth occurs at the edges of your comfort zone. Boredom can feel highly uncomfortable. It’s an agitator. Boredom forces something to happen. The reaction is action. Do something. The benefit here is the longer you sit agitated the more pronounced the action is. You’re a bow string pulled taut and the more you sink into boredom the more taut you become.

Play is where you give boredom a space to matter, to contribute in a positive way. Play greets boredom. Play brings boredom in and works with it. Play allows the creative agitation of boredom. Play says, ‘I dunno. Let’s find out.’ The notion that you’re outwardly playing might seem awkward so play inwardly. Give yourself permission space on the inside. The playful mind is where playful thoughts and playful behaviors are made.

If anybody challenges your boredom, just say ‘I’m boring myself to action.’

[[_SVA]]
(https://www.linkedin.com/events/casestudy-mitdeployschatbotwith7148338782021287936/theater/)
(https://gaiinsights.com/blog/10-types-of-generative-ai-0)
Alden Do Rosario - CustomGPT creator
Orbit.mit.edu gives you chatMTC (Martin Trust Center)
Chatbots need to cite their sources since most information is unstructured.
A chatbot for each department, HR, Finance, Legal, Design, etc…
Use Zapier to add data or use sitemaps, create sitemaps from YouTube videos and playlists using CustomGPT
Retrieval Augmented Generation
You need to be concerned that your input gets fed to OpenAI
Caught by CustomGPT in the middle
Data gets intercepted and their data using RAG is all their data
CustomGPT gives you metrics on the number of questions you can’t answer.
Add best practices to pages when doing something new.
If you are new to a task, to an anything, but mostly new to a situation it can reduce anxiety to have information on best practices and survival tactics.
CustomGPT works by constructing sentences only from their data source
Hosted SaaS
Need to have system refreshes to note updates and deletions
A multiplicity of resources are available for use, Claude, OpenAI, Google, Perplexity so consider that your ChatBot is the only way.
Installing one of these on an intranet might be beneficial. I’d be concerned whether the tech could support it. Maybe the integration could be done a different way.
Ingestion was less than 2 hours.
They wanted to give chatGPT to non-developers.
Legal assistant GPT in the Dominican Republic. And education.
CustomGPT is not a deep dive into ML, it’s more front-line for the dumb-dumbs, the non-initiates.
Pulls in audio, video, word
(desktof pree?), Pinecone, LLM GPT4, 5k hours on hallucinations
$100/mo for 1k pages
OpenAI is a platform company who will be beneficial for their models.
CustomGPT features autosync, ingesting YouTube, creating Slack integrations, give citations, working with local people, the one person and not the business, and it uses RAG. It is working.
What's your favorite television station? PBS. Nielsen ratings proved this wasn't true. The insight is that this person wanted to be the type of person whose favorite station is PBS.
Better is a powerful tool. Everything you point it at becomes better. How do you decide where to wield better? At which dimensions do you point better? Making that decision easier involves consideration for the people who will benefit from your particular better. Point better at helping who you want to help become who they want to become. If you start here it becomes obvious where to make things better.

Sometimes better is not more of the same. Sometimes better is different. Be willing to go off and explore new directions.

[[_SVA]]
Originality is a highly sought after quality in a work or in a person. We elevate originators. Well, we call people originators only when they are original to us. The truth behind their originality becomes meaningless when they become original to a culture or society. At any rate, originality is something many strive for and few achieve. I posit this is not because originality is difficult to achieve but because the path to originality is uncomfortable.

The quickest path to originality is through error. Mistakes are wholly original and unique to the human experience. It still is that pen marks on paper cannot be un-made. But humans don’t like mistakes. You can call them ‘happy accidents’ if it helps but it rarely does. All most people will see is the missed attempt at realizing their intention. The pen mark that cannot be un-made can be transformed into a new element of the page. Your intention has not failed you, the chaos of the world is giving you a helping hand. The mistakes we make ought to be celebrated and amplified.

[[_SVA]]
*not written by me

Design is a complex process that involves a multitude of skills, including creativity, strategy, and execution. To deliver high-quality designs, you need a team of talented and experienced professionals who can collaborate and work efficiently. However, even the most experienced teams face challenges, and it's essential to develop strategies to overcome them.

Hire Senior Craftspeople

One of the most important things that Dylan emphasizes is hiring senior folks who spike in craft. Many teams tend to expect senior folks to focus more on strategy, but Figma loves to have senior craftspeople on the team, too. They play a crucial role in mentoring, pairing, and giving craft feedback to the rest of the team. When you have experienced designers who are passionate about their craft, they can guide and inspire others to achieve their full potential.

Create a Culture of Riffing

At Figma, they do a thing called "riffing" a lot! It's where folks share their design files, and people pop in to create different iterations of things, visually. It's a great way to provide feedback that's more visual than written. It also encourages designers to be open to feedback and to embrace the idea that their work isn't precious. By having a culture of riffing, you create a safe space for designers to share their work and explore new ideas.

Encourage Constant Focus on Craft

Focusing on the craft is essential to creating high-quality designs. At Figma, they talk a lot about the craft and encourage their team to give visual and interaction feedback. Even early in the process, they don't shy away from providing feedback. Dylan makes a point of giving folks craft feedback himself and explains the rationale behind why it matters. He emphasizes that visual decisions help achieve the goals of the project, or make things easier for users. By focusing on the craft, you can elevate the quality of your designs and ensure that your team is constantly improving.

Facilitate Riffing

If you want to encourage your team to riff, there are some simple rituals or guidelines you can follow. Start by creating a culture of trust, where everyone feels comfortable sharing their work. Encourage team members to share their design files and provide a link to riff on. During crits, designate a "Riff Zone" in the files, so that people can go in and riff on ideas. When asking for feedback on Slack, include a bit that says, "Here's the link if you want to riff!" By facilitating riffing, you can create a collaborative culture that promotes innovation and creativity.

Conclusion

Building a high-performing design team is challenging, but it's achievable if you focus on the right things. By hiring senior craftspeople, creating a culture of riffing, and encouraging a constant focus on craft, you can increase the quality of your team's output. These tips have worked for Figma, and they can work for your team too. By implementing these strategies, you can create a team that is passionate, collaborative, and dedicated to creating high-quality designs.

[[_SVA]]

#programming 
== is the equality operator
!= is not equal operator
< >
<= >=

#python #programming #beginner 
These generative AIs are really good at externalizing the lingual aspects of our brain. They are getting better at externalizing the visual aspects as well. When you're looking to augment yourself with these second brain technologies, don't limit yourself to language alone. Look for a second visual brain as well.

#secondbrain #business #learning #ai #music-app
- WebXR Device API(https://immersiveweb.dev/)(https://immersive-web.github.io/)(https://developer.mozilla.org/en-US/docs/Web/API/WebXR_Device_API)
	- Three.js(https://threejs.org/docs/index.html#manual/en/introduction/Installation)
	- Ammo.js (https://threejs.org/docs/#examples/en/animations/MMDPhysics)(https://medium.com/@bluemagnificent/intro-to-javascript-3d-physics-using-ammo-js-and-three-js-dd48df81f591)
	- WebGL(webglfundamentals.com)(webGL mdn docs)()

- ARCore(https://developers.google.com/ar/develop)on Chrome and Android(https://developer.android.com/studio/publish)
	- Java
	- https://developer.android.com/courses/pathways/android-basics-kotlin-two
	- https://developer.android.com/courses/android-basics-compose/course
	- ARCore Geospatial API(https://www.youtube.com/watch?v=NbSqmZFROIU)(https://developers.google.com/ar/geospatialcreator)

- Unreal
	 - C++

- Unity
	- C#
	- XR Interaction Toolkit
	- AR Foundation

- SteamVR
- Havok
- Freya Holmer

- Python
- Lua
- D3.js (https://d3js.org/)
	- https://data.sfgov.org/City-Infrastructure/Map-of-Public-Bathrooms-and-Water-Fountains/5zvx-hht7
	- https://data.sfgov.org/City-Infrastructure/Map-of-stormwater-inlets-drains-and-catch-basins/xbxd-zkc9
	- https://www.researchdatagov.org/
- Tensorflow

[[How I will put an AR game about the Barbary Coast on my website.]]
WebXR, Three.js, Ammo.js
It will be a website that people can go to. Make it a business on Google for people to access? Or make it a sight you have to tell them about?
(https://codemaker2016.medium.com/develop-your-first-webar-app-using-webxr-and-three-js-7a437cb00a92)

ARCore
Will be Android. Google business can still work but will have to download app. No iPhone support. ARCore Geospatial API

Bringing the skeeze back to the coast

OpenXR, Unity, Meta
PC and console gaming, through Steam. Chance to take the game further. MORE BETTERER!

SteamVR
Steam. The DOPEST!

Unreal
The MOST UPPEREST OF LEVELS!

[[Anybody out there want to help me set up a CI/CD, BDD, TDD environment for an android app I'm developing?]]
Points to a larger idea of emergency protocols, risk mitigation, disaster preparedness

If it hasn’t happened to you then rehearse for if it does

Adopt a “when” not “if” mindset

If it has happened to you and you’re freaking out you need to physically exhaust yourself. You need to go bend steel. A quick way to exhaust yourself is through a series of isometric exercises held to exhaustion. Thinks planks and squat holds. Carrying something heavy up stairs is the most metabolically intensive exercise you can do. Grab a heavy backpack and walk uphill.

Once your body is exhausted your brain doesn’t have energy for freaking out.

If you have experienced failure and are calm you can get to work.

If you are about to go into an experience where you think you’ll experience failure do some hyperventilation exercises to oxygenate your blood. This will regulate your calm and allow you to breathe through stress better.

[[_SVA]]
#ux #ai 

https://design.google/library/ux-ai

The user's understanding of their role in calibrating the system needs to be clear or it's HAL3000 again.

Consider the problem of being your own photographer. Your life becomes taking the photo and not experiencing the moment you're capturing. If you had a photographer to capture those moments you could focus on living them instead of photoing them.

Axioms of HCML (human-centered machine learning)
 - [[If a human can't perform the task neither can an AI.]]
 - [[A deep dive into the methods of an expert separates signal from noise and guides you with data collection, labeling, and component modeling.]]

Early experiments exposed crucial gaps and caused assumptions about quality to be reassessed. At the time of this parable there was not a singular intelligence that understands all things and can transfer knowledge from context to context.

Train the model on what bad looks like to distinguish it from the value in the good. The model also needed to be trained on framing and who to ignore.

This model was trained on social cues like the amount of time people spend in proximity to another. Models need a lot of training data. For this model; time, distinct aesthetic qualities, and familiarity of people where considered when providing data.

Avoiding unwanted redundancy without missing too many moment is a complex UX challenge for this situation.

All of the user's data stays on the camera until the user says otherwise.

Familiarity and control were guiding UI principles. Users got more moments to delete what they didn't want.

[[Fake it with real content over an ML model as the latter is way more costly than the former to get wrong.]] ML affords design logic like 'when something looks sort of like x, do y.'


Don't be the British and enforce a government on a people that never asked for it. Don't force your designs on a people you didn't design with.
#ux #ai 

https://aidesign.tools

Last activity 2023.
Okay Perplexity, I'm starting a brand and don't know what I'm doing. Where do I begin?

#ai
#ux #ai 

Disambiguate before acting.


#ux #ai 

https://medium.com/@refiredesign/ai-design-principles-ux-guide-0e8b285f2b1a

Begin with the audience's need and preferences. Use personas and journey maps to tell stories and reveal touchpoint opportunities for the AI. Make sure the AI does not perpetuate existing biases. Consider the context in which the AI will be used such as at a gym, in a studio, while driving, et al.

Use ML to analyze historical data and predict future actions for the user.
Communicate how the AI is using the user's data to make recommendations. [[Make your privacy policies accessible.]]
[[Use user input to improve AI over time via feedback loops like answer ratings or Roman voting.]] [[Give the human the ability to override the AI's decisions at any point.]] Keep the AI accessible. Onboarding is critical for educating the user on interactions and functions of the AI.
I was inspired and have been reflecting on a challenge for those who have profited off open source efforts to apportion their profits towards the open source effort else they be considered as preying 
https://www.linkedin.com/learning/ux-for-ai-design-practices-for-ai-developers
Taught by John Maeda

There are co-pilots and plug-ins. Co-pilots are agents. [[The new way of doing things is building experiences that use the model.]]

AI orchestrates between models/infrastructure and apps.

Old way, I'm going to build a model. New way is I'm building with a model. This new structure is collaborative.

The user is the boss, AI is not the boss but the AI is only as good as the boss. OpenAI had a sonic boom moment that kicked off the AI craze. Curiosity allows you to be inventive because you're less afraid. Non-tech people who aren't developers will grasp this. Trust must be appropriate that the Copilot understands the intent and purpose.

The three laws that matter in the field of AI
 - emotion
 - trust
 - failure, non-deterministic so there is always a chance of failure, it the actual sense

Computers used to be a command interface but this AI era is not a commanding medium but a collaborative one.

Eliza the first chatbot in 1966 from MIT Joseph Weizenbaum revealed that people put a human behind the AI instead of seeing the dead behind the eyes or that metal glean of distrust. [[This leads to the UX patterns of 'hey, this thing is an AI', 'here are some suggested actions', and 'give us your feedback.']]

AI orchestrates with a kernel. Hardware and GPUs are the infrastructure for maintaining AI. Models are the second layer. The UX is the dashboard. Plug-ins are what you add to the vehicle. [[UX and plug-ins are the places of great leverage. Everything else is non-deterministic.]]

The Iron triangle guides the human and Copilot relationship. Mathematics are non-deterministic, you know mathematically. You gotta lean into it. You can only lean on speed and cost not quality. Quality is governed by speed and cost. Make your UX feel faster and encourage people to pay more.

Progress bars make it feel fast. Think about elevator mirrors and that story. ChatGPT streams out text making it feel faster. Share status updates to why it takes a while. I'm doing this. Showing the number of files increase transparency. There's a UX study on that for an airline or something. You can display reference material for the user to browse while the AI does its thing. [[Make waiting fun is a core UX for AI principle.]]

Now we're getting into code
https://github.com/microsoft/semantic-kernel
This is the AI notice pattern in code, for Microsoft.
https://build.microsoft.com/en-US/sessions/bac1bf0b-7c70-4366-bb86-0abd11b009bc?source=/speakers/ea57976b-5f80-4ad3-9a99-fec904bf107b

The OpenAI API process you need to undergo to use the semantic kernel in VSCode begins with creating an account or logging in if you already have one. ChatGPT can be your login hub to OpenAI. Much like Google if you are logged in there you're logged in here. You may think that's old hat. I find the ecosystem and architecture kinda amazing.

You can create an account with your Google or other platform. I think Facebook and maybe Apple. Or an e-mail. You do you.

[[Working with the OpenAI api.]]

https://platform.openai.com/api-keys
You'll see a prompt to create a secret key.

I know exactly nothing about this so what the heck permissions do I give it? I went with Read on all and Write on Model capabilities. I figure that does the least amount of damage and gets me whatever Model capabilities are.

Perplexity didn't tell me much I didn't already know. I don't know if this will work and I'm concerned too much is at stake and I'm too ignorant to deal with it.

Which is actually pretty true. That I'm doing it anyway may be a testament to my ignorance but I'm doing it anyway. So...

Perplexity says a best practice for securely using API keys is to store them in your ~/.bash_profile

Open your terminal. You can search your Mac or Windows/Linus, I don't know what else, for it. Once it is open then your command string is as follows.

bash
nano ~/.bash_profile

Now you'll find yourself in a text editor you may not have seen before. It is quirky. You don't have to be here long.

Copy and paste the proceeding snippet into the text editor.
export OPENAI_API_KEY='yourkey'

Replace yourkey with your key. The quotation marks matter. You put your key in between them. Don't leave them out.

CRTL+O, confirm the file, and you're out. You can quit terminal.

Almost

Open terminal.

bash
nano ~/.bash_profile

Check for the changes and if they aren't there add them, save, and exit. Check for what was missed. You'll figure it out.

That concludes the adventure in saving our OpenAI API key

Speed is perception and design could be leveraged to work with it. Cost is more expensive.

Ada spawned DaVinci but is much cheaper to use. You gotta make a cocktail of the models. You're doing some strange things to make sure you save cost and need to be celebrated for it.

Cost per token.

Have a conversion to think out loud while it thinks out loud. You can play with most sophisticated models. You can accelerate your slow thinking muscle.

Non-determinism is a thing. The thing. Native code is deterministic. Syntax and Semantic, Precision and Power. Someone who is the lever for both wins. This is quality.

A tetrahedron point is reveal as emotion. The Iron triangle plus one. Paul Eckmen in 1976. I think this is the Lie to Me guy. Only one of his six is positive. 5/6 are negative. Check out the Kubler-Ross grief cycle. You want to design something highly familiar and highly novel. [[Don't humanize the AI so emotions are mitigated when the AI lets you down.]]

[[Adding friction is key to the new UX.]]

Always say 'for example' when you open your mouth because you will always make sense.

[[John Maeda's UX patterns for copilot.]]

Much gratitude @JohnMaeda
#ux #ai 

https://uxdesign.cc/artificial-intelligence-in-ux-design-54ad4aa28762

Use cases
 manager receives countless approval requests,
 up to a certain amount, specified in the software, the budget requests are approved.

Pretty good summation of of the principles
 - put the human first
 - design for trust & transparency
 - make the AI explainable
 - Allow the user to provide feedback and control
 - Everyone who works on AI is accountable for it.
#ux #ai 

https://www.shapeof.ai/
https://www.linkedin.com/in/emmiecampbell/

Shape of AI is aggregation and pattern creation/revelation referred to here as emergent patterns.

Shape of AI is well poised to become a critical part of the modern UX milieu.

Don't be surprised when people expect you to cater your parlance to these ideas and concepts.

These arguments are conclusive, expansive, and well-formatted.

The anti-patterns and abundance of evidence are high points of the argument's integrity. The softwares analyzed are ubiquitous enough to uphold the findings at mass.

This is some next level stuff.

For free.




The prime challenge is distinguishing the AI. Separating it out. Identifiers distinguish the AI. Identifiers give it presence. Signifiers is a sufficient substitute for identifiers. One way to make that distinction is with dress. [[A visual distinction immediately creates separation.]]

Naming is a challenge and is not alone sufficient enough to distinguish the AI. My take is to go with the brand name, not some person name. Dehumanizing, deplorable in all manners, instances, and occurrences aimed at another person, is an active necessity with AI.

The second challenge is presenting how to use the AI to get where you are going. Wayfinding is an ecological perspective transplanted onto a digital environment. Where am I trying to go and how do I get there are basic questions which guide our lives and are beneficial to architect your software around.

[[Suggestions, mad libs, and templates address the bulk of the wayfinding challenge.]] Nudges offer up a chance to engage with the AI.

The text prompt is not the ideal interface but it does have its benefits. The challenge of the prompt remains the challenge of a blank slate.

The third challenge is one of benefit. 
[[Beneficial interaction patterns to aid an AI's utility are auto filling mass data cells, the suggestion enhanced text prompt, collaging from existing sources, and providing synthesis structures.]]

One way to get an output from AI is to remix and blend an existing one. Remixing blends well with collage. Essentially you are exposing someone to a prefilled template and left to figure it our rather than exposing then to a blank slate. This person gets it.

The fourth UX challenge of AI is tuning the model, whether to decrease your sigmas of deviation or personalize the AI to your brand voice or personality. [[Allowing for immediate controls to the AI output like parameters, filters, weighting, negative prompting, sliders, widgets, et al benefit the user with their editing operations.]]

Allowing for long term changes requires a feedback cycle. The feedback cycle is how you address drift. [[Using edge cases as special input into your feedback cycle is a pro level play.]]

These models are like characters in a game. You need a breakdown of their stats to determine the best model for the task. Create a character sheet for each model, benefits, deterrents, excellences, failures, most successful with _blank_ and for _blank_.

The final challenge of UX for AI is trust. Caveats point to transparency, expectations, and confronting reality. Controls like stopping, starting, and continuing actions keep the user in the pilot seat. Footprints keep the AI credible through citations and provenance of statements.

Feedback can help impart ownership of the AI onto the user. The key trust aspect of feedback is accountability. [[Prove the model gets better at what does works and where necessary good at what doesn't work.]]

Data privacy is a consideration and transparent access to it for the user is needed.
Press releases and outreach 6-8 week upfront
Give influencers and bloggers early access
Brief analysts
Leak information on social media
Create announcements constantly
Enlist channel partners and distributors
Offer free trials
Create in-depth usage videos
Make 'how-it-was-made' videos
Give discounts
Start a referral program

#marketing
Roger Barker psychologist, (Ecological psychology, 1968)

https://youtu.be/k4fKBqu-Ris
These words express a truth of most any change, interpreted here as a product, gift, or offering, abstracted though to it's ultimate Saiyen in change. This highly probable reality of not asking for something from you and not benefitting from what you've provided is best acknowledged as to allow the reasoned among the crowd to make their decisions. We want our approach to be positive and only give people what they asked for and what they might benefit from but that's often not the position we can start from. To ensure this scenario doesn't occur it's best to come with proof that someone did indeed ask for what you've provided and therefore will benefit from it. Sometimes though what you benefit most from is not what you asked for and it takes heart and moxie to give to someone what they did not ask for with the promise they will benefit from it.
Generative AI is a maquette. It will "act like" anything and spew you falsehoods. A true con, never to be trusted. I share some of these concerns about quality and credibility. I think the solution is in community. The idea of using each other to correct each other. Iron sharpens iron. Steel sharpens steel. Credibility is approval. You passed the test. Learning courses are just steps to pass a test. Credible sources can publish tests instead of texts. It will be more efficient.

Prompt: Give me a doctorate level test determining my competency in the field of Interaction Design
Prompt: Use this text and give me a 20 question multiple choice exam testing my knowledge of affordances, complete with practical exercises

These prompts are a reality and are useful. Pretty soon we will have a certified IxD bot that provides credible answers to even the toughest questions. 

Using ChatGPT to test yourself. [[The ChatGPT revolution is editing, curation, and taste.]]

Mine literature on the Barbary Coast
for stories, facts, and games.
Connect with Barbary Coast literates
Map the Barbary Coast medallion
-AND-Find the public record of their locations
Build Google Maps directions list
When you check in at the location +- 3ft it creates a list, marks your map with the other medallion locations, and marks your list with where you've checked in at
%completion
Picture match for AR scan
Saves experiences
Execution is how you free yourself from the confines of design.

By nature design is a preemptive act. Design is what you do before you act. In a small twist, design is also the history of what you have done. Though that is of no concern for now.

It seems to me there exists a tendency to conflate creation and design. I believe this is due to the proliferation of the idea of a design process. Of any process really.

Processes are moments of action sequentially linked by time. You can’t design and act simultaneously. Because action is placed under the banner of the design process we consider them one and the same.

You aren’t designing a work of art if you are putting paint to canvas, you are creating.

Does that mean design can’t have a process? Is the act of designing defined as the process of creating a design or is it something else entirely?

Practically, it doesn’t matter. Only the high-mind concerns itself with such distinctions. Which I think is precisely the point.

Somewhere along the way we need to concern ourselves less with design and more with what we’re making.

By all means, go forth and design but someday I expect you to quit and start making instead.

[[_SVA]]
Being that the promise of design is success it only makes sense that it can be pointed at you and your future. Designing your life and your work life are popular topics in modern culture. Something either happens by design or by accident and you don’t want your future self to happen by accident.

I think that’s all nonsense. Design helps you achieve success but cannot guarantee it. What happens next is unknown. That isn’t to say that you can’t design your future self. I am saying though that you need to be a little squiffy with what it means to design at that point. When dealing with timelines that are a generation long the only design you can provide is one that evolves. Design becomes the verb not the noun. When designing your future self you’re continually designing. Which is what most people call living. We don’t unintentionally become who we are. We can’t. Every action by a human is intentional. It cannot be any other way. You’re constantly designing your future self, one moment at a time. Here’s how you get better at it.
 - Interview someone from the oldest generation you have access to, note relevant and irrelevant wisdoms (the past is not guaranteed to carry the future, not everything will be applicable)
 - Set up milestones around qualities you wish to possess not achievements you wish to be known for
 - Write your milestones at least once a month
 - Understand values
 - Form a group with people from generations younger and older than you, change it as generations are born and die
 - Reflect with them on the qualities you possess
 - Seek advice for changing
 - Join a similar group for someone else

[[_SVA]]
[[Loose systems encourage appropriation or at least allow for it]]
Inheritance is a key concept.

[[To add inheritance in Csharp use colon {class} after the variable name.]]

[[If a variable will not be changed from another script then keep the variable as private.]]

#programming 
New world context
How do the modern leaders build products?
How do we remain relevant?
How do we maintain an awareness of the industry?
What are ways to deliver to development teams outside of handing HTML/CSS?
How do we become a better team?
How do we better collaborate amongst each other?

Critique

Craft
 Front-end
 A11y
 Design Sprint Moderation
 Figma
 Social Media
 Storytelling
 Animations
 Prototyping
 Building rapport vs offending during testing, especially now
 CSS/Flexbox
 Inspiration sites like Flash Awards

Business
 Piloting
 PowerBI
 Smarketing
 Who has the funding to do the testing?
 Exposing the need
 Interview practice
 Value to Improving
 Involvement opportunities

Design
 UX vs CX
 User Story Mapping
 UX Strategy O'Reily book
 Strategy
 Robotics
 AI Conversations
 Behavior models
 Service Design Blueprints
 New Tech
 Design thinking in-depth and in practice
 Ideation
 UX Myths
 UX Fake News

Life
 Success
 Failure
 Decision Making
 Data Visualization
 Data Archaeology
 Time & risks
 What's going on in the world
 How to give a talk
 Building relationships
 Managing energy levels

Culture
 More on the mental aspect of the job
 Staying focused
 Remote working
 Balance
 Process enforcement
 Nuance when we are one man wrecking crew
 UX culture

Communication
 For example, if someone attacks you, apologize and flip it back using a Label™: It sounds like you’ve got a reason for saying what you just said. 

User Experience (UX) User Interface (UI)
Product Design
Interaction Design
Wireframing 
Design Thinking 
Human-Centered Design
Usability Testing
User Research
Graphic Design
Visual Design
Software as a Service
Product development
Prototyping
Design Strategy
Branding
Brand loyalty
Software design
Analytics
Innovation
Creative Direction
Problem Solving
Data analysis
Creative thinking
Analytical thinking
Technological literacy
Curiosity and lifelong learning
Resilience, flexibility, agility
Systems thinking
A.I. and big data
Motivation and self-awareness
Team management
Service orientation 
Social influence
Design leadership
Design operations
If you interact there's a 60% chance you'll learn better.

AI mimicks reasoning but cannot actually reason. It looks human but is dead inside. It is filled with the mathematics not the esse.

People will pay to make money or at least feel like they are. #webinars

Chatbot generating sales and appointments. #conversationdesign
for sales. Like an appointment bot for a Dental office. Or sales bot for comic stores.

Show them a demo. The chatbots sell themselves. 1 chatbot a week to sell at $1k. You've made the chatbot. You're selling it to them.

$1-5k v salary

AI Avatars for comic book stores. AI voice, AI virtual avatars, AI costumes, AI writer.

Trends, ride to the middle, for your niche. Visual AI and UX.

5k words. write this from a professional cleaners perspective. Copy and paste, expand on point 500 words. Upsell to an audio book through eleven labs into synthesia or other marketing tool.

sell through chatbots, websites, amazon, ebay

6 months and 30% increase, testimonial
for selling yourself to others

sell and report your results on LinkedIn, don't sell on LinkedIn

Meetups about AI & UX, visual UX
What's good party people? The format of this meeting will be. It will be approximately blank in length and will cover blank topics. You're generous to attend.
 - goana gimme dem e-mailz

I could sell AI UX audits, where I compare your AI against the HAX and other heuristics.
 - make a video of me doing an audit
 - record calls and sell them
 - 90 minute audits for 120 dollars, that's 2.6% of my corporate rate, giving you a total discount of 97.4%.

Sell access to my Figma for $4/mo, $1/wk

Pay for a community Discord, $1000/mo currently open to 1000/new members.
100 people @ $10k/mo
10 people at $100k/mo

Newsletter
An unpredictable publication focused on AI, UX, Interaction Design, and likely other things.
A weekly gateway into the nexus of AI & UX for image generation
Plus whatever else I'm into.
Probably at some point something humorous and hopefully poetic.

A primer on the important tasks for making movies.
All there is to know about UX design.

What gives me the right?
To proclaim as expertise?
This is not an exercise in empathy. 
I submit I was born with a right to experience what I want and through my experience I am made right. Albeit relative to my experience and the credibility of its relation to others' in the field. You may cry I'm a subjective expert and therefore invalidate myself. I might call out a history of evaluation against affirmed experts. My practice has been anchored in UX, IxD, and image generation for the better part of expert hours, often in collaboration with other ascribed experts. Plus I enjoy this stuff so I seek it out and toy with it. Relative to chance do the odds of my involvement matter? I know who improves because of me and I know how they improve because of me. Whether anything I say or do will shift forces relevant to your needs is the conjecture of the ancients.
I proclaim the right of expertise to my experience and testimonials?

[[You could have KREA make movies! ]]

#ux #ai 

https://www.linkedin.com/events/whatdesignersneedtoknowaboutaiw7163223170869628929/theater/

Data Science, Strategy, & Consulting
MoonPig, Bank, Startup
We've got this market we want to enter, how do we think about it? #strategy
How do we get access to LLM in a secure environment and then how do you train it?
How do I incorporate AI into the business. Output validation is difficult.
Message personalization is valuable. Copy to customers would go through layers of reviews. A genAI customer support person is what they want yet have found it doesn't work well especially with layers of reviews.
How do you decide the features that bring benefit and work? ChatGPT is the chatbot of the current era. Everything doesn't have to be a chatbot. It is hard for people to imagine what could be done. You ask them for an image of anything and they ask for a cat or a dog.
Value downstream and data upstream meet in the middle with unstructured data, one-step task instructions, and better leverage of existing documents as the likely opportunity areas.
One step create brand guides, process docs, internal wikis, training materials, HR policies.
The chatbot is a default design pattern. We need to do it this way because this is what we're capable of and we need to launch now. How do you affect change in that environment, in an environment with a Head of AI? ML power is with engineers.
Breaking down a trust pilot review? Is it a positive or negative or classification is the old way. Now you can write a summary, identify issues, identify the sentiment, and guess the NPS. Now, as UX you need to create your own demos and ideas, don't wait on engineering.
The border between UX & AI. The inward pass from UX and outward push of AI. The two meet in a neutral location.
How do you approach AI with a better interface? We don't know the patterns yet. What is beneficial are multiple points of attack at different altitudes and success variabilities. Stay aware of new models and how you can incorporate them.
Setting up a production environment is still in the realm of engineering but prototyping is up for anyone. You can use Replit for production code. Write the code in chatGPT, paste any runtime errors back into chatGPT, and keep going.
Designers are behind. How do you stay at the forefront?
Podcasts, Twitter, LinkedIn, Reddit, Newsletters
Thursday AI is probably way too much but it's good. Latent Space is an interview and also good. The best way to stay ahead is to try with new models and tech.
What is the value of design in a software like MidJourney?
It is still easy to design really bad experiences. As an example with greeting cards, does the UX of AI generated cards make enough sense to be valuable? The chances are low given what customers expect out of a greeting card experience. They aren't coming to make their own cards so why give them a tool to do so?
New approaches to old problems like onboarding are a good way to go or submitting a complaint. Voice interactions that turns the AI into a conversation partner.
Lots of open source models give you common sense answers yet the big players don't. Is it okay to sacrifice 100 grams of pasta for a GPU?
What budget do you have for maintenance?
It's still roughly 90% of public that don't know or care about this stuff. It is still beneficial to temper expectations.
Engagement leads to understanding and is far more valuable than understanding.
[[Character sheet -> genAI model -> 3D model]]
They work in the layer between GPT4 and web.
#ux #ai 

https://www.linkedin.com/feed/update/urn:li:activity:7086602430917791744/

Through these resources you will get way to design responsible AI experiences that put humans first, remove biases and assumptions, provide understanding, explain the decision-making process and give users feedback and control.

Many of these seem not to consider partnership with an ML person and as such become tools of education and vision rather than implementation. Don't read these, find a ML person and build a thing.

Clearly if you want to work for a company it would help to design inside their paradigm so pick your house and run with it.
  
[[AI interface design patterns with Smarter Patterns.]]
[[AI x Design toolkit.]]
[[People + AI by Google]]
[[IBM has a guide for AI.]]
[[Microsoft has pulled together their guide called the HAX.]]
[[AI + design toolkit by Corinne Schillizzi and Tangity.]]
[[AI Design Process Toolkit by Futurice]]
[[Responsible and Ethical AI Practices, by Microsoft.]]
[[Responsible AI Toolkit by PwC.]]
[[Designing human data by Thomas Otto.]]
[[Everyday ethics for AI by IBM.]]
[[Designing AI For Children Toolkit (+ Checklist) by World Economic Forum]]  
[[AI governance principles by Future of Life.]]
[[AI-driven design on Awwwards.]]
[[Designing for AI, a UX approach.]]
[[AI design tools design + AI publication.]]
There’s a TED video somewhere on the internet in which a man discusses his drive behind this large scale knit-the-world initiative he undertook. It begins with him bedridden and bored. Bertrand Russell teaches us, interestingly enough, the same thinking I had. Boredom is a catalyst. It is an activator. There is real human value in anything which helps you stave off boredom.  

“Human beings show their superiority to the brutes by their capacity for boredom, though I have sometimes thought, in examining the apes at the zoo, that they, perhaps, have the rudiments of this tiresome emotion. However that may be, experience shows that escape from boredom is one of the really powerful desires of almost all human beings.” (Bertrand Russell, 1950)  

If your aspirations outpace your capacity to achieve it may be because you’re not bored enough to do anything about it.

[[_SVA]]
To begin you need the capacity to run your AI. If you don't own the equipment or if you want to do this at scale you'll need to rent the capacity. A cheap, though not free, yet quality option is RunPod. A free, yet public and not commercially viable option is Kaggle. You're renting GPU space.

If you want to work locally you'll need a computer with a high-end graphics processing unit. NVIDIA is the leader in this space and most likely will remain so for a while. These GPUs or graphics processing units can work fast and are the only thing capable of handling the immense number of calculations AIs need to run at speed.

The idea is to leverage the innate power of a GPU so the CPU doesn't have to jump in. Your CPU can run a model but you'll get a result back in days rather than minutes and you won't be doing anything else on the computer while it is processing.

RTX A4000, 16GB VRAM, 6 virtual CPUs, 23GB System RAM, 40GB ROM

In both these instances you are creating a new notebook, whatever exactly that means. A notebook seems like an instance of some software setup. These are Python 3. You'll want to go line by line and understand why numpy and pandas are helpful.

You can learn most of what you need to know about the Stable Diffusion or any model through Kaggle's model cards or their GitHub repos.

You'll need to give your phone number to Kaggle to run on their GPUs. It doesn't look like Runpod asks for your phone number.

Once you've uploaded the sample notebook you can see the code required to run stable diffusion. You can execute the code blocks one by one to see what each does or run them all at once.

The process of running through the code takes about 10 minutes on Kaggle and 5 minutes on RunPod.

You need to turn the notebook off so someone else can use it when you're done.

Ollama can help you run an LLM locally.
https://www.youtube.com/watch?v=k4ReYshcA08
[[Cost of hosting Llama is not less than ChatGPT.]]

[[LoRA is a method to fine tune weights from CLIP and Unet.]]

Models are trained on image sizes. Image sizes like 512x512. Any image size outsized of the size the model was trained on will produce unexpected results.

Reproducing the same image means using the same seed.

Use latent noise when adding an object not in the image. Start from the CHAOS! Kafka would be proud!

Denoising strength gives more or less weight to the prompt over the image content.
A low denoising strength favors the image over the prompt.
To overcome this you need low barriers and a high perceived present value.


Jakob Nielsen covers common complaints about the usability of prompt-driven AI tools, such as those used for image generation. Users may find it challenging to articulate their needs effectively through written prompts, particularly if they lack advanced literacy skills.
- https://www.linkedin.com/pulse/prompt-driven-ai-ux-hurts-usability-jakob-nielsen

Manish Agarawal ruminates on the black box nature. He profers a solution of conversational interactions using shared semantics.
https://magrawala.substack.com/p/unpredictable-black-boxes-are-terrible

I'm relieved to find someone other than myself who I can agree with on this matter. His language and interpretation are his and as such are not the way I would put it though in aggregate we've arrived at the same destination.
To understand what I mean, these two assumptions need to be considered true. There is no future. There is only now. 

Design’s promise is an idealized future. Design is useless right now. Design can only be meaningful right now if right now was created by a design.

You’re probably thinking I’m off my rocker. You say, ‘design isn’t useless. Design is, or at least can be considered, the only way forward.’

But design is a historical artifact. It deals exclusively with a moment when whatever was designed did not exist. Design is the precedent. It is the foundation. 

Obviously I’m wrong. This is all high-minded nonsense from someone who has too much time to think about existential crises like the non-existence of the future.

Pragmatically, actions have consequences. Designs lead to future outcomes. We’re here and our world is the way it is because of design. 

There is a tension though. You have to start from where you are to get to where you want to be.

[[_SVA]]
I get that whatever you’re doing is important. It is so important that getting it wrong is not an option. You might fail but you won’t give up until your design succeeds. That’s a lot of pressure. Even if it isn’t it still is. You probably think about your design in the quiet moments of your life. This isn’t a bad thing but the weight of responsibility only grows. The more you’re aware the more you’re pressuring yourself to do better, be better, succeed, don’t fail, die rich and happy.

I’m not saying to let all that go. Imagine for a moment that your design isn’t important enough to think about in the quiet moments. That your design doesn’t matter. That what you’re doing is worth doing simply because you enjoy doing it not because of what you’ll create.

Designing something that is fun and playful can be a serious affair. What requires effort has value and value is something to take seriously. Breathe and let it go. Let the serious facade recede. Let the preposterous center shine. Release the jester. Entertain the court. Crack a joke. Make it inappropriate. Design something absurd. You might find this notion nonsensical, but there is more real estate in the absurd than in the serious. Don’t constrain yourself by taking yourself too seriously.

[[_SVA]]
#ux #ai 


#ux #ai 

Articulation Barrier
Users often struggle with creating the right prompts for AI image generation, leading to cognitive and typing effort, as well as challenges in expressing their visual concepts in writing.
- https://www.nngroup.com/articles/ai-articulation-barrier/
- https://www.linkedin.com/pulse/prompt-driven-ai-ux-hurts-usability-jakob-nielsen

Unreliability of AI in Evaluating UX Screenshots
AI is found to be unreliable in identifying usability problems in screenshots, with a significant percentage of issues being overlooked. This can lead to potential inaccuracies and inefficiencies in the UX evaluation process.
- https://jakobnielsenphd.substack.com/p/ai-ux-evaluation

Impact on Job Market for Designers
There are concerns that generative AI could impact the job market for designers, particularly junior designers, as AI is increasingly capable of automating tasks traditionally assigned to entry-level designers, potentially leading to job displacement.
- https://www.toptal.com/designers/artificial-intelligence/ai-ethics-in-design
- https://www.nngroup.com/articles/ai-articulation-barrier/

Usability Challenges
The usability of prompt-driven AI tools, such as those used for image generation, is a common complaint. Users may find it challenging to articulate their needs effectively through written prompts, particularly if they lack advanced literacy skills.
- https://www.linkedin.com/pulse/prompt-driven-ai-ux-hurts-usability-jakob-nielsen

Hallucinations and Inconsistencies
AI-driven redesign suggestions are reported to be inconsistent and untrustworthy, often leading to inaccurate or misleading recommendations. This can result in wasted time and potential negative impacts on the design process.
- https://jakobnielsenphd.substack.com/p/ai-ux-evaluation
Meaning is a fickle concept. It is not static or constant. It varies per person per context. It is perhaps the most important concept to human development. Meaning is significance to your situation right here, right now.

Information carries no meaning. Our brains construct meaning. In that sense, meaning is the way the brain slots the information into its internal library. If something has no meaning it is ignored and forgotten.

Definitions propose a starting point for meaning but really a definition is information. Meaning needs an emotional component perhaps more so than an intellectual one. If you don’t attach positive emotions to the idea of design it has no meaning.

What then can design mean? Design can mean actualization, hope, faith, control, structure, power, stability, success, et al. There can also be meaning in the act. It is valid to say the point of designing is to design. None of the proposed meanings are universal. It is important to realize that design carries no meaning. You do.

[[_SVA]]

[[Python is a general purpose language whereas Javascript is specifically for webpages.]]

[[Python comes installed on a Mac.]]

[[Instructions for reading and writing code inside an IDE]]

[[Statements are the individual actions your program takes.]]

[[Troubleshooting begins by defining the error.]]

[[Variables and data types store information.]]

[[Strict programming languages require defining your variables and type before using them.]]

[[Java, C#, and C++ are strict languages.]]

[[Strict languages lead to less surprises at runtime.]]

[[Blocks are statements related to an opening condition.]]

[[Python inherits ideas from the programming language C.]]

#programming #beginner #python
#design
Prototype in what the final product will require or close to it. This may mean prototyping in a game engine, WebGL, or other simulator. Be comfortable being bad at this until you're good at it. 
#ux #ai 

[[Given what an LLM is good at can it be beneficial in this context?]]
#ux #ai 

https://www.awwwards.com/AI-driven-design

Chapter 4 is great with examples not just text.
Trust & Transparency
User Autonomy & Control
Value alignment
Ethics

Some specific ethical challenges mentioned are housing of data, privacy, lack of transparency, lack of control, alienation of human capabilities.

Consider how you can use AI to maximize outcomes while minimizing input. Design for failure.

Chapter 2 has a great breakdown of the feedback loop to design for including an example from Google.

Use cases for law enforcement is exploring and linking data, detecting objects, faces, and clues, location evidence with situational awareness or disaster, and effortless data exchange via chatbots.

Heuristics
AI confidence
Source citations
Human-driven recommendations
Feedback

Expectations is a breakdown of trust. Considering failure and provide a way forward.

[[The main challenge of AI is how to translate subjective human needs, values, and experiences into algorithmic parameters the model can optimize for.]]
As a provocation, consider that the best way to wreck your opposition is to help them. If all your opposition wants to do is burn the world down it may seem strange but show up with a can of gasoline and some matches. This is not a tactic of subversion or espionage. This is an attempt to understand how your opposers gains benefit from others. In the process you will gain some practical empathy. Empathy is always valuable.

[[_SVA]]
We have an obligation to do work that moves us forward in significant, meaningful, and humanitarian ways. What you make matters. Money is easy, integrity is hard.
You can think of the brain as a biological device consisting of three layers. From oldest to newest they go motor, emotional, intellectual. From control they go motor, emotional, intellectual. It’s a fact there are certain motor actions you cannot deprogram. Touch a hot stove and don’t pull your hand back. Just sayin’

What we can do with this information is design for each layer.

Designing for the motor layer involved understanding the bio-mechanics of the body. Knees don’t bend backwards. There are other truths about the way the human body is mechanically engineered that can be useful when designing but you really need to spend time to understand the motor capabilities of your audience. We’re all built the same way but we’re not all capable of the same things. Olympic athletes require a different design than couch warriors.

Designing for the intellectual layer seems difficult and is perhaps the most frightening of the layers to explore but it’s not overly complicated. It is true that the intellect is one area where humans diverge the widest. Our experiences make us into different intellectual beings. How I interpret the world may be different than how you interpret the world. Explore context, culture, and history and you’ll have solid ground to start your designs on.

The emotional layer is the trickiest because it is the layer with the largest influence. Your intellect changes based on your emotional state. It is possible that in certain emotional states new areas of your motor ability are activated. The stories of mothers moving cars off their trapped children tell us that humans are capable of more than we generally allow ourselves to be capable of. However, for the vast majority of us, those cases are rare. It is generally supposed that emotions impact our intellectual capabilities much more readily than our physical.

Designing for emotions involves understanding what has to be true for someone to shift states or true for them not to shift states. You seek comfort at least as much as you avoid discomfort. Shifting out of negative states requires a release. The negativity has to be confronted and worked through. Fear dissipates when the fear is labeled and processed. The same goes for sadness, grief, melancholy, and the many other shades of depression we experience. Designing for happiness means giving a feeling of forward motion, satiation, and control.

Follow the rules of your brain and design for the physical first, emotional second, and intellectual third.

[[_SVA]]
Some ideas are unequivocally bad ideas. Some ideas sound bad but are good ideas. Some ideas we call bad because we’re afraid of them but they are actually good ideas. Some ideas are obviously good ideas. The notion of constructive dialogue is beneficial but is a wholly insufficient means of creation. ‘Yes, and’ establishes the past as the truth. That’s the ‘yes’ part. I accept what you said. It is now part of reality. ‘And’ is what I’m doing with that information. The subtext is that ‘and’ does not reverse ‘yes.’ The truth is set, move on.

Piling onto the past helps everyone feel included in the creation process. It does not inherently produce a desirable creation. A common wisdom is that great writing is rewriting. A common phrase illustrating this point is, ‘I could have written a shorter speech if I had more time.’ Creation and curation. Variation and selection. Exploration and evaluation. Writing and editing. The creation part is only half the process. ‘Yes, and’ is creation not curation.

The complement is critical reflection. You need to take a step back from whatever you ‘yes, and’-ed into existence and assess it’s value and merit. Make note of the great ideas, the serendipitous synergies, and the moments of unexpected pleasure. Make note of the bad ideas. Don’t turn a good idea into a bad idea. Realize though that creation produces more failures than successes. You’re stripping what you made down to the irreducible core. This core is now the new truth, the new ‘yes’ that you ‘and’ onto.

I get that in a world of abundant criticism and denigration we need a tool of inclusion and positivity. Understand though that in a world of inclusion and positivity we also need criticism and denigration. Humans and our nature are rarely singular. Yin and yang need each other. ‘Yes, and your idea is not a good one’ is a perfectly valid way to create.

[[_SVA]]


### youtube_LlcFkDFYFkk.txt

[Music]
good afternoon everybody um I am going
to be presenting a talk I did at AI user
group for developers a couple weeks ago
uh because this was extremely last
minute Jackson asked me literally 5
minutes ago uh so please bear with me me
as I try to present on the spot here
it's really a test of my
job but yeah I'm excited to share a
little bit about how to build a great UI
from canvas perspective on AI so if
you're not familiar C with canva it's a
design tool that you can utilize to
create lots of assets from marketing
materials to social media and more this
presentation actually is entirely done
in canva as well and we have an app
store that we launched last year to the
public in June at our canva developers
event called canva extend which is a
sweatshirt I'm wearing and since we've
launched that App Store we've had over
100 apps including over 50 of those
being AI apps live on our app store and
we've reviewed many many many more than
that so we've learned a lot of tips and
tricks to make a really good UI
experience for your AI app through our
experience so I'm going to be talking a
little bit about how to build a great UI
for your AI from a n non-designer at a
design oriented
company so I'll give you some tips that
we've learned from our experience we'll
then go ahead and try to live fix an app
together and then I'll show you some
resources as
well so here are some of the things that
we've learned as a company from
reviewing lots and lots of AI apps from
a lot of thirdparty AI developers out
there how many of you are an AI startup
or starting out on your AI journey and
trying to bring a product to Market
a few of you okay so this could be
really helpful for you as you're
continuing to develop that or if you
even if you already have a product you
might get some information here um that
could be beneficial for your
product so the first tip I want to look
at now you guys are actually designers
this time the developers had no idea
what was wrong with these uis when I
tried this for those designers in the
room any thoughts of what about this UI
could be improved or isn't
ideal no
now okay how many people are familiar
with the canva editor has everyone used
canva a decent amount okay um so for
those of you who aren't familiar with
the canva editor this is a snapshot of
the canva side panel um so if I actually
just like zoom out for a second it's
that real estate here on that black side
panel jump back right right back in So
when we're talking about a limited
amount of pixel width we want to be
really cognizant of how how we're laying
out that page to maximize the amount of
user inputs we're able to accept so by
actually thinking about the vertical
layout a little bit more because we
don't have the entire real estate of the
screen here we're actually able to get a
lot more user input onto that page by
better utilizing our vertical layouts so
here not only are we able to change how
many inputs we have available for our
users to select we're also able to add
additional ones which means that a user
no longer has to be a PR engineering
genius to be able to use our AI we're
able to make them select a couple of
those beforehand so that they are
getting a better result once they're
creating it by allowing re really
thinking about how we're using that real
estate laying it out a little bit better
and allowing users to select more
options as opposed to forcing them to
try to type it into their
prompt our next tip is also about
vertical layout any thoughts on what
could be improved here
now okay let's think about the button
layout right the primary action that we
want a user to do is to actually
generate that image actually use our
technology by putting the amount of
credits you have which really isn't a
foundational component of your app is
just letting users know what they can
continue to do we're taking it away and
we're making users continue to have to
scan the screen to try to find where
that primary action is again let's
utilize that vertical real estate if we
don't need all of it don't use all of it
make sure that you focus in on and
making sure that the primary action your
primary mode that you want a user to
interact with your application is really
easy to find and really obvious to be
able to create a better
app our third
tip
is any ideas
here
around loading how many people have seen
a loading bar that just kind of sits at
like 5% now all of a sudden you jump up
to 70% and then you sit there a while
and then you jump up to
80% it's really arbitrary how like what
does that actually mean to a user it
never actually is um representative of
the amount of time that it actually
takes to loading to load an image so
let's go ahead and remove those
percentages and let's also think about
the loading experience if your AI takes
a while that's okay but don't let users
think that they can change the input
values while that information is loading
if all of these text box are enabled
while my AI is actually loading I as a
user think oh crap maybe I can actually
go ahead and change that input I really
didn't actually want an Australian
accent I wanted an English accent or an
American accent and then when the output
comes back to me and doesn't have that
change I'm going to be really confused
remove all of those options to make sure
that a user doesn't think that they can
change during that loading experience of
your AI to make sure that they are
getting an expected output from their
inputs into your
application so for longer loading we
highly
recommend offloading it to a different
screen to enable users to understand
kind of what's happening in the
application also providing an option to
cancel it if they realize they made a
mistake and want to go back this also
will save you some GPU costs as well
because you're not going to be
processing the entire request only to
have them try it again and try it again
and try it
again our next tip is around user
input how many text boxes do you see on
this screen text
inputs one two three
four four I see four four four you are
wrong there is one text input on
here so let's go ahead and clean that up
and make it more obvious obious what
actually is a text input for users so
those were actually just some
pre-selected example texts that we
wanted to show users because sometimes
it's really helpful to provide them
starting points for their text inputs
let's go ahead and clean that up make it
more obvious what is actually a text
input field where the prompt is actually
going to allow them to make a proper
selection and understand what they are
selecting so by changing the layout of
our pre-selected options it's more
obvious that those are suggestions or
helpful starter inputs and not actually
text inputs that I can
change additionally with our language
selection we're going to go ahead and
change that and make it a little bit
more obvious what uh options there are
for language but let's look at that one
a little bit more in
detail so if we go ahead and look at
that expanded menu of languages that are
available there's a lot of choice here
is that a really good user experience am
I as a user going to be able to make a
choice really easily be able to find
really easily like the language or
dialect that I'm looking
for not
necessarily so by changing this around a
little bit enabling you to filter and
sort and also search a little bit more
obviously it's going to be a much easier
user experience and I'm able to find
what I'm looking for a lot faster and
I'm not going to get frustrated and give
up I'm actually going to be able to get
to the point where I am going to be able
to generate audio from this application
as well also by limiting the amount of
selections that are available to a user
at the very very beginning you're
removing that paralysis of Choice by
making it really easy for them to go
from zero to one and then if they really
want a specific language then they can
go ahead and search for it but go with
those most obvious choices or those most
used choices most popular choices and
only show those before showing
everything that is available
our next tip is
around
buttons how many primary actions should
be on one
screen one how many are on this screen
two so what do I do here is this a
generation page or is this a start a new
or an ad to a design
page really focus in on highlighting
what you want to user to do in this
space so once my image is already
created I really want a user to add that
to a design so that's going to be my
primary action if I want a user to start
over or recreate something separate that
out make it really obvious what the
primary action is that you want a user
to do in that space But if you want to
keep those other options there keep them
separate make sure it's obvious that
this is going to be a net change and
you're creating a net new design here as
well so always always always have just
one primary action on a
page and the last tip I want to talk
about is anyone have any idea what this
app
does no neither did I when I saw it
either this is a caption generation app
not obvious so what we want to do is
actually make it a little bit clearer
what you can do with this app you upload
an image and image will return a caption
in this PCT in this example I uploaded
an image of a cattoon cart it's or sorry
a cartoon cat um and it's much more
obvious that what was returned to me is
a caption that I can now add to my
design if I want to make my design more
accessible I'm also able to see the
original image my primary action is very
clear about adding my caption to the
design and it's very obvious how to
start over here as well so by cleaning
up these little things it really makes
your app so much more usable and so much
more obvious to a user what they're
supposed to be doing what the intent of
your app is and what the value ad of is
and all of these examples that I just
showed you are actual apps from our app
store in their before State then they go
through our app review process and then
this is our end state so we've really
helped a lot of users improve their app
or sorry a lot of developers improve
their app experience through our design
review process and by providing them all
of these tips that we have learned as a
design company in our 10 years of
experience and helping them apply it to
their apps as well and we've Al also
heard from users that they've taken this
and applied it back to their primary app
so they've gone back to their website or
their app or their like desktop app and
modified it to be able to include all of
these tips and tricks that they've
learned from our app review
process now with that let's actually go
ahead and try to fix the UI of an
app so I going to have a fake text to
image AI app I actually haven't tested
this today so I have no idea if it's
going to work so bear with me um but
what we're going to do is we're going to
create a really simple texted image app
that takes a user input and returns an
image that I can then use in my
design so I'm going to go ahead and jump
over here
oops all right so I need to go back a
little
bit I believe it's in
projects what's in here
yes
okay um sorry again I was asked to do
this like 5 minutes before this started
so just need to get things up and
running real
fast all right so I'm G to actually
start at my local development
environment so this is actually going to
be starting the Cana apps SDK starter
kit so this is what you could use if you
were trying to build your app into canva
and when what this will do is it'll
actually start my local server and with
my local server started I can actually
oops go ahead
and I want to go to our canva Dev
portal and I can actually go ahead and
start testing my app live inside of the
canva editor so my app is running on my
local server and then this is a
productive version of canva and my app's
actually running inside of it right now
so in this case I have a button a text
input field and what it's supposed to do
is generate an image for me from um an
inference model that I currently stole
from hugging face and put up here if I
go ahead and generate
image oh apparently I didn't undo all of
the changes that
I guys this is what happens when you
actually have to present on the spot
here
um see oh no okay what app is it
running sorry give me a a second while I
figure out what project I actually have
running
here yeah it's already
open you know what I probably didn't do
save my
changes oops there we go okay
cool all right I'm going to rewind back
out some of those changes that I already
made and now okay let's go ahead and
reload our app so in this case if I I'm
a texted image app and I want users to
input a prompt and then generate a
result if I don't have any sort of
indication about loading state I'm just
going to slam that button as a user
because I don't understand what's
happening until I get a result that's
going to run up your uh GPU charges
immensely you don't want a user kicking
off multiple instances of your AI unless
you really enjoy really high usage costs
does anyone enjoy that probably not um
so one of the really key things to do
here is to make sure that button is
disabled and in a loading State once a
user presses it so they know something
is actually
happened yeah so now we're getting a
couple images being generated because I
just smashed that button and it doesn't
really know what to do with that so um
Cana oops before I jump over there Cana
actually has lot of UI components that
we've created for you to make it really
simple for you to build your app as well
so if I go ahead and look up a button in
our story
book I'll go ahead and zoom in a little
bit better you can see we actually have
a lot of properties already available
from that button so it's really really
easy for me to add uh the state of the
button add a loading action to the
button make sure that it's disabled
stretch it so it fits the entire screen
so a lot of this is going to be
responsive out of the box box so then as
you saw what I did earlier what we're
going to go ahead and do is use that
loading
State and we're going to check to see if
the
state I forget what my state variable is
called sorry pause please loading
state is equal to
loading so by simply setting that
property using a little bit of react
code I'm able to then add that loading
state I'm going to go ahead and save my
changes this time go back to my
app and now when we click generate image
it will automatically add that loading
state so it's really obvious to a user
that there is something happening please
don't smash my button please don't run
out my CPU charges please just wait for
a response to come back from the
AI now the other thing that we might
want to consider here too is um making
sure that we only show
show the image card once the image is
available so if we don't have the value
of the sample URL don't show that so if
you don't show any placeholders until
it's absolutely necessary to show
placeholders so by just going heading
and using our state and wrapping it in
that so we just want to make sure that
loading State equals success in this
case and then we can go ahead and show
our image card
did I do something
wrong no yeah what did I do
wrong
oh y' I backed out all of the change I
backed out all the changes from the
wrong example my bad also
um quotation marks are really critical
here so again we're going to go ahead I
don't know anyone have a good prompt
idea
here okay fine cat doing
yoga so we'll go ahead and G an image we
only want to show that image card once
that image is actually ready we also can
use um we have loading State indicators
as well so if I wanted to have like a
placeholder
[Music]
image
um here we go yeah sorry loading we have
loading indicators we have placeholder
images
oopsies um so you can also create like a
loading State easily with our UI
components to show a progress as well
that like we're trying to generate
something we're going to create it and
by using our progress or our placeholder
images you can also show kind of the
shapes that are going to be coming down
the line
and then once our image actually
resolves it'll actually show up in our
side panel and then we're really easily
able to add it to
our to our application just by clicking
it but another thing that you might want
is to be able to drag that image onto
that page so with our IM oops I keep
going to the wrong place guys sorry um
with our image cards we're also able to
add an on drag start event as well which
enables us to really quickly add the
ability to drag an image from the side
panel into our image as well so making
sure that it's really obvious and
consistent with the design experience
throughout the application so in canva
when you go to add anything to a design
you can always expect to be able to drag
and drop it onto the page making sure
that it's a consistent experience
whether it's an app or even in your own
application of just making sure that
it's a consistent experience of how
users interact with elements and add
them to your your page or create designs
it's going to make it a lot simpler to
create a good user experience where
users want to continue to use your
product also I didn't practice this so I
have no idea how I am on time do I need
to wrap up or okay
cool thank you guys for bearing with me
as I present on the spot here I'm just
going to wrap up real quickly and um
point you to some of the things that we
helped
use today um so our apps SDK is what
enables us to actually interact with the
canva canvas so if you want to bring
your AI Tech into canva we have a lot of
resources to help you actually interact
with the different spaces within canva
we have that UI kit as well which is a
lot of react pre-built components that
are responsive to screen size including
mobile devices because a lot of our Cana
users actually are on mobile and so this
will provide you a lot of tools to help
you get started building your UI even
faster we have plenty of guid again from
our experience of building a design
front forward company um so we have
plenty and plenty of design guides and
common patterns that you will see and
then a little bit about our app review
process so you can learn a lot about how
those apps actually went from the first
page to that second page and improving
their app
experience and you can always learn more
at canva.com
[Music]
integration the entire magic Studio that
we have embedded in canva and then also
take a look at uh the canva developers
experience a little bit more if you're
interested in diving a little bit deeper
on this and getting hands on keyboard
thank you guys all for bearing with me
as I presented this super last minute I
appreciate it and hopefully you learned
a little something about UI
[Music]
today
[Music]

### youtube_ybLDSAWyEZY.txt

thank you
[Music]
let's first start with similarity our
brains like to group objects together
regardless of where they are placed in
this case we group these circles based
on color not by location
the human brain loves to categorize
things when you look at the following
random assortment of squares and
triangles what do you see better yet how
do you see them
there is likely a chance your brain is
deciding to group together the triangles
like in this example or it has decided
to group the squares together like in
this example
your brain is working hard to make sense
of the different shapes presented
the principle of similarity also applies
to color
texture
shape
position orientation and size and
knowing how the brain works here comes
in handy as a designer we can use this
principle to shape how we develop our
layouts
we can bring attention to the most
important elements in the design by
making it different than the rest
we could do that by making it a
different color like this example
we have two layouts each shape
represents a photo text or element in
the layout we are using similar shapes
in our layout this helps everything feel
like it belongs together
this example features different shapes
of photos and content which does not
allow the brain to categorize all the
different information presented causing
confusion
the next principle we're going to go
over is the principle of proximity close
objects are grouped together
your car console uses the idea of
proximity to make it easier for you to
find and locate related controls on the
dashboard you may notice all of the air
conditioning and heater dials located in
close proximity to each other you may
also see the radio controls put tightly
together in relation to the other
unrelated controls in the car this is a
helpful concept to keep in mind when
doing layout design we can group related
items in the layout together so they
feel like a larger cohesive group that
share a similar goal this helps the
human brain organize larger amounts of
information that would otherwise be
overwhelming
in the logo above the logo on the top is
a good example of the principle of
proximity in action the logo on the top
has the words of the company travel and
loop spaced rather closely together
I'm able to read this logo as one
company name travel Loop
in the logo in the middle you see a
wider gap between the two words and they
start to read as separate words
but also start to feel disconnected from
each other
the event name and the descriptor line
are grouped together in the same area
you can also see related date and
location items group close together
this allows the viewer to group related
items together so they can easily
understand the information imagine if we
placed all the information into one area
without any sort of Separation it could
be really messy and intimidating for the
viewer to look at
the next principle is the principle of
simplicity and we break down elements
into the simplest forms possible
we see the image on top as one complex
shape with curves and lines
instead what our brains try to do is
break that complex image down into
something easier to handle and we
suddenly see three simple shapes instead
of just one complex shape
we see the principle of Simplicity
applied to Icon design all the time
icons need to be seen in very small
sizes if we were to have a detailed
illustration for a small icon it would
not always be easy to tell what it was
we instead simplify illustrations down
to icons that could be identified in
many different sizes
so when you take this icon for example
when reduced down to smaller sizes this
simplified icon fares much better than
the more complex illustration
one thing to always ask yourself when
creating a design is can I make this
more simple
you could do this by reducing
unnecessary elements graphics and even
combining texts that are saying the same
thing
simplification can make your message
appear more clean and concise
ask yourself another question is this
graphic or element adding value to my
design
as designers we typically feel we need
to show off our creativity but remember
your Design's overall message is always
the most important make it clear concise
and rewarding to look at
so take this example
the layout to the left is busy and
complex with many different sized
elements and structures
simplifying our layout to focus on our
main photo idea or focal point can help
a viewer cut through the noise so to
speak to have an enjoyable experience
using Simplicity makes complex objects
easier to understand the goal is to
reduce it down to the point where it
still retains its core meaning and use
this clock is still understood as a
clock even though it's just a circle and
one bit line
[Music]

### Untitled 16.txt


What Is the Role of an AI Designer?
How AI designers are bridging the gap between user needs and technological capabilities.
Amanda Linden

Amanda Linden
·

Follow
6 min read
·
Jun 11, 2019

About 4 months ago, I began managing the product design organization for Facebook’s Artificial Intelligence team. We are a central organization that provides AI services for Facebook, Instagram, and other Facebook apps. We also work to develop new experiences, powered by AI.

Before joining the Artificial Intelligence team I had been reading a lot about AI and was really excited about the idea of working in an emerging space. I’d been working on mature mobile and web apps for the last 10 years, so being in a position of learning and ambiguity felt really energizing. I also felt a responsibility knowing that AI technology will be extremely transformative to society, more-so than even the mobile revolution has been. I wanted to use my skills to ensure that AI tools are built in a responsible way.

To be honest though, I wasn’t exactly sure what the role of product design would be on the AI team. We don’t own a consumer product surface of our own, so there isn’t an app for the team to maintain day-to-day. I also had a preconceived bias against designing “technology first” versus “people problem first”, so figuring out how to work effectively in a world where technological capabilities are unfolding real-time (and you are working to apply them in the right way) felt backward and unfamiliar to me.

I thought it might be useful to others to share the approach we are taking to offering design support to our developer & application team partners, and in the creation of new experiences. This information might be useful if you are also building out an AI design team, or if you are curious about pursuing a role designing AI.

Generally speaking, designers on the team are working on the following project types:
Designing AI Prototypes

When an AI tech team needs a prototype, demo, or visualization of their technology, they work with a product designer. AI designers make sure that people see what’s possible with AI. We create prototypes showing how a particular technical capability might be used by people when the AI is working well. As an example, we might create a demo of AI suggesting a possible caption for your Instagram post, or AI helping you know where to buy a pair of shoes you see in a post.

For an AI Demo designer, the creation process is usually to illustrate a set of product ideas as one page briefs with a set of visuals to briefly illustrate the idea. We use the one pager to get buy-in from the broader team that the idea is worth building out further. The finished prototype be used to green light a new research initiative or development project within the AI org.

Designers working on AI Demos are working on a wide variety of ideas, they are highly generative rather than going deep in one technology area. They have a strong understanding of current AI capabilities and keep track of how new capabilities are developing. As a designer working on demos, you might be creating a visual search experience, on a way that users with visual impairment can “see” newsfeed posts by rolling over the photos with their fingers.
Shaping New Technology

AI designers can also work as an embedded part of a technology team, shaping new technology. AI designers work on long-term areas of investment like computer vision, speech, language, video, and AI assistant initiatives. These project teams are developing new AI capabilities (rather than working with existing AI capabilities). The work you do as a designer on a technology team blurs the lines between design, PM and research. You are working to ensure that developer teams understand user needs relating to a particular type of technology and are building the technology to directly solve those needs. You are imagining user experiences that might be seen by users in 3–5 years, and would take significant improvement in AI technology to achieve. AI designers go deep in understanding the long-term vision for AI in their area of focus.
Developing AI Centered Products

Another project an AI designer might work on is to design new AI centered applications, testing them for viability, and (if promising) pitching them for further investment. The time horizon for projects in this space are farther out, so you are working in a world where you imagine people living life 5–10 years from now. You are thinking about how AI can offer better socially powered services to people longer-term. The products you build might be the Facebook or Instagram of the future, or might be a totally new way of engaging with your community.

Designers in this space often have a background in building new hardware or working in a startup space on new app ideas. They are comfortable with ambiguity and have an understanding of how to create the criteria for continuing to pursue or shut down a line of exploration.
Collecting Data for AI to Learn

One of the most important parts of shaping AI technology is giving AI the right data to learn. AI designers work with the engineers who build tools for this data collection and annotation, and design the platforms that enable it, to streamline efficiency and make it intuitive to collect good quality data. In some cases designers help gather datasets when more automated methods won’t work.

Here is an example of how a designer might help with data collection helps AI learn: We may need to teach AI to know when a person is raising their hand. In order to teach the AI, we gather thousands of video examples of people raising their hand, ensuring that examples come from people of various ages, genders, ethnicities and physical differences so that the data set is inclusive. They then gather thousands of examples of people NOT raising their hand to help the AI know when the answer to, “Is the person raising their hand,” should be, “No.” Finally, they show examples of people raising their hand that are potentially harmful (i.e. someone raising their hand in a Nazi salute) so that the AI can learn to flag those examples when identified.

AI designers help to ensure that we are developing data collection systems that are safe, fair, ethical, and apply to real user problems. These designers create frameworks and guidelines where needed to ensure the safe and secure use of AI. They design the libraries that our machine learning systems use to learn, ensuring that they are free of bias, clean and effective.
Designing AI Developer Tools

Designers on the AI team also build applications used by AI engineers, as well as the external developer community through open-source projects. Product designers on this team are building specialized developer applications, ensuring that we are creating a set of tools that work well as a system. Designers in this space need to have a deep understanding of the AI development process and a passion for empowering engineers across the globe. They often have a strong background in engineering or systems thinking.

At a high level, AI designers are bridging the gap between user needs and technological capabilities. Knowing that our goal is to give people the power to build community and bring the world closer together, we want to use current and future capabilities of AI to design the future of how people connect and collaborate.

There are big differences in the role of a typical product designer and an AI designer. Rather than launching a product feature that shows up in an app in an immediate and obvious way, our output is often clarity for engineers on how the technology could be applied. Because AI capabilities might take 2–3 years to develop, it’s important for designers to help developers understand the potential of different solutions and their impact on people’s lives when developing AI. And even more exciting — Beyond using existing AI capabilities to solve problems that exist on our platforms today, these designers get to imagine and imagining how AI will reshape the world tomorrow.

### youtube_4VWrl98KzCE.txt

hello everyone and welcome to mr
simplifies tutorials in this tutorial
we're going to look at gestalt
psychology the concept the principles
and the applications of the same
gestalt is a german word which most
closely equates to patterns
forms or
a unified whole in the simplest of ways
gestalt psychology is a is a school of
thought that believes that the whole of
an object is more important than its
individual parts as simple as that
now over the course of our lives our
minds tend to perceive objects as part
of something larger and something more
complex and this is what just all
psychology elaborates
now in reality there is a lot of chaos
and disorder in the world as we all know
but human beings tend to search for
order
in disorder
and this is also what just all
psychology focuses on
and it therefore helps us understand
human perception and sensation
so who came up with just all psychology
gestalt psychology was founded in
germany by max wertheimer and supported
by kurt kofka and wolfgang koller
now wertheimer observed some lights
switching on and off in a sequence in a
railway station and realized that
they're actually creating an illusion of
movement he called this the phi
phenomena
this refers to our tendency of sensing
movement where there is actually none
and this is what eventually gave birth
to just old psychology
when you see sequential fairy lights
you get an illusion that light is moving
from one corner to the other right it's
however just lights sequentially turning
on and off and there is actually no no
real movement there it's just our brain
interpreting a sequence
of lights turning on and off as a
movement and making it look better and
more satisfying than it actually is
a video game
is a similar but more complex example
what you actually see on the screen is a
complex arrangements of arrangement of
lights
which
gives you a perception of people objects
and motion
and in a similar way when we play some
strings
on a guitar or or some digits on a
keyboard let's say in a sequence our
brain
interprets what we listen to as music
just all psychology is applicable
not just
in the visual context but also in the
auditory context or any other context
in all contexts where there is a
possibility of a pattern
there are some principles of just all
psychology that that govern how human
brains work
when it comes to interpreting movement
and patterns so let's look into some of
them now and after that look into the
applications of gestalt psychology
including gestalt therapy
okay though so the first principle is
the principle of proximity the principle
of proximity states that when objects
are placed close to one another we
perceive them to be related to one
another and to be a part of the same
group
now in the graphic we see a group of
eight dots and we see
that they're grouped into two parts
and we see two groups
and we clearly see two groups even if
the colors are mixed together
and this is the effect of proximity
another example is lettuce coming
together to form words it's essentially
the same alphabets used to produce so
produce so many different words right
and it's the same alphabets that are
being used it's just that they're
clubbed together to form different words
the next principle is the principle of
similarity now this principle states
that we tend to group together
objects which appear similar to one
another
in the graphic below for example we have
an s
formation or a five
clearly visible because the colors make
the the brain group the the red balls
together
another example can be
us grouping people together if they if
they wear the the same colored clothing
to support the the team of their choice
in sport
the next principle is the principle of
figure ground now this principle states
that people tend to
instinctively put objects in the
foreground or in the background
in certain situations we tend to place
prominent objects in the foreground
making them the figure and place other
objects in the background making them
the ground so that's figure ground
now this can vary as per your perception
so what's figure for me can be ground
for you and vice versa
now there are pretty complex visual
examples available to explain this but
in the simplest of examples let's see
the following two block combinations
many in the first image would see the
the small square to be the figure
on a white background and
in the second image many would see the
the black box to be the figure
to be a square donut-like shape and
perceive the the white
box as ground now some could perceive
things completely differently though so
this is
all based on your own perception
now the next principle is the principle
of continuity
this principle states that the human
mind prefers to gauge continuous lines
or curves rather than separate
components that make up the line or the
curve
in other words if several objects are
arranged in a line or a curve and some
objects are not
the objects in the line or the curve
formation are considered to be a unit
for example in the below graphic we have
dots arranged such that we have a smooth
line and a smooth curve
the dots on the half of the curve seem
more related to the dots on the other
half
rather than the second half of the line
the same is true in the case of the line
and this is despite the color
differences
or for example if you if you have leaves
covering your vision of the mcdonald's
logo somewhere
you will complete the the logo in your
own mind and not think of it as a half
logo because there is a pattern and you
recognize that pattern
the next principle is the principle of
closure this principle refers to our
preference to see
complete
and not partial element
we once again look for a single pattern
in our brain in our mind which is
recognizable now the mcdonald's logo
example can be used again as it also
works
on our tendency to close the logo
as as we saw previously or if you look
at
the ibm logo for instance it's been
designed in a way that you actually need
to complete the logo in your mind
it's deliberately designed in that way
the next principle is the principle of
common fate this principle states that
when objects are seen to be in the same
enclosure
or are seen moving together
in a certain direction they can be seen
as grouped together they can be
considered as in the same group army
formations are a good example wherein
people are perceived to be in the same
group due to similar movements and
formations
the next principle is the principle of
symmetry
it's human nature to find a try and find
order in chaos
finding things in symmetry and harmony
gives us solidity and order
if you look at the example below you'll
notice how powerful symmetry is we have
a couple of open and close
opens and closes of brackets
our mind processes the
space in the brackets as groups
despite the brackets being quite close
to one another
so it
kind of is more important than proximity
so it takes precedence over proximity
now look at now let's look at some of
the main
applications of gestalt psychology one
of the most important applications of
gestalt psychology is gestalt therapy
gestalt therapy is essentially a
humanistic
client-centered therapy with a focus on
facing current challenges in life and
taking responsibility
of one's own life
some of the key characteristics of
gestalt therapy are as follows
focusing on the present now focusing on
the present challenges and not delving
too much
or too deeply into the past is one of
the main hallmarks of gestalt therapy
this is because spending too much time
in the past
or going too far into the future as well
can can both create anxiety in a client
a gestalt therapist will therefore focus
on bringing a client's attention back to
the present by building rapport and
being observant about the body language
and basically focusing on the current
challenges in that client's life
the next characteristic is therapist
perception since just all psychology
helps us understand human perception a
gestalt therapist would understand that
his or her
own experience in life and judgment can
actually influence therapy they would
therefore look into not imposing their
own judgment
in the session and keep the therapy
client focused
self-awareness self-awareness is an
important part of gestalt therapy
guided imagery role play and activities
could be used to to to open
with and make a client aware of his or
her abilities and strengths
gestalt therapy is one of the main
applications of just all psychology and
can be used in treating anxiety
depression
low self-esteem and relationship
problems as well
what are some of the other applications
there are various applications in user
interface design and product design as
well
now just all psychology can actually be
used in ui design to strengthen user
experience
for example in designing better quality
websites which engage and educates users
at the same time
the principles we looked at can each be
used from a user interface perspective
to optimize client engagement
for instance the the principle of
similarity can be used to ensure that
similar content blocks on a website and
and calls to action in a website are
placed in a similar color scheme
another good example of of good user
interface design would be to use
symmetry to ensure that web pages are
symmetric to one another so that
the information displayed
is considered orderly and pleasant to
the human brain while serving the
intended purpose because if a person is
unhappy or dissatisfied by the layout
scene
of the imagery and the text on the
screen that person is is likely to click
away from the website or out of the
website or just close it down distal
psychology can also similarly be used in
product design and development so you
can develop better quality products and
designs by using gestalt psychology it
is therefore extremely important
not just
from a therapy point of view
not just from
an understanding of a human brain or a
mind perspective it's also very
important in design
in bridging that gap between
user interface and user experience
design and the actual needs of a
business
okay i hope this tutorial was helpful
for you in terms of understanding
gestalt psychology and distort therapy i
thank you all very much for your
attendance as always and as always
please use the comment section to
recommend topics you want covered in
this channel please use the the
subscribe button and the like buttons
spread the the word about this channel
share this content and as always and
most importantly take
very good care of yourself thank you bye

### Untitled 17.txt

An intro to Machine Learning for designers
The basics of machine learning and how to apply it to the products you are building right now.
Sam Drozdov
UX Collective

Sam Drozdov
·

Follow
Published in

UX Collective
·
6 min read
·
May 30, 2018

Photo by Gertrūda Valasevičiūtė

There is an ongoing debate about whether or not designers should write code. Wherever you fall on this issue, most people would agree that designers should know about code. This helps designers understand constraints and empathize with developers. It also allows designers to think outside of the pixel perfect box when problem solving. For the same reasons, designers should know about machine learning.

Put simply, machine learning is a “field of study that gives computers the ability to learn without being explicitly programmed” (Arthur Samuel, 1959). Even though Arthur Samuel coined the term over fifty years ago, only recently have we seen the most exciting applications of machine learning — digital assistants, autonomous driving, and spam-free email all exist thanks to machine learning.

Over the past decade new algorithms, better hardware, and more data have made machine learning an order of magnitude more effective. Only in the past few years companies like Google, Amazon, and Apple have made some of their powerful machine learning tools available to developers. Now is the best time to learn about machine learning and apply it to the products you are building.
Why Machine Learning Matters to Designers

Since machine learning is now more accessible than ever before, designers today have the opportunity to think about how machine learning can be applied to improve their products. Designers should be able to talk with software developers about what is possible, how to prepare, and what outcomes to expect. Below are a few example applications that should serve as inspiration for these conversations.
Personalize Experiences

Machine learning can help create user-centric products by personalizing experiences to the individuals who use them. This allows us to improve things like recommendations, search results, notifications, and ads.
A basic overview of how video recommendations are influenced.
Identify Anomalies

Machine learning is effective at finding abnormal content. Credit card companies use this to detect fraud, email providers use this to detect spam, and social media companies use this to detect things like hate speech.
Create New Ways to Interact

Machine learning has enabled computers to begin to understand the things we say (natural-language processing) and the things we see (computer vision). This allows Siri to understand “Siri, set a reminder…”, Google Photos to create albums of your dog, and Facebook to describe a photo to those visually impaired.
Provide Insights

Machine learning is also helpful in understanding how users are grouped. This insight can then be used to look at analytics on a group-by-group basis. From here, different features can be evaluated across groups or be rolled out to only a particular group of users.
Prepare Content

Machine learning allows us to make predictions about how a user might behave next. Knowing this, we can help prepare for a user’s next action. For example, if we can predict what content a user is planning on viewing, we can preload that content so it’s immediately ready when they want it.
Types of Machine Learning

Depending on the application and what data is available, there are different types of machine learning algorithms to choose from. I’ll briefly cover each of the following.
Supervised Learning

Supervised learning allows us to make predictions using correctly labeled data. Labeled data is a group of examples that has informative tags or outputs. For example, photos with associated hashtags or a house’s features (eq. number of bedrooms, location) and its price.

By using supervised learning we can fit a line to the labelled data that either splits the data into categories or represents the trend of the data. Using this line we are able to make predictions on new data. For example, we can look at new photos and predict hashtags or look at a new house’s features and predict its price.

If the output we are trying to predict is a list of tags or values we call it classification. If the output we are trying to predict is a number we call it regression.
Unsupervised Learning

Unsupervised learning is helpful when we have unlabeled data or we are not exactly sure what outputs (like an image’s hashtags or a house’s price) are meaningful. Instead we can identify patterns among unlabeled data. For example, we can identify related items on an e-commerce website or recommend items to someone based on others who made similar purchases.

If the pattern is a group we call it a cluster. If the pattern is a rule (e.q. if this, then that) we call it an association.
Reinforcement Learning

Reinforcement learning doesn’t use an existing data set. Instead we create an agent to collect its own data through trial-and-error in an environment where it is reinforced with a reward. For example, an agent can learn to play Mario by receiving a positive reward for collecting coins and a negative reward for walking into a Goomba.

Reinforcement learning is inspired by the way that humans learn and has turned out to be an effective way to teach computers. Specifically, reinforcement has been effective at training computers to play games like Go and Dota.
Things to Consider
What approach is viable?

Understanding the problem you are trying to solve and the available data will constrain the types of machine learning you can use (e.q. identifying objects in an image with supervised learning requires a labeled data set of images). However, constraints are the fruit of creativity. In some cases, you can set out to collect data that is not already available or consider other approaches.
What is the margin of error?

Even though machine learning is a science, it comes with a margin of error. It is important to consider how a user’s experience might be impacted by this margin of error. For example, when an autonomous car fails to recognize its surroundings people can get hurt.
Is it worth it?

Even though machine learning has never been as accessible as it is today, it still requires additional resources (developers and time) to be integrated into a product. This makes it important to think about whether the resulting impact justifies the amount of resources needed to implement.
Closing Thoughts

We have barely covered the tip of the iceberg, but hopefully at this point you feel more comfortable thinking about how machine learning can be applied to your product. If you are interested in learning more about machine learning, here are some helpful resources:

    Machine Learning for Humans — Simple, plain-English explanations accompanied by math, code, and real-world examples.
    Machine Learning Algorithms: Which One to Choose for Your Problem — Tips for developing an intuition for picking a machine learning algorithm to apply to a problem.
    Machine Learning is Fun! — A slightly more technical series that walks through implementing a machine learning example.
    Neural Networks by 3Blue1Brown — A collection of engaging, technical Youtube videos that step through what are neural networks and how they work.
    Andrew Ng’s Machine Learning Course — Highly rated technical course that broadly covers many areas within machine learning.

Thanks for reading. Chat with me on Twitter @samueldrozdov

### youtube_jtwl9M-UNQE.txt

hey I'm Colin I'm one of the founders of
visual electric and I wanted to share a
little bit about the thinking that led
us to uh building this product so I open
up in my browser here the you know three
of the more popular image generation
products today this is mid Journey which
you can access through
Discord this is Dolly which you can
access through chat GPT and staple
diffusion which you can access through a
number of different uh interfaces this
is the one that stability uses sorry
this that stability made called dream
studio and all of these share a pretty
similar interface pattern which is this
conversational view where you send
messages back you s you send messages
and you get images back and it's this
very linear process and you know as a
designer and someone who's been used to
working as out of tools like figma or
illustrator um the thing that felt
obviously wrong about these interfaces
is that it forces the sort of linear
process that doesn't really map to how
the creative process works it the
creative process is not linear uh and
you will often you know go down side
streets and explore ideas only to
discover that they're a dead end and
then at that point you need to back up
and uh find something that you were
looking at before and that might spark a
new idea and and all of this sort of
unfolds
into what becomes this kind of beautiful
mess and this is my mess this is my
visual electric canvas that I was
working in and this represents you know
a couple hours of Flow State of me just
exploring and riffing and pulling and
reference
images uh seeing what ideas it sparked
generating new images from from those
ideas and and there is a logic to how
this all unfolds uh it may seem kind of
overwhelming
to somebody else but to me this is a
this is like a journey that I went on
and uh there's various signposts along
the way and if I need to return to
something or find an old idea that
didn't seem right previously but now
makes sense I know how to get to it and
all of this becomes a kind of instrument
that you play and improvise with and
experiment with and and the goal really
is to have the tool disappear have it
just be about you and your ideas and
exploration and and all this is sort of
made possible by uh having a tool that
that makes sense to designers that works
the way creativity works and that was
the thing that we felt like was missing
uh in the market so I'm going to dive
into specific features and talk about
the various tools and how we design them
um but I just wanted to give that high
level overview of what led us to
building visual Electric in the first
place

### Untitled 15.txt


Designing with AI
What I learned from designing an artificial intelligence–enabled experience
Erica Virtue
Facebook Design: Business Tools

Erica Virtue
·

Follow
Published in

Facebook Design: Business Tools
·
8 min read
·
Sep 26, 2017

At Facebook, AI is everywhere.

Behind the scenes, AI helps make Facebook smarter and easier to use. We use it to help translate text so people can understand each other better, to recognize what’s in images so visually impaired people can “see” the photos their friends post, and to filter out undesirable content like spam. We also use AI to understand the intent behind what people post so we can improve their experience on Facebook.

When I started as a designer at Facebook, I hadn’t thought much about AI or how it could be used as a tool in product design. But then I ended up designing Facebook Recommendations, which uses AI to detect when people are asking for local recommendations, and then to match the places that their friends recommend to Facebook Pages. It’s one way we help connect people and local businesses.
It All Started with a Problem

I’d noticed a lot of posts in my Feed in which people were turning to Facebook to find recommendations for places to go and things to do. These posts got a lot of engagement, but weren’t very useful. You had to scroll through all the comments, then copy and paste the names into Yelp or Google to find out more about the places your friends were recommending — even though over 60 million businesses have Pages on Facebook. The worst part was that it was really easy to lose these posts in your Feed, so they were only useful for as long as you could find them on your Timeline.

I wanted to make it easier and faster to collect and consume the recommendations that people get from their friends — and help them get more recommendations from people they trust.
How We Arrived at AI

People were already asking for recommendations on Facebook, and we didn’t want to get in the way of the behavior that was already happening. Ultimately, AI turned out to be the best approach because it let us make their posts better by turning their unstructured conversations into a helpful shortlist or travel guide. We didn’t reach this solution right away, though. First, I explored a number of possible solutions to our problem, which we validated through user research and live experiments.

One of the first concepts we tested was an approach where you’d have to say up front what you were looking for and where. But we found that people didn’t really understand why they would do this. They didn’t see the value of adding this additional metadata to their post, and it was tough for us to demonstrate the value we could give them when they couldn’t actually see the experience for themselves. We were also fighting against existing behavior, which was to just write a status update with their question.

Another concept we tested was a more educational approach. We thought that by stepping people through a tutorial that explained what was going to happen, we could help people feel more comfortable with the product. We found, again, that it was difficult to explain in words or illustrations how we were going to provide value before letting them experience it for themselves. Once people used the product for themselves, they loved it, but not surprisingly, we saw some drop-off in usage when we added in additional steps before posting.

From testing these more structured approaches, we learned that the less friction we added to the experience, the better it was for people. We decided that the best approach was something “automagical” that would augment the behavior that was already happening, without being too intrusive. In order to trigger the experience in a frictionless way, we relied on artificial intelligence to understand when people were asking for recommendations and what places their friends were recommending when they replied.
How Recommendations Works

With Recommendations, you can post your question on Facebook as you normally would, and when a friend comments with a recommendation, we link to the corresponding Facebook Page and display details like ratings, price range, open hours, and addresses. We also put all the places they recommend on a map so you can find everything easily. We’ve seen people use Recommendations to find everything from water during a hurricane in Florida to the best craft breweries in Australia. There are even Facebook Groups, such as the Tri-State Restaurant Club, where almost every post is a request or offer for Recommendations.
The AI Behind the Product

The Recommendations product seems pretty simple. Making it work is a lot more complex. In order to turn a status update like “Friends! Where’s the best place to get a haircut in Chicago?” into a Recommendations post, we have to first understand: (1) that you’re asking for recommendations, (2) what types of places you’re asking for, and (3) where you’re looking. This is easier said than done, especially considering the way people use slang and casual language on Facebook.

We partnered closely with the Conversational Understanding team at Facebook to use Natural Language Understanding (NLU) to power our experience. This team built AI technology that can understand text posts to accurately detect when someone is asking for a local recommendation, enabling us to automatically trigger the Recommendations experience.

When your friends comment on your post, suggesting all the cool places you should check out, we use AI to understand the text and extract the most likely place(s). AI also gives us a confidence score that indicates the likelihood that it’s the right place. This score shapes the user experience that the commenter receives. If it’s high, we simply attach a place card to their comment (with the ability to remove it). If we have medium confidence, we ask if it’s the right spot before attaching it. When the score is low, we show them an empty card that opens up a search bar that lets them manually search for the place that they want to add.
What I Learned About Designing with AI

The allure of AI is that it can make your product “magically” work. But my experience on Recommendations hammered home that AI’s power doesn’t lessen the need for thoughtful product design — just the opposite, in fact. Of all the lessons from the project, here are the ones I keep coming back to:
Look for existing behavior

AI opens up a lot of opportunities to make existing behaviors faster and easier for people. We didn’t try to invent a completely new behavior; rather, we found an existing one and made it way better! AI made it possible for us to deliver a magical experience while introducing as little friction as possible for people to give or receive recommendations.
If you don’t notice the AI, you’re doing it right

When you use AI in a way that enhances an experience, rather than defining it, it can actually feel almost invisible. AI lets you break free from a traditional user interface and solve problems for people in a seamless and almost magical way.

We purposely decided not to make it feel like you were talking to a robot or like Facebook was interjecting itself into a conversation you were trying to have with your friends. Instead, we used a design that augments the comments you receive from friends with helpful information. This approach feels more natural, and keeps your conversation with your friends at the forefront. In fact, in user research, when we showed the experience to people who said they’d never seen it before, some said “Oh yeah, I’ve used this before! It’s great!”
Test, test, test

As soon as you start introducing “magic” into the experience, people assume that it should work all the time. When we first started testing our experience, our AI got things wrong. A lot. It’s not a great experience when we suggest that you link to a dentist’s Page when you’re trying to recommend a restaurant. Usability testing with real people was very important, especially once we had a working product. We also looked at a lot of public Recommendations posts to get a feel for how well the product was actually meeting people’s needs. By watching people go through our experience early, we uncovered a lot of issues with our AI we wouldn’t have noticed otherwise.
Don’t depend on perfection

Even if your AI works most of the time, there are going to be moments when it completely fails. If people can’t accomplish their goal when this happens, you’re going to end up with a lot of very unhappy users. One thing that makes Recommendations work is that even if our AI didn’t recognize your post, it didn’t stop you from posting your question and getting recommendations from your friends — your post just wouldn’t be as helpful.
Degrade gracefully

By falling back to alternative UI, you ensure that you can provide a good experience for people even when your AI fails. Though it was more challenging to design multiple UI treatments, we were able to provide a less intrusive product by differentiating the experience based on AI confidence. For Recommendations, we experimented with raising and lowering the confidence levels and with a number of different UI treatments at each level, until we found the combination that worked the best.
Feedback is a gift

This is a saying at Facebook, and it’s especially true when designing with AI. It’s important to provide ways for people to give feedback about our guesses and then use it to improve the experience. By letting people x-out our suggestions when we were wrong, we not only provided an escape hatch, we also created a way to collect valuable information about how our AI is doing. Every piece of feedback we receive helps to improve our AI and the overall Recommendations experience.
Influencing AI’s Future

Since launching Recommendations, we’ve continued to improve the experience and I’ve continued to learn a lot about the challenges of AI and the opportunities that it can unlock. Above all, I’ve learned that designing with AI is just like designing anything else. Focus on people problems, test your assumptions, and provide affordances for when things go wrong.

As AI inevitably becomes deeply integrated with the products we build, it becomes more and more essential for product designers to take part in how it evolves. It’s a natural fit — making technology feel human was obsessing product designers long before AI came along. By applying design thinking to AI-enabled products, we can help ensure that those tools truly serve the people who use them.

### Untitled 3.txt

Marielle Lexow

Published in

UX Collective
·
23 min read
·
Aug 17, 2020

The story image shows a photograph of the wave pattern inside Antelope Canyon in North America.

InIn Silicon Valley, automation and artificial systems are present everywhere. For the people living there for years, it might be normal, but it was a new experience when I moved to the San Francisco Bay Area for a UX internship last year. Straight from Germany you probably can imagine how crazy it was to see the big tech companies for the first time but also the typical American things like straight out of Netflix. Just to mention the burgers and burritos but also the traffic and broad streets. I was working in automotive and was surrounded by inspiring people, a fast-moving world and a try and error mentality. You see autonomous driving prototypes from Waymo or Nuro in the real traffic, next to you on the street. It was interesting to look at Waymo’s cameras and sensors outside and inside of the vehicle while waiting at the traffic lights. It measures data from the surrounding environment and every traffic situation. The test driver monitors the live generation of the data, but the evaluation and analysis happen invisibly and deeply confidential in big tech companies and start-ups. Artificial Intelligence is more present than in any place I have ever been to before. Working on future mobility concepts and attending a talk about “Designing for Automation” from the Oracle design team at AIGA in San Francisco, I was so curious about designing for AI products and services, that I wanted to learn more about it. And this is what the article is for, to give an overview of Artificial Intelligence in User Experience Design. We will take a look at questions like which influence does AI have on the creative industry and its UX designers? How can User Experience actively shape the era of Artificial Intelligence and Machine Learning? And how does designing for AI work and what are the most important design principles? Here we go.
Automation vs. Artificial Intelligence

Before we dig deeper into the UX Design for AI, we should first talk about the differences between Automation and Artificial Intelligence, so we are all on the same page. As a designer allocated on an AI project it is crucial to understand at least the basics of how AI works and what goes with it to collaborate well with developers and engineers alike. For both terms Automation and Artificial Intelligence, there is not the one definition, unfortunately. Everybody understands something different, depending on the exact professional field they come from. But the common understanding is, that automation uses structured data as an input. The rules and exceptions the system uses are defined. This means the output the machine gives to the user is predictable. Automation is being used for traditional processes and very task-oriented repetitive workflows. In the previously mentioned talk at AIGA, Oracle shared an interesting example of an automation project. The use case was the budget approval process in large companies. The manager receives countless requests for approval every day, each of which must be processed manually. To simplify this process and make it more efficient for the user, a tool based on automation was developed. Up to a certain financial amount, which the manager determines in the software itself, the budget requests are automatically approved by the system. The manager only reviews the requests from the amount he considers financially relevant. In this use case example, automation has served its purpose.

Artificial Intelligence goes much further. AI uses the input data to find patterns and provide predictions and insights as an output. The AI system uses specific models and algorithms to analyze and interpret data autonomously. It feels “smart” because they are trained with a fair bit of data and are improved continuously. Spotify for example uses Artificial Intelligence for its “Discover Weekly” feature. The user gets a weekly personalized playlist with suggested tracks that fit the own taste of music. Based on the personal playlist for each of the current 286 million monthly listeners the use case is technically too complex for simple automation. Spotify solves the problem with Artificial Intelligence since it is not possible to define concrete rules for the song suggestions in advance because every user has different music preferences and tastes. AI should also not be confused with the term “Machine Learning”. As well as “Natural Language Processing” (NLP), “Computer Vision” and others it is part of the broader bucket AI. They are various algorithms and tools to enable the AI to simulate human intelligence and behavior. In practice, Automation and AI often complement each other. This is also the case in UX Design because there are a lot of similarities when it comes to the current design principles for AI. However, in the following lines of this article, I refer to the influence and design of AI-based systems.
How AI impacts the creative industry …

Due to Corona, many of us are working from home right now. It feels like a new world of work, where the digitalization overruns us very fast and spontaneous talks with colleagues at the coffee machine are over. At least for now. Offices, but also universities are closed and a lot of my fellow students are not able to work on their projects due to closed workshops on the campus. Forrester Magazine writes, that Europe only scoops out 12% of its digital potential. It will probably change after the crisis — studies show, that companies will urgently increase their investments into automation technologies after Corona. These technologies as well as artificial systems have had an impact on the creative industry for several years and will continue to do so. Just to name a few examples: Adobe Photoshop can retouch an image with only one click by using Artificial Intelligence. Logo Makers can create a logo in seconds that fits your brand and design language and suggests you, based on your data, additional colors and fonts. Furthermore, AI-based website generators can throw out a ready-to-rollout-website within a few steps.

During my research for this article, I was struggling to find the right source on how AI will impact especially the UX industry. In the literature, there is currently not much out there. But Adobe has published a major study "Creativity and Technology in the age of AI" in 2018 on the influence of AI on the creative industry, where UX is a part of. The study says that AI is good at doing repetitive tasks like searching for stock images or test different design approaches and find recurring patterns. This might be a big potential for the creative industry to have more time for qualitative and creative processes and outcomes. The good news is that the creativity that characterizes the industry cannot easily be replicated by an AI.

Creativity is such a complex task, even the researchers have not yet fully explored it. It is not only intentional but situational, inspirational and executional. Anthony Brandt and David Eagleman, authors of the book “The Runaway Species”, explain:

    “To achieve a creative artificial intelligence, we would need to build a society of exploratory computers, all striving to surprise and impress each other. That social aspect of computers is completely missing, and this is what makes computer intelligence so mechanical.”.

The authors mentioned the social part of creativity. Probably a lot of my UX folks will agree with me at this point: I better do concept development with coworkers in front of a huge whiteboard, instead of discussing ideas with an AI in a lonely room. The study also predicts that AI, Machine Learning and Neural Networks will have an impact on visual outputs, its perception and its role in society. An example is the computational AI-based art, where artworks and imitational mimics are generated by the system. Another development is the democratization of sophisticated visuals. Non-designers get the tools to create their artifacts without going to a design professional. Look at Instagram: AI mapped rabbit ears on our face to share it in stories and short clips instantly. Everybody can design something. And even for professional designers, AI tools will support the creatives in tasks like data analysis from research, faster testing, or visual outcomes.

We can say, that AI will have an impact on the creative industry. Processes, workflows, tools and probably jobs will change. Most of these are assumptions for now, but we can see some developments going in this direction. As part of the creative industry, most of the mentioned future predictions will also have an impact on the UX industry…
… and its UX designers

Also, we technology-savvy UX designers are afraid, that AI might eat our job. Many jobs will be automated over the next decades. There is a concern, that AI will devaluate the designer’s visual skills or that we will lose control over the design process when smarter intelligence becomes the boss. For now, AI still seems like a black box and we can not predict the exact outcomes from it. It is simply letting go of control, that makes us feel unsafe. Basically, artificial intelligent systems are capable of collecting endless data and interpreting them to predict user behavior. Sounds like our UX job, right? But no worries, it is all good. With very high probability we will not lose our loved job. It will just adapt a bit. Evan Abrams, Motion Designer and Instructor summarizes:

    “AI will shift the designer to be a creative director. That will shift the focus from creating to decision-making — but no AI will supplant decision making.”.

UX designers make sure that the vision as well as the implementation follow the right direction. Our intentions and strategic knowledge are becoming much more important, but also our ability to connect the dots. The CEO of Microsoft, Satya Nadella explained, that humans have the creativity, empathy, emotion, physicality and insight, which can be mixed with powerful AI computation. Instead of working against each other, humans should work together with machines to solve “society’s greatest challenges”. But how would this collaboration look like? The current opinion of people in the industry is, that AI will be an assistant instead of a replacement. AirBnb, for example, is using AI technology to transfer low-fi wireframes into code, almost in real-time. It allows them to quickly test their ideas, because the required testing time should be zero, according to Benjamin Wilkins, former Experience Design Lead at AirBnb. Netflix uses AI to create show thumbnails in different languages based on the locations of the customers.

These products and services should support the user (if it is a customer or an internal design team) and it is the role of the designer to represent the user needs and concerns in the holistic design process. AI can assist UX designers in their daily business. Those of us whoever had to evaluate tons of video material from qualitative user interviews know, that is it very time-consuming. An intelligent assistant can transfer, cluster and point out the highlights from the complex data to help us generate insights. The same applies to quantitative research. Data from millions of people can be used for automatically creating personas. Personally, I am not the biggest fan of using personas in my projects, except it is necessary due to specific use case reasons. Every user is different so I better go with user needs. Another concern of automated personas might be the lack of human equality. AI learns from past data, but it also has to be aware of current cultural and social developments, to name the Black Lives Matter movement for example. We designers define the parameters so the AI can do its job. We will be the curators and make the decisions. Companies but also universities have to invest in the continual and lifelong learning of their designers and students by offering workshops and classes. Doing so, Junior and Senior Creatives can deal with millions of AI design variations and tools while productivity increases in a fast-moving environment. We will work with AI tools in research, idea generation, prototyping, testing and in creating and maintaining design systems. These are very exciting times for UX designers in every career level and we should keep in mind what Simon Sinek always says: Start with WHY.
Let’s start — Resources

AI is a huge topic and you can not learn all of it in only one weekend. If you google “AI” but also in connection with UX Design, you will quickly feel overwhelmed. But instead of giving up directly, it is okay to approach the topic in small steps. To help you get started, I have compiled a few sources below to help a UXer read up on the topic of AI for UX. Even if you are already working on a particular design project, they are still good references.

My first recommendations are the articles from Jennifer Aue Sukis. She is the Design Director for AI Transformation at IBM and says it all starts with becoming a data-driven designer. Including data to the design process helps to better understand user needs and user behavior and to improve the Interaction and UI Design. Therefore it is essential to know the basics about how to integrate and apply data-driven design approaches as well as how Artificial Intelligence and Machine Learning work. IBM published a website about their design for AI practice. You can read about the basics like characteristics of AI, relationship development or the AI/human context model. Since ethics are a very important aspect of AI design and development, IBM handouts a report called “Everyday Ethics for Artificial Intelligence” and it is being updated every year. They also consider information about user data rights and conversation design based on natural language for chatbots and agents. Another big player, Microsoft, also published a website only for AI. Their learning opportunities and resources are mainly intended for developers, but digging deeper into the content, you can find guidelines for Human-AI Interaction and Inclusive Design based on responsibility. Especially the guidelines for Human-AI Interaction have been explained in detail in a paper that you can download here. Since Microsoft approaches AI mainly from a broader business perspective, it is a good resource if you are a (design) manager. Last but not least I warmly recommend the ebook series “AI Driven Design” by Joël van Bodegraven and guest authors, published by awwwards books. In four chapters they are sharing knowledge about ethical challenges, biases, AI design principles and the basics about AI and Machine Learning. As the resources I have shared above, they are also writing about the role of responsibility and situational awareness. Regarding the design challenges of AI-driven applications, they hand out a nice worksheet template to identify UX challenges. View the ebooks here. There are way more resources out there as I shared here in this chapter — for example Google’s People + AI Research Library or the publications from Partnership on AI in cooperation with world-leading companies. Now, that you have a bunch of resources to refer to, let us continue by designing AI products in a valuable way — with the AI design principles.
Do it valuable — AI design principles

    “As a creative community, we are shaping what AI can become in the future.”.

This sounds very exciting, but also like a lot of responsibility for us designers, when we think about what Joël van Bodegraven and Chris Duffey mean with this sentence. We are still at the beginning of the AI era, but Artificial Intelligence is rapidly evolving. In order not to feel lost, there are a lot of AI design principles out there. I have tried to select the most frequently mentioned principles from experts working in the industry. The principles are based on current AI developments and will probably adapt or change over the next couple of years. But for today, here they are:
#1 Putting the human first

Also when it comes to designing for Artificial Intelligence it is the most important thing to be aligned with a real human need. The user’s role, as well as the goal, have to be clear. To deliver good interaction concepts and address user needs, it is all about the insights we have generated and will generate during the design process. Therefore we should keep in mind, that different users might prefer different things, especially when it comes to AI. Not everybody has the same level of experience or trust for this technology. For us designers, it also means to handle the uncertainty, which AI and Machine Learning systems bring. Rachel Been, Design Lead at Google Nest says:

    “As designers, we need to be flexible and ready to react to new questions: What if the user gets an error? What if she wants more transparency into what the AI is doing? How do you onboard her, so she understands it?”

The understanding of what the AI is doing plays an important role, but it does not necessarily mean, that the user has to understand the math behind the algorithm. Instead, the UI could visualize it in a way that makes the AI decision-making process more transparent to the user. No matter which interaction between human and machine, trust is a fundamental part which comes along with building and maintaining the relationship between both parties. Mark Knapp, a professor who researches nonverbal communication, explains the evolution of a relationship in his model. First of all, there is the initiating phase. As the first impression, the AI establishes its presence, personality and tone. User and System explore each other in value and authenticity in the second stage. Through context-aware and multi-step interactions the relationship intensifies. It is discovered, if both parties are interested in continuing the relationship. Fourth, the AI profile is established in the user-system relationship. Last but not least, they reach a high level of trust and appreciation in the bonding phase. His model might sound very romantic due to its transferability to human relationships. But it can also be adapted to humans and machines to understand the psychology of building a relationship.
#2 Design for trust and transparency

Not only designers but also users have to deal with uncertainty and risks by interacting with technology. When there is a lack of control, we need to have a certain level of trust, for example when it comes to storing our data in the cloud. The trust in machines can be influenced by factors like Human Characteristics (personalty, ability), Environment Characteristics (culture, tasks, institutional factors) as well as Technology Characteristics (performance, process, purpose). Applied to our example above it means, that someone with a trusting character is more likely to trust the data storage in a cloud.

The research shows, that the trust in digital contexts (called “e-trust”) is based on four kinds of components:
1. Communication Trust like available network connections, 2. Information Trust as believe in the quality of the information, experiences and uncertainty, 3. Social Trust in the sense of trust in the honesty of relationships e.g. in Social Media and 4. Cognitive Trust as the expected knowledge of reliability and competence.

Whether the user actually trusts the AI also depends on her/his personality, demographics and prior experiences, not to forget influencing factors from the environment like legal aspects or other people. In our UX and UI concept development, we gain trust in showing transparency and honesty. The user should know, which data is coming from where and how it is used. Currently, a Waymo vehicle for example displays what it is seeing in the environment during the ride on the infotainment system. Visually, the UI could show indicators and explanations on the predicted information or different suggestions which can be controlled by the user. Running apps for example can suggest routes which are save and lighted for the evening run. In the end, algorithm-based information are displayed so the user can decide to trust or not.
#3 Explainability

Explainability is a crucial principle to understand the AI decision-making process and setting the right expectations. The user should always know how the system came to this conclusion or recommendation. But how to achieve this? First, the user should be able to ask questions regarding the decisions the AI has made. Secondly, the reasons behind the system recommendation should be reviewable, especially when there is highly sensitive personal data in use. And thirdly, teams of multi-users like medical teams should be given access to the AI decision-making process, when data policies allow it. In cases the user or the team does not have full access to it, they should still know the intent of the AI and its level of transparency. Since AI is based on data, a lot of research has been made on algorithm aversion. Explainability helps averse users to trust the system more, but at the same time protecting them in over-trusting the AI. This could be very important for AI products or services in the medicine or finance sector, where risks might have a high impact. Another hint to consider is showing the explanation right after the user action because people learn better when cause and effect are clear. When the user is looking for café recommendations for example, explain why the system recommends exactly these. Nevertheless, let us stay realistic. Sometimes, explanations might be difficult, especially when the developers and data scientists do not know either, why the AI is doing what it is doing. We designers have to find ways in concept and visual design, how to communicate this to the user. A common solution is to display the AI model confidence level. This helps the users to estimate how much they can trust the AI decision. The UI can show the confidence level as categories, alternatives, numbers, graphs and others. Here it is also highly recommended to test a selection of confidence level visualizations to figure out what works better for this use case and users.
#4 Ability to give feedback and control

Of course, the all-time favorite of all design principles should not be forgotten — the feedback. It is important for all kinds of interactions therefore also for AI, to create a better User Experience, improve the product as well as the technology. User feedback improves the algorithm behind the product and is a supporting part in the communication between users, the product and the team.

For the user, giving feedback does not primarily mean improving the algorithm, but rather, for example, personalizing the content. This comes along with the ability to give them some kind of intervention. Especially when driving with Autopilot or semi-autonomous vehicles, human control should always be given. Controlling things manually or even stopping the process by the user should be considered. To look up, Google figured out three things to look at for feedback and control in their “People + AI Guidebook”:

1. Align feedback with model improvement.
Ask for permission to collect user data and get implicit feedback on interactions and user behavior on the one hand. On the other hand, you can get explicit feedback from the user like comments, ratings, surveys or thumbs up/thumbs down. The given feedback can either go directly into the AI algorithm or be used by the product team.

2. Communicate value and time to impact
Communicate the benefit users will have by giving feedback so it motivates them to share valuable and impactful feedback.

3. Balance control and automation
As designers, we do not have full control of how the users interact with our product in the real world. But what we have in our hands is to let users edit and adapt the output, so it matches their needs. Moreover, we have the responsibility not to automate everything that comes into our hands. It is better to automate unsafe or unnecessary tasks (like setting an automated temperature in Nest or calling an Uber driver) than the ones where people are better than a machine.

Feedback could also be negative, for example in error cases triggered by the AI system. In this case, the designer can approach it with humor or like Netflix does, with like or dislike options on suggested shows. By giving feedback here, the user trains the algorithm in the background and gets a little control of personalized output.
#5 Accountability

As humans create AI interactions and algorithms, every person in the process has the responsibility for the possible impact our decisions can have on the world. Therefore, communicate company policies from the beginning of the project, so everyone is aligned with accountability. Figure out, where which responsibility begins and ends. Document design decisions and see, if the team or the company has any knowledge of the laws regarding artificial intelligent systems. The United Nations, as well as the European Commission, published some guidelines for a trustworthy and ethical AI. Especially for AI concept development, it is even more important to work in interdisciplinary teams with professionals like data scientists, behaviorists and sociologists to build a technically feasible, user-centered and ethical product. From my point of view we should also be honest to ourselves and talk about it when something feels wrong for us and if it does not match our values.
Do it clever — AI design tips

Even if designing for AI takes into account some specialties, it follows a similar design approach as for non-AI projects. We still need to do user research, find the real user needs, define insights, user goals and more. We are also able to use the typical UX design methods like card sorting, mind mapping, ecosystem maps, user journey, sketching, storyboarding or prototyping. The AI/Human ecosystem is described by IBM in their Context Model. The Artificial Intelligence learns from humans, business needs, market goals and external factors from the world. I think it is very helpful to understand how the dots are connected. Like in any other design project, there is a user and/or business intent at the beginning. The following data from the user and the world which is used by the system underlies different policies we have to keep an eye on. In between is the huge machine learning part, where the system gets the data input and tries to find a logic behind it. It learns from the past data and delivers the response to the user who reacts to it. Based on that, the user can improve and continually teach the system. All steps in the AI/Human Context Model will have an impact on the outcome to solve a real user problem. Oracle shared another helpful design tip. Based on the budget approval software for managers I mentioned earlier, they referred to their “Three Tier UI System for Automation”. They differentiate between a highly-automated UI, a semi-automated UI and a manual UI.

By creating the user journey they figured out, which automation potential each step has. By doing so, they were able to identify eliminable and automatable tasks. According to the VP of Design, Fintech and ERP at Oracle, Winston Wang, it is his “[…] version of thinking of the continuum between fully manual vs. fully automatic work and control”. I find it is a really good approach. At this point many thanks to Winston for the support and sharing your thoughts with me. Last but not least, I would like to mention a helpful worksheet called “UX of AI challenges” by Nadia Piet, a design researcher and strategist. She created a table with some questions to think about when it comes to design principles like user trust, transparency and control. It was published in part four of the awwwards e-book series “Artificial Intelligence Driven Design”. In general, you will probably learn most tips and tricks if you are working on a project based on Automation or Artificial Intelligence. Companies like IBM or Oracle have found their ways and approaches to AI and Automation Design in their teams. So I think it will remain very important that these approaches are shared with the design industry to inspire and adapt. For now, we got some starting points on how AI might change our UX jobs, we learned about designing for trust, explainability and other principles as well as looking for helpful models. But in the end, they are all applied as a part of the design process.
The image shows the AI/Human Context Model from IBM. It describes the connections between business, world, machine and human.
IBM AI/Human Context Model
Do it organized — AI design process

When I planned this article I asked myself if designing AI products will lead to a completely different design process? Do we have to change our way of creative thinking? As I was indicating earlier, our common UX process and especially the design thinking tool is quite applicable to AI projects. It supports by dealing with the complexity AI brings along and aligning the project team of developers, engineers, managers and other stakeholders. AI products are built with a multidisciplinary team in an iterative design process. It is about understanding the user and identifying the problem, ideating solutions, iterating prototypes and delivering the concept. Holistically, designers are making sure the team has a clear intent and applies the “putting the human first” principle. Try to make as many decisions as possible based on data, not on assumptions. Even if it is not always possible in real projects with limited time and budget. Another question to discuss with the team is if you really need AI to solve the user problem. People want the best solution which fits their needs, no matter what the technical solution behind it is. So do not build a product based on AI just to build a product based on AI. Identify the user and business needs in a team workshop to stay on the right track (with markers for everyone and a whiteboard!). After that, you can cluster and prioritize the core intents. In co-creation with data experts, you can then figure out, which data you need, which data is available and what is needed to teach the AI. The “Personal Data Canvas” from designhumandata.net is a valuable framework you can download online to figure out some answers.

In the next step of the process, the team can check, which ideas have the potential to be implemented. Crazy ideas are good, but some people actually have to code it so it should be technically feasible. From the concept point of view also think about potential misunderstandings or a repurpose of the product on the one hand, when it is used by the real customers. Thoughts about worst-case scenarios are still a good chance to reveal points that need to be questioned. On the other hand, find out additional benefits on the user or the business, when considering direct as well as indirect effects on the AI. Again, IBM published a helpful toolkit for Enterprise Design Thinking with some approaches on AI.

In the next years, Artificial Intelligence can take over some tasks in the design thinking process, which have a high potential of automation. Examples are competitive analysis, clustering and discovering insights from user interviews or sitemaps and A/B testing methods. AI tools that are capable of analyzing and interpreting a large amount of data can help create better products in the future of design thinking. For now, Craig Nelson, Partner at ISG Research summarizes the design thinking in the context of AI with the following words:

    “Executives who promote design thinking in their organizations can accelerate AI adoption, achieve organizational alignment and drive commitment to their goals while reducing resistance to organizational change.”.

Conclusion

We live in a time which is characterized by both excitement and reorientation at the same time. Who knows what the world will look like after Corona in the long run or how exactly the technology of Artificial Intelligence will develop? In my opinion, it is a great opportunity that UX designers, among others, can contribute to the future development of Artificial Intelligence with our creative and analytical way of thinking but also with our empathy. We are used to dealing with uncertainty. Because let us be honest: In many projects, we do not know on the first day in which direction it will develop and how exactly the final product will feel and look like. Especially here in Germany, I would like to see more courage and openness to the try and error mentality, as I experienced it in Silicon Valley. These do not have to be the Waymos on our streets, but at least a little more visibility of new (AI) solutions. For this to happen, however, they first have to be designed. As designers, we set the parameters that need to be designed and work with other experts to ensure that AI-driven products are not only human-first but also technically feasible, ethical and environmentally responsible. To this end, we should question ideas and concepts or even approaches and be aware of current developments as well as the chances and risks of our AI concepts. This also includes looking at how AI and Machine Learning work and being able to communicate better with developers and engineers. On the other hand, they should also be included in the Design Thinking process. The organizations that still only build technology-oriented products will hardly be able to compete with the organizations that approach products based on the user problem. Tasks that people can do better than an AI should continue to be performed by humans. AI should become like an assistant that takes care of easily repeatable tasks, leaving more time for real thinking and creating. Especially in times of AI, it is more important than ever to work interdisciplinary and iteratively. True to the motto “Do it right or do the right thing” within the scope of AI projects, we can also apply and adapt our well-known UX methods or invent completely new ones that bring us closer to a goal. But this can only work well if the tools and methods are also used to do the right thing. For example to pay attention to possible bias and accountability. Not only in the products we design but also in the products we design with. After all, at the root of possible future innovations, we also have a certain responsibility towards ourselves, the users and our world. AI is still a young topic for creators and users, which will take off in the coming years. As things stand today, Artificial Intelligence will not replace UX Design jobs, but it will certainly change them. What is certain, however, is that new job profiles will emerge and it is essential that we keep learning continuously. There are still no researched forecasts about the impact of AI developments on the UX design industry as such. However, there will probably be more data sets available in the next years. The digital and design industry should continue to exchange and share knowledge. I strongly believe that the best products and services are created in a team of interdisciplinary people. In this sense: Let us exchange ideas, learn from each other and be prepared for the era of Artificial Intelligence!

This article was written as part of the M.A. Design Management class taught by Prof.
Holger Fricke at HAWK Hildesheim, Faculty of Design.



### Untitled 14.txt

AI and Design: why AI is your creative partner
Miklos Philips
UX Collective

Miklos Philips
·

Follow
Published in

UX Collective
·
14 min read
·
Apr 14, 2020

AI and design. AI is your creative partner.

AI and its subset disciplines, such as Machine Learning and Computer Vision are shaping the future. Design tools and designer roles, workflows, and processes will be molded by it. In light of this, we need to start thinking about AI not as “artificial” but as augmented intelligence, and in the ways we can take advantage in order for it to become our creative partner.

It’s time to shift our mindset from a human vs machine to a human plus machine mindset. Becoming familiar with AI will shift our approaches and ignite new thinking. AI in design will be more about designing awesome experiences, not UIs — creating better products, services, and improving people’s lives.
An analogy

Take an isolated tribe in the Amazon rainforest. These people have had no contact with civilization, and have never seen anyone who looked different from them. Imagine — completely cut-off from the 21st century. No TV or electricity, no phones, no Twitter, Instagram, or Netflix.
Photograph by Ricardo Stuckert

This is a photograph of the low-flying helicopter that due to a diversion because of a storm, took the National Geographic photographer Ricardo Stuckert out there, above the tribe. What did the helicopter look like to them? Scary? You bet.

In fact, they shot arrows at the helicopter! Terrified, to them, it seemed like a monstrous flying beast! Were they wondering: “is it a massive metallic dragonfly?”
Photograph by Ricardo Stuckert

Why am I bringing this up?

Because we fear that with which we are unfamiliar. The fear of the unknown.

Do we have the same response to AI?

Remember this guy?

### Untitled 10.txt

#5: Machine Learning is Very Much a UX Problem
Yael Gavish

Yael Gavish
·

Follow
9 min read
·
Jul 25, 2017

This is part 5 of the 6-part tutorial, The Step-By-Step PM Guide to Building Machine Learning Based Products.

We previously discussed how to set up your organization to work effectively— let’s see how to help your users benefit from the results.
ML Models and Results Are Not Easily Explainable

Many ML algorithms are black boxes — you input a lot of data, and get a model that works in mysterious ways, which makes the results difficult-to-impossible to explain. In many algorithms there are interaction effects that makes the models even trickier to explain — these are relationships between various features that explain parts of the behavior that cannot be explained by just adding up the effect of each feature individually. Think about it as a compounding effect between features — the whole is greater than the sum of its parts, in a lot of strange and intricate ways not digestible by a human.

That said, you and your team will need to be convinced that the results make sense, and it’s easier if you can understand the results at a level beyond dry statistical metrics. It also helps to identify cases that are not covered or areas where the results don’t make sense, as we saw in the model building phase. This is even more critical with your users — in many cases they will require an explanation before they trust your results. You won’t have credibility from the get go, even if your results are 100% accurate, so your users may require an explanation to the outcomes you’re showing them. In extreme cases you may even be legally obligated to explain the result, as in the case of rejecting a loan application — by law you have to give the customer a reason for the rejection. To add complexity, your model will not be 100% accurate, as even 80% accuracy is considered quite good, so in some cases users will want to understand results that are actually wrong! In other words, the bar is for your user to see blatant errors once in a while (which they likely will) and still trust your results overall. That’s a high bar to meet.

The challenge is not limited to models used for external customers — the need to earn user trust applies to internal users as well; even though they’re rooting for you, your internal teams are a lot less likely to adopt results they don’t understand or trust. I’ve seen cases where teams preferred using an easy to understand rules engine rather than a ML model that is likely to produce significantly better results, just because a rule engine is explainable — humans write the rules so they can understand them.

This is not a problem you can set aside until after you built the model(s) — it is important to think in advance about the data and components of the model that the user may want to see and how to present results in a way that builds user trust. The answer may actually change your approach to building the model, and will help prevent a situation where you have an answer and no way of explaining the answer to a user. That said, thinking about this in advance will not exempt you from doing so again once you have the results, since model building is inherently an iterative process and extensive changes to your approach may be required if your model has changed.
Modeling for Explainability

The need for explainability may influence the way in which you build your model, including the level of granularity you need to support. Let’s say we’re building a platform for investors to evaluate startups based on Marc Andreessen’s framework, which states that the three core elements of each startup are team, product, and market. Now, Andreessen believes that the market is the most important factor, but let’s say other investors believe that a good team can find ways to grow a small market, therefore the team is more important. You can come up with an overall score or probability of success for companies that combines these 3 dimensions and gives some “absolute truth” you believe is correct, but investors may not necessary buy it. More specifically, investors may want to understand how good the company is on the particular dimension they care the most about. In addition to your model, you may need to be able to give them visibility into that. Here are a couple of different approaches:

    Build 3 separate models for market, product and team, each evaluating the company on a single dimension. Then build an aggregate model which combines all these features (and potentially many others) into an overall result. Investors could both look at the aggregate result and the specific dimension(s) they care the most about.
    Build an aggregate model and find a way to extract the features that are most applicable to each dimension from it and give users a sense of their value and importance, or to show data points that align with each dimension to build confidence in the results.

The right approach depends largely on your problem space, available data, modeling approach etc., but should be explicitly discussed and evaluated before you move on to prototyping the model.
Presenting Results to Users

When deciding how to show results, the goals should be to make them clear, believable and most importantly — actionable. There’s no playbook here — every problem will result in a different presentation of the results. I’ll review a few possible approaches and considerations to give you some ideas.

    Backdating. This is taking historical data and plugging it into the model to produce past predictions that could be verified against known values. For example, if you build a model that predicts values in year N based on data from year N-1, you could plug into the model data from 2 years ago and see if the prediction for a year ago is correct, since that information is known. This is also a potential way to test your models. Depending on the completeness of your historical data, it may be challenging to get enough data coverage to use it fully without some simplifying assumptions and/or model tweaks (e.g. if your model uses data from social networks, you can’t backdate to a time where social networks didn’t exist). This is also not feasible for certain models, such as reinforcement learning models.
    Explaining your methods and inputs. Simply telling the user what the types of data you took into account in your model builds trust by helping them see that the decisions are based on the same types of variables they would consider themselves if they had to make this decision. In the Andreessen startup evaluation example, a brief explanation for the market evaluation piece could be: “The market potential of a startup takes into account the number of companies in the market and their total sales, the growth of that market in the past 5 years worldwide, the number of new product launches over time, M&A activity in the space and macroeconomic trends”. While it’s not a full explanation, it does gives the user a glimpse into the black box. This is definitely necessary if you’re introducing a new score, as previously discussed.
    Exposing some of the underlying data. This approach is the easiest for users to understand and believe since they see the data for themselves, but not always the easiest to design and has several downsides: You need to expose data you may not wish to or be able to expose (e.g. because it’s proprietary, due to legal constraints etc.), the data may not agree with the conclusion in some percentage of the cases (modeling is about probabilities), or the data may not even be there; the algorithm doesn’t need full data coverage for 100% of the entities it evaluates — it can make up for gaps in the data if it has a large enough data sample for similar entities.
    Simplifying and only showing select results to facilitate decision making. Unsurprisingly, Amazon does it well with some of its product recommendations. I searched for a knee sleeve, see below the page I landed on from Google search results.
    Amazon knows for each related product the exact probability that I will buy it, yet instead of giving me 30 sorted options of similar products, I’m presented with a very easy choice between two — either the cheapest or the best selling + top rated product. I know nothing about the criteria they used to pick the comparative set of products and whether it corresponds to what I would pick if given the option, but at this point they made the decision so easy for me that I don’t really care.

Example: Product landing page from search

    Defining a new metric. One question you should consider is whether you’re creating a new metric (a new type of “score”) or predicting a well understood one: You can build your model to predict an existing metric (e.g. revenue of a company, value of a house etc.); alternatively, you can create a score that embodies a certain concept that doesn’t yet have an accepted metric, in order to enable stack ranking of entities by that concept (“the FICO score for <industry X>”). The decision largely boils down to whether there’s a single metric that expresses the business objective you’re trying to reach with your model, or it’s a mix of several factors that need to be weighted somehow. For example, if we’re evaluating the attractiveness of a commercial real estate asset for retail use, we may want to create a “retail fit score”, which will be comprised of several components such as sales per square foot, all in cost per square foot and location brand value contribution (say you believe a location on Fifth Avenue adds brand prestige beyond the pure foot traffic it attracts). In that case, there’s no single metric that encompasses these metrics, so you’ll likely have to model each component individually and then bring them together through some type of relative weighting. An important consideration when choosing to go with a new score is that you will likely have to spend more time and effort to educate your users about it. Think about having to convince the first financial institutions to use the FICO score when it was first introduced…
    Precision doesn’t always matter. A lot of models generate results that are a very precise number — probabilities, values etc. If you show them such precise numbers you risk users taking them more literally than you intend. A home with a predicted value of $583,790 isn’t definitively more valuable than a home with a value of $580,625. The margin for error is probably much greater than the ~$3K difference. Sometimes displaying the results to the customer in those precise terms is counter productive and gets them to read more into the numbers than they should. It may be a good idea to consider giving results in ranges, deciles, grades or some other less precise measure of value rather than showing the customer the exact output of your algorithm.
    Strategically providing access to raw data. In addition to showcasing the results of its own risk models, Lending Club provides access to its raw data for other people to build their own ML models on top of it. Is this approach relevant for you? Could it drive growth in some other part of your business? In addition to providing potential monetization options, this approach also helps the ML research community to accelerate the pace of innovation in the space. As an example, the availability of Microsoft’s COCO and the CIFAR data sets has greatly benefited image classification capabilities.

Again, the choice of user experience highly depends on the subject matter, product and user needs — there’s no “one-size-fits-all”. It’s entirely possible that none of the options above would be remotely relevant for your product. The key takeaway is to not underestimate the amount of thought and effort you need to put into the user experience side of the problem — even the best model is useless if users can’t understand, trust or act upon its output.
An Extra Geeky but Important Note

Explainability is an evolving area of ML research, with researchers actively looking for ways to make models less of a black box. One example is LIME (Local Interpretable Model-Agnostic Explanations, also here): An “explainer” for models that are classifiers (algorithms that map input data into categories or labels) that is used after the model is built to explain the results in a human-digestible way. Whether it’s relevant and/or sufficient for your purposes depends on the specific case and models you use.

Another area of research is Layer-Wise Relevance Propagation (LRP) — a technique to “deconstruct” the prediction of neural networks to visualize and understand the contributions of individual input variables to the prediction.

While the engineering aspects of building an effective machine learning infrastructure are largely outside the scope of this tutorial, keep in mind that product needs can affect engineering decisions and requirements. More on that next.


### Untitled 7.txt


When to book and when to fly? Explaining prices in Google Flights
Slava Polonski, PhD
People + AI Research

Slava Polonski, PhD
·

Follow
Published in

People + AI Research
·
9 min read
·
May 6, 2020

Slava Polonski, UX Researcher
Roxanne Pinto, UX Writer

Editor’s Note — Even though much of the world is currently in lock-down and air travel is drastically reduced, the questions this post addresses are as relevant now as they will be once the people of the world again feel they can travel safely to be in one another’s company.
Illustration by Roman Muradov for Google

Imagine the scene: you’re living your normal busy life, doing the day-to-day grind, and you realize you haven’t booked that flight for that trip you’ve got to take. Oh right, you may think, the holidays are coming up, I still need to book my flights. I bet flights cost a fortune already. We can relate. In fact, millions of people around the world can relate — flight pricing is tough to anticipate, including for many Google Flights users. Flight prices are subject to changes, inconsistent across sites, and hard to understand. As this video from CNN says, “It’s rocket science.”

Identifying patterns in flight prices is tricky. They change a lot. According to some popular blogs, even on a single plane, a type of seat that sells for 100 dollars to one user can easily sell for 500 dollars to another user.

We at Google Flights thought that if we can put some of the data and smartness in the hands of our users, that could help them demystify what they’ll need to pay at a certain time for a certain flight. We hoped we might save our users time, stress, and maybe some money too!

Our first stop was the Explainability + Trust chapter of PAIR’s People + AI Guidebook which provides a useful framework for thinking about these sorts of issues. Here’s what we came up with when we applied it to our unique challenges.
The user need

In user study after user study, the Google Flights team kept hearing the same message: buying a plane ticket is nothing like buying a cappuccino. When searching for flights to new destinations, it’s difficult to estimate the fairness of a price, not to mention that prices can jump up or down in unpredictable ways, sometimes doubling or tripling in a matter of hours. And then you have to figure out the fee for checking your bags.

### Untitled 6.txt


A snapshot of AI-powered reminiscing in Google Photos
People + AI Research @ Google
People + AI Research

People + AI Research @ Google
·

Follow
Published in

People + AI Research
·
7 min read
·
Jun 1, 2021

Illustration for Google by Lukas Egert

By Thryn Shapira

Thryn is a designer who is passionate about building products that work well for everyone. She leads product inclusion efforts on Google Photos and contributed to the People + AI Guidebook.

If you were alive before smartphones and digital cameras, you might remember when your photographic memories were in physical photo albums or a shoebox that you thumbed through when you got the urge to reminisce.

Now that we carry high-quality cameras in our pockets to snap selfies and take videos of our cats, our photo and video libraries are getting huge. It’s great — so many pictures😃; and overwhelming — so many pictures 😩. Special moments that we capture are quickly buried in an overwhelming black hole of digital obscurity, and the majority of photos backed up in Google Photos might never be viewed again.

Still we took them for a reason — to document, to share and to remember those meaningful moments. We on the Google Photos team saw an opportunity to reconnect people with their memories, and we used AI to understand what photos are meaningful and worthy of reminiscing. That said, because a large, diverse group of people use Photos, and because reminiscing is so personal, we knew that we’d need to give individuals control over their experience.
How AI helps us reminisce

In Google Photos we use AI to make your images easier to search and organize by people, places, and things. It also powers features that go beyond search and organization. We use AI to automatically combine photos and videos into a short movie set to music and generate animations from photo bursts. If face grouping is on, AI creates collages featuring a recent photo of someone next to an older photo of them in a similar pose. Personally, I love that these show how someone has grown over time, like this one that shows my daughter at age one and age three.
Google Photos collage; photo credit: Thryn Shapira

A few years ago, we introduced AI-powered reminiscing features. Rediscover This Day resurfaced photos from the same day in previous years, and They Grow Up So Fast compiled photos and videos of a loved one over time into a short movie. These quickly became some of our most loved features; people enjoyed seeing these meaningful moments they might not otherwise revisit. We wanted to build on this and resurface more photos and videos buried in people’s digital libraries.
“Rediscover this day” feature in Google Photos
Make Memories from mountains of pictures

We started working on our Memories feature with the goal to make reminiscing a central and everyday part of the Google Photos experience. With the help of AI, we set out to curate meaningful content from your photo library and display it in an immersive story player.
Memories experience in Google Photos

That said, Memories needed to be enjoyable for everyone — no matter the size of their photo library, whether or not they travel, have kids or pets, or if they take hundreds of pictures a week or a few pictures a month. To create an engaging reminiscing experience that everyone would enjoy we needed to make tough decisions about what types of content to include or filter out.

In addition, reminiscing is personal and not all memories are welcome. Some memories are intensely sad, upsetting, or painful — such as photos of an ex-partner or a loved one that has died. When we expanded our reminiscing features and automatically brought more photos and videos out of obscurity and put them front and center in the Photos app, the impact of getting things wrong became much higher.

With this in mind, we knew that we needed to give each individual some control over their experience. AI-driven products are probabilistic by nature and the experience won’t be perfect for everyone, every time. It’s important to allow people to adapt the output to their needs, edit the experience, or even turn it off.
Curate The Right Photos in Memories

To build Memories, we didn’t just start with AI — we started with people. We conducted research with a diverse set of users and those learnings guided how we defined the AI models that power Memories.

To start, AI curation for Memories takes a set of photos and filters out the bad, boring, and sensitive stuff — from receipts and parking lots to all the blurry photos you took of your fast-moving toddler before you snapped a sharp one. We do this in two ways: non-pixel-based detection models produce signals and labels (i.e. things, people and pets) that determine how likely it is that a photo could be a receipt or picture of your tax forms that shouldn’t be included; and pixel-based models filter out near-duplicates, and score photos on a set of aesthetic qualities like blurriness and lighting.

Then a set of non-machine learning filters based on photo metadata (image resolution, file formats, photo dimensions) filter out things like screenshots and low-resolution photos. We use rule-based filters because AI models simply aren’t needed for this. The camera codes information, like the resolution and whether or not it’s a screenshot, directly into the image file. Because of these filters I’ll never encounter the 64 screenshots of my phone’s lock screen that my daughter took while I’m reminiscing.

Finally, the set of photos is packaged into a memory.
Giving people control

Even if we could accurately predict the significance of each photo, we can’t accurately predict how someone will feel about revisiting a particular moment. And we’d heard from some people that photos surfaced from our earlier Rediscover This Day feature were sometimes unwelcome. In Rediscover This Day, users could turn off the feature or swipe the card away.

For Memories to be positive and meaningful, we needed to continue to include explicit controls so people had the final say over their own reminiscing experience. I understood this need myself. For a while after my dad died it felt too painful to see photos of him resurface unexpectedly. But a year later I was ready to revisit the photos from his funeral where my siblings and I were all together sharing grief and reminiscing about his terrible dad jokes and astonishing life-long devotion to the San Diego Chargers.

With Memories prominently placed at the top of the main app view, we had to be especially sensitive to needs like this. While our AI models do their best to filter out sensitive content, they won’t — and can’t — always get it right. For example, it may seem obvious to automatically detect and filter out photos of funerals. But many photos of funerals and weddings in Western countries share the same objective characteristics: people wearing dark suits, people seated in an assembly or around tables. Funeral traditions are also not universal, and don’t always fit the stereotypical western image. Hindu widows wear white, and at a funeral I attended when I lived in Cameroon, community members wore bright colors and patterns. Even at my Grandma’s funeral, very few people wore black because we knew how disappointed she would be if we treated it like a somber affair. Instead we dressed in bright springtime florals while we celebrated her long and very productive life.

To give people control in Memories, we used existing controls and added new ones. Shortly after we launched Rediscover this Day, Google Photos gave people the ability to hide specific faces in their library. You can hide photos of an ex-partner or an obnoxious in-law, and their face won’t show up in reminiscing features ever again (and you can of course bring those memories back if you change your mind). We felt strongly that the ability to hide dates was also important, and research supported this hypothesis. So we built controls to hide dates and date ranges directly from the memory player. And you can also remove memories all together. The result is key controls for people to adjust and personalize their reminiscing.
User controls in the Memories feature

In the end, it was rewarding to see how AI could be used to power such a personal experience that lets people get more out of their photos: reliving memories and seeing a snapshot into the past. Of course we learned a few things along the way, including how AI shouldn’t be the only tool thrown at every problem, in this case rule-based filters work well, and that there’s room for personal control even with automatic features.


### Untitled 11.txt

UX design in AI
Introduction

Currently, computational capacity is doubling roughly every 18 months. The pace of this development, amplified by rapid improvements in software, has resulted in artificial intelligence (AI) and advanced algorithms that are quickly evolving to understand and interpret some of our most complex natural processes.
At the same time, the ability to access this capacity is multiplying due to sharp increases in bandwidth, improvements in latency and other quality of service parameters with technologies such as 5G. Interfaces are also becoming more seamless due to advances in cloud computing as well as visual, tactile, and verbal interface technologies.

These exponential improvements have brought what, just over a decade ago, were considered industrial-strength processing and communication capabilities into the homes and hands of individuals everywhere. As industries adopt these technologies to modernize and automate their business processes to increase value chain efficiency and effectiveness, a new service-based concept for the technology has emerged. The self-driving or autonomous car is an example of this new concept. Eventually cars will no longer have drivers, a fundamental change in the concept of a car. The passenger of such a vehicle will interact with it on a much higher and abstract level as a service. When we apply this concept to the telecom sector, i.e. creating a “self-driving network”, AI technology will be the brains behind this change. This presents two main challenges for those developing the concept and service:

    The conceptual shift from today’s understanding of what a network is, becoming something more abstract than what it is today, operating on new parameters.
    The fact that a user of such a service will interact with the system on a much higher, more abstract level.

Therefore, the understanding of the business goals and the user of the system is key to success. With the role of users shifting from drivers to passengers and from operators to managers, designers will need to create highly collaborative solutions allowing tangible and reliable interaction between AI technology and the user.

In light of this, the Experience Design team at Ericsson has been researching and developing how to design trustworthy, AI-powered services for telecom operators. Through designing the Cognitive Operation Support System service concept, we have identified four components of human trust that can be applied to AI powered systems. These four pillars - competence, benevolence, integrity and charisma - are the key areas designers and business owners need to address to be successful when it comes to the adoption of AI.

In this paper, we will share our experience of designing a trustworthy, AI-powered Cognitive Operation Support System (OSS) service.
AI today
The current face of AI

AI is an umbrella term encompassing many different methodologies and concepts, referring to any machine developed to perform tasks that would require intelligence if done by a human. Although the media commonly portrays AI capabilities as superior to human capabilities – i.e. as an artificial super intelligence (ASI) – the truth is quite different. Since the earliest explorations into the AI field, the scientists and practitioners have sought to create a computer with a level of intelligence similar to a human. Known as an artificial general intelligence (AGI) – these would be machines with a reasonable degree of self-understanding and autonomous self-control, able to solve a variety of complex problems in a variety of contexts. Despite the huge advancements of AI, especially in the last decade, we are still far away from being able to create an AGI, let alone an ASI.

The current form of AI we are working with is known as an Artificial Narrow Intelligence (ANI), or “weak AI”. ANI systems are created to carry out specific tasks showing specific aspects of intelligence in a specific context. All current applications of AI, whether it is an autonomous car, a chatting app camera filter, or an intelligent OSS, are all considered narrow or “weak” by this definition.

An easier way to describe the role of current AI applications is to call them “agentive technology” - whereby we can think of them as our assistants or agents, handling a discreet task and not the entire job.

In this current context, humans still need to have a view of the bigger picture and are still required to supervise, evaluate, and orchestrate the work of these AI systems.
Levels of AI

Figure 1: Levels of AI
The key to AI success
Trust as a vital component in AI adoption

There is an increasing trend of digital assistants appearing in many different aspects of our lives. Powered by machine learning (ML) models, they analyze data to come up with statistical probabilities that can be used to offer recommendations and make predictions and decisions, from suggesting the optimum route to take on a commute, to adjudicating whether we are viable for a loan or not.

Although they sound less impressive than the idea of the ASI’s superior artificial brain, these recommendations, predictions, and decisions taken by the AI systems can be considered a fundamental change in the way humans are using tools – a paradigm shift in the human-tool relationship. Since the beginning of this relationship, humans have always been in full control not only of what the tool should do, but also exactly how it will work, at least in the design and creation phase. The progression to the current status of AI is an evolution of this relationship in two ways.

First, it is an upgrade of the tool’s status from the role of a “slave” to that of “agent,” giving it agency by having a degree of autonomy with regards to “what” it should be doing. And second, it is a change in that with AI, we no longer entirely decide “how” the tool executes its function. In fact, in many cases, the creators of an AI system cannot entirely describe the criteria that the ML model has used to reach the output. This is known as the “Black Box problem”.

Taking these points into consideration, the following can be said about the current state of AI systems:

    Rather than just executing what the human user wants, AI systems will autonomously come up with predictions, recommendations and decisions.
    We are not always able to fully understand or explain why an AI/ML system has reached its output.
    AI/ML output is based on statistical probabilities just like human decision-making – it judges low or high probability of outcomes, it’s not some kind of ultimate truth or absolute objective correctness.

We can therefore reach the conclusion that a degree of trust is needed, before the user can hand responsibility over to the AI - and give the autonomous car the steering wheel.

The requirements in building this trust-based relationship varies according to the specific task the AI is supposed to handle. Accepting an AI’s recommendation on which movie to watch is much “easier” with a lower trust threshold than, for example, the recommendation on which medicine a doctor should prescribe to their patient.

In a recent survey asking owners of smart voice assistant devices to list the tasks they perform using the device, 84.9 percent reported they use it to set a timer, while only 3.5 percent reported using it to call a cab.

A recent study has shown that when it comes to the application of AI in a business context, 94 percent of business executives understand that AI is essential to business strategy, however a separate study by MIT Solan found that only 18 percent of companies are widely adopting and understanding AI. In designing an OSS AI solution that takes critical decisions affecting the performance of an entire network, we discovered that the success of the system depended on more than building more efficient and accurate models and algorithms. We came to the realization that trust is an essential factor in the human-AI interaction, and if we want the users of our AI solutions to accept handing over more critical tasks and decisions, we need to design them to be trustworthy.
What is trust?
The four components of trust in human relationships

Although the concept of trust in human-AI relationships is a new field, we don’t have to work from scratch.

Our approach at the Experience Design team in Ericsson was human-centric. Humans have been trusting other humans since the beginning of our existence, and once human-human trust relationships were established, we started to putting our trust in entities and organizations; religions, political parties, banks, schools, business and so on. Our approach was to draw on the formula of trust already functioning in these human-human and human-organization relationships, and use it as a base for building trust in human-AI interaction.

The four main factors that contribute to building trust in another person or entity are: competence, benevolence and openness, integrity and charisma. A good example to illustrate these four components in action, is the process of decision making when hiring an employee that will be responsible for a task in an office. When dealing with “digital” assistants in the form of AI systems, exactly the same framework of trust applies.

The following pages examine each of these components in turn, from the perspective of human-AI interaction, along with relevant examples of design-related decision and focus areas that can contribute towards creating a trustworthy AI experience.
The components of trust

Figure 2: The components of trust
Competence
Can you do the job?

In practice within an AI system, the trust component of "competence" essentially means the system is designed to demonstrate that it is capable of fulfilling the user’s needs and that it can deliver what it promises.
Adoption of AI-powered networks requires knowing they’re up to the task.

Here are some practical examples of how UX designers and practitioners can contribute to an AI system’s ability to demonstrate competence:

    Explainability
    Ensuring the system can communicate the reason behind its decisions and its confidence in different results and recommendations in a way that users can easily understand.
    Usefulness
    Making sure the system is employing AI capabilities to fulfil an actual need or solve a real problem for the users in an effective way.

Components of trust – competence

Figure 3: Components of trust – competence
Network performance diagnostics

Network performance diagnostics

    Trialability
    Giving the users the ability to try the AI system or test out its recommendations in a quick, safe and controllable way before they decide to use or approve it.
    Demonstration of results
    Being able to show evidence that using the AI system has resulted in an improved outcome.

Cognitive OSS prototype design demonstrating ”Explainability”

Figure 4: Cognitive OSS prototype design demonstrating ”Explainability”
Demonstration of results

Figure 5: Demonstration of results
Benevolence and openness
Are you on my side?

An AI demonstrating "benevolence" can be defined as a system designed to make decisions in the user's best interest, and to communicate the intentions behind decisions to the human user. It should also show flexibility, acceptance of change and new input – exactly as you would expect from a new human colleague.
Showing a system is open to influence from the user is a big building block of trust.


Some practical examples of how UX designers can contribute to the benevolence and openness of an AI system are:

    Controllability
    Providing an easy way for the user to intervene and change, undo, or dismiss an action or decision taken by the AI, as well as the ability to feed their own recommendations into the system.

Components of trust – benevolence and openness

Figure 6: Components of trust – benevolence and openness
Supervising network performance

Supervising network performance

    Adaptability
    Making the system flexible and dynamic enough to adapt to the user’s explicit or implicit preferences and feedback.

Controllability, enabling users to take a participatory role in the decision-making process

Figure 7: Controllability, enabling users to take a participatory role in the decision-making process
Adaptability, showing the user that their preferences have influence

Figure 8: Adaptability, showing the user that their preferences have influence
Integrity
Do you share my values?

The concept of integrity in an AI system comes down to whether the user feels that the system is honest, and whether it adheres to the same high ethical standards as the user.

There are two ways UX design in AI contributes to the impression of integrity in a system:

    Veracity of promises
    Setting the right expectations for the user by clearly communicating the capabilities and limitations of the AI system - knowing what it can promise to do and follow through on and what it cannot or is not designed to do.
    Transparency on safety, security and permissions
    Making sure the user understands what kind of data is collected, how it is collected, for what reason and how it will be used.

Components of trust – integrity

Figure 9: Components of trust – integrity
Setting the right expectations and showing the user the different possible outcomes of the AI’s recommendations

Figure 10: Setting the right expectations and showing the user the different possible outcomes of the AI’s recommendations
Charisma
Do I like you?

And finally – charisma. Charisma in an AI system comes down to crafting it in way that gives it general charm and appeal, and that the system looks and sounds appropriate to the task it is handling.

UX designers and practitioners can contribute to the attractiveness of an AI system by implementing:

    Visual appeal
    Crafting the system’s look and feel in an aesthetically pleasing and visually organised way, so that the human user perceives it to be more efficient and understandable.
    Tone-of-voice suitability
    Making sure that the style and tone of the copywriting and voice interactions are aligned with the message that you want to convey, the desired personality of the system, and the traits of the targeted user group.

Components of trust – charisma

Figure 11: Components of trust – charisma
Appropriate tone of voice for the scenario

Figure 12: Appropriate tone of voice for the scenario
Clear and organized visual layout contribute to increased perceived trustworthiness

Figure 13: Clear and organized visual layout contribute to increased perceived trustworthiness
Beyond the building blocks
Other factors that can affect trust in AI

All the elements that are mentioned so far in this framework are those that are represented in one way or another in the interaction and the interface of the AI system, and are therefore relevant to the UX design.

There are numerous other factors that can affect trust in an AI system, and although these additional factors cannot be translated into the interface as UX, they are nevertheless essential elements in the building of a trust-based relationship.

For example:

    Accuracy
    If the output results, predictions, recommendations and decisions of the system are not accurate to begin with, then the system will not meet the aforementioned criteria needed to satisfy the "competence" component.

    Bias in AI
    One widely discussed topic in the AI community is the concept of bias - specifically that ML selects incomplete, uninclusive or biased data sets to train the model, whether deliberately or otherwise. This will result in output that is not fair and biased towards a group of users - meaning that the core pillar of "integrity" will not be met.

    Laws and ethics
    Without sufficient and clear laws and a code of ethics that regulates the relationship between the user and the AI system, for example defining who is responsible if the output of the system affects the user in a negative way, then the trust in the human-AI relationship will not survive any potential mistakes the system makes.

AI-powered OSS
With the right design principles in place, AI-powered OSS could open up a more powerful future for network.
Conclusion
The future of human-tool relationships

When introducing AI-powered software like Ericsson's Cognitive Operation Support System (OSS) services, the notions of what a network is, what the owner or network operator’s role is and what a system provider contributes
are changing.

The interaction will be on a much higher and abstract level. Instead of changing gears in the car, the focus will be on the passenger's journey. Instead of having field technicians manually climbing towers to fine-tune the radio, business operators will collaborate with the AI machine to reach the organization’s business intent, impacting the roles of the system providers and the network operator.

A user-centric design process will be even more important when designing AI-powered services than in traditional services. If users and organizations are going to trust the AI-powered system, for example an airplane without a pilot, the trust must be designed into the system and the relationship from the very beginning. Without it, these services will fail.

Designing an OSS AI solution that takes critical decisions that can affect the performance of an entire network is about more than focusing on building better AI models and algorithms. Trust will be the most vital factor in human-AI interaction.
If we want the users of our AI solutions to accept handing over more critical tasks and decisions to AI, we need to design them to be trustworthy.
The essential human in the loop
Designing for trust is a cornerstone of building successful AI systems.
Authors
Mikael Eriksson Björling
Mikael Eriksson Björling

Mikael is Experience Design Line Manager at Ericsson Experience Design Lab and an Ericsson Evangelist. He was previously Director at the Networked Society Lab. His specialty is in understanding how new behavior, emerging technologies and new industry logics are shaping the future society and in the intersection of these areas design great user and customer experiences. Mikael believes that with the ongoing digital transformation we have a great opportunity to shape a better world. Mikael joined Ericsson in 1998.
Ahmed H. Ali
Ahmed H. Ali

Ahmed is visual and user experience designer at Ericsson Experience Design Lab. With over 15 years of experience, his career inside and outside Ericsson was focused on designing digital systems that satisfy users’ needs and help them achieve their goals by bringing design thinking to the product development process, applying human-computer interaction best practices, and delivering UI/UX concepts and insights. Ahmed joined Ericsson in 2018 and he holds an M.A. in visual design from the University of Hertfordshire in the UK.
References

    Minsky, M. (1982). Semantic information processing.
    Goertzel, B. (2007). Artificial general intelligence (Vol. 2). C. Pennachin (Ed.). New York: Springer.
    Gobble, M. M. (2019). The Road to Artificial General Intelligence.
    Noessel, C. (2017). Designing agentive technology: AI that works for people. Rosenfeld Media.
    Bathaee, Y. (2017). The artificial intelligence black box and the failure of intent and causation. Harv. JL & Tech., 31, 889.
    Andras, P., Esterle, L., Guckert, M., Han, T. A., Lewis, P. R., Milanovic, K., & Urquhart, N. (2018). Trusting intelligent machines: Deepening trust within socio - technical systems. IEEE Technology and Society Magazine, 37(4), 76-83.
    Muir, B. M. (1987). Trust between humans and machines, and the design of decision aids. International journal of man-machine studies, 27(5-6), 527-539.
    Siau, K., & Wang, W. (2018). Building trust in artificial intelligence, machine learning, and robotics. Cutter Business Technology Journal, 31(2), 47-53.
    Commerce is a conversation: Survey on Amazon Echo and Voice Assistants - Experian Insights, 2016.
    Intelligent Economies: AI’s transformation of industries and society -The Economist Intelligence Unit, and Microsoft, 2018.
    Ransbotham, S. et all. Artificial Intelligence In Business Gets Real - Pioneering Companies Aim for AI at Scale. MIT Solan, 2018.
    Stern, M. J., & Coleman, K. J. (2015). The multidimensionality of trust: Applications in collaborative natural resource management. Society & Natural Resources, 28(2), 117-132.
    Sanders, K., Schyns, B., Dietz, G., & Den Hartog, D. N. (2006). Measuring trust inside organisations. Personnel review.
    Schoorman, F. D., Mayer, R. C., & Davis, J. H. (2007). An integrative model of organizational trust: Past, present, and future.



### youtube_TPmtiglPnEY.txt

[Music]
hello everyone um my name is KL I'm s
founder of Lazer agency so what we do is
that we do user experience for AI
companies um the short info would be
that we helped our clients raised half
of a billion dollarss uh out into our
design work we also nominated as the
agency of the year last year and uh yeah
we won more than 100 different Design
Awards been doing this for almost 10
years and yeah excited to share you some
of the case studies and thoughts that we
have about the user experience in Ai and
how the future of the interfaces would
look like that you actually can build
right now so um the big biggest problem
in the AI space right now is that uh
yeah 90% of the Alli startups fail with
30% of them uh due to the lack of the
product Market fit and as the user
experience designers uh we believe that
that's one of the biggest problems out
there and it's one of the actually um
easiest things to fix um lots of the
companies you know uh were building the
rubers of the CH gbt and uh in one day
they all dead um the what they should
have been built in the right way is is
if they would do the proper user
resource there wouldn't be that stressed
about the all the you know open AI
openings uh even within the agency we
built like a six different AI startups
and three of them were essentially will
never be able to go to public because of
that um because the VCS and the market
push you to go to the you know to the
life and the demo stage as soon as you
can but the reality is that is that one
month spended the proper user research
can save you can save you months uh in a
development and essentially can help you
to go to achieve your goals instead of
just wasting the time which lots of
people think what the user experience
all about um another thing that I want
to put it out there is that uh in this
space uh even in the chat GPT uh which
got 100 million uh users a week right
now there is very low Traction in daily
uh in the daily usage of a products and
um I think that's the thing to consider
and that's why and and we mainly believe
that it's happening because of the lack
of the user experience and the
personalization and uh thinking of how
to build the product for the users
instead of how to build the product
itself um we believe that in order to
create a successful AI product you need
to differentiate respond to the actual
human needs and desires and but
interface that will stick with you and
that will stick with users that's the
most important part so yeah yeah cool
the crypto was cool well by the way the
crypto might be cool soon too right U if
you are following 30% growth in the last
month so uh let's wait um you know the
next wave of uh crypto I startups coming
next year um but yeah the the whole
thing is that we believe that you need
to be different and you need to
understand the users and to build the
products uh that built exactly for that
uh for that audience how you need to
find the niche uh you need to unlock the
actual user needs and then uh yeah you
need to consider accessibility and
usability especially into the multimodel
LMS that's coming right now you need to
think about the voice you need to think
about the images you need to put it on
top of your uh decision proess and if
you think about the actual use cases how
your audience going to use it not how
you think you going to build the product
itself um so yeah Define the market
Define the target audience and uh rece
seource the problem need and build the
product around
that um yeah do it as much as you can so
yeah um there is a little bit of process
uh that's a d diamond that everyone who
is in design SP seen here but uh we do
believe that research uh rules at all
and uh the more you know about the users
the better product stick and the better
reaction you have and you don't actually
need to be in AI space to do that um so
yeah the good design gives people what
they want and the great design solves
people problems uh in innovative ways uh
I feel that's the case so how to build
the interfaces for AI products out there
the first thing is
that everyone is trying to build the
product using the chat B right so we
have this crazy opening I think and
you're just like oh wow that's a new way
how to interact with the interfaces
that's the future but the reality is
that there is a big problem out there
uh there is a new word that appear right
the new T The Prompt engineering but in
order to be the prompt engineering you
need to be the the engineer you know
there is two parts The Prompt and the
engineer and very few of us are
Engineers out there uh I feel that In
This Crowd it's actually much more
Engineers that you know that's out there
uh in the world and therefore um you
need to design the interfaces that will
help the users to use them and uh this
help to solve this barrier of entering
uh what they actually looking for
because within the chat interface only
you put the user in position in a so
they would have to type and type and
type and type and type till they the end
result instead of just like helping them
to go through through way but how you
can do it well yeah uh the the first
phase of the presentation right you do
use a research to understand what they
actually need and then you tailor the
design uh for that um so we think that
the future is the hybrid yeah there is a
prom base and uh graphic interfaces so
this is one of the products that uh we
design that is in development right now
um the use case here is that we believe
that the interface should be the mix of
the text and the widgets that should be
built through the design system and
should automatically pop up when the
users request for the data that they
need for so for example uh here the user
is looking to set up the know the call
and set up the notification and then we
the llm can understand that intent right
and then based on the intent it can
create the diget for you and then you
can do some interactions in the diget
instead of typing okay can you resle the
reschedule this okay can you do X by
that and you know instead of doing 10 or
I know five or or 10 text prompts you
can do this two clicks um so we believe
that the static interfaces are de where
the designers were creating everything
for the users but the mod interfaces are
the future where you actually using the
text and a vets um out there here is
another one um it's called Pika uh this
product uh was begged by mazilla and
supposed to to go to um the search to to
replace the search all and what we were
doing there is that um you see this um
blue um you know like a popup uh in the
center so this is how we help the user
to navigate and how to chat uh with our
research and this is how we put the
user's attention in in the core of the
app following all other different uh
interfaces and elements of the
interfaces out there um here is some of
the other examples of that but I will
dive deep into this um in a
second so um once the user is starting
to use your chat based product you can
recognize the partners that they have
and and the reality is that the users
are usually using the your uh LMS in a
very particular use cases for themselves
so for example I always uh use improve
uh as the prompt uh because I'm not a
native speaker and I'm just like okay
here is my text can I just improve it
right and I
essentially 50% of the time that I you
charge P you just one prompt and I and
always typing this improved next and uh
this gave us an idea that why don't we
realize the pters of what others users
are doing and put it as the widgets and
put the use cases that the way the users
use the product as the widget so they
can one click it so instead of typing
the summarize ACT test find similar
improve compare wherever you you you sa
you can analyze that and you can put it
as the button in your chat interface and
it will save
uh hours and hours of um users
time so yeah the more you understand the
users you can go even further and you
can uh do it automatically or
semi-automatically if I'm using improve
every single time I can adapt the model
to automatic applies for every promp uh
that I do and how cool would that be
instead of just clicking it it could be
done automatically and I can just
disable it in my settings so the can
essentially analyze the patterns and
create the settings personalized for the
every single users that that they are uh
that they out there and this is how you
create hyper personalized product and
the users will stick to it and will
never go to any of your
competitors um in order to do that you
need to build a modular UI and um yeah
you need to think about the proper
design system so yeah in a design space
everyone's saying the design system is
the key for years but right now I think
that's even uh
more important because um there is
endless amount of the use cases out
there and there that's a beauty and the
scariness of the llms and uh because
there is endless amount of the use cases
the designers should only think in the
way of that is building Design Systems
and the components that then once you
realize the patterns you can build the
vit on top it pretty much right ahead
and it's very easy to track because you
can track all the requests in your AI
product right so once you see that some
of the case is popping up you just build
the visit on top of the design system
but you need to think in advance of
about the scalability and actual use
cases for it um here I here is some
other sorry let me Zoom it out so if you
would for example you could pull the
data from the predit and Twitter and
Facebook and Instagram and wherever and
put it in one nice chat and it could be
as the widget right here on on your
homepage or you can collect the data
about the videos and a post and you can
structure them in a nicely created UI
for the
user there are some other examples how
how I bu it for the source but the core
things here is that the more flexible
you are and the more consistent that
system is the easier for you to be to
scale yeah not going to stick here for
four years but essentially you can pull
there once we know that there is a
person information there is a different
type of the data sets and attributes
that collected to the person and this is
how we can add this tabs uh pretty much
and
listen um the good design is the little
design as possible so you need to think
about the functions um and uh based on
the functions you add the
functionalities not vice
versa um and the design is system that's
a key for it there's another product but
uh that we design but essentially once
the design system is set up you just go
for it
um all right another thing that we
thought as cool is that once you connect
your LM and your product to the uh
through the ipis to a different bunch of
the products so essentially this is what
the this is what we've been doing before
the open AI did it so right now I feel
kind of embarrassed that I'm selling it
out loud but the idea is that the more
Integrations you have in your product
the more your product uh would be useful
for the user therefore they they will
have more usage of it right uh as simple
as that and when you're building it you
need to think in advance and you need to
think what kind of ipis we can connect
uh to and what kind of wigets we can
pull within the context that we have um
and yeah getting back to that prom
engineering part right um I think that
would be this this would be the next
feature of open AI um but before they
did it I think that the co-pilot to help
users find write prompts is one of the
coolest thing out there because you can
help the user to navigate and you can
help the users to write their prompts
easily and you can tailor this to the
use case of the product that you have um
yeah communicate what your product can
and can do U explain how it makes
decisions and always display why AI is
doing important decisions one of the
biggest um threats uh out there from the
users this is was one of the research I
think were done by the Salesforce that
users are afraid where the information
is came from in thei they can trust it
and uh because of that we came up with a
very easy decisions well you just you
know do your thing you just uh show the
call outs where you actually pull the
information from and instead of having
like a 10 different links that you have
ask the your open AI to to create you
can just right ahead okay this is where
I pull the information from and this is
how you start to build the trust to your
AI product and once you build the breach
of the trust the users would love to use
it more another cool part is that um so
is the hot keys right um for this
particular product this one is uh
special specially made for the VCS to do
the market research so if you're in the
VC space you need to go and search for
the companies and competitors and
analyze the market to understand who is
doing what and why and you have the
analytics who are sitting out there um
yeah you can just add this cool little
hot keys that will help you to navigate
through it and essentially reduce the
amount uh of time that the users uh
going to look for certain functions in
your
product um yeah another cool thing that
we recognize is that there is a
different metrix and I think uh this
part works you know the different
lecture uh but essentially you can track
if your product is successful not by
finding the S wordss uh in the chat so
if the user is using extensive amount of
s wordss uh you might you know your AI
might doing something wrong and by this
small uh indicator you can um track
whether the product is going in the
right direction or wrong but another
cool thing is that um yeah uh you can
track response time and quality by
Leading from the user Behavior how many
times do they have to re ask the
question and how fast do the exit
conversation um once they get the answer
or not it's like one of the biggest
challenges out there for all the product
metrics is that if the user enter the
problem six time you are uh you know the
average time spending in the product is
higher but is it actually leading the
user for the success probably not so our
aim as the people who are building eii
product is to reduce the time and to
reduce amount of the requests that
they're creating therefore you need to
create a different metric to measure
your product
success okay so there is four
ingredients for ux fori uh research
research and uh research again um yeah
you need to go through all the classical
usability and uh eristics and also you
need to build the um hybrid interfaces
uh the hyper personalization the more
personalized experienc user would have
the cooler it would be for them and the
more they going to use the product and
all the interfaces starting uh today
right now I'm kidding uh would be
modular uh modular and self-build
interfaces um there is a small case
study that I want to walk you really
quick if you're not yet bored uh so this
is the product uh that I was showing you
before and the whole thing is that we
figure out then once the resarch or in
the VC is doing research on some n or
Market they always do it in a split
screen mode so they're picking
information from a different part of the
web and then they're kind of preparing
it as the separate uh document to to to
show to their senior level management
and once we realize that we're just like
wow why don't we build it as the poor
functionality of the product to be
different and to tell the product to the
user needs and this is the literate
example of how the resource can lead you
to the
um you ask that uh not that common but
tell her to your audience uh your
audience another part is that the if you
are doing the research and if you're a
researcher you would love to um track
the data you can and then convert it
into sheets and a spreadsheet so we
build this um cool tool is that once you
have any statistics you can build a
graph from it right ahead and you can
create a tables uh that are convenable
and exportable right
ahead um and yeah then we try to the
commends and one the users ended to
doing something we suggest them with a
lots of different uh functionalities
that put on top of it so I found this
information say I'm the research and I
found this information about this
company and then and I ended the the
conversation and then uh once I track
track this fet to the second part uh
yeah like I've showed you are here we
can ask you okay what do you want to do
with this you can send the sumary to
email you can download the sumary as the
PDF uh you can create the report from it
and you can track and send updates to
email so one of the functionalities that
that we put as the part of this
interface is that say you're at the VC
and you found this company you liked it
but you ah I'm not sure if they're going
to survive to the precedent series stage
I would love to follow up with them
later so but how do you check it well
now you can do it within the one click
you click the track and then it follows
the company updates on the LinkedIn it
sees if they hire senior level positions
uh from the biggest companies out there
so you it it adds more points uh to the
internal uh document and once you set up
this point system yeah you will be
notified if they're doing good or bad
and it's all done
automatically um and yeah and as I told
you pretty much everything can be
converted in a much easier way and it
helps users with a large amount of text
in their uh research another cool part
is that if you are the researcher uh you
can also apploud the different data sets
to this llm moreover you can set up the
data sets that you want to use during
your search and you don't want to use so
right now uh if you think about the
products you always fit them in a data
sets that you think are needed for the
user but what if the user can decide
what he actually needs to pull the data
from and this is one of the things that
we add there after the resource because
we found out that different people using
the product in a different way and they
need to different type of the data to
rely on and U you know another version
of this product is used by the hedge
funds and the banks to do the research
and predict how the price of the stocks
uh going to look like so they have their
own data that they want to up out uh so
for we created the whole interface of
the selecting of the data sets out
there I guess that's it it's time for
[Music]
Q&A yeah so we are a design agency and
this is how our clients work um so U
this is the company called acern ACC Ern
um yeah they've been in the space since
2015 and we've been helping them since
2015 they working on the AI product uh
is this this product is s for the VCS
but they have another one for the banks
and another one for the Hench funds and
there is a different use cases how you
can how you can use it yeah so I mean if
you are hedge funds or uh hedge fund or
bank or a VC that's the product for you
yeah it's paid yeah I'm not sure about
the pricing though I'm sorry
yeah that's the greatest challenge as
the agency I mean we show the direction
of the user of the clients who made the
research and and the statistics of the
clients who didn't I mean is the you
know at the end of the day we're an
agency and we would follow the
properties that the client would choose
but we always say okay guys here is the
uh product that we scale from the series
C to the series B and uh you know why
because we were doing research all the
time here is another use case is how we
did it but essentially we tell you that
uh you can you can save hours and hours
and hundreds of thousands of up millions
of dollars uh once you are uh building
the product and research can save you
that so resarch is just an Roi on on
your cash on your
[Music]
money I feel that the product should be
tailored to the audience that going to
be using the product and in this
particular case we know the use cases
for for these guys and we tailored their
you know the recommendation engine by
the sour of the markets for the VCS and
we spend a lot of time in doing in doing
that and I think that the more
personalized your product is the the
better it will work so I'm not sure if I
would I mean and maybe that's one of the
reasons why openi is not doing out the
suggestion because you can go as broad
as you can or as short as you can and
that's kind of you know one of the
purposes of the uh uh CH GPT um but for
the most of uh of of of us we are not
building the competitor the shadt we're
building the product for the very nich
use case for the very particular
audience that would use it in a very par
rate and the faster we find it out the
better we can build all the features and
all the little things around and I would
not I mean unless you building the
comparator of the charg PD I would not
go and think in in that Direction I was
just like okay how can we make the most
of these users and how how can we help
them well we generally say that um here
is the cost of the building the MVP and
uh you know here is the cost of the redo
in MVP and here is the price that
associated with that um usually I mean
that's very you can know the ballpark
depending on where your team base if
it's local team or if it's the team over
re You can predict the price of the of
that and on top of that you have the
budget the marketing budget spend to go
to the growth and T the users and you
can ask that client the client about it
right ahead so okay guys how much you
ready to spend to to to track it and
they would probably say well we need
like at least 100K to validate the ideas
to test it out and say well um that's
cool and then you need like a 300K to
500k to build the product out so we're
talking about the you know like a a
million dollars worth of the MVP and how
much are you ready to spend to make sure
that this MVP got all Ed to your user
and that's the moment of the
negotiations uh that's it because if you
would do redo it how big of a Runway you
have would you be able to do do it two
times probably yes right no one you know
nowadays no one raising less than a
million in B at least and but you will
not be able to do it do it three or four
times so that's how we talk to our
clients we say well that's this is what
what you got to invest but I think about
it
together I love the you know that you
can build the model uh you know the
charge model in a in a day so in an
agency we do talk to clients right and
we created our sales agent in a day
before we haded different you know
Outsourcing team who were building this
for us and we build it in a in a day and
we just essentially decided not to
continue this project uh with them so I
think that's one of the coolest thing
out there and yeah the vision is
something uh very interesting I've
talked to one of the researchers uh
through the with with the team of openi
and he said a lot of great things that
how they actually work on this and how
they change the way how the computer
Vision Works within the gbt vision they
essentially recreated it and from a
different perspective I think there is a
lot of opportunity out there
too
[Music]

### Untitled 13.txt


AI Product Management: Research, Requirements and Scope
Nadya Tsech
UX Planet

Nadya Tsech
·

Follow
Published in

UX Planet
·
11 min read
·
Jan 2, 2020

What is AI good at? What questions should you ask during the research phase? How should you prepare business requirements for the development team?

There are several ways companies become interested in AI:

    They talk to users, learn about problems, and gather requirements. And come to the conclusion that AI is the most suitable tool to solve the problem.
    Or they start research with questions such as “How can we use AI to our advantage?” or “How can this technology, everyone is talking about, help our users?”

In both cases, product managers need to answer baseline questions to define requirements.
Part 1. Problems and Opportunities
How Can AI Help Your Clients?

AI can solve a range of problems: optimising repetitive tasks, assisting with decisions and making decisions autonomously. If your users are facing some of the following problems, AI might be the right solution:
1. Is there time-consuming noncreative work that users do repetitively?
Organising scans using AI. Source: Transforming Healthcare With Machine Learning

Every time IDEXX radiologists see a new patient, they spend around 30 seconds rearranging and grouping scans. It’s not only a waste of time but also an irritating task that specialists have to perform many times per day.
2. Are there tasks that need double-checking because of errors?

As I write this post, I’m relying on Grammarly and it’s AI algorithms to assist me.
3. Do your users spend a significant amount of time manually labelling data or creating complex rules for it?

Ataccama’s clients have hundreds of data sources and millions of tables. Usually, the data is unlabeled and hard to find. Data stewards spend a considerable amount of time manually labelling data and writing labelling rules.
Ataccama Metadata Management & Data Catalog

Ataccama AI algorithms spot patterns in data, learn from the users’ actions and assist data stewards with labelling or automate it completely. It saves users from going through data sets one by one and doesn’t require writing rules.
4. Can assistance make users or the whole organisation more efficient?

In 2016, Moorfields Eye Hospital had 7K urgent referrals for people who were in danger of losing their sight. Patients had to wait up to 6 weeks before seeing a specialist because of the huge number of appointments. It turned out that only 800 of the 7K referrals were urgent.
DeepMind Health Research

DeepMind created an algorithm to assist ophthalmologists in analysing scans to diagnose urgent cases and reduce the number of deteriorations. Now it’s working at the level of world experts.
5. Are there extra tasks users have to complete to do their main work?

Data analysts spend up to 60% of their time searching and preparing data before they can start the actual analysis. It’s not only expensive for companies, but it’s also a boring task for analysts. AI can reduce these tasks using NLU and pattern recognition.
6. Does a user have to analyse the data and make decisions over and over again, many times per day?
Tractable AI Estimating

In insurance, AI is used to calculate the price of damage based on images of a car. Trained using a library of photographs from past accidents, AI estimates repair costs. AI minimises the waiting time for payment and reduces work for insurance inspectors.
7. Do clients have rule-based systems?

AI would be overkill for simple rules, but if your users are creating complex rules with dozens of conditions that are changing over time, they would benefit from self-learning algorithms. Examples: Spam detection, segmentation, search, recommendations.
8. Are there systems they have to monitor and check regularly?

Machine learning is good at spotting patterns and anomalies in these patterns. If your users’ job is to make sure everything works (security, fraud, cyber-attacks, system failures, medical results), anomaly detection might help them spot anomalies faster and even find ones not visible to human eyes.
9. Do they have to customise work for their clients?

Customer support, marketing campaigns, chat-bots, reservation systems can be automated if there is enough information about customers and their past interactions with a service.
Source: Blog.edrone.me

Zalando’s marketing content is generated by algorithms. They use information about past purchases and wish-lists of their customers to personalize marketing materials.
10. Is there a middleman between your system and end-users?

It’s the reality in a lot of large organisations. For example, to make business decisions, managers and strategists require access to data. Often they have to request data from their more tech-savvy colleagues in the IT department. It might take weeks or months until the data is available.
Ataccama Metadata Search

Allowing less-technical people to interact with the product in the natural language might change their work experience.
11. Are there problems and tasks that change over time?

Dynamic prices, navigation, logistics, supply chains and stocking are examples of problems that change over time. One of Ataccama’s clients is a large hospital group. They use data to predict how many ambulances they need at any given time and in a given location based on the time of day, week and year, weather, events, air pollution, traffic, and many other changing factors.
12. Is there information that might change your users’ business that is unavailable now?

Danny Lange (ex. Head of Machine Learning at Uber) recommends using the thought process “If we only knew ____” to uncover unexpected business possibilities. “If only we knew how many ambulances we need at any given time”, “If only we knew when to turn on the TV to see the most important moment of the game”.

Example from an Australian cricket broadcaster. Cricket matches can take as long as 5 days. To win, a teams has to take 20 wickets. About half a minute of meaningful moments out of 30 hours. If only fans knew when something interesting was going to happen and could be notified. Foxtel trained their AI algorithm, Monty, on historic videos of cricket and taught it to predict the chance of a wicket. Monty calls users to watch the wicket fall.
Monty’s Wicket Warnings
Is AI the Right Tool for the Problem?

Check-list to spot red flags in the beginning:

1. Do you have access to data? Can you acquire the data you need? Are users willing to share the data? What data are they willing to provide?

2. Do you have permission to use the data? Are there regulations you should contend with?

3. Can you ensure the users’ data is secure?

4. Can you ensure the data is trustworthy and up to date?

5. Is it worth it? Gathering data, keeping it in shape, building a model, and testing and iterating are both time and money consuming. Do you have a team? What is the trade-off? Maybe you need to update the model every day and it’s too expansive.

6. Can you solve the problems with simple rules and logic?
Part 2. Research

Once the problem is defined, it’s time for the research phase. The goal is to gather requirements and learn about constraints.

Answering the following questions will shape the scope and design:
1. Who are the users?

What is their expertise? Are they tech-savvy? What value are they expecting to derive from this product? How familiar are they with AI-based products?
2. Understand user attitudes towards data use

Are users willing to share the data? What data are they willing to provide and what data won’t they provide? Are there company- or industry-wide policies and regulations? What is considered ethical/unethical?
3. Identify the context in which users will use the product

Which environment does the problem occur in? What are they doing before and after? What type of tools do they use? Who do they interact with? What other needs or problems can occur at the same time and in the same environment?
4. What are other tools in their workflow?

If your product is part of a workflow, other tools may affect user habits and expectations. Are they using AI in their work? What type of AI? How are they used to interacting with other AI-based systems. Are there complementing tools you should take into consideration?
5. Who are the competitors?

Are they direct competitors? Would it be possible for your client to switch from one tool to another? How much money and effort would it cost?
6. What are the industry trends?

In the B2B and enterprise world, trends and analytics reports from research and advisory companies have considerable impact. What sources of information do they trust? Are they partnering with any of the advisory companies?
7. What part of the work are users proud of or would be reluctant to automate?

Automation of work can be a sensitive topic. How do we address users’ fears and explain the benefits of AI? Some work is tied to KPIs and bonuses. Your tool might automate or replace this work. How can you help clients to adapt not only to a new tool, but also to the new culture around it?
8. What level of automation should you aim for?

Should you aim for an autonomous system or collaboration between AI and a human? Some task users would outsource to AI, but there are activities people prefer to do to themselves. What are these tasks?

How much time and money would full automation save your clients? Is it worth it? What are the disadvantages of full automation?

📝 More about automation “Human in Control or Automate Everything?”
9. What level of accuracy is required?

How much would the error cost? In terms of money, time, reputation, health, delight, and experience. Are errors acceptable? What are the consequences of false-positive / negative results for the task? Would your clients rather have some errors in the prediction than manually solve tasks? The more accurate the results, the fewer predictions AI makes.
Altoros

In the case where AI was used to calculate the price of damage based on images of a car, what percentage of the time could AI make the wrong estimations but still be profitable? How much would it cost if the AI needed the assistance of people every time it’s unsure?
10. How detailed do the results of interpretability/explainability need to be?

Is full interpretability required by law or policies? For instance, in banking, when a mortgage application is declined a client may request the exact reason.

There are many experiments using AI in radiology. To assist doctors, AI needs to provide all the data and explain the logic behind the prediction.

On the other hand, when Zillow estimates the market value for a property, it doesn’t provide all the data points or explain the algorithms they use. For the user, the explanation is short “We calculate the estimated range based on the current market and the info we have about this house”.
Zillow Zestimate

What information do your clients need to trust the prediction or make a decision based on AI suggestion?

📝 More about explainability “Explaining system intelligence Empower your users, but don’t overwhelm them”
11. How can you ensure the data flow?

The amount of training data is one of the most important components for building a precise system. When working on an AI solution, getting the initial training data and supporting continuous data flow is the product team’s job.

Research whether or not you can enrich your data with public data sets and get new insights. Do your clients have additional data you can use for their benefit?
12. How often should results be updated?

Can the prediction be calculated in advance or should it be updated every time the new information arrives (clicks, likes, photos, scans)? This question is important for technical requirements.
13. Pay attention to users’ communication style

How much jargon is appropriate, how much explanation do they need? Would your users rather have an assistant with a personality or would they trust numbers and percentages more? What terms are considered industry standard and what needs additional explanation? What words are used by experienced people and beginners?
Part 3. Business Requirements Check-list

The design of user flows and the interface depends on business requirements, scope, and a use case that a product management has prioritized. Both design and development teams need the following information to start working on a problem:

✓ Who will be using your product/feature?

✓ What problems do we want to solve?

✓ What type of impact are we aiming for (user satisfaction, reduce cost, minimise time, maximise safety)?

✓ What are the assumptions and hypotheses we want to test?

✓ What are the priorities?

✓ Use cases that are out of scope for this product/feature. Some use cases might be expensive to solve and would have a low impact on clients.

✓ Metrics (money, clicks, conversion rates, manual engagement rate).

✓ Data obtaining strategy and DQ metrics.

✓ User onboarding.

✓ Roadmap. What should the alpha-version look like? How will the feature evolve?

✓ How will the product be tested (monitoring system performance, adoption to change in data or user behaviour, data, model, usability)?

✓ How should we gather and work with user feedback?

✓ Known constraints (legal, data, trust)?

✓ What are the potential risks (biases in data, lack of data or trust, risks for reputation)?

✓ How do we ensure security and safety (from bad data, manipulation, theft)?

📝 More about business requirements for AI features Recommendation Product Driven Machine Learning (and NYC Parking Tickets)
Part 4. Interface Design

When requirements are defined, the design team can start working on the interface. Read about visualisation and prototyping in the next post.

https://medium.com/@nadyatsech/the-design-of-ai-based-products-13-things-to-consider-297ce9c0f0ba
Takeaways

I‘d say the number one thing product managers need to do is to align on the problem and important metrics for users. Changing the problem definition and the scope in ML development is much harder and may cause a lot of trouble. On the other hand, we can be less focused on details because the iterative nature of ML development supports changes and improvements.
Sources
📝 Articles

    Building AI-first products
    Product Driven Machine Learning. How business goals shape the AI building process.
    Machine Learning for Product Managers
    3 Common Problems With Your Machine Learning Product and How to Fix Them
    The Step-By-Step PM Guide to Building Machine Learning Based Products
    How To Create A Successful Artificial Intelligence Strategy

▶ ️Videos

    How to Be a Good Machine Learning PM by Google Product Manager. What problems AI solves, solution examples, processes for managing AI projects.
    What Is Machine Learning for Product Managers Like by Google PM? Basics of AI for PMs

### Untitled 4.txt

Human-Centered Machine Learning
Jess Holbrook
Google Design

Jess Holbrook
·

Follow
Published in

Google Design
·
13 min read
·
Jul 9, 2017

7 steps to stay focused on the user when designing with ML

By Josh Lovejoy and Jess Holbrook

Machine learning (ML) is the science of helping computers discover patterns and relationships in data instead of being manually programmed. It’s a powerful tool for creating personalized and dynamic experiences, and it’s already driving everything from Netflix recommendations to autonomous cars. But as more and more experiences are built with ML, it’s clear that UXers still have a lot to learn about how to make users feel in control of the technology, and not the other way round.

As was the case with the mobile revolution, and the web before that, ML will cause us to rethink, restructure, displace, and consider new possibilities for virtually every experience we build. In the Google UX community, we’ve started an effort called “human-centered machine learning” (HCML) to help focus and guide that conversation. Using this lens, we look across products to see how ML can stay grounded in human needs while solving them in unique ways only possible through ML. Our team at Google works with UXers across the company to bring them up to speed on core ML concepts, understand how to integrate ML into the UX utility belt, and ensure ML and AI are built in inclusive ways.

If you’ve just started working with ML, you may be feeling a little overwhelmed by the complexity of the space and the sheer breadth of opportunity for innovation. Slow down, give yourself time to get acclimated, and don’t panic. You don’t need to reinvent yourself in order to be valuable to your team.

We’ve developed seven points to help designers navigate the new terrain of designing ML-driven products. Born out of our work with UX and AI teams at Google (and a healthy dose of trial and error), these points will help you put the user first, iterate quickly, and understand the unique opportunities ML creates.

Let’s get started.
1. Don’t expect Machine learning to figure out what problems to solve

Machine learning and artificial intelligence have a lot of hype around them right now. Many companies and product teams are jumping right into product strategies that start with ML as a solution and skip over focusing on a meaningful problem to solve.

That’s fine for pure exploration or seeing what a technology can do, and often inspires new product thinking. However, if you aren’t aligned with a human need, you’re just going to build a very powerful system to address a very small — or perhaps nonexistent — problem.

So our first point is that you still need to do all that hard work you’ve always done to find human needs. This is all the ethnography, contextual inquiries, interviews, deep hanging out, surveys, reading customer support tickets, logs analysis, and getting proximate to people to figure out if you’re solving a problem or addressing an unstated need people have. Machine learning won’t figure out what problems to solve. We still need to define that. As UXers, we already have the tools to guide our teams, regardless of the dominant technology paradigm.
2. Ask yourself if ML will address the problem in a unique way

Once you’ve identified the need or needs you want to address, you’ll want to assess whether ML can solve these needs in unique ways. There are plenty of legitimate problems that don’t require ML solutions.

A challenge at this point in product development is determining which experiences require ML, which are meaningfully enhanced by ML, and which do not benefit from ML or are even degraded by it. Plenty of products can feel “smart” or “personal” without ML. Don’t get pulled into thinking those are only possible with ML.
Gmail looks for phrases including words like “attachment” and “attached” to pop a reminder when you may have forgotten an attachment. Heuristics work great here. An ML system would most likely catch more potential mistakes but would be far more costly to build.

We’ve created a set of exercises to help teams understand the value of ML to their use cases. These exercises do so by digging into the details of what mental models and expectations people might bring when interacting with an ML system as well as what data would be needed for that system.

Here are three example exercises we have teams walk through and answer about the use cases they are trying to address with ML:

    Describe the way a theoretical human “expert” might perform the task today.

    If your human expert were to perform this task, how would you respond to them so they improved for the next time? Do this for all four phases of the confusion matrix.

    If a human were to perform this task, what assumptions would the user want them to make?

Spending just a few minutes answering each of these questions reveals the automatic assumptions people will bring to an ML-powered product. They are equally good as prompts for a product team discussion or as stimuli in user research. We’ll also touch on these a bit later when we get into the process of defining labels and training models.

After these exercises and some additional sketching and storyboarding of specific products and features, we then plot out all of the team’s product ideas in a handy 2x2:
Plot ideas in this 2x2. Have the team vote on which ideas would have the biggest user impact and which would be most enhanced by an ML solution.

This allows us to separate impactful ideas from less impactful ones as well as see which ideas depend on ML vs. those that don’t or might only benefit slightly from it. You should already be partnering with Engineering in these conversations, but if you aren’t, this is a great time to pull them in to weigh-in on the ML realities of these ideas. Whatever has the greatest user impact and is uniquely enabled by ML (in the top right corner of the above matrix) is what you’ll want to focus on first.
3. Fake it with personal examples and wizards

A big challenge with ML systems is prototyping. If the whole value of your product is that it uses unique user data to tailor an experience to her, you can’t just prototype that up real quick and have it feel anywhere near authentic. Also, if you wait to have a fully built ML system in place to test the design, it will likely be too late to change it in any meaningful way after testing. However, there are two user research approaches that can help: using personal examples from participants and Wizard of Oz studies.

When doing user research with early mockups, have participants bring in some of their own data — e.g. personal photos, their own contact lists, music or movie recommendations they’ve received — to the sessions. Remember, you’ll need to make sure you fully inform participants about how this data will be used during testing and when it will be deleted. This can even be a kind of fun “homework” for participants before the session (people like to talk about their favorite movies after all).

With these examples, you can then simulate right and wrong responses from the system. For example, you can simulate the system returning the wrong movie recommendation to the user to see how she reacts and what assumptions she makes about why the system returned that result. This helps you assess the cost and benefits of these possibilities with much more validity than using dummy examples or conceptual descriptions.

The second approach that works quite well for testing not-yet-built ML products is conducting Wizard of Oz studies. All the rage at one time, Wizard of Oz studies fell from prominence as a user research method over the past 20 years or so. Well, they’re back.
Chat interfaces are one of the easiest experiences to test with a Wizard of Oz approach. Simply have a team mate ready on the other side of the chat to enter “answers” from the “AI.” (image from: https://research.googleblog.com/2017/04/federated-learning-collaborative.html)

Quick reminder: Wizard of Oz studies have participants interact with what they believe to be an autonomous system, but which is actually being controlled by a human (usually a teammate).

Having a teammate imitate an ML system’s actions like chat responses, suggesting people the participant should call, or movies suggestions can simulate interacting with an “intelligent” system. These interactions are essential to guiding the design because when participants can earnestly engage with what they perceive to be an AI, they will naturally tend to form a mental model of the system and adjust their behavior according to those models. Observing their adaptations and second-order interactions with the system are hugely valuable to informing its design.
4. Weigh the costs of false positives and false negatives

Your ML system will make mistakes. It’s important to understand what these errors look like and how they might affect the user’s experience of the product. In one of the questions in point 2 we mentioned something called the confusion matrix. This is a key concept in ML and describes what it looks like when an ML system gets it right and gets it wrong.
The four states of a confusion matrix and what they likely mean for your users.

While all errors are equal to an ML system, not all errors are equal to all people. For example, if we had a “is this a human or a troll?” classifier, then accidentally classifying a human as a troll is just an error to the system. It has no notion of insulting a user or the cultural context surrounding the classifications it is making. It doesn’t understand that people using the system may be much more offended being accidentally labeled a troll compared to trolls accidentally being labeled as people. But maybe that’s our people-centric bias coming out. :)

In ML terms, you’ll need to make conscious trade-offs between the precision and recall of the system. That is, you need to decide if it is more important to include all of the right answers even if it means letting in more wrong ones (optimizing for recall), or minimizing the number of wrong answers at the cost of leaving out some of the right ones (optimizing for precision). For example, if you are searching Google Photos for “playground”, you might see results like this:

These results include a few scenes of children playing, but not on a playground. In this case, recall is taking priority over precision. It is more important to get all of the playground photos and include a few that are similar but not exactly right than it is to only include playground photos and potentially exclude the photo you were looking for.
5. Plan for co-learning and adaptation

The most valuable ML systems evolve over time in tandem with users’ mental models. When people interact with these systems, they’re influencing and adjusting the kinds of outputs they’ll see in the future. Those adjustments in turn will change how users interact with the system, which will change the models… and so on, in a feedback loop. This can result in “conspiracy theories” where people form incorrect or incomplete mental models of a system and run into problems trying to manipulate the outputs according to these imaginary rules. You want to guide users with clear mental models that encourage them to give feedback that is mutually beneficial to them and the model.
An example of the virtuous cycle is how Gboard continuously evolves to predict the user’s next word. The more someone uses the system’s recommendations, the better those recommendations get. Image from https://research.googleblog.com/2017/05/the-machine-intelligence-behind-gboard.html

While ML systems are trained on existing data sets, they will adapt with new inputs in ways we often can’t predict before they happen. So we need to adapt our user research and feedback strategies accordingly. This means planning ahead in the product cycle for longitudinal, high-touch, as well as broad-reach research together. You’ll need to plan enough time to evaluate the performance of ML systems through quantitative measures of accuracy and errors as users and use cases increase, as well as sit with people while they use these systems to understand how mental models evolve with every success and failure.

Additionally, as UXers we need to think about how we can get in situ feedback from users over the entire product lifecycle to improve the ML systems. Designing interaction patterns that make giving feedback easy as well as showing the benefits of that feedback quickly, will start to differentiate good ML systems from great ones.
The Google app asks every once in awhile if a particular card is useful right now to get feedback on its suggestions.
People can give feedback on Google Search Autocomplete including why predictions may be inappropriate.
6. Teach your algorithm using the right labels

As UXers, we’ve grown accustomed to wireframes, mockups, prototypes, and redlines being our hallmark deliverables. Well, curveball: when it comes to ML-augmented UX, there’s only so much we can specify. That’s where “labels” come in.

Labels are an essential aspect of machine learning. There are people whose job is to look at tons of content and label it, answering questions like “is there a cat in this photo?” And once enough photos have been labeled as “cat” or “not cat”, you’ve got a data set you can use to train a model to be able to recognize cats. Or more accurately, to be able to predict with some confidence level whether or not there’s a cat in a photo it’s never seen before. Simple, right?
Can you pass this quiz?

The challenge comes when you venture into territory where the goal of your model is to predict something that might feel subjective to your users, like whether or not they’ll find an article interesting or a suggested email reply meaningful. But models take a long time to train, and getting a data set fully labeled can be prohibitively expensive, not to mention that getting your labels wrong can have a huge impact on your product’s viability.

So here’s how to proceed: Start by making reasonable assumptions and discussing those assumptions with a diverse array of collaborators. These assumptions should generally take the form of “for ________ users in ________ situations, we assume they’ll prefer ________ and not ________.” Then get these assumptions into the hackiest prototype possible as quickly as possible in order to start gathering feedback and iterating.

Find experts who can be the best possible teachers for your machine learner — people with domain expertise relevant to whatever predictions you’re trying to make. We recommend that you actually hire a handful of them, or as a fallback, transform someone on your team into the role. We call these folks “Content Specialists” on our team.

By this point, you’ll have identified which assumptions are feeling “truthier” than others. But before you go big and start investing in large-scale data collection and labeling, you’ll want to perform a critical second round of validation using examples that have been curated from real user data by Content Specialists. Your users should be testing out a high-fidelity prototype and perceive that they’re interacting with a legit AI (per point #3 above).

With validation in-hand, have your Content Specialists create a broad portfolio of hand-crafted examples of what you want your AI to produce. These examples give you a roadmap for data collection, a strong set of labels to start training models, and a framework for designing large scale labeling protocols.
7. Extend your UX family, ML is a creative process

Think about the worst micro-management “feedback” you’ve ever received as a UXer. Can you picture the person leaning over your shoulder and nit-picking your every move? OK, now keep that image in your mind… and make absolutely certain that you don’t come across like that to your engineers.

There are so many potential ways to approach any ML challenge, so as a UXer, getting too prescriptive too quickly may result in unintentionally anchoring — and thereby diminishing the creativity of — your engineering counterparts. Trust them to use their intuition and encourage them to experiment, even if they might be hesitant to test with users before a full evaluation framework is in place.

Machine learning is a much more creative and expressive engineering process than we’re generally accustomed to. Training a model can be slow-going, and the tools for visualization aren’t great yet, so engineers end up needing to use their imaginations frequently when tuning an algorithm (there’s even a methodology called “Active Learning” where they manually “tune” the model after every iteration). Your job is to help them make great user-centered choices all along the way.
Work together with Engineering, Product, etc. to piece together the right experience.

So inspire them with examples — decks, personal stories, vision videos, prototypes, clips from user research, the works — of what an amazing experience could look and feel like, build up their fluency in user research goals and findings, and gently introduce them to our wonderful world of UX crits, workshops, and design sprints to help manifest a deeper understanding of your product principles and experience goals. The earlier they get comfortable with iteration, the better it will be for the robustness of your ML pipeline, and for your ability to effectively influence the product.
Conclusion

These are the seven points we emphasize with teams in Google. We hope they are useful to you as you think through your own ML-powered product questions. As ML starts to power more and more products and experiences, let’s step up to our responsibility to stay human-centered, find the unique value for people, and make every experience great.
Authors

Josh Lovejoy is a UX Designer in the Research and Machine Intelligence group at Google. He works at the intersection of Interaction Design, Machine Learning, and unconscious bias awareness, leading design and strategy for Google’s ML Fairness efforts.

Jess Holbrook is a UX Manager and UX Researcher in the Research and Machine Intelligence group at Google. He and his team work on multiple products powered by AI and machine learning that take a human-centered approach to these technologies.

Akiko Okazaki did the beautiful illustrations.


### Untitled 5.txt

AI Design Principles: UX Guide
Refire Design

Refire Design
·

Follow
6 min read
·
Oct 23, 2023

Photo by Choong Deng Xiang on Unsplash

The growing field of Artificial Intelligence (AI) has opened up many opportunities to improve user interactions in digital environments. While chatbots are often seen as the face of AI-driven design, the role of AI in user experience (UX) design goes much further. It includes a variety of applications that can enhance user engagement and simplify complex processes.
Understanding the Audience

Getting to the heart of user-centric AI design requires a deep understanding of the audience for whom the AI products are being created. Successful AI design largely depends on aligning the AI’s functionality with the users’ expectations, needs, and preferences. Here’s a closer look at understanding the audience in the context of AI products:
1. Identify User Needs and Preferences

Comprehensive user research is fundamental to identifying user needs and preferences. Employ methods like surveys, interviews, and usability testing to gather insights into user behavior, pain points, and desires. For example, when designing an AI-powered educational platform, understanding the learning preferences, the challenges of traditional learning environments, and the goals of your target audience is crucial. This foundational understanding will guide the design process, ensuring the AI functionalities effectively address the users’ needs.
2. User Personas and Journey Mapping

Creating detailed user personas and journey maps is key to visualizing the user’s interaction with the AI product. User personas summarize the characteristics, goals, and behavior of different user segments. Journey maps provide a visual narrative of the users’ interactions with the AI product, identifying touchpoints, pain points, and opportunities for AI to enhance the experience. For instance, in designing an AI-driven healthcare app, journey mapping can reveal touchpoints where AI can streamline appointment scheduling, offer personalized health advice, or automate medication reminders, thus enhancing the overall user experience.
3. Empathy and Ethical Considerations

Embracing empathy and ethical considerations is vital in understanding the audience for AI products. Given AI’s pervasive nature, being mindful of potential biases, privacy concerns, and ethical implications is critical. Ethical design practices should ensure the AI product respects user privacy, provides value, and promotes inclusivity. For instance, when designing an AI-driven financial advisory app, ensuring the AI does not perpetuate existing biases and provides accurate, unbiased financial advice to a diverse user base is crucial.
4. Contextual Understanding

Understanding the context in which the AI product will be used is essential for designing interfaces and interactions that feel natural and intuitive. Understand the environment, the devices, and the circumstances under which users will interact with the AI product. For example, an AI-driven fitness app used in a gym setting might need to consider offline functionality, integration with gym equipment, and a user interface that is easily accessible during physical activity.

In AI-driven product design, grounding every design decision in a deep understanding of the audience lays the foundation for creating AI interfaces and interactions that are meaningful, intuitive, and highly user-centric.
UX Nuances in AI Design

The realm of AI design is nuanced, requiring a solid grasp of user experience (UX) principles to ensure AI integration enhances rather than hinders user interactions. Here’s a closer look at the UX nuances inherent in AI design:
1. Predictive User Experiences

AI excels at analyzing data to predict future user actions. Designing predictive user experiences involves creating interfaces that anticipate user needs and proactively provide solutions. For example, a weather app might analyze past interactions to predict which weather information a user wants to see first, such as the likelihood of rain if they often check that statistic.

Use machine learning algorithms to analyze historical user data and predict future actions. Conduct user testing to validate the accuracy and usefulness of predictions.
2. Transparency and Trust

Trust is crucial in AI-driven design. Users should know when they are interacting with AI and understand how their data is being used. For instance, if a health app provides personalized workout recommendations, it should clearly communicate how it’s using the user’s health data to make these recommendations.

Employ clear labeling, make privacy policies accessible, and use user-friendly language to explain AI functionalities.
3. Error Handling

Since AI can make mistakes, effective error handling in AI design is about creating intuitive pathways for users to correct or override AI decisions. For instance, if a language translation app provides an incorrect translation, it should allow users to easily correct the translation and learn from that correction.

Provide clear feedback, offer easy-to-access corrective actions, and use user input to improve AI accuracy over time.
4. User Control

Striking a balance between AI automation and user control is essential. Users should feel in control of the interactions, with AI acting as an aid, not a substitute. For instance, an email categorization tool should allow users to easily override the AI’s categorization decisions and categorize emails manually if they wish.

Offer settings or preferences for users to tailor the AI’s behavior, and provide clear options for users to override AI decisions.
5. Accessibility

It’s crucial that AI-driven designs are accessible to all users, including those with disabilities. For example, voice-activated AI should have alternative interaction methods for users unable to speak commands.

Follow accessibility best practices like the Web Content Accessibility Guidelines (WCAG), ensuring AI-driven features are accessible through multiple modalities.
6. Ethical Considerations

Ethical considerations in AI UX design include respecting user privacy, combating bias, and ensuring inclusivity. For instance, ensuring a facial recognition system can accurately recognize faces of all skin tones is a fundamental ethical consideration in AI design.

Use diverse training data, conduct thorough bias testing, and engage in ethical review processes to uphold ethical standards in the AI product.
7. Feedback Loops

Establishing feedback loops for users to provide input helps the AI learn and improve. For example, a recommendation engine should allow users to provide feedback on the relevance of recommendations, which the AI can use to refine its future recommendations.

Implement feedback mechanisms like thumbs up/thumbs down or rating systems, and use this feedback to continuously refine the AI algorithms.
8. Education and Onboarding

Educating users on interacting with AI-driven features and what to expect from the AI is key to a positive user experience. For instance, a clear onboarding tutorial can help users understand how to interact with an AI-driven virtual assistant.
Use onboarding tutorials, tooltips, and help centers to educate users about the AI functionalities and best practices for interaction.

By exploring these UX nuances, designers can navigate the complex landscape of AI design to craft user-centric AI-driven experiences that are intuitive, engaging, and trust-inspiring. Achieving excellence in AI design hinges on paying meticulous attention to these nuances, ensuring AI acts as a powerful ally in enhancing user satisfaction and achieving the desired outcomes.
Wrapping Up

Exploring AI-driven design goes beyond just creating conversational chatbots. It’s about blending AI with a user-centric approach, where AI enhances the user experience instead of replacing human interaction. Paying close attention to understanding the audience, refining the UX nuances, and incorporating design elements that align with AI functionalities helps in crafting digital experiences that are intuitive, engaging, and highly user-centric.

Merging AI with thoughtful design leads to digital products that are not just smart but also intuitive, engaging, and firmly user-centric. This results in a range of AI-driven experiences that meet the varied needs and expectations of users, taking satisfaction and engagement to new levels. It envisions a scenario where AI serves as a strong ally in boosting user satisfaction and achieving the desired outcomes.

At Refire Design, we’re at the forefront of navigating the complex landscape of AI design. Our experienced team of designers and developers excel at creating user interfaces that encapsulate the robust capabilities of AI while ensuring a smooth, enjoyable user experience. We advocate a user-first approach, where every design decision stems from a deep understanding of the user’s needs, preferences, and interactions with AI-driven features.

Whether you’re looking to create intuitive AI-driven apps, engaging conversational interfaces, or robust AI-powered platforms, Refire Design is ready to turn your vision into reality. Our expertise in UX/UI design for AI products, along with a keen understanding of the latest trends in AI and machine learning, makes us a top choice for businesses aiming to create impactful, user-centric AI-driven digital products.

Start your AI design journey with Refire Design as your reliable partner, and experience a well-managed design process that ensures your AI product not only meets the functional needs but also delights users with a seamless and enriching user experience. We are committed to delivering AI design solutions that deeply resonate with your target audience, driving user satisfaction and taking your business success to new heights.



### Untitled 12.txt

The Design of AI-Based Products: 13 Things to Consider
Nadya Tsech
UX Planet

Nadya Tsech
·

Follow
Published in

UX Planet
·
8 min read
·
Jan 2, 2020

Once the problem has been researched and defined, a design team can start working on testable prototypes. There are 13 things that need special consideration.

    You can find information about the research of AI-based products in the first post.

AI Product Management: Research, Requirements and Scope
What is AI good at? What questions should you ask during the research phase? How should you prepare business…

medium.com
1. Designing for Data Acquisition

Collecting training data could be the first design task before you even start building a model. If there are no available sources of data, we need to create a data flow ourselves. Balancing the collection of data and providing the value for users without an AI.

As Andrew Ng mentions in his ML course, The Virtuous Cycle of AI, Better product > attracts more users > they generate more data > and data improves the product.
The Virtuous Cycle of AI. Image

It’s hard to build a recommendation service without views, ratings, stars, reviews or clicks. But it’s possible to collect this information by using polls, gamification or asking users to provide their reviews and stars in exchange for solving their problem.

If your model relies on a specific data format, you need to consider input restrictions, data firewalls and validation.
2. Onboarding

Not every AI feature needs tutorials, but considering the nature of AI, we need to explain to the user how the system works, how the data is collected, set expectations and ask for permissions to collect data.

✓ Ask for permissions to collect data and explain how it will be used. Let the user/company set up the data they want to provide. Explain which data is crucial for the algorithm and how it will affect the work of the tool if the user won’t provide it.

✓ Set up user expectations:

    Explain what the system can do and the benefits for the specific user type.
    Explain what the system can’t do.
    How will it do it?
    What is needed from the user?
    What will happen if the system fails?

✓ If the model becomes smarter over time using the product, explain how it will evolve and how a user can level up the system.

✓ Can it be personalised and set up? Show the user how they can manage collaboration with AI.
Apple iPhone Siri settings

✓ Does the product need training before the company can leverage its potential? Create a flow for trainers/annotations.
Ataccama ONE Master Data Management solution. Users are asked to train the system on a sample of data (20 out of several million). This training is available to users with special qualifications and special permissions.
3. Activation

Design the activation/deactivation process. Is it a button, a word, or a gesture? Should it be on by default or is it an expensive operation that needs user authorization to start? How does the user know it is activated?
Voice activation of Google Assistant
Casetext lets the user switch off/on an AI algorithm for detecting issues in legal documents.
4. Visualisation and Placement

Is it important for a user to differentiate AI content? Would it affect the way they work or make a decision? We should let users decide how they will use algorithm-generated content.

✓ In a special sidebar, tab or a dashboard.
IBM Cognos Analytics AI Assistant in a special sidebar
Google Analytics Insight in a dashboard
Salesforce Einstein AI insights and recommendations in a dashboard
Entelo provides a special sidebar with recommendations.

✓ Put AI suggestions in context.
Luminance shows recommendations right in the text.
Entelo. When analysing a candidate’s CV, Paysa shows the predicted salary range next to the job position.
Wootric analyses customer feedback and labels it with the indication of positive, negative or neutral.

✓ Show predictions and trends in charts.
Konux predicts issue evolution.
Alloy forecasting
Salesforce Einstein AI
5. Communication Style

Communication style and personality are especially important for conversational interfaces. If it’s not a conversational UI, you still need ways to communicate and explain decisions to users. AI features can have the same style as the rest of the product or it can have a personality to highlight its difference.
6. Confidence Visualisation

Is there a well-understood metric among your users (score, colour-code, price) or should you create a new metric to show the prediction confidence?
INK analyses content and gives a user a content relevance metric which is already known among their users.

✓ Group results (high/medium/low, score, colour-code, a/b/c).
Appzen uses the colour-code to show risk score.

✓ Number (0–1, percentage, distance, score).
Firebase Predictions in percentage
Netflix shows match confidence in %s.
Falkonry shows confidence level 0–1.
Amazon Comprehend API provides a number from 0–1.

✓ Sort by relevance or show Top N results.
Google autocomplete suggests top N results.
Spotify. Suggested songs are sorted by relevance.

✓ Chart
Entelo show the probability of a potential candidate leaving their job as a chart.

✓ Mixed approach.
Customer satisfaction prediction in Zendesk is displayed with a colour-code, chart and numerical value at the same time.
Monty’s Wicket Warnings shows the number and a pie chart.
7. Explanation

The bigger the impact of a prediction, the more detailed of an explanation you need to provide. For instance, explaining a credit score can help people to improve it.

✓Explain why a specific outcome was predicted or suggested.
Tableau shows the popup with the information “Why is this recommended?”
Appzen gives a user explanation message and additional information including showing data from external sources.

✓ Explain how AI understands user input or intent.
ThoughtSpot explains why a user sees specific results of a search.

✓ Example-based explanations can be provided when it’s hard to describe the logic behind the prediction.
8. Actions

✓ Accept or reject AI suggestions.
Timelyapp time tracking app

✓ Action for editing and supervising suggestions.
Rossum automated data extraction

✓ Let users create labels to mark found data and patterns.
Falkonry lets users label and track found patterns.

✓ Recommend further action based on the analysis.
Alloy suggests ordering more items based on trends.
Salesforce Einstein AI gives actional advice based on predictions.
Snappr analyses professional photos and gives advice on how to improve the photo.
9. Defaults and Settings

✓ Consider defaults that won’t overwhelm the user while the system learns and gathers data.

✓ Let the user set up a threshold for notifications and suggestions.

✓ Adjust system behaviour according to the number of predictions it makes.
10. Error Handling

✓ Let the user intervene.

✓ Support correction.

✓ Support dismissal.

✓ Let the user provide additional information and reevaluate predictions.

✓ Explain to the user how the system learns based on their corrections.

✓ Consider fallback in case of an AI emergency.
11. Feedback

Design a flow where a user can provide actionable and understandable feedback for the model:

✓ Explain how feedback will benefit the user and improve results.

✓ Let the users provide explicit feedback.
ThoughtSpot
When a user overrides a strong suggestion, you can ask for a reason to learn more. Product Management for AI/ML by TheProductWay
Toutiao learns not only based on implicit feedback from clicks, reads and time spent, but also has a button labelled “not interested”.
In Zendesk, a user can report a wrong score.
The plant identification app, PlantSnap, lets users manually enter information about a plant or send it to a professional.

✓ Use implicit feedback from user interactions (clicks, views, time, share, interactions).
12. Microinteractions

✓ Loading and calculation.
INK analyses the content relevance based on intent and the text.
Snappr analyses professional photos on LinkedIn.

✓ Error messages.

✓ Notifications.
13. Delight

This whole post was focused on user problems. In the B2B world, solving a user’s problem makes a big difference and can delight users more than anything. But as a product team, we should keep an eye on opportunities to give a user more value, surprises and delights. Something that Spotify and Netflix do with their recommendations.
Prototyping and Testing

Testing an AI-based product can be the trickiest part. There are several recommended methods in the design community:

    Human on the back-end or Wizard of Oz method. Helps to understand if this functionality is needed and if it’s trusted.
    Testing many scenarios in different environments to uncover possible faults or inconsistencies.
    Ethical check. Many times in the short history of AI mass usage, we have witnessed how neutral in nature products have caused harm. To avoid it:

    Test the product in different environments.
    Check data for biases.
    Select diverse demographics for testing.

4. Prototype using available AI tools:

    Mathematica to test image recognition, text classification, and classification or regression of generic data. It has an interface and doesn’t require tech skills to use it.
    Wekinator to test musical instruments, gestural game controllers, computer vision or computer listening systems. It’s open-source, no programming required.
    Keras a user-friendly wrapper running on top of TensorFlow, CNTK, or Theano. It is made for prototyping.

📝 More tools Quick Prototyping Tools for Emerging Technologies
Takeaways

When working on interfaces, designers should treat AI as any other technical component. It’s important to understand the constraint, but the technical implementation shouldn’t affect the design process.
Sources
📘 Books

    Machine Learning for Designers by Patrick Hebron.

The first part explains ML fundamentals. The second is about design principles and emerging best practices. The book focuses more on conversational ML and chat-bots, but the principles from the book can be applied anywhere. The chapter about prototyping has a lot of information I haven’t seen anywhere else.
📝 Articles

    People + AI Guidebook is the most comprehensive resource on designing AI interfaces with examples, worksheets and glossary.
    AI UX: 7 Principles of Designing Good AI Products
    UX Design Guide for Data Scientists and AI Products
    UX Design for AI Products. Step by step guide for conversational AI

▶ ️Videos

    Product Design in the Era of the Algorithm by Josh Clark. Design philosophy, ethical questions and practical advice.
    Designing an Artificial Intelligence Interface. Case study

### Untitled 8.txt


Tuning out Toxic Comments, with the Help of AI
Can a machine learning-powered moderation tool make the internet a healthier, safer place?
Quinn Madison
Google Design

Quinn Madison
·

Follow
Published in

Google Design
·
5 min read
·
Nov 21, 2019

Illustration by Niv Bavarsky

This is the second article in a series that shows how the practices and principles of the People + AI Guidebook are reflected in the design and development of human centered AI products at Google. It was written in collaboration with the Jigsaw Team.

There’s so much potential in online interactions. They can be positive — you might learn something fascinating, perhaps meet a remarkable person — or they can be negative, even harmful. According to a Pew Media Research Center study, about 41 percent of American adults have experienced online harassment, most commonly on social media. A significant portion of those people — 23 percent — reported that their most recent experience happened in a comments section.

A single toxic comment can make someone turn away from a discussion. Even seeing toxic comments directed at others can discourage meaningful conversations from unfolding, by making people less likely to join the dialogue in the first place. The Pew Research Center report revealed that 27 percent of Americans decided not to post something after witnessing online harassment.

The power to moderate comment sections — to identify, reduce or eradicate toxic comments — has historically been granted to platform moderators. But what if, instead of relying on moderators, people could control for themselves the comments they see?

We wanted to make it happen, so we designed and built Tune.
Introducing Tune

Tune is an AI-powered Chrome extension that lets users moderate toxicity in their comment threads. It’s designed to give users (not platform moderators) moment-to-moment control over the tenor of comments they see. With Tune, users can turn down the “volume” on toxic comments entirely (zen mode) or allow certain types of toxicity (profanity, for example) to remain visible.

We built Tune on Perspective, an API we developed that uses machine learning to spot abusive language. Tune works on the commenting platform Disqus as well as on Facebook, Twitter, YouTube, and Reddit. It’s open source (find it on Github) and part of the Conversation-AI research project, which aims to help increase participation, quality, and empathy in online conversations at scale.
Tune, in action
Empowering people

Designing Tune required extensive user research, deep empathy for users, and ongoing collaboration between product managers, engineers, and UX designers. From the start, we approached the problem with a user-centered focus by asking:

How might a machine learning-powered moderation tool empower individual users as they read comments?

We thought about how best to build trust, how to design an interface that would offer users control, and how to allow for feedback. Above all, we wanted users to feel empowered to change the toxicity level of the comments seen in their feeds.

Three design goals arose: Build user trust, give users control, and design for transparency.
Finding a metaphor

First: We had to set user expectations and make it easy for each new user to quickly grasp how Tune works. We searched for an easily understandable metaphor.

Our research revealed that users value control. Tune didn’t have to be perceived as something that worked by magic. Being perceived as transparent, we found, would engender user trust. The idea of volume as a metaphor took hold, and with it came the notion of a volume dial. This familiar object reinforced the message we wanted to send: that each user can take control, make “volume” adjustments, and explore what works well for them.
Understanding errors

Perspective was originally developed to enable publishers of all sizes (New York Times, The Economist, and others) to set toxicity thresholds for their platform. But we wanted Tune to serve end users, empowering individuals to set thresholds for themselves.

That said, the output of ML models isn’t always easy for end users to understand. And no matter how rigorous our ML model, we knew errors would still occur. There’s no exact calculus on how to define toxic language, and toxicity isn’t always obvious and universal. We knew our model was likely to classify certain comments in ways that differed from user expectations.

Some comments obviously intend to troll, insult, or provoke the person on the receiving end. But most toxic comments are subtle and ambiguous — not extreme. And in many cases, harmful conversation isn’t caused by the substance of a comment but by the tone in which the ideas are conveyed.

With that in mind, we designed the UI to support transparency: Comments are visible as users turn their “volume” dial to increase or decrease their toxicity thresholds. Users can easily see how the adjustment impacts what types of comments remain visible.
People + AI Guidebook principles

Designing Tune required trial and error and a commitment to human-centered AI design. Our users needed insight into what was happening, so they could trust Tune. They also needed control over toxicity thresholds, so they could adjust in real time.

People and AI Guidebook principles were foundational to the design and are evident in the final product. Those are:

Explainability and trust

Optimize for trust. Explain predictions, recommendations, and other AI output to users. The right level of explanation helps users understand how an ML system works. When users have clear mental models of the system’s capabilities and limits, they can understand how and when it can help accomplish their goals.

Feedback and control

Understand when your users want to maintain control and when they’d appreciate ML automation. We didn’t automate control entirely. We made sure for example, users could minimize toxicity themselves by turning down the dial.

Design to engender feedback — and then align that feedback with model improvement. Ask the right questions at the right level of detail (don’t overwhelm users with questions and avoid wordiness). Ask at the right moment — immediately. When Tune didn’t perform as expected, it was key to enable users to give feedback immediately.

Errors and graceful failure

Set user expectations for “failure” (when the system for example, perceives and classifies a comment as toxic but the user disagrees), and provide paths forward when the system fails. Design and build with the knowledge that errors happen and can help your ML model learn from users. Design an error experience that’s user-centered, because the product needs to provide ways for users to continue their task and help the model improve.
Parting words

We’re proud of what we’ve accomplished so far, but we don’t view Tune as a finished product. We see it instead as an ongoing experiment that empowers users (not platform moderators) to set their own thresholds for what they see. We want Tune to enable a healthier internet — one where toxicity can be dialed down and where people can feel safe.

Quinn Madison leads content strategy for People + AI Research (PAIR) core operations and is a coauthor of People + AI Guidebook.


### Untitled 9.txt

How to Meet User Expectations for Artificial Intelligence
Research-based recommendations to create a human-centered AI experience
Kathy Baxter
Salesforce Designer

Kathy Baxter
·

Follow
Published in

Salesforce Designer
·
9 min read
·
Apr 12, 2017

For those unfamiliar with artificial intelligence (AI), it is the simulation of human intelligence (i.e., learning, reasoning, self-correction) by a computer system or machine. AI has been around since the term was coined by John McCarthy at The Dartmouth Conference in 1956 but it has seen a recent resurgence in interest because there is now more data and computing power available than ever. Neural networks that couldn’t work a few years ago are working overnight and that’s due to greater computing power.
Salesforce Einstein

Salesforce Einstein is applying AI across our CRM products to enable our customers to make better informed decisions and complete tasks faster. We want to make AI accessible to everyone, not just data scientists, because we believe that democratizing AI can improve everyone’s lives.

This is an exciting time for those working in AI but there is a lot we still don’t know. New blog posts, articles, and news stories are published everyday on the topic but much of it is more speculation and opinion than actual empirical research.

To ensure we are making data-driven decisions, the Salesforce User Research and Analytics team conducted a literature review of internal and external user research on AI. Kathy Baxter, Greg Bennett, Yakaira Núñez, and Mru Kodali have combined our own research insights with published research from academia and industry to identify the core expectations users have when interacting with any AI system. Based on those expectations, we have provided recommendations for how AI systems should be designed with users in mind, regardless of tool (e.g., chatbot, case classification) or domain. This is a rapidly evolving field and as such, these expectations and recommendations will continue to evolve with technological advancements and user experiences over time.
1. Know your limits

No AI is perfect, especially when it is learning, so it’s important to know the limits of the system and to stay within the bounds of what it can do to support the user. Don’t allow the user to make errors or force them to remember specific words the system recognizes (Nielsen’s 10 heuristics). Overreach and the user will be disappointed at best, angry at worst.
The Assist chatbot clearly lists the things it can help with.
Recommendations

    Don’t pretend to be human: Not all consumers know what a “chatbot” is so it is especially important to communicate that an artificial assistant isn’t human. Pretending to be a human sets the user’s expectations too high and they may become angry if they feel they have been “duped” by the system.
    Be prescriptive: If you do not have the ability to intelligently support free-text, clearly and concisely communicate what is possible (e.g., “Which model are you referring to? A, B or C?”). Think internationally. You need to know how to respond if the user is trying to communicate in a language you cannot communicate back in.
    Convey level of certainty: Using words like “suggested,” “hint,” or providing confidence scores conveys the level of confidence a user should put into the recommendations and not be overly disappointed when it isn’t correct.
    Take responsibility: Never blame the user when things don’t go as planned. “I’m sorry but I seem to be having difficulty” lets the user know the system realizes it is to blame, not the user.

2. Establish immediate value

Once you know the limits of what you can achieve, you must ensure that you can still provide value to the end user and demonstrate it immediately. The tools/systems cannot be simply usable or entertaining, they must also be useful.
KLM’s chatbot allows customers to manage their travel needs
Recommendations

    Speed is critical: It should go without saying that if the AI can’t help the user complete their task(s) faster and/or more accurately, there is no point in having it. Having to edit suggested responses or repeatedly request information wastes time and the user’s goodwill. Brevity and clarity are also key here. Users should not have to spend additional time trying to understand the recommendation.
    Be accessible: It’s just as important for AI systems/tools to be accessible as any other product. Unfortunately, not all chatbots are accessible. Before launching your smart tool into the world, make sure it is universally accessible. These two posts are great resources to get you started: How to Describe Complex Designs for Users with Disabilities and 7 Things Every Designer Needs to Know about Accessibility.
    Offer an escape hatch: One of Nielsen’s 10 heuristics is “user control and freedom.” When the system fails, user needs a way out. There should always be a way to decline/undo any suggestions or changes the system makes. Chatbots should also offer a way to redirect to humans at any point by asking for one (e.g., submit a case, post to the user community). Sentiment analysis to detect when the user is angry should automatically connect the user to a human. Forcing the user to engage with the AI, especially when it is wrong, will only result in the user avoiding the system (e.g., turning off the suggestions, abandoning the product).

3. Build trust over time

It can take years to build your brand and earn your customers’ trust but in a world where anything can go viral, it can be seriously damaged in days or minutes.
DoNotPay is a lawyer bot that helps people fight unfair parking tickets.
Recommendations

    Don’t be evil: When a group of scientists and technologists were recently asked about grand challenges for the 21st century, concerns around fairness, ethics, and protecting humans in AI systems were frequently cited. Users expect AIs to make the right recommendations in terms of not only accuracy but also based on ethics. A great example is DoNotPay, a lawyer bot that helps users fight unfair parking tickets, gets landlords to repair their tenet’s buildings, and helps refugees apply for asylum.
    Don’t be creepy: You wouldn’t expect nor want a new human administrative assistant rescheduling meetings with your leads or answering emails for you without your direction. The same is true for an AI assistant. Knowing too much is creepy and inserting itself unrequested is annoying, especially when it is wrong. Any AI system should begin by making suggestions and limiting what it offers to do. Demonstrate learning over time and offer to do more as accuracy increases. One example of this is MuseBot which recommends daily activities to enrich your child’s life. It can actually predict lifetime outcomes based on what it learns but does not share that with parents since that could cause more harm than good.
    Be transparent: Users are uncomfortable with a “black box.” They want to understand the inputs that went into making the recommendations and have the ability to edit incorrect information that could negatively influence the accuracy. Amazon’s recommendation system is a great example of showing customers why a particular recommendation was made and allowing them to edit the information to improve recommendations.
    Take feedback: Users will not trust a system it cannot give feedback to. Users should be able to evaluate the accuracy of the AI’s predictions and tell it to course-correct, as well as govern how information is shared between parties (both internally and externally) throughout the auto-sync of information. Netflix allows customers to rate movies, which are then taken into consideration for future recommendations.
    Have a guardian: Although some users will intentionally try to break your AI (e.g., Tay), most users expect companies to have safeguards in place to protect their data and to interact with them legally and ethically. Since AIs are designed to be constantly learning, they may stray considerably from the guidelines their programmers initially gave them. As the complexity increases, they will become “black boxes” to human understanding. It would be virtually impossible for any human to monitor these constant changes, understand, and determine if they are legal or ethical so having an AI guardian will be important to protect users and maintain trust.

4. Respect social norms

Although a chatbot shouldn’t pretend to be a human, it must still respect social norms to avoid being perceived as “rude” or having uncomfortable interactions.
Joy can respond to the user’s mood
Recommendations

    Convey listenership: If the bot is limited to canned responses and isn’t utilizing natural language processing (NLP), it can provide entire sentences instantly in response to a user’s request, but this instant response will feel rude, as if the system isn’t “listening” to the user’s request. Speed is critical, but taking natural pauses and using varied language to show understanding of the request is expected for courtesy. Consider including filler words such as, “Ah, okay. Let me check,” or “I’m still here, just checking,” or “Still getting results” to fill time for long-tailed recall. Consider modeling turn-taking structure and phrasing around best practices for transactional interactions.
    Don’t interrupt: No one likes to be interrupted. AI systems shouldn’t interrupt a user’s task and chatbots shouldn’t interrupt a user mid-speech.
    Detect mood: Responding to a serious customer issue with smiling emoticons or jokes will only anger the user. Bots must detect emotion and respond accordingly, including escalating to a human when the user is angry.
    Context matters: Users expect humans and systems alike to remember previous interactions and content. AIs should also leverage contextual information like location (e.g., airport), time of day (e.g., midnight), and issue types (e.g., flight cancellation) to prioritize and respond accordingly. Is the user looking for an entertaining exchange or is s/he trying to immediately rebooked a cancelled flight? The AI must be able to tell the difference.
    Be polite: Many people say, “Thank you” in response to a bot’s assistance. The bot needs to understand these types of courtesies and how to respond (i.e., “You’re welcome”). Equally, it should respond politely but firmly when the user becomes abusive to avoid normalizing abusive interactions.

5. Have personality

Every system/tool we use should be a pleasure to use.
Starbucks’ bot matches their brand and uses beautiful photos of their products to communicate with customers.
Recommendations

    Be delightful: Chatbots in particular should have a personality. Ideally, a chatbot should be as interesting to interact with as a human. We identify with characters that reflect back to us who we believe we are or who we want to be. The chatbot should be able to adapt to varying conversational styles and preferences and adhere to them. This includes how to respond with the user becomes aggressive or intentionally tries to break it. Ask AmEx gives a variety of options to choose from and goes above and beyond by reminding the user of upcoming holidays.
    Be authentic: The voice and tone of your bot should match your brand. Users will pick up on inconsistencies (e.g., informal slang, jokes and emojis from a very formal financial services company) and can raise alarm bells. Starbucks’ bot matches their brand and uses beautiful photos of their products to communicate with customers.

Einstein teams across Salesforce are levering these guidelines as they design and develop new features. These are living guidelines, meaning that we are constantly evaluating, adding, and fine-tuning them. We’d love to hear what guidelines or insights your team has developed when developing AI tools/systems!

Thank you Ian Schoen and Raymon Sutedjo-The for all of your feedback!


### youtube_ZtRnZHWXYfs.txt

Del 3 is a massive Leap Forward and in
today's comprehensive tutorial we're
going to cover prompting Del Vision
imagery imagination using gpts Del 3 and
so much more prepare to level up and
let's get right into it to get started
open chat.
open.com Del 3 is powered by GPT 4 so
just make sure you're using the latest
GPT 4 model by selecting it in the top
left corner now you can generate images
right here in the regular Chad GPT
window as Chad GPT can automatically
detect when you're looking to get an
image generated or you can head over to
the explore page and launch the Del GPT
from there there's currently no real
difference between using the Chad GPT
window or the Del GPT in terms of
capability and features the only Quirk
I've noticed between the two options is
that when Chad GPT is being buggy the
Del GPT is not and vice versa gpts were
recently just launched so if you're new
to them and would like a bit more
context feel free to bookmark the GPT
build tutorial I've linked below for
today's dily 3 tutorial you'll need a
chat GPT Plus or Enterprise subscription
to use all these features you can see
what plan you're currently on by heading
over to the my plan section and just in
case you're on a plus plan and can't
access Del in your Chad GPT account head
over to settings and beta beta features
and make sure plugins and Advanced Data
analysis are enabled okay let's start
with D 3's most popular use case image
generation we'll enter a basic prompt
asking it to generate a car driving on
the mountain side and voila it turns our
prompt into two image options we can
further edit this is a decent image but
it could definitely be a bit better as
we'll see in a second but before that
let's click into one of the images then
we'll click into the ey icon next to the
download icon clicking the IE icon
reveals a really cool feature you can
view the actual prompt D 3 used in order
to give you an image it deems
satisfactory so why did it change our
prompt well Del 3 is powered by GPT 4
which is the incredibly powerful large
language model that also Powers the
latest version of chat GPT open a
research showed that using very detailed
prompts gives significant better results
when generating images so every time you
type in a prompt D 3 goes through a
process known as prompt rewriting which
Taps into the incredible natural
language processing ability of GPT 4 to
optimize your prompt so it can deliver
what it deems the most visually desired
results and whenever you download an
image the file name will actually
contain the prompt as well pretty cool
and convenient in case you'd like to
come back in the future and regenerate a
similar image okay now that we know that
Del works better with more detailed and
descriptive prompts let's take our first
prompt and add some out of this world's
detail to it the prompt will ask it to
give us an image that is truly out of
this
world now of course art is very
subjective but honestly I much prefer
our second attempt by a country mile
let's pick the second image as you can
see we're now on an alien planet with
beautiful scenery and breathtaking
Landscapes but interestingly even with a
very detailed initial prompt gp4 still
changed it quite a fair bit to produce
this Interstellar result there are ways
to increase the adherance of the final
prompt to your original prompt either by
saying so in the chat window itself or
by using Advanced options such as gpts
and custom instructions which we'll be
taking a look at later in this tutorial
Del 3 is incredibly powerful and as
we've just seen to really unleash its
potential it's important to always work
on and experiment with your prompts
because even though it tweaks your
prompts in the background by giving d a
really good starting place you'll be
able to make your desired images that
much faster however fear not if you
struggle with generating compelling
prompts Chad GPT is an awesome
brainstorming partner let's say I want
help generating an image for a dessert
because food is life
let's get Chad GPT to help with
prompting so enter I'd like to generate
a photograph of a mouth watering dessert
that looks like was taken by
professional foodie can you create a
series of prompts to help me decide what
the final image should look like Chad
GPT then goes on to give us a series of
really delicious looking prompts as it
says each prompt is designed to capture
a different Essence and style of dessert
photography from classic and elegant to
playful and colorful you can choose the
one that reson Ates most with your
vision for the final image this is
awesome there's no way on Earth I would
have thought of any of these
descriptions by myself let's pick option
two you know what this looks pretty good
but the great thing about di 3 and chat
GPT is that you can always ask it to
generate a different option if you
change your mind as it keeps track of
your entire conversation so let's let it
know that I'd actually prefer to go with
option four okay this looks pretty
strange and quickly looking at the
prompt with you can see how it pretty
much used its own fleshed out
descriptions to generate this
deconstructed cheesecake now Del 3
really excels when you give it
instructions a normal human being would
understand so sometimes it is worth
resisting the temptation to get too
complicated and fancy with your prompts
but congrats at this point you now have
a foundational understanding of AI
Generation image prompting there are
tons more interesting prompting
techniques and I will continue to
introduce new ones as we go go along but
fundamentally being detailed and
descriptive in your prompts should get
you that much closer to the results
you're looking for from the get-go just
remember detailed doesn't mean
complicated now let's take a look at
editing and refining our AI generated
images first let's prompt it to give us
a close-up drip painting of an elderly
woman with a hopeful look in her eye
this is a much shorter prompt than I'd
recommend but for the purpose of time
and this tutorial I'll let D 3 do its
magic behind the scenes and would you
look at that our first roow block as I
mentioned before there are hiccups to be
found darly 3 seems to have pretty
strict copyright God rails which I found
often times geted very wrong so if you
run to this sort of error what can you
do you can simply tweak your prompt and
try again so let's try just that you can
either click the little pencil here and
change your first prompt but for
comparison's sake let's tweak our prompt
and then reprompt it in the message box
down below okay so we changed our prompt
to a close-up of an LLY woman with a
hopeful look in her eye the artwork
should embody the drip paint style let's
see if that gives us a better result and
lo and behold it worked now before we
dig into the final prompt D 3 used to
generate the stunning image you will
notice our short but sweet prompt still
includes several key details you should
aim to have in your image generation
prompts depending on what you're making
these are the subject style composition
and emotion I like the first image
better here so let's go with that and
this is our optimized prompt pretty
incredible stuff now let's edit our
image we'll prompt D to add a faint
image of the Rising Sun to the first
image to further convey the feeling of
Hope and see what we get okay the
floating head with the drip painting is
kind of creepy so let's give her and
neck and
shoulders okay this one is much cooler
and much more compelling now supposing
you feel like you're on the right path
but would like to see different
variations you could simply ask it to
generate new variations based on the
updated prompts so let's ask it to
generate new variations that use a
dramatic monochromatic color scheme you
notice my prompt actually has a typo and
is grammatically incorrect but gp4 is
smart enough to use usually pick up on
what the user truly intends I really
really like the first image let's click
into it and briefly look at what the
final prompt was absolutely
brilliant now as you've seen most times
di is going to give you square images
however you actually do have the option
to set the aspect ratio at any time
supported formats are standard which is
square wide which tends to be 16 by9 and
vertical for mobile formats I do
strongly recommend establishing your
aspect ratio right in your initial
prompt as I've seen that it sometimes
struggles to ideate and properly expand
upon images it has already generated
either way let's give it a try with a
hope portrait and see what happens I'll
ask it to convert the first image into a
wide format and as you can see there is
a pretty big dramatic difference from
the first image in square format and the
second image wide format which is why I
mentioned including your aspect ratio in
your very first prompt before we move on
though let's try copy that exact prompt
in the image we did like and see if that
helps so I'll open my preferred image
click copy then paste it as is then the
aspect ratio should be wide and let's
see what happens this time around okay
still a bit different but you know what
we'll take it but I think in this case
it image number one wins yet again and
for good measure let's quickly see what
happens when we convert the first image
into the vertical
format and boom a mobile friendly image
ready to go now of course if you'd like
more creative freedom you could generate
most of your images in the wide format
export them into a tool such as canva or
photoshop and then edit them down to the
size you most prefer now at this point
in time you may have noticed that I'm
actually in my third window we started
with our Mountain car drive the dessert
photo and our hope photo every time you
prompt a d your chat GPT it
automatically names your chat however in
this case since we started with an error
it then named our chat content policy
not mat so you can simply click the
three dots next to chat name click
rename and we'll call it our hope
portrait now apparently you don't have
to start a new chat for New Image ideas
but I do like clean starts when working
with new contexts images and ideas as
sometimes Chad GPT does hallucinate and
might pick context from the wrong piece
of
conversation okay when open AI CEO
tweeted this image earlier this year
this one detail blew everyone's mind
while at first glance it might seem like
a bit of a clumsy font the fact that
perfectly legible text was generated by
Del was incredible for example the exact
same prompt in di 2 yields absolute
gibberish and this applies to current
versions of other well-known and very
capable tools such as mid journey and
stable diffusion so let's try and
generate our own text in Dar 3 we'll
start with this prompt a billboard that
says closing down sale which is located
in an abandoned city that's now overrun
with
vegetation okay image one seems to have
the correct spelling but looking at
image 2 it has a definite typo so let's
click into it and see what its prompt
was interesting how it added details
such as a post-apocalyptic scene with an
abandoned city overrun by lush green
vegetation pretty cool when it comes to
typos you could try overcome them by
employing our prompt fundamentals which
are to provide a clear and detailed
description that avoids ambiguity
especially when it comes to the desire
placement of the text but remember if
you're going to be generating images
containing text in Del 3 do expect for
it to be an iterative process where you
will have to have a back and forth dally
until you land on the Right image
spellings and placement honestly at
least for now it may be best to just
generate your image without text and dly
and then add it in later using a tool
such as canva or Doby Firefly but let's
try correct our typo we'll let it know
that the second image is a typo in the
word closing and it should only have one
eye and would you look at that these
images look much cooler and they have
the correct spellings a job well done
okay crazy thing is we have just
scratched the surface of Del 3 and
things are about to get a whole lot more
interesting first I'm going to upload
this delicious looking breakfast clearly
someone made this Del 3 tutorial hungry
you can upload images by dragging them
directly into the message box or
clicking the the little attachment icon
and selecting the files from there and
for now let's just hit enter and see
what happens incredibly Del has
perfectly described the image right down
to it being in a skillet with a sunny
side up egg with its yolk still intact
it even notices the bread in the corner
and suggests that it's either Rye or
whole grain bread really impressive so
how did it do all of this well this is
because Chad GPT and so by extension
dally is equipped equipped with what's
known as computer vision or more
popularly now ai Vision in a nutshell
computer vision is a field of AI that
enables computers to derive meaningful
information from digital images videos
and other visual inputs we are literally
living in the future so let's take a
look at three practical use cases of di
3's Vision capabilities we'll start with
image recognition first let's pretend
the image we just uploaded is a picture
I took at a restaurant and I'd like to
know how to make it at home we'll ask
you to suggest the recipe I can make at
home to replicate the dish pictured and
just like that we have an awesome recipe
that seems pretty legit and I for one am
a fan as this recipe doesn't come with a
long backstory on why the author happens
to resonate so much with eggs and for
the cherry on top let's get it to
provide us with the nutritional
information for this creation and just
like that we have our key nutritional
info with this dish coming in at about
600 to 800 calories which does sound
pretty legitimate Del also provides a
disclaimer at the very beginning knowing
that it does require precise
measurements for each ingredient as well
as knowing the specific products used as
for example you could use turkey
sausages instead of pork sausages which
would have a difference in calories okay
if your mind isn't blown yet let's use D
for image analysis as our Second Use
case I'm going to upload one of the most
famous pieces of artwork in the world
van Go's star night and I'm going to ask
D to act as a curator at a world renown
Museum and tell us about the piece side
note adding act as to your prompts is
another great prompting technique to
better guide Del in the direction you'd
like it to go and here we now have a
pretty compelling description of this
painting with Dolly letting us know that
it's renowned for its swirling vibrant
Sky filled with dazzling stars that seem
to pulsate with energy and emotion feel
like I'm at the Museum already the third
fun use case of D's Vision AI is
reimagining images this means creating a
new image based on the properties of an
uploaded image how it works is Del when
analyze your image to generate a text
description for itself which it'll then
use as the basis for reimagination let's
take this Skyline View of Copenhagen as
an example and reimagine it in a very
healthy Universe where everything is
made of vegetables and see what we
get and would you look at that it's
transported our image to a world where
everything is made of vegetables now
clearly this looks nothing like
Copenhagen but it did pick up on the key
features such as roadways waterways and
medium rise buildings and looking at the
prompt it seems each vegetable has been
assigned a very important role such as
trees made from broccoli and cauliflower
now there are both tons more fun and
practi iCal use cases for Del's Vision
capabilities so following this tutorial
be sure to take time to experiment and
when in doubt it's okay to ask Del
itself for guidance as we saw before
just a note before we move on Del 3
currently can't directly manipulate or
edit images so for example you can't add
in a vacation pick and tell it to erase
your X for now at least as they're
constantly adding in new features at
this point you now have a really good
grasp of how to prompt and iterate with
Del to achieve your desired outcome
we're now going to build gpts that
leverage di as gpts are a great way to
supercharge your creative workflow gpts
are custom versions of chat GPT that
combine instructions extra knowledge and
any combination of skills so you can
think of them as highly skilled and
talented helpers for very specific tasks
this may sound like it's getting a bit
complicated but as we're about to see
it's very easy to wrap your head around
gpts and you'll become a d 3 power user
in no time as an example for some people
including myself creating or writing
grade starting prompts can be tedious
especially if you find it hard to always
start with a blank canvas so now we'll
be learning how to build a custom di 3
GPT that can not only help us ideate but
also supercharge our AI image generation
workflow to start head over to the
explore tab then click create a GPT
before we get going switch to the
configure Tab and make sure that D image
generation is selected in the capability
section this ensures our GPT will call
upon D when needed back on the create
tab this is where we're going to design
and modify our custom GPT and I'll take
a moment just to appreciate how
incredible this feature is we're
literally going to be doing some
Advanced coding without even writing a
single line of code something like this
just even months ago would have involved
hacking together dozens of different
tools tools okay in the Builder we're
going to let it know we'd like to make a
creative who helps generate visually
stunning images by asking good questions
that help thish out an idea to provide
the key aspects needed to generate an
image next the gbd Builder wants to know
what name would like to give our gbt I
actually like it suggestion visual Muse
so let's go with that following our name
selection it then generates a logo for
us let's tweak the logo to show how you
can easily make changes in GPT Builder
and as you can see see we then get an
updated logo now I should mention again
all of this is in beta so hiccups and
bugs are to be expected for example here
it's asking me how I feel about the
image but it then seems to have jumped
into the next follow-up question before
I could answer the prior One the good
thing is if you answer both questions at
the same time it will still understand
what you're saying though sometimes
you'll find that it will prompt you one
by one and sometimes it will just happen
to give you two questions so your
mileage may vary so we'll let it know we
like the logo and we like it to start
with a specific question about the user
image
idea now the follow-up question here is
asking us what guard rails we like to
put on our D GP te let's let it know
images should always look like they're
from Another Universe just for
laughs and just like that visual Muse is
good to go before we test it out in the
preview pane let's simplify our convers
ation starters by heading over to the
configure page and let's change the two
opening prompts to Let's brainstorm an
image and the second one to be I need
some inspiration for an image and then
we'll get rid of the last two you can
also click into the instructions box to
view how the GPT Builder translated your
input into instructions it'll follow you
can always add and remove instructions
as you desire right in this window or
through the regular GPT Builder click
clicking into our instructions you'll
notice the last paragraph which it added
itself about maintaining a supportive
tone and encouraging creative
exploration guiding uses towards
envisioning scenes or elements that are
surreal ethereal or distinctly unworldly
that is absolutely incredible as I would
have never imagined an instruction so
detailed let's close out of instructions
by clicking close and now let's test out
our Del GPT we'll go with the first
prompt and get it to help us bring
brainstorm I'll go with an alien planet
now the good thing about gpts is you can
be as detailed as you want or let it do
its thing and see what it comes up with
and then edit from there so for example
I'll let it know that the sky will have
multiple Suns and moons but that it can
then decide on everything
else and then it gives me key details of
the image such as the landscape the sky
the inhabitants and the structures for
consideration and I can tweak the before
getting to generate but these look great
so let's see what the actual image looks
like and here's our final work of art
now this is a pretty basic GPT and it's
meant to show you just how capable yet
easily customizable both Chad GPT and d
3r and best part is if you run out of
ideas building your GPT you could simply
ask it to lend a hand for example let's
ask it how else we could improve our GPT
and we'll do that back on the create
page and as you can see it's trying to
guide the GPT to a place where it can
build upon really useful and refined
details that you can then use to
generate an image that the user will
truly be happy with and when all is said
and done remember to save your GPT and
you'll have the option to save it
privately get a sharable link or make it
public for when the GPT store rolls out
before I hit save you notice that even
though we named our GPT visual Muse that
actually didn't get translated to the
GPT name in the top left corner this
again is 50/50 as the gpts I've made
where the name I've given it in the
Builder is the name that the GPT takes
but if this happens that's okay simply
head to the configure page and then type
in your gpt's name there and now once
your GPT has a name you can then proceed
to save it and now look at our shiny new
visual Muse GPT ready to go your newly
created GPT will either live on the left
bar in the recently used gpts or back on
the explore page under your my GPT
section now instead of building gpts you
alternatively could create custom
instructions by clicking on your
username then custom instructions just
like gpts these allow for the
customization of chat gpts and Di's
responses based on your preferences and
can be modified or removed at any time
the first box is where you give Chad GPD
context about yourself you use case and
preferences for example it can be things
such as where you're based what you do
for work your hobbies and so on the
second box is where you set the tone
response style and length of responses
you prefer for example Some people
prefer long detailed responses while
some would much prefer short and
straight to the point answers if your
use cases for Del and Chad GPT don't
change much you may be okay setting
custom instructions here personally I'd
recommend the use of gpts for the
various tasks you'd like to do this is
because custom instructions said here
apply to all your new conversations
whether they started in the chat GPT
chat or dadly chat whereas a GPT can
have very specific instructions that
apply just to itself okay great job
making this far we covered a lot of
ground and before we look at some of our
key takeaways for Del 3 let's talk about
its limitations so that you can save
time from troubleshooting at the time of
recording prompts can be up to 400 100
characters long which should be long
enough in most situations as yes you
want to be detailed but also not
convoluted next it's worth noting both
Chad GPT and D 3 have lots of guard
rails in place particularly when it
comes to avoiding copyright infringement
this means that there'll be times where
it falsely Flags your prompts as
violating their content or copyright
policies as we saw earlier which then
results in no image being generated best
you can do in those scenarios is to
tweak a prompt and try again again as it
did work for us speaking of copyright
Del won't let you replicate any living
artist's work as it is protected by
copyright law though of course some
people very creative prompts seem to be
able to get around this but it does seem
open AI is increasingly clamping down in
those Generations however anything in
the public domain such as star KN is
fair game also beware of Del's limits as
these are constantly evolving and lastly
when Del emerged into the public sphere
hands were its Kryptonite while they've
come a long way if you do generate
images that feat your fingers be sure to
vet them to make sure they look like
human hand so to wrap things up here are
10 key takeaways for your D 3 journey be
specific and detailed in your prompts
take an iterative approach the first
image generator doesn't have to be
perfect and it's okay to have a back and
forth of di set your desired aspect
ratio in your opening prompt if you'd
like to use normal language instead of
aspect ratios you can simply let Del
know you'd like the image in standard or
Square format for 1X one wide for 16x9
or vertical for mobile format be patient
when generating text or better yet add
it in after with an external tool for
more control leverage D's AI Vision
capabilities for both inspiration and
learning do build gpts that each serve a
specific purpose to save time in the
long run as mentioned previously I'd
pick gpts any day over the custom
instructions feature
keep learning this is still a very
rapidly evolving area with many more
advancements to come and last but not
least have fun we're truly living
through a transformative time in history
thanks for making it through the
tutorial I really hope you found it
valuable and that you gain skills that
you'll be able to use both in your
professional and personal lives if you
have any questions or tips you'd like to
share please feel free to leave them in
the comments down below thanks for
watching and catch you in the next one



### youtube_20N53khArXA.txt

Voiceover: Imagine that
you're sitting at home
and you're watching a
basketball game on your TV.
What you're actually seeing
are a bunch of still images
put in front of one another
and what you're doing is
taking those still images
and putting them together in your head
and basically telling yourself
that you're watching a fluid
realistic basketball game.
How was it that we're able to do this?
This is what the gestalt principles
basically attempt to address.
Gestalt principles.
The gestalt principles
basically seek to explain
how we perceive things the way we do.
Why is it that we don't tell ourselves
hey, the basketball is
just a bunch of pictures
but rather that it's a fluid realistic
representation of a basketball game?
There are several different laws
or principles that the
gestaltist came up with
and we're gonna look at each one of these
and look in an example.
Over here we're gonna look at the law
and over here we're gonna
write down the definition.
The first law or gestalt principle
is the law of similarity.
Law of similarity.
The law of similarity basically says
the items that are similar to one another
are grouped together by your brain.
Grouped together.
What does this mean?
Let's look at an example.
In this example you can see
that there are squares
and there are circles.
Basically there's a square
here, there's a circle here
and so on and so forth.
Maybe the first thing that you noticed
was that this image looks like
there were a bunch of
squares on top of one another
and a bunch of circles
on top of one another.
In other words your brain
naturally noticed a pattern.
It naturally notice that the squares
created these vertical
column and these ...
Sorry, these circles
created this vertical column
and these squares created
these vertical column.
Your brain naturally
organized this picture
in vertical columns
rather than in this
longer horizontal columns.
This is what the first
gestalt principle is saying
is that things that are
similar to one another,
so circles will be grouped
together by your brain.
The second gestalt principle
is the law of Pragnanz.
Pragnanz.
This basically says that reality
is often organized or reduced
to the simplest form possible.
Reality is reduced to simplest form.
What do I mean by this?
Let's look at an example again here.
Here you see five circles
that are juxtaposed on top of one another.
What the law of Pragnanz basically says
is that we look a this image
and what we do is break
it down into five circles.
Here's one circle, here's two circles.
Why is it that we don't break it down
into more complex shapes so
we could look at this object
and say okay, here's this weird diamondy
ovally shape over here
and then there's a semi circle over here,
and then we've got ...
Or you could say here's one line
and then here's another line.
We can look at this and break it down
into much more complicated
shapes but we don't.
We look at it and we just notice
that here's a circle
and here's another circle
and they're on top of one another.
We're basically looking at this
fairly complex set of lines
and reducing it down to its simplest form
which is five circles
juxtaposed on top of one another
rather than more complex shapes
that are coming together
to form this image.
The third gestalt principle or law
is the law of proximity.
Law of proximity.
This basically says that objects
that are close to one another
are grouped together.
Grouped together.
Let's look at an example
for the law of proximity.
Over here we see a bunch of circles.
When you look at this image
you naturally notice this pattern,
rectangular pattern of circles
and you notice this other
rectangular horizontal
pattern of circles.
These circles are grouped closer together
than this set of circles right here.
Basically your brain ...
Let me just erase this so you can see.
Why is it that we didn't just look at
this set of circles and
kind of put them together?
That's because these
circles are closer together
than these ones are.
There's more of a distance here
between the circles
than there is over here.
Smaller distance.
We naturally look at the distance.
We naturally look at how
close different objects are
and group the ones
that are really close
to one another together.
The next law is the law of continuity.
The law of continuity basically says
that lines are seen as
following the smoothest path.
Lines are seen as following
the smoothest path.
Let's look at an example.
In this example we see
again a bunch of circles.
When you look at these
you kind of notice that
there's this continuous flow
in this set of circles
rather than a flow this way.
That's because the angle here
is much less steep than this angle.
Your brain naturally
draws this line over here
and notices that these
circles are continuous
whereas these ones are a
little bit discontinuous.
Another thing that your brain does
when you're looking at this image
is that it basically takes these circles
and organizes them as one entity.
It puts them together
and notices a pattern that
hey, these circles are
forming this continuous line
and it puts together and
you group these circles
in one category, in one mental category
than these guys over here
that are in their own separate category.
That's what the law of
continuity basically says.
The final law or gestalt principle
is the law of closure.
Law of closure.
Basically this is just saying that
the objects grouped together
are seen as a whole.
We ignore gaps and complete contour lines.
Let me just write down the definition.
Objects grouped together
are seen as a whole.
Let's look at an example.
Over here we see this angle over here,
we see this angle, we see this
weird Pacman-looking semi circle thing.
Your mind naturally
fills in this triangle.
I don't know if you guys saw this
but there's like this triangle here.
There are gaps
and your mind naturally fills in the gaps.
It fills in the contour lines
and you perceive this triangle.
Let me just go ahead and remove that.
You can see that even though
there isn't actually any
triangles in this image
your brain is telling you
hey, there's a triangle.
You're noticing this triangle.
That's what the law of
closure is basically saying
is that your mind is filling
the missing information
to create familiar shapes and images.

### first.txt








The UX of AI




UX of AI
Artificial Intelligence shapes how we think, feel and behave. It drives the decisions that define our future.
We have the responsibility to use this potential for humane technology. Building an AI based on our diverse values and needs requires thoughtful design.
UX of AI is a primer on designing personal AIs that empower us. The technology deeply influences our lives, so everyone working on it should think about the user experience (UX) of AI. This site briefly summarises core design principles and links to more in-depth articles for each.




Start with the user
The technology you use should be guided by the user experience you want to achieve. Instead of diving headfirst into algorithms, think about how people do the task today. Figure out what’s valuable, and how you can enhance the experience. Along the way, you might find a solution without AI that is easier to build or understand. The same goes for marketing: Talk about the user benefits, not the AI technology.

Human-Centered Machine Learning
Set the right expectations
Since everything from self-driving cars to smoothie makers calls itself AI, expectations for what that means are all over the place. People will expect your AI to be both smarter and dumber than it is. Try to explain in plain language what your AI can do, and where its limitations are. Generally, under-promising and over-delivering is a good way to build trust. Over time, users will learn how to best integrate the AI into their workflow.

How to Meet User Expectations for Artificial Intelligence
Don’t Call AI “Magic”
Explain the results
AI is only useful if we understand its decisions. Ideally, the user should be able to trace any result back to the supporting data points. If that’s not possible, explain the basic operation of the algorithm. Lay out which data sources you use, and which qualities the AI focuses on. If you aggregate data from multiple sources, break them down to let the user reproduce the result. This information should be available as part of the user flow through a consistent interface.

Interpretable Machine Learning
The Building Blocks of Interpretability
The Dark Secret at the Heart of AI
Machine Learning is Very Much a UX Problem
Communicate your confidence
Users rely on your AI to make decisions. They have to understand the quality of results to trust them. If the confidence of your algorithm varies, indicate the confidence for each result. You could show a percentage, or try a more abstract visualisation (e.g. star ratings, colored indicators). For results that have multiple parts, break down the confidence for each. Additionally, consider showing multiple results ordered by confidence, and giving the user the final say.

Design in the Era of the Algorithm
Degrade gracefully
Designing for AI means designing for many different outcomes. When the input is clear and the answer certain, you don’t want the user to hesitate. Less confident results need to be presented differently. You could start by toning down the boldness of your visual design, or altering the layout and copy that frames the result. Above all, don’t be afraid to say when you don’t have an answer. It’s okay for an AI to fail, as long as you design for it.

Systems Smart Enough To Know When They’re Not Smart Enough
Know what not to automate
Not everything should be automated. Most tasks have some parts that are a good fit for AI, and ones that should be left to humans. Reasons not to use AI could be that the task requires abilities that are unique to humans (e.g. understanding emotions or motivations), that there is an intrinsic value to the manual process (e.g. it provides dignity or enjoyment), that it requires subjective evaluation (e.g. ethical or moral decisions), or that it has far-reaching consequences for an affected party.

Applications of Machine Learning for Designers
Design in the Era of the Algorithm
Keep the user in control
Instead of an AI that replaces humans, think of ways to amplify and augment our abilities. Don’t turn us into spectators. Ultimately, the user should be the one in control. That means being able to intervene, provide feedback, reverse bad actions and reward good ones. AI is more empowering when it works with the user, not for the user.

Human-centered Machine Learning: a Machine-in-the-loop Approach
The incredible inventions of intuitive AI
Using Artificial Intelligence to Augment Human Intelligence
Build trust over time
Be careful when introducing your AI to new users. Make sure it doesn’t require much existing personal data. Lean towards making suggestions instead of decisions. As your AI gets to know the user, you can automate more and ask for permission less. This gives the user time to understand how the AI works, and your algorithms can gradually learn along with them.

UX for AI: Building Trust as a Design Challenge
Help your users grow
Over time, the AI will have to adapt to changing behaviour of your users. This happens for each user, but also for your user base as a whole. Even the values and needs of our society change over the years. If your AI is stuck with what it has learned in the past, it will hinder progress. Even ideas that are universal today might not be part of the future we are working towards. Your AI should aim ahead of the curve, without forcing your own values on users.
Balance predictability and serendipity
Any personalised AI adopts the user’s bias. This is great for tasks that require predictability, where you need consistently effective results. But for other tasks, it limits our curiosity. It constrains us to options inside our comfort zone. Part of being humans is following your intuition off the beaten path, even if it might lead nowhere. You can tweak your algorithms to find the right balance, and maybe even design your interface to offer ways to escape the filter bubble.

Predictably Smart
Escape the personality cult
AI should feel at home with the rest of your product. Don’t try to make features feel “more human” through a witty personality. This will only confuse your users and set expectations you can’t meet. Instead, stick with your existing brand values.

Robots that act like humans are a waste of time
Avoid chatbots for single tasks
Chatbots are inherently limited in their capabilities, but they dress up as if they aren’t. The resulting uncertainty can frustrate or alienate users. In many cases, a few forms fields and buttons will be a better experience.

Bots won’t replace apps. Better apps will replace apps.
Principles of bot design
Prototype with real data and fake AI
Using real user data for early prototypes helps you build your machine learning model on the right assumptions. You can use the wizard-of-oz method to get the user experience right before actually building the AI.

The UX of AI (Google Design)
Work with everyone
AI impacts everyone. All of us should be part of the discussion of what we want AI to be. This means working with a diverse team. AI is shaped by the experiences and values of the people that make it. As we are still figuring out the foundations of AI design, collaboration is more important than ever. Data analysts, researchers, developers, marketers and designers all need to work together to build a cohesive product. Domain experts should be deeply involved in the design of both the ML model and the user interface. It’s your job to translate their expertise into a shared understanding that your team can build on.

Fair Is Not the Default
Why AI Is Still Waiting For Its Ethics Transplant
Share your process and intentions
Transparency extends beyond the product. Tell users how their data is gathered, handled and processed. Explain the choices you made when developing the model and designing the interface. Consider open-sourcing the AI of systems that make critical decisions. Sharing insights with your users and the community builds trust and goodwill.
Avoid collecting user data
Users own their data. Don’t collect it if you don’t need to (use on-device ML instead). When the user controls their data, they can decide what the AI learns. If you do need to collect data, explicitly ask for permission and explain what you need the data for. Once user data is on your servers, you have the responsibility to protect it. Determine exactly which data you need, how long you need to keep it and who needs access to it.

Guide to the General Data Protection Regulation



Made 2018, by Lennart Ziburskime@lennartziburski.com@ziburski
Privacy PolicyLegal Notice



AiUX Patterns |  Nudges | A type of Wayfinders

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersWayfindersNudgesSuggestionsTemplateNudgesNudgesAlert users to actions they can take to use AI in their existing toolsOverview:What happens when a tool can do a million things and the user is only aware of a handful of them?Â Nudges use progressive disclosure to help users identify AI and use its capabilities in ways that that they didn't know existed. They also help people get back to important actions so they can easily access them the next time. Look for distinct cases where these are appearing:As in-app clues - The capabilities of these tools go well beyond what an average user might think to use them for. Open chat experiences may give someone full control of the possibilities, but the other side of this is users may feel anxiety to know where to begin. Nudges help users get a feel for how a tool works, and show them the basic features and capabilities to give them confidence to explore on their own.Where they serve as in-product marketing - Companies are constantly everboarding users into new features. This will be especially true given the fast-moving nature of this technology and the lack of clear product strategy. Nudges can help users identify new features in a way that gives them the most value - whether the feature itself is new or the user finally reached a moment in the journey where it makes sense.Take MyMind's Serendipity feature, which is only available once you have saved 25 items. Not only does this make it more likely that a user will get benefit from the feature - it also helps the product developers ensure that the feedback and data they are responding to represents users who have reached a critical threshold of usage.Where they serve to sell you on the AI feature - In other cases, companies are taking a spaghetti development approach to AIâthrow everything against the wall and see what sticks!Â In these cases, the prompted actions are not contextually relevant to the user, or the user is not in a place to use them to positive effect. Notion's suggested Summary action results in a blank purple box when plopped into an empty page, with no affordance about what to do next.Think through the journey of your product or feature. What are the moments where AIÂ is most likely to be helpful?Â Which of those moments are most difficult to discover? Nudges are especially prominent in generative tools, like Writer.com, Jasper.ai, or Copy.ai, as well as knowledge management systems like Coda and Notion. They help users identify ways to use AIÂ to create value on top of content that already exists (e.g. find action items), to take care of mundane tasks (generate a summary of your meeting notes), or to remix the content and improve it ("make it shorter").Use this framework to identify the capabilities most useful to the user at any moment. If it's unlikely they will have discovered or mastered it yet, consider a nudge to show them how it works.Benefits:Contextual progressive disclosureThe best time to teach someone is when your assistance can help them achieve a goal they are actively striving towards. Affordances like nudges help people understand the technology by applying it to something they are already trying to do.Develop power usersAs AIÂ makes it easier to perform difficult or labor-intensive tasks faster, these prompts can open up features of your product they never knew existed, demonstrating new value and helping people get more out of your experiences. I'm waiting for the action that will take data and develop a pivot table for me, and then show me how they did it. Progressive hand holding, combined with guidance through chat interfaces can help you continuously onboard your users well into their journey.Anti-patterns:BloatYou don't need to show someone everything you can do on the first interaction. Make sure that the actions you are nudging don't lead to dead states. Consider setting guardrails to ensure people only unlock those features after they have hit critical mass or critical moments. These guardrails might be invisible, or examine how you might gamify them. Remember:Â AI is here to help, not just shine.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Suggestions | A type of Wayfinders

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersWayfindersNudgesSuggestionsTemplateSuggestionsSuggestionsSolves the blank canvas dilemma with clues for how to promptOverview:For as powerful as these models are, they suffer from the common 'blank canvas' problem. They can do so much but users donât know where to start. Sample suggestions help a user learn what they could ask the system to do, and keep the generative conversation moving forward as it progresses. Generally these appear in a list of 3-5 nudges that pre-fill the chat input when selected.This pattern is very similar to templates and nudges, other wayfinding devices. The difference here is that these are generally used in the open chat request type. Templates and nudges are more closely associated with writing and creative apps or more structured database tools.However despite the fact that this is now one of the most common patterns seen in the wild, IÂ hesitate to list its status as âset.â The affordance itself seems likely to stick around, but we should expect (at least, IÂ hope we can expect)Â changes to how the suggestions are formed and their relevance to the user.There is a natural cliff to the value of this pattern as it's currently implemented across most products. An internet joke is already forming around the insistence of AIÂ companies to let their chatbot plan your vacation. I just started a new ChatGPT conversation. Despite months of use at the premium tier, the four options it provides to me are completely irrelevant to my interests and my work:Four suggestions from ChatGPT, none of which have any relevance to me despite months of useUntil these products introduce personalization and smart routes based on the user's existing behavior, or learn from the user's existing data in their systems, they have diminishing returns as a useful pattern.That said, consider this pattern table stakes if you are designing a generative interface. For now, even if they have a cliff of usefulness, they get users starting to interact with the experience, which gives you the start of the data you need to improve it.âLesser patternIt's worth noting a related pattern emerging that may prove to be more useful:Â the prompt improver nudge. This is present in writing tools like Jasper, which also includes the standard icebreakers. If the first cliff a user faces is figuring out what they CAN ask the model, a fast follow is the dilemma of learning HOW to ask these questions effectively.Prompt improvers take a simple prompt written by a user (i.e. what should I pack for my trip to Paris) and return a stronger prompt that can be requested directly from the input box.As products improve onboarding and learn the users' preference, perhaps weâll see icebreakers get replaced with these types of learning affordances instead.Benefits:Zero cost to entryIf your goal is to simply get someone to see or feel how your product works, these prompts offer immediate gratification. The best examples learn from the user, and draw from the current state of the conversation.Seeds advanced tacticsI was surprised when I clicked on the suggestion in ChatGPT to "write a thank you note to my interviewerâ, and it re-formatted my prompt to read: Write 2-3 sentences to thank my interviewer, reiterating my excitement for the job opportunity while keeping it cool. Don't make it too formal. A newer user would never know that they could specify the length (2-3 sentences) or the tone (formal but cool) until they saw it in practice. Explore how icebreakers and "improve prompt" nudges can be remixed together, or follow up an ice breaker with the option to fill out the rest of a template with parameters to improve the user's results without stalling their speed.Anti-patterns:Irrelevant suggestionsThe first interaction can get away with feeling random. After that, users will expect them to learn their preferences, or they will ignore these elements completely. Once someone has seen useless suggestions a few times in a row, it cheapens the entire experience. Consider combining these with the ability for users to set and see their preferences, or provide fingerprints to the conversations from which you are drawing the suggestions.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Template | A type of Wayfinders

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersWayfindersNudgesSuggestionsTemplateTemplateTemplateStructured templates that can be filled by the user or pre-filled by the AIOverview:Templates are a specific type of Suggested Action that offer a simple way to onboard someone into a complicated product area. They take the affordances of nudges or parameters and turn the knob up to 11.Suggesting basic ideas like "give me ideas to help with my kids' homework" can be sufficient to help someone understand how a product works. It falls flat when the person doesn't know how to write more advanced prompts, or when nuances to how to use the product are difficult to grasp.Templates solve for both of these.In their simplest form, Templates make it easy to construct a familiar frame for doing a task. For example, you might already use Figma's Figjam to create a workspace for a retrospective with your product team. Sit down for a moment and think about the last thing like this you created. Now try to describe it in a way that is most likely to get an image generator to produce what you have in mind. Tough, right?Beyond saving you users the time it would take to create and arrange all of the boxes for this workspace, Figjam makes it so you don't have to describe it (or at least, not most of it). Set a few parameters and add a bit of information in the open chat, and figma will create it for you.This blend of parameters, suggested prompts, and open text give templates their power. Any tool that would require a long and specific prompt to get a predictable outcome would benefit from a template.They are very common in ai writing tools like Copy.ai. Users can select a template, fill out a few words (instead of writing a 500 word prompt), and the machine will generate a first draft.Hypotenuse's image generating tool also includes a template, using shortcuts to add parameters to make it easy for the user to generate their prompt.You can imagine other uses.Excel users could benefit from a template that prompts users with smart defaults about which columns or formulas to include.Recipe sites could ask a user to include or exclude specific ingredients (maybe based off weight loss goals or medical needs) along with an open text to describe their meal. Imagine being able to remix with a photo of food you saw in a restaurant but sculpted to your dietary preferences!One thing to consider is that templates aren't always necessary. If the task someone is going to perform is fairly simple, limit how many hoops they have to jump through the first time. Figjam offers another good example of this, giving people the option to adjust their template AFTER they have built it. Sometimes you have to know that you missed the mark before looking for help to get back on target.Benefits:True time savingsTemplates keep a user from having to spend time generating the perfect prompt. Consider how you could show the user your work upfront like copy.ai's templates, or share the generated prompt afterwards so they can tune it to their needs as they get more advanced.Blank slateSince these are just emerging as a pattern, there is a ton of blank canvas to play with as you shape an experience perfect for your users. How could you convert your existing product template library into smart templetized prompts?Anti-patterns:Inflated expectationsJust because a tool generates a complicated prompt for the user doesn't mean it's helpful. Be wary of oversetting expectations, especially if you require someone to do the work upfront. Consider constraining your template generation experience to optimize for the parameters you provide, and show the user their work in the form of the actual prompt so they can trace the input to the output.Limitations unknownBecause these rely on a familiar pattern of a recognizable template, when they don't work as expected it is immediately obvious to the user. Figjam can create a flow chart, but not a wireframe flow (which results in a flow chart). That was a let down. Provide extra context and be clear about what your templates can do. It's better to do one thing perfectly than three things poorly.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Auto Fill | A type of Interactive prompts

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersInteractive promptsAuto FillOpen chatRemix / BlendSynthesisAuto FillAuto FillMakes it easy for users to extend a prompt to multiple inputs at onceOverview:Users of spreadsheets and databases are already familiar with the concept of auto fill. Affordances in tools like Excel have made this capability easily discoverable for years.Itâs no surprise then that this familiar paradigm is being extended to include GenAI capabilities.Before: A user of Google Sheets might insert a date in the first cell of a column and be prompted to auto-fill dates for the remaining cells in order or based off of some formula Now: A user might tell the system to capture the date of incorporation for everyone company in a database, and rely on the model to return those dates automatically into the columnThis pattern is a clear example of the agentive nature of Artificial Intelligence to complete mundane tasks and save us time. The implications here are especially powerful when considering large data modeling of proprietary information, and the ability to connect people with information that has been available to them but buried.For example, imagine a Customer Success Manager creating a spreadsheet of their customers, and using Auto Fill to capture usage data, risk assessments, and the names of their key stakeholders in one place ahead of a Quarterly Business Review.Like other uses, this request type could be susceptible to mis-information. Trust markers like confidence indicators or fingerprints such as direct links to the scrapped sources should be considered to provide for easy human-review of the results.Benefits:Quick feedback loops of valueUnlike Open Chat, using Auto Fill as a request format makes it easy to draw the connection between the user's day-to-day tasks and the value that the model can provide to make their lives easier.Contextual wayfindingâAuto Fill generally starts with some structure in place, such as columns and headers in a database, and often references existing data. It can be easier to provide Wayfinding clues that feel somewhat personalized, compared to other request types. Think about what data a user is likely to have or be willing to share, and then consider offering Auto Fill through progressive disclosure as a means of getting the user started with the technology.Anti-patterns:Proprietary exposureIt's far more likely that someone would be sharing personal or propriety data in spreadsheets, compared to open-ended prompt generation. There is a reason large companies are restricting their employees from sharing this data with public LLMs. Consider the security implications of this feature.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Open chat | A type of Interactive prompts

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersInteractive promptsAuto FillOpen chatRemix / BlendSynthesisOpen chatOpen chatOpen ended prompt inputs that can be used in conversations or to tune resultsOverview:The "Open Text" pattern has become the cornerstone of interactive AI design, fostering a dialogue between users and AI systems. This pattern is characterized by its simple interface that feels familiar, inviting the user to converse with the model underneath. By using natural language, it doesn't take long for someone to get comfortable with the general interactivity. Where the pattern's limitations show is after the first few interactions, when someone doesn't know what to say next. There's a false perception that simple means easy. When someone knows what they are looking for then this way of interacting with the model makes sense. Â This could apply to use cases like a search portal, or customer support.However, when someone reaches an open chat bar and doesn't know what they are looking for (content generation sites, ChatGPT), it can lead them to feel crippled by the choices - the blank canvas. On top of that, prompting skills are not widespread. Most users will not understand how to craft a prompt to get the result they have in their head.Wayfinding patterns like ice breakers can help users get the conversation started. However, this pattern so far lacks affordances to help people construct better prompts that get them the outcomes they are looking for. As result, users report feeling frustrated by the lack of consistency, predictability, or perceived quality in what is returned.This pattern allows users to fully express themselves. They can use the words and framing that is more natural to them to construct a query. Open chat won't be going away, but we will likely see it evolve. Templates can help users craft better prompts without having the full skillsetNudges to improve your prompt can show users what "better"Â looks likePutting filters and parameters at the users' fingertips can make this more complicate feature accessibleThink past the initial interaction. What's step two?Benefits:Accessibility and Ease of UseâBy leveraging natural language processing (NLP), the Open Text pattern makes powerful AI tools accessible to users without specialized knowledge. This democratizes access to technology, enabling a broader audience to benefit from AI advancements.Flexible InteractionsâThe pattern supports a wide variety of user intents and queries, accommodating diverse needs and preferences. This flexibility enhances the user experience by providing personalized responses and solutions.Enhanced User EngagementâThe conversational nature of the Open Text pattern fosters an engaging and interactive user experience. It invites exploration and discovery, keeping users engaged and encouraging deeper exploration of the AI's capabilities.Rapid Iteration and FeedbackâUsers can quickly iterate on their queries based on the AI's responses, leading to a dynamic interaction that feels more like a conversation with a human than an interaction with a machine. This immediate feedback loop helps users refine their queries and better understand the AI's capabilities and limitations.Anti-patterns:Overload and ParalysisThe sheer openness of the interface can sometimes overwhelm users, especially those unfamiliar with the AI's capabilities or those who prefer more guidance. Without clear prompts or examples, users may struggle to initiate the conversation or articulate their needs effectively.Misinterpretation and AmbiguityâNatural language is inherently ambiguous. Without the constraints of structured input, users might phrase queries in ways that the AI misinterprets, leading to unsatisfactory or irrelevant responses. This can frustrate users and erode trust in the system.Privacy and Ethical ConsiderationsâGiven the open-ended nature of the interaction, users might share sensitive or personal information. This raises significant privacy and ethical concerns, necessitating robust data handling and privacy policies to protect user information.Dependency on Natural Language Processing AccuracyâThe effectiveness of the Open Text pattern heavily relies on the underlying NLP technology. Inaccuracies in understanding or generating responses can lead to user frustration, highlighting the importance of continuous improvement and refinement of the AI models.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Remix / Blend | A type of Interactive prompts

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersInteractive promptsAuto FillOpen chatRemix / BlendSynthesisRemix / BlendRemix / BlendCombine prompts with each other or other sources to get new resultsOverview:When you enter a prompt or request, the model looks for tokens of what you are asking for, and what you might be looking for in return. You can see this in action by using Midjourney's /describe command, which returns a list of tokens it pulled from the image you upload.Knowing this, it makes sense that sources can be remixed into new outputs. Essentially, the model is treating the other prompt, or the document, or the image, and so on as a source of tokens, and uses that along with other text to generate a new result.This leads to powerful capabilities, and a user doesn't need to know all that's happening below the scenes to take advantage of them."Remix or blend" prompts already have many different applications:Image generators allow users to combine different images, or introduce tokens from an image as an input source to your open ended promptContent editors allow users to direct the model to reproduce the original output with new parameters, like "shorter" or "more conversational"Document parsers summarize the information in a website, document, or attachment and allow users to "chat"Â with the textChatbots store a history of information from a conversation that a user can retrieve or ask about even if the conversation has moved onUsers can regenerate previous responses using the original prompts, or adding new informationRemixing prompts might be the most human element of Artificial Intelligence today. If you have ever found yourself humming a familiar tune with new lyrics, or finding connections between books that seem to have nothing to do with each other, you know the power of remixing. From a product and experience perspective, remixing can help resolve dead ends. When someone isn't getting the results they want out of a prompt, giving them the ability to share a reference point, or add new information helps them feel like they are back in control. Make these features clear and obvious. They let users play with the model. The more you play with something, the better you understand it.Benefits:Novel use casesAsking a remote bot questions in an open ended field becomes tiresome. This pattern opens up new ways of prompting that many users have not been exposed to yet. What if you could analyze today's newspaper and uncover the most consistent themes - allowing you to ask the bot questions about current events. What if you could upload an old resume and your current LinkedIn, and ask the bot to give you a new way of defining yourself in a turbulent world. This is a space to be creative.Make room for playâThe next big thing will start out looking like a toyâ said Chris Dixon in 2010. With remixing, users don't have to get something perfectly right the first time. Each input leads them closer to where they are going (or, alternatively, let's them explore things they never thought to explore). The nuance here is to know your use case. In professional settings, conformity is critical. Design for that end (add parameters and clues to help shape better prompts). In consumer settings, giving people the tools to play might the best formula for retention and delight.Anti-patterns:New inputs, new riskEach new set of information introduces more things for the model to process, and more risk for chaotic results. Look for ways to make this predictable for users. Specific prompts like "make shorter"Â give users clues for which parameters you will explicitly introduce. Better yet, give them a way to see the improved prompt. Teach them to become better at writing inputs, so you can focus on making the outputs of your model exceptional.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Synthesis | A type of Interactive prompts

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersInteractive promptsAuto FillOpen chatRemix / BlendSynthesisSynthesisSynthesisDistill or reorganize complicated information into simple structureOverview:As AIÂ tools evolve, they allow people who don't have a technical background to quickly find connections in large data sets that would have been difficult to find previously, or may have eluded them. The Synthesis prompt gives average people that super power.This prompt type is frequently seen in open canvas tools, where users may have a lot of data strewn across a document and need help collecting it and structuring it. Most of the whiteboarding tools (Figjam, Miro, etc)Â offer this in a similar way, suggesting this patten is becoming commoditized.Another application of thesynthesis prompt is to summarize long documents, or multiple documents. Many text editing tools are adding the ability to summarize documents or pull out key takeaways. Grain and other video tools offer similar functionality for voice files.There are many other applications where this prompt makes sense. Consider talking with data scientists at your company to learn how they approach large data sets for inspiration into how to make this more accessible to consumers.Benefits:Clear valueA user doesn't need to think of a clever prompt to enjoy this function. Most people can probably think of a recent moment where it would have been helpful to summarize or synthesize some big piece of informationOpen endedAfter this prompt is complete, it opens up many other paths for engagement. Perhaps you want to ask questions to the chatbot to learn more about the topics, or remix this with a previous exercise to see what changed. Asking AI to compare two articles through synthesis and then deliver a thoughtful debate between the two could help students with critical thinking. Simply asking yourself, "how might we use this" will help you vision a ton of ideas.Anti-patterns:Lack of caveatsWhen this is applied in a canvas setting, it may be difficult to warn users of the limitations of the AI in a way that breaks through. People could draw conclusions off of the synthesis that are not strong, or fail push back on the AI's organization. No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Filters / Parameters | A type of Tuners

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersTunersFilters / ParametersModel managementPersonal voiceFilters / ParametersFilters / ParametersLet users define constraints to improve the quality of their resultsOverview:The cliff of adoption for generative AIÂ is steep. Once users generally understand the nature of how to shape a request of the model, they begin to wonder how to get better results.Filters and parameters give users that control, while helping to teach the user more advanced prompting methods through progressive disclosure.Parameters are generally included ahead of time. For example, Midjourney allows users to include negative tokens through the use of the --not parameter, which reduce the sample set for the generative image to exclude images with that parameterFilters operate as parameters in the background, but tend to take the form of more familiar UIÂ elements, such as Perplexity's option to focus results to specific media, i.e. summaries of academic articles vs. discover videos to watch.Iâve listed this pattern as emerging despite itâs reliance on familiar paradigms. The way it can shift how users interact with and command models remains to be seen.On one hand, this opens up the ability for more agentive power on the part of users, in its ability to give specific and predictable commands to the model, and improve the consistency of results. For example, if the model were built to understand the parameters --source [[journal name]] or --cc [[by-sa]], a user could explicitly query information aggregated from a single academic journal, or information shared under a specific type of Creative Commons license, respectively.âCommercial considerationsThe commercial implications to this is massive, and itâs something I donât see many companies exploring yet. Could authors assign meta data to their work that allows it to be licensed to models that follow specific commercial terms, dictated by their set parameters?Could this information be traced through the fingerprints of the sources aggregated in existing LLMs?âToken intelligenceI also find this pattern fascinating based on its ability to help us better understand what is happening beneath the hood of models without being able to see the tubes and data themselves.For example, we know that tokens carry inherent bias due to its statistical relationship to other tokens. For example, if IÂ prompt ChatGPT and include the spoken parameter [[Take a deep breath]] within my request, there is evidence to suggest the model will return a better result. The reasons for this may be unclear so far, but by playing with different parameters, we can isolate parts of the system to study that arenât clear on the surface.âA more direct example of this can be seen in image generators. Combining the tokens ::Panda bear::Â and ::City::Â will return a bear in an urban environment surrounded by red pagodas and other symbols of Chinese architecture and culture. The tokens ::Bear::Â and ::City:: most likely return a bear in a more Western-appearing urban environment. Adding the parameter --no [[china]] to the first result brings it closer to the second. While this is obviously beneficial for people using prompting to generate specific results, it also represents a great tool to teach the ways that these models permeate bias into their results. Students, social workers, and so on can benefit from seeing this in action so they can understand the nature of inherent bias in predictive models. âIâm bullish on the ways designers can use parameters to improve the ethics and the results of the models they are designing, and the interfaces they are designing to interact with those models. âPutting it into useâ¦Filters are a familiar pattern that help users get the results they expect. Rather than relying on users to know how to use parameters, and which to lean into, consider allowing users to built their prompt filtered to specific parameters with a template, similar to Hypotenuse. If parameters are injected into the users' prompt, let them see it alongside the results to they understand that it was used, how it was used, and how to use it in the future.Benefits:Give users controlParameters allow users to set boundaries around a model to improve the quality and the accuracy of their results. This makes GenerativeAIÂ more useful in a commercial or academic sense, and gives agency to the individuals interacting with the data to maintain human-centerednessCommercial benefitsThe ethical concerns with training data for large models are well documented, but no obvious solution has emerged. Parameters might be a viable option. Fingerprints, meta data, and even blockchained relationships between data points could be used to combine or exclude training sources based on permissions, legality, personal data, etc. The GDPRÂ implications alone could be massive. How do we ensure that large swaths of consumers donât find themselves excluded from this technology because the companies building it didnât do a sufficiently good job of excluding their personal data?Â Parameters may offer a solution.Academic benefitsFor similar reasons, parameters can help control variables in academic contexts, helping to ensure predictable results. They can be used to expose hidden relationships across data that would have been missed, or exclude and control for variables.Educational benefitsBecause these tools give users the ability to control and manipulate the data set to a point, they can be used in a hands on way to teach how these models work to non-technical users. This could be especially useful in order to expose how bias and other patterns are captured in the dataset without us knowing, decreasing the risk of unexpected consequences from the use of these models in financial and policing settings.Anti-patterns:Blank canvas anxietyParameters, though helpful, are still a complicated feature of LLMs. Consider using Wayfinders to help people discover parameters to apply, or include them upfront as filters such as in the Perplexity interface. Don't rely on users understanding how this advanced feature works.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Model management | A type of Tuners

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersTunersFilters / ParametersModel managementPersonal voiceModel managementModel managementLet users specify what model to use for their promptsOverview:There are any number of reasons why a user may want to switch the model they are using for generationNewer models may be more prone to hallucinations and errors, since they have had less time to improve through feedback and QAOn the other hand, newer models are more likely to contain updated references, making them a good choice over older models for low-risk researchCommercially, they may not want to spend the money or tokens to use a newer model. Older models can be used to hone a prompt before it is applied to updated dataImage generators appreciate the different aesthetics they can tap into with different models, much like someone may choose to listen to a specific album on vinyl for its aesthetic vibe despite the higher audio quality of digital recordingsSome image generators enjoy remixing across models, capturing the aesthetics of one model, and then remixing it in a different model that might return more predictable results against their promptFor security reasons, users may avoid using certain models with delicate or proprietary data due to how the model provider handles this type of informationResearchers, engineers, etc may want to move between models to compare resultsWhatever the reason, we should assume that this emergent pattern will start to stabilize soon.If you are working on an interface that allows for this setting to be changed, consider who should have that permission to change it. Companies may wish to restrict or enforce the use of certain models for compliance reasons.Consider also that regulations related to AIÂ are in flux. Be prepared for entire models to be restricted from use in certain geopolitlcal areas do to their policies.Benefits:Shape the clayGiving something the ability to see and shape the operational stuff behind the scenes can help them become more advanced users of the tool. By exploring how different models affect their results, users can learn to tune their results to get predictable results across models, or take advances of differences within themCo-ownershipBy allowing users the ability to change their model, or even eventually upload their own, you will learn things about your own software interface that you couldn't easily uncover with this scale of use. Converting users into co-owners of the model through feedback and prompt results improves the model overall.Commercial opportunitiesWill we see a market for LLMs or SLMs?Â There every reason to think we will. Allowing users to manipulate models across prompts makes this a more viable possibility. Imagine someone being able to blend the model of a large research institution with their layer of information. Think of the ways this could be use in UXÂ research, academic, education, etc. Could they operate similar to how child themes operate on parent themes in large CRMs?Â Could people test a model before buying it? We should expect to see these business models emerge, and prepare our software and our experiences.Anti-patterns:Access does not absolve accountabilityJust because something is available doesn't mean its producer loses responsibility for the outcome. Think about how many beta products exist that lead to poor customer experiences and missed expectations because those limitations were not clear. If you do provide the ability for people to switch models, make it obvious to the user which model they are using, and if possible the differences between the two so they can expect how it will impact their experience.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Personal voice | A type of Tuners

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersTunersFilters / ParametersModel managementPersonal voicePersonal voicePersonal voiceEnsure outputs match your voice, tone, and preferences in a consistent wayOverview:For AIÂ tools to be used professionally, users need confidence that the output will be configurable and at least as consistent as what they would have produced by themselves. This could mean having the same tone of voice, for individuals and for brands. It could also mean including the same parameters or inputs into your prompts without having to write them over and over. Tone of voiceMost generative writing platforms offer the ability to define one or more "voice"Â that represent a brand or individual. It would not be good if the content produced by Marketing team A sounded completely different than Team B.Beyond the production efficiency, this has interesting use cases that could be explored in the future. For example, what might it look like to define your voice so your family can "talk" to you while you are away (perhaps, deployed or even in cases of death). How could we use this in research to understand how different personas might respond to a prompt.Personality is not the same as voice and tone, but the comparison isn't far off.âKey words and templatesMany tools are also allowing users and companies to store terms or information that can be drawn from in the future. For example, Copy.ai allows teams to save information about brands, products, trends, and so on and then introduce that context as a parameter into a prompt.if a company had a specific way of referring to their product offering, this could be helpful when generating content to cover a launch.Or, perhaps a user wants to set limitations about what should or shouldn't be contained in a response. ChatGPT allows users to set information that is included in prompts by default. For example, my bot is asked to tell me how it came up with an answer when prompted.âIf the use cases behind your product include someone using the result for commercial or professional reasons, voice and tone controls will likely be critical. Think ahead of the use cases to find ways to differentiate. Could you change the voice of the chatbot, borrowing from Character.ai?Â Or perhaps you want to instruct the bot to provide responses that are more or less technical by default.These are advanced parameters that will only make the technology more powerful, and more useful in commercial settings.Benefits:Fuller control for users There are only so many ways that open ended chat boxes built on the same model can be useful, especially in the enterprise. Personalization features make AI more useful, since they allow you to direct the technology at tasks that previously only a human could have performed.Small-business use casesThe marketing for these tools tends to be targeted at larger companies. The benefits might be most felt by smaller operators and teams. People who manage small businesses can spend their time on work that directly serves their bottom line.Non-commercial use casesHow could we use tools like this to serve other purposes?Â For example, there are dramatic differences in tone and language across cultures. Could this help people learning languages more quickly grasp conversational terminology and flow?Â Could this help people who have been injured or suffered neurological damage reconnect with themselves?Anti-patterns:Ethical considerationsYour voice and tone has been developed by humans working to generate that value for you or your business. The convenience of being able to replace them with a computer that mostly sounds like that raises serious ethical concerns. Not to mention, writing is just as susceptible to the Uncanny Valley effect of sound just non-human enough to feel off. These settings are great for fine tuning final drafts. That doesn't mean we should replace our human writers with robots.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Caveats | A type of Trust markers

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersTrust markersCaveatsControlsFeedbackFootprintsCaveatsCaveatsInform users about shortcomings or risk in the model or the technology overallOverview:How do we encourage responsible use of an emerging technology?Users span technical backgrounds. Familiarity with the limits of generativeAI, ethical concerns, or how to responsibly interpret results will vary widely. Companies are looking for simple ways to shield themselves from liability and push responsibility onto users.For less technical or younger users, these caveats are simple ways to signal limitations to the product. In that regard, itâs not much different than a warning label on your hair dryer telling you not to use it in the bath.At the same time, these models are complex and rapidly evolving. It may be sufficient to smack a caveat on as a first step. Generally though, companies will need to find better ways to help users navigate the nuances of these models if they want to provide them to a mainstream audience.Benefits:Encourages responsible usageReduces the likelihood that users could mistake the modelâs response as absolute truth.Expands usageWhen it is clear to users that beta models have limitations, developers may feel more comfortable expanding availability. That's true in this case as well. The more users who have access to the model, the more perspectives and experiences will feed its improvement.Anti-patterns:Doesn't protect companies from hallucinations or weird behaviorAs models are tuned, there are still many unknown unknowns that could impact the experience a user has with the technology. AirCanada recently had to provide a refund to a customer, despite it being against their policy, due to their chatbot providing inaccurate information. A caveat is not sufficient to remove responsibility.Companies could use these to skirt ethical responsiblityIn the race to get AIÂ products to market, companies are not prioritizing crafting well-constructed experiences. Chatbots that quickly turn racist, image generators that ignore entire races, aggregated sources with inaccurate dataâthese are recent examples of this technology gone awry. Caveats are a bandaid, and not a suitable substitute to creating thoughtful experiences. There is an ethical imperative for companies to think about how to ensure responsible use and interpretation of the content they provideNo items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Controls | A type of Trust markers

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersTrust markersCaveatsControlsFeedbackFootprintsControlsControlsManage the flow of information or pause a request mid-stream to adjust the promptOverview:Response times may vary depending on the size or complexity of the request. As a result, a pattern has emerged and is quickly standardizing to let a user control the output.The most common control is the stop icon, which allows users to pause a request mid-fetch. We might presume that there is a business case here to reserve server time for requests that people want to make. From a UX perspective, this saves the user time by allowing them to stop and re-set their prompt if they are not getting the results they expected.The fast forward button allows users to continue their request if it times out. The use most frequently seen here is where a model might return up to a certain amount of information, presumably to once again save server processing time. For example, if a user asks for 100 blog posts titles, the model might return 20, leaving it up to the user to click the next button in order to retrieve the final 80. There's a parallel here to the âAre you still watching?â prompt you might get after a few hours binging Netflix.The play button is used to represent that a request is ready to run. It is interchangeable with a paper airplane or sparkles.Benefits:Gives users control over the flow of informationâThis may by the first moment where it âclicksâ to them that they are directing the botSaves the user time and frustrationAvoids the equivalent to the âspinning beachball of deathâ effect caused by latencyConsider how you might combine other patterns to maximize user empowermentJoining this with Wayfinder patterns can help users improve their prompt if they didnât get what they were looking for the first time. For example, when a user clicks the stop sign, that could be a signal to show a nudge or suggestion on how to improve it. Parameters could also be introduced here.Anti-patterns:Remain consistentUsers may get frustrated if the stop a prompt and start it again expecting to get a similar result. Variances can cause the second response to be quite different than the first, which is confusing.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Feedback | A type of Trust markers

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersTrust markersCaveatsControlsFeedbackFootprintsFeedbackFeedbackSignal expectation gaps or errors in the model â but is that clear to the user?Overview:Giving users the ability to rate their interactions has become a table stakes pattern in service and conversational experiences (think chat support, or Uber).On its face this pattern is rather tame and familiar. Its potential risk factor may be buried and hidden to the user. What happens after they rate their experience?In scenario A, the user knows they have been interacting with the model. A thumbs-up or down signals to prompt engineers whether the design of the model itself is effective. This could be especially helpful for proprietary internal models or secure models trained on sensitive data.In scenario B, the user doesnât know if they are interacting with a human or a model. OR they donât know what experiments the company is running to potential replace human engagement with digital engagement. Even an average person could feel put off by the ethical implications from that lack of transparency.This pattern is fairly standardized, as thumbs or stars, with a few outliers. We should not expect it to change much.What we should expect to see, or at least hope to see, is more information about what happens based on the user's rating, and transparency to the user about whether they are rating the response to their request, or the model as a whole.Benefits:Improves the overall experienceEngineers and designers get realtime feedback into situations where the model is failing to product its intended results.Empowers usersSo long as the feedback is being used to make improvements to the prompter's experience, this pattern allows users to operate as contributors to the model's overall strength.Anti-patterns:Ethical riskIf some cases this information is used to determine how well the model is performing at replacing human labor (as opposed to simply tuning the model itself). People could be upset to learn that their input is helping to displace people from jobs. Companies should be upfront about how they are using this data.No immediate value If no additional affordance is provided to improve the user's experience, companies are collecting user data with no immediate or cathartic value returned in exchange [âif the service is free, you are the productâ]. Avoid this by offering suggestions to the user for how to get better results, or teach them how to improve their results by giving their feedback directly to the bot.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Footprints | A type of Trust markers

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersTrust markersCaveatsControlsFeedbackFootprintsFootprintsFootprintsGive users the ability to trace the relationships between sources and resultsOverview:Working with generative AI can feel like wandering through a maze in the dark. Even if you start to find your way, you often donât know how you got there in the first place.Footprints as a term represents an array of emerging patterns to trace the relationship of sources and results through different requests and results.AI-generated Google results are shown beside the sources that were scrapedTools like Midjourney include the dominant tokens in the metadata of the images they produceChats can be seeded with requests to provide annotations and footnotes that add context to the result.That said, we donât know what we DONâT see: the traces left behind on the data that we donât have the technology or patterns to view yet.Footprints relate closely to Filters/Parameters, in that both represent ways of looking at the data at the meta level. Where parameters can precipitate trends in data that werenât clearly visible, footprints are the clues left behind that parameters can sniff for. They are like the scent of data, but users still need to know to dig.In a private or secure dataset, footprints help us find relationships between data to control for variables and find important relationshipsIn large models, or less secure databases, they can help protect against the inadvertent exposure of personal data, intellectual property, or biasIn products likely to be scrapped for their data, proactively considering the footprints of our information make for more safety and more trustworthy experiencesâLegal, ethical, and commercial implicationsWe are likely to see more attention paid to these as legal challenges around LLMs mount, and users become more savvy.Consider for a moment that you were using a chat interface to request information about reproductive rights in your state. While your personal information, IP address, and so on might be secure, you leave other fingerprints about you behind. For example, let's say you search for information about a healthcare provider near your home, or you asked for doctors within your healthcare network. It's not hard to assume someone who wanted to connect your behavior to you would have more clues to work with than you realize.Designers can proactively stave off risk by looking for ways to isolate metadata and connect results to their sources. Any tools that allow for the scrapping of personal data of any kind should be up front about this, and avoid the dark matter patterns of nesting these settings deep within user option panels.When designing interfaces to allow people to interact with Artificial Intelligence, look for ways for people to browse intelligently. Consider going beyond a basic caveat, and provide warnings when people are including personal information in their prompts. Consider allowing users to see the map they are leaving behind and delete personal data.People can only change behavior they are aware of. More intelligent, ethical, and trustworthy results can help to reinforce intelligent use of AI, thus expanding commercial, academic, and other use cases and making it more likely that the technology can be used for good.Benefits:See the matrixFootprints allow users to see what they left behind, or understand the path the model took to get to their response. This builds trust in the model and help users improve their results through personal feedback loopsVerification at your fingertipsWhen users can view the sources or logic that led to a generation by AI, it is easier to follow those paths to the original sources and ensure the data presented by is accurate.Anti-patterns:All or nothingWhen an AI returns sources, this can have a cognitive bias effect and cause someone to think they are seeing the full picture, when it fact some other information may have been intentionally or unintentionally withheld by the model. This matters in situations where the user may be using the response to form an opinion or understanding. This can go too far in the other direction as well(see Gemini's false equivalence of Elon Musk and Hitler). The trick may be teaching users how to maintain skepticism and ask follow ups to a bot.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Color scheme | A type of Identifiers

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersIdentifiersColor schemeIconographyNameColor schemeColor schemeVisual cues to help users identify AI features of contentOverview:How do you know if you are interacting with a person or a model?Â How can you distinguish between information returned via a prompt request from information that was manually entered?Color has emerged as a helpful signal to help users identify AI products and features. There is by no means a set color scheme, and this pattern is likely to evolve more as high-performing products start to break free of the pack and differentiate. Where there is a degree of uniformity, two colors stand out: purple and green.Purple is the more dominant of the two. It is present in a majority of products boasting AIÂ features, which could be the result of many patterns converging at once:Â Trends in modern web design driven by the aesthetic style popularized by Linear, which heavily features the color purpleEarly uses in design-centered AIÂ tools like Diagram's Magician plugin for FigmaThe need for a color that wasn't commonly used elsewhere in interfaces but still felt familiar (purple being a close cousin to the ubiquitous blue)The other color, green, probably has more predictable roots since it is the dominant brand color of ChatGPT, the largest player in the space. Green and purple are also complementary to each other on the color wheel, so the pairing shouldn't be surprising.Should you use purple or green, or something else? That's up in the air, and up to you.Some companies are opting to rely on iconography over color, extending their brand color to AIÂ applications instead. ReWord is an example of a company marching to the beat of their own drum. Grammarly benefits from their existing brand color, green, being in the popular palette. However unlike almost anyone else in their space, they rely on colorful iconography instead of the more common flat sparkles patterns, making the departure from the purple/green color palette feel striking.Perhaps this is because these two companies are in a highly commodified space, where creative brand and aesthetics styles are necessary to stand apart. We will need to watch patterns emerge in other categories before we can draw a definitive conclusion.Itâs likely weâll continue to see brands play around with balancing consistency and their own color schemes. Purple is probably not going away, but it may fade in the background. Brands whose entire product revolve around AI,Â or in competitive spaces might be the first to develop their own aesthetic.âLesser patternsThere are some smaller trends emerging related to color. Gradients are used in many sites, though that may have as much to do with an interest in appearing modern as anything else (RIP Flat Design, and good riddance). Google is one player to watch, for obvious reasons due to its size but they also are playing with color in ways that arenât echoed by other sites as far as IÂ can tell. In their AI-generated search results, conversations alternate between different hues of pastel for each response in the search window. This has the combined benefit of separating conversations from each other while still contrasting with the rest of the search results page.Benefits:Pattern convergenceSince the entire market seems to be catching onto the purple trend, using it to distinguish your product or feature is a safe way to signal the technology youâre using. This is beneficial from a marketing perspective, but also helps consumers confidently navigate their options and identify when this technology is present.Visual contrast as affordanceColor increases trust as users are able to identify which information was generated by them or other humans, and what was generated by the model. Using different colors in a similar palette, like Google's pastels, can help users distinguish between conversations while maintaining clarity of what is machine generated.Anti-patterns:AccessibilityColor alone is not sufficient as an affordance due to differences in physical or cognitive ability such as colorblindness. Combine color with text-based or iconographic indicators to help users navigate information by source and type.Grades of AIGiven how quickly this technology is moving, a single color may not be a sufficient affordance to differentiate between models and other factors that could impact the strength of the results. Consider a different visual treatment for results returned from a beta model, or a model trained on more sensitive data.Over-saturationWith everyone using the same color, it can be difficult for consumers to recognize one product from the next. If you want to stand out, consider playing with other colors while relying on alternative indicators of AIÂ presence.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Iconography | A type of Identifiers

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersIdentifiersColor schemeIconographyNameIconographyIconographyImages that convey the form the AI takes in a productOverview:While it seems like the sparkling stars icon is everywhere as a visual indicator of AI's presence, the iconographic language of AIÂ actually appears to be solidifying around three general metaphors:â¨ Sparkly stars are the most ubiquitous. These tend to represent AIÂ as a feature (such as on marketing pages or in buttons), and also distinguish information that has been generated by or with AI. This icon started appearing around 2020 as video enhancement features became more common, possibly owing to its suggested meaning of magic or enhancement[A lesser pattern of a magic wand ðª shows up occasionally, but it's not clear if this is an alternative metaphor to the sparkly stars or carries its own meaning]ð® A glowing orb appears to represent text or chat interfaces specifically. The most direct inspiration tends to come via the OpenAIÂ logo, but some of the examples with a rainbow gradient border are closer in form to the Siri orb (another chat interface reference)ð¤ Robots tend to be used literally to represent bots or agents. The popularity of the GitHub CoPilot bot is likely driving this, with newcomers like the design tool Musho.ai following in its footstepsAs the use cases for this technology evolve, we will likely see the iconography evolve as well. However, like the hamburger menu or the save disk icons, while there may be some debate at the edges we are probably going to live with these icons for a while since users have gotten used to them.Overall this isn't a bad thing. Consistent iconography leads to predictability and trust by users and consumers.Where we may see issues pop up relates to the unknown ways that the technology will evolve, and whether these metaphors hold. Will we start to see signifiers or watermarks on products built on OpenAI's models or Gemini's models?Â How will that change the icons associated with them, or those that aren't?Users may be able to distinguish CoPilot's look, similar to how Octocat took on a life of its own, but will they be able to distinguish between multiple 24x24 px robot icons, or will we see a convergence?For now, sticking with the sparkles may be the safest bet.Benefits:Pattern convergenceVisual language tends to converge faster than UI or Interactive patterns, so it is no wonder we are seeing the sparkles emoji pop up in everything from small plugins to Google's flagship model Gemini. Using familiar iconography is a safe way to help users pinpoint the features in your product that use AI and the content generated from its models. Emerging languageIf we continue to see these three iconic patterns used in a literal way, it may help users distinguish between different types of AIÂ products and interactions. Try and identify which youâre building, and look for other common patterns to make it feel safe and comfortable.Anti-patterns:MisrepresentationThe sparkles and robot emojis are used frequently in other use cases as well. Make sure you arenât using these icons in a way that could lead someone to think some feature does something it does not. Use them consistently across your ecosystem.No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
AiUX Patterns |  Name | A type of Identifiers

HomeAboutContactâ All patternsAll patternsIdentifiersWayfindersInteractive promptsTunersTrust markersIdentifiersColor schemeIconographyNameNameNameHow do we refer to the AI?Overview:What do we call this thing?Some companies have started to give an actual name to their AIÂ bot (Fin from Intercom is a good example). Even if you extend your brand to cover your assistant, we still need a common term to refer to the technology of AIÂ itself.Is it a bot?Â AI?Â ChatGPT?Â An Agent?Â Something else?Users deserve to know what or who they are interacting with. In environments where a user is knowingly interacting with AI, this may not be as critical. However, consider being onboarded into a new company, and you learn you are interacting with a third-party AI agent, not someone on your team. Or, perhaps you are sharing personal information in a therapy session and you realize the "person" on the other end is AI. This is a ambiguous pattern. We should expect to see companies play around with proprietary names, possibly keeping terms like AIÂ associated with the bot to make it clear who the person is. Here are a few examples in the wild today:Character.ai:Â Gives each character a name (Ask Socrates)Klarna:Â AIÂ Assistant (Ask our AIÂ assistant)Notion:Â AI (Ask AI)ChatGPT:Â ChatGPTÂ (Ask ChatGPT)Jasper:Â Jasper (Ask Jasper)Leena:Â Leena.aiGithub:Â Copilot (Ask copilot)As naming conventions sort themselves out, a smaller pattern is emerging that adds a badge to the AIÂ or the interface to making it clear when you are interacting with AI versus a human.Intercom puts this badge inline with chats from the AIÂ Agent. Character.ai follows the same lead. Leena adds the detail at the bottom of the screen. This pattern is not widely adopted yet, but will likely expand to make AIÂ interaction more transparent, to protect companies against liabilities, and to make users feel more comfortable.Benefits:Brand association There is no doubt that assistances like Siri and Alexa have become synonymous with their companies. Giving a character to your AIÂ can make it feel more inviting while creating an emotional connection for consumers, helping to build your brand.AIÂ recognitionNames can help users recognize whether they are speaking. Using iconography, a personal name, and other identifiers can help users understand the difference between talking with a bot and a human. This could make the handoff of conversations from bot to human feel more natural for users, and give them cues for how to interact.Anti-patterns:Uncanny ValleyHuman-like names can be confusing. Avoid situations where a user would not know if they are talking to a bot or a human by adding other cues into the interface. No items found.What examples have you seen?Share links or reach out with your thoughts?Name *Email Address *Message *Thanks for reaching out!There was an error submitting your form. Please check that all required fields are complete.Â© Emily Campbell 2024 | Sharable under CC-BY-NC-SA | Contact
Law of Similarity | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allLaw of SimilarityThe human eye tends to perceive similar elements in a design as a complete picture, shape, or group, even if those elements are separated.The human eye tends to perceive similar elements in a design as a complete picture, shape, or group, even if those elements are separated.TakeawaysElements that are visually similar will be perceived as related.Color, shape, and size, orientation and movement can signal that elements belong to the same group and likely share a common meaning or functionality.Ensure that links and navigation systems are visually differentiated from normal text elements.OriginsThe principles of grouping (or Gestalt laws of grouping) are a set of principles in psychology, first proposed by Gestalt psychologists to account for the observation that humans naturally perceive objects as organized patterns and objects, a principle known as Prägnanz. Gestalt psychologists argued that these principles exist because the mind has an innate disposition to perceive patterns in the stimulus based on certain rules. These principles are organized into five categories: Proximity, Similarity, Continuity, Closure, and Connectedness.SourceFurther ReadingGestalt Principles of Design — SimilarityChris ButlerSimilarity Principle in Visual DesignAurora Harley | Nielson Norman GroupThe Law of Similarity - Gestalt PrinciplesInteraction Deisgn Foundation | Mads SoegaardDesign Principles: Visual Perception And The Principles Of GestaltSteven Bradley | Smashing MagazineUse Gestalt Laws to Improve Your UXSabina Idler | Usabilla BlogBuy Large Format Poster
Download free posterRelatedLaw of Common RegionElements tend to be perceived into groups if they are sharing an area with a clearly defined boundary.Law of ProximityObjects that are near, or proximate to each other, tend to be grouped together.Law of PrägnanzPeople will perceive and interpret ambiguous or complex images as the simplest form possible, because it is the interpretation that requires the least cognitive effort of us.NextLaw of Uniform ConnectednessBack to Top© Jon Yablonski 2024ContactOval 9 CopyRectangle 15triangleCombined ShapeOval 3Serial Position Effect | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allSerial Position EffectUsers have a propensity to best remember the first and last items in a series.Users have a propensity to best remember the first and last items in a series.TakeawaysPlacing the least important items in the middle of lists can be helpful because these items tend to be stored less frequently in long-term and working memory.Positioning key actions on the far left and right within elements such as navigation can increase memorization.OriginsThe serial position effect, a term coined by Herman Ebbinghaus, describes how the position of an item in a sequence affects recall accuracy. The two concepts involved, the primacy effect and the recency effect, explains how items presented at the beginning of a sequence and the end of a sequence are recalled with greater accuracy than items in the middle of a list. Manipulation of the serial position effect to create better user experiences is reflected in many popular designs by successful companies like Apple, Electronic Arts, and Nike.SourceFurther ReadingSerial Position Effect: How to Create Better User InterfacesEuphemia Wong | Interaction Design FoundationThe Serial Position Effect: Why ABC and XYZ Stand Out the Most Among All the AlphabetsAbhishek Chakraborty | Medium.comPsychology in Design (Part 1)Andri Budzinskiy | Medium.comSerial Position Effect on WikipediaWikipediaBuy Large Format Poster
Download free posterRelatedPeak-End RulePeople judge an experience largely based on how they felt at its peak and at its end, rather than the total sum or average of every moment of the experience.Miller’s LawThe average person can only keep 7 (plus or minus 2) items in their working memory.Von Restorff EffectThe Von Restorff effect, also known as The Isolation Effect, predicts that when multiple similar objects are present, the one that differs from the rest is most likely to be remembered.NextTesler’s LawBack to Top© Jon Yablonski 2024ContactRectangle 15triangleOval 9 CopyOval 3Combined ShapePeak-End Rule | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishPeak-End RuleA closer look at how our feelings during the most emotionally intense moments and at the end are averaged in our minds and heavily influence how we assess an overall experience to determine if we’d be willing to do it again or recommend it to others.April 20, 2020UXpsychologycognitive biasThis article was originally published on UX Collective.People judge an experience largely based on how they felt at its peak and at its end, rather than the total sum or average of every moment of the experience.Key TakeawaysPay close attention to the most intense points and the final moments (the “end”) of the user journey.Identify the moments when your product is most helpful, valuable, or entertaining and design to delight the end user.Remember that people recall negative experiences more vividly than positive ones.An interesting thing happens when we recollect a past event. Instead of considering the entire duration of the experience, we tend to focus on an emotional peak and the end, regardless of whether they were positive or negative. In other words, we remember our life experiences as a series of representative snapshots rather than a comprehensive timeline of events. Our feelings during the most emotionally intense moments and at the end are averaged in our minds and heavily influence how we assess the overall experience to determine if we’d be willing to do it again or recommend it to others. This observation, known as the peak–end rule, strongly suggests we should pay close attention to these critical moments to ensure users evaluate an overall experience positively.OriginsWe’ll start with taking a look at the origins of the peak-end rule, and the visionary psychologists that identified it.Initial EvidenceEvidence for the peak–end rule was first explored in the 1993 paper “When More Pain Is Preferred to Less: Adding a Better End” by Daniel Kahneman et al.1 They conducted an experiment in which participants were subjected to two different versions of a single unpleasant experience (Figure 1). The first trial involved participants submerging a hand in 14 °C water for 60 seconds. The second trial involved participants submerging the other hand in 14 °C water for 60 seconds, then keeping it submerged for an additional 30 seconds as the water was warmed to 15 °C. When given the choice of which experience they would repeat, participants were more willing to repeat the second trial, despite it being a longer exposure to the uncomfortable water temperatures. The conclusion by the authors was that the participants chose the longer trial simply because they preferred the memory of it in comparison to the first trial.Figure 1. Graphic depicting experiment conducted during “When More Pain Is Preferred to Less”.Subsequent StudiesSubsequent studies would corroborate this conclusion, beginning with a 1996 study by Kahneman and Redelmeier2 which found that colonoscopy or lithotripsy patients consistently evaluated the discomfort of their experience based on the intensity of pain at the worst and final moments, regardless of length or variation in intensity of pain within the procedure.A later study by the same researchers3 expanded on this by randomly dividing patients into two groups: one that underwent a typical colonoscopy, and another that underwent the same procedure in addition to having the tip of the scope left in for three extra minutes without inflation or suction. When asked afterward which they preferred, patients who underwent the longer procedure experienced the final moments as less painful, rated their overall experience as less unpleasant, and ranked the procedure as less aversive in comparison to the other participants. Additionally, those that underwent the longer procedure were more likely to return for subsequent procedures — a result of these participants judging the experience positively because of the less painful end.Psychological Concept: Cognitive BiasesTo understand the peak–end rule, it is helpful to have an understanding of cognitive biases. The topic warrants an entire book of its own, but here I’ll just give a brief introduction in the context of the peak–end rule.Cognitive biases are systematic errors of thinking or rationality in judgment that influence our perception of the world and our decision-making ability. First introduced by Amos Tversky and Daniel Kahneman in 1972,4 these mental shortcuts increase our efficiency by enabling us to make quick decisions without the need to thoroughly analyze a situation. Instead of constantly becoming paralyzed by the process of mental examination every time we must make a decision, we can rely on these unconscious automatic responses to help expedite things, only engaging in heavier mental processing when necessary. However, cognitive biases can also distort our thinking and perception, ultimately leading to inaccurate judgment and poor decisions.Perhaps you’ve tried to have a logical discussion about a polarizing hot-button issue with someone else, only to discover it was incredibly difficult. The underlying reason for this can quite often be attributed to the fact that we attempt to preserve our existing beliefs by paying attention to information that confirms those beliefs and discounting information that challenges them. This is known as confirmation bias: a bias of belief in which people tend to seek out, interpret, and recall information in a way that confirms their preconceived notions and ideas. This is but one of many common biases humans are susceptible to on a daily basis.The peak–end rule, also a cognitive bias, is known as a memory bias because it impairs the recall of a memory. We remember intensely emotional events more than less emotional events, and this has an effect on how we perceive an experience: we recall not the sum of how we felt throughout the experience but the average of how we felt during the peak emotional moments and at its end.The peak-end rule is related to another cognitive bias known as the recency effect, which states that items near the end of a sequence are the easiest to recall.ExamplesOne company that demonstrates proficiency in understanding how emotion impacts user experience is Mailchimp. The process of creating an email campaign can be quite stressful, but Mailchimp knows how to guide users while keeping the overall tone light and reassuring. Take for example the moment when you’re about to hit Send on an email you’ve crafted for your audience’s inboxes. This emotional peak moment represents the accumulation of all the work that has gone into that email campaign, compounded by the potential fear of failure. Mailchimp understands this is an important moment, especially for first-time users, so it goes beyond presenting a simple confirmation modal (Figure 2). By infusing a touch of brand character through illustration, subtle animation, and humor, the tool defuses what could potentially be a stressful moment. Freddie, the company’s emblematic chimp mascot, hovers his finger over a large red button as if to imply he is eagerly awaiting your permission. The longer you wait, the more nervous Freddie seems to get, which is evident through the beads of sweat that appear on his hand and subtle shaking.Figure 2. Mailchimp’s email campaign confirmation modal (source: Mailchimp, 2019)Mailchimp’s artful capitalization on key moments doesn’t end there. Once the email campaign is sent, users are redirected to a confirmation screen (Figure 3) providing details pertaining to the campaign. There’s also an Easter egg on this screen that validates the user’s hard work: Freddie gives them a high five, as if to reassure them of a job well done. These details reinforce the feeling of accomplishment and enhance the experience, creating positive mental snapshots for people that use this service.Figure 3. Mailchimp’s email sent screen (source: Mailchimp, 2019)Positive events aren’t the only things that have an impact on how people feel about a product or service. Negative events also provide emotional peaks and can contribute to a user’s lasting impression of an experience. Take for example wait times, which can have a profound effect on how people perceive a product or service. Ride-sharing company Uber realized that waiting was an unavoidable part of its business model, and sought to reduce this pain point by focusing on three concepts related to wait time: idleness aversion, operational transparency, and the goal gradient effect.5 Uber Express POOL customers (Figure 4) are presented with an animation that helps to keep them not only informed but also entertained (idleness aversion). The app provides an estimated time of arrival and information on how arrival times are calculated (operational transparency). It clearly explains each step of the process so customers feel that they are continuously making progress toward their goal of getting a ride (goal gradient effect). By focusing on people’s perceptions of time and waiting, Uber was able to reduce its post-request cancellation rate and avoid what could easily become a negative emotional peak while using their service.Figure 4. Uber Express POOL (source: Uber, 2019)Technique: Journey MappingOne handy tool for identifying the emotional peaks of end users throughout an experience is journey mapping. This qualitative exercise is invaluable for visualizing how people use a product or service through the narrative of accomplishing a specific task or goal. Journey mapping results in the creation of a design artifact (Figure 5) that not only helps designers and project stakeholders align to a common mental model, but also creates a deeper shared understanding of the customer experience and aids in identifying the challenges and opportunities present within an experience.Figure 5. Example journey mapLike all design exercises, journey maps can and should be tailored to the purposes and goals of the project. That being said, they’ll usually contain some key information:LensThe lens of a journey map establishes the perspective of the person the experience represents. It usually will contain the persona of the end user, which should be predefined based on research on the target audience of the product or service. The lens should capture the specific scenario that the journey map is focused on. This scenario may be real, or it can be anticipated in the case of a product or service that hasn’t been launched yet. Finally, the lens usually describes the expectations of the persona in that scenario. For example, Jane (persona) is using a ride-share service app to order a ride (scenario) that she expects to arrive at her exact location in 10 minutes or less (expectation).ExperienceThe next part of a journey map is the experience section, which illustrates the actions, mindset, and emotions of the end user mapped across a timeline. Starting from the top, the experience is first organized into high-level phases. Next are the actions, which define the steps that the end user must take within each phase to accomplish their task or goal. Following the actions is information pertaining to the mindset of the end user during the experience. This can vary based on what insights the journey map is aiming to uncover; it’s essentially a contextual layer of information that provides a deeper view into what the customer is thinking during each phase.Typical information captured within this layer includes general thoughts, pain points, questions, or motivations that originate from research and user interviews. Finally there’s the emotional layer, which is usually represented as a continuous line mapped across the entire experience and captures the emotional state of the persona during the experience. This layer is especially significant with regard to the peak-end rule, because it captures the emotional peaks of the customer.InsightsThe last part of a journey map is the insights section, which identifies the important takeaways that surface within the experience. This section usually contains a list of possible opportunities to improve the overall experience. It also typically contains a list of metrics associated with improving the experience, and details on the internal ownership of these metrics. Going back to our ride-share example, providing real-time information on the location of the vehicle after the ride is ordered can help reduce the pain point of waiting (opportunity). That feature will need to be designed and developed by the product team (internal ownership) and can be monitored according to post-ride ratings (metric).Key Consideration: Negative PeaksIt is inevitable that at some point in the lifespan of a product or service something will go wrong. There might be a server failure that has a ripple effect and leads to service outages, or a bug might open up a security vulnerability, or a design decision might be made that fails to consider all customers and leads to some unintended consequences. All of these types of situations can have an emotional effect on the people that use your product, and ultimately inform their overall impression of the experience.Such setbacks can also be opportunities, however, if the right fallbacks are in place. Take for example the all-too-common 404 error page. When a web page can’t be found users may become frustrated, creating a negative impression. But some companies use this as an opportunity to create a rapport with their customers and enforce their brand personality by leveraging some good old-fashioned humor (Figure 6).Figure 6. Various 404 pages that use humor and brand personality (sources: Mailchimp, Ueno, GitHub, and Pixar, 2019)Our memories are rarely a perfectly accurate record of events. How users recall an experience will determine how likely they are to use a product or service again or recommend it to others. Since we judge past experiences not based on how we felt throughout the whole duration of the event but on the average of how we felt at the peak emotional moments and the end, it is vital that these moments make a lasting good impression. By paying close attention to these key moments of an experience, we can ensure users recollect the experience as a whole positively.Kahneman, Daniel, Barbara L. Fredrickson, Charles A. Schreiber, and Donald A. Redelmeier. 1993. “When More Pain Is Preferred to Less: Adding a Better End.” Psychological Science 4(6): 401–405. ↩︎Redelmeier, Donald A., and Daniel Kahneman. 1996. “Patients’ Memories of Painful Medical Treatments: Real-Time and Retrospective Evaluations of Two Minimally Invasive Procedures.” Pain 66(1): 3–8. ↩︎Redelmeier, Donald A., Joel Katz, and Daniel Kahneman. 2003. “Memories of Colonoscopy: A Randomized Trial.” Pain 104(1–2): 187–194. ↩︎Kahneman, Daniel, and Amos Tversky. 1972. “Subjective Probability: A Judgment of Representativeness.” Cognitive Psychology 3(3): 430–454. ↩︎Kamat, Priya, and Candice Hogan. 2019. “How Uber Leverages Applied Behavioral Science at Scale.” Uber Engineering blog, January 28, 2019. https://eng.uber.com/applied-behavioral-science-at-scale/. ↩︎RelatedThe Psychology of DesignA look at how designers can leverage psychology to build more intuitive, human-centered products and experiences.Design Principles for Reducing Cognitive LoadA look at both the causes and ways to reduce extraneous mental processing for the user.Designing with Occam’s RazorHow a classic problem-solving principle can help improve our designs.NextThe Psychology of DesignBack to Top© Jon Yablonski 2024ContacttriangleRectangle 15Oval 3Combined ShapeOval 9 CopyVon Restorff Effect | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allVon Restorff EffectThe Von Restorff effect, also known as The Isolation Effect, predicts that when multiple similar objects are present, the one that differs from the rest is most likely to be remembered.The Von Restorff effect, also known as The Isolation Effect, predicts that when multiple similar objects are present, the one that differs from the rest is most likely to be remembered.TakeawaysMake important information or key actions visually distinctive.Use restraint when placing emphasis on visual elements to avoid them competing with one another and to ensure salient items don’t get mistakenly identified as ads.Don’t exclude those with a color vision deficiency or low vision by relying exclusively on color to communicate contrast.Carefully consider users with motion sensitivity when using motion to communicate contrast.OriginsThe theory was coined by German psychiatrist and pediatrician Hedwig von Restorff (1906–1962), who, in her 1933 study, found that when participants were presented with a list of categorically similar items with one distinctive, isolated item on the list, memory for the item was improved.SourceFurther ReadingPsychology in Design (Part 1)Andri Budzinskiy | Medium.comThe Psychology Principles Every UI/UX Designer Needs to KnowThanasis Rigopoulos | MarvelVon Restorff Effect on WikipediaWikipediaSuperior pattern processing is the essence of the evolved human brainMark P. MattsonWorking Memory and Attention – A Conceptual Analysis and ReviewKlaus OberauerBuy Large Format Poster
Download free posterRelatedPeak-End RulePeople judge an experience largely based on how they felt at its peak and at its end, rather than the total sum or average of every moment of the experience.Serial Position EffectUsers have a propensity to best remember the first and last items in a series.NextZeigarnik EffectBack to Top© Jon Yablonski 2024ContactCombined ShapetriangleOval 3Oval 9 CopyRectangle 15Law of Uniform Connectedness | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allLaw of Uniform ConnectednessElements that are visually connected are perceived as more related than elements with no connection.Elements that are visually connected are perceived as more related than elements with no connection.TakeawaysGroup functions of a similar nature so they are visually connected via colors, lines, frames, or other shapes.Alternately, you can use a tangible connecting reference (line, arrow, etc) from one element to the next to also create a visual connection.Use uniform connectedness to show context or to emphasize the relationship between similar items.ExamplesGoogle Search ResultsThe Law of Uniform Connectedness can be seen within Google’s search results with borders that surrounds specific items such as videos and ‘featured snippets’. This border helps to visually connect the content and also separate it from other results by giving it a bit more priority.OriginsThe principles of grouping (or Gestalt laws of grouping) are a set of principles in psychology, first proposed by Gestalt psychologists to account for the observation that humans naturally perceive objects as organized patterns and objects, a principle known as Prägnanz. Gestalt psychologists argued that these principles exist because the mind has an innate disposition to perceive patterns in the stimulus based on certain rules. These principles are organized into five categories: Proximity, Similarity, Continuity, Closure, and Connectedness.SourceFurther ReadingGestalt Principles of PerceptionAndy RutledgeLaws of Proximity, Uniform Connectedness, and ContinuationInteraction Design Foundation | Mads SoegaardDesign Principles: Visual Perception And The Principles Of GestaltSteven Bradley | Smashing MagazineBuy Large Format Poster
Download free posterRelatedLaw of Common RegionElements tend to be perceived into groups if they are sharing an area with a clearly defined boundary.Law of ProximityObjects that are near, or proximate to each other, tend to be grouped together.Fitts’s LawThe time to acquire a target is a function of the distance to and size of the target.NextMiller’s LawBack to Top© Jon Yablonski 2024ContactCombined ShapetriangleOval 3Oval 9 CopyRectangle 15Tesler’s Law | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishTesler’s LawTesler’s law, also known as the law of conservation of complexity, states that for any system there is a certain amount of complexity that cannot be reduced.February 12, 2024UXpsychologyThe following is an excerpt from the 2nd edition of Laws of UX: Using Psychology to Design Better Products & Services.Tesler’s law, also known as the law of conservation of complexity, states that for any system there is a certain amount of complexity that cannot be reduced.TakeawaysAll processes have a core of complexity that cannot be designed away and therefore must be assumed by either the system or the user.Ensure as much as possible of the burden is lifted from users by dealing with inherent complexity during design and development.Take care not to simplify interfaces to the point of abstraction.OverviewWho should bear the burden of complexity within an application or a process— the user, or the designers and developers? This is a fundamental question when considering the design of user interfaces and, more broadly, how humans interact with technology. A key objective for designers is to reduce complexity for the people who use the products and services we help to build, yet there is some inherent complexity in every process. Inevitably, we reach a point at which complexity cannot be reduced any further but can only be transferred from one place to another. At this point, it finds its way either into the user interface or into the processes and workflows of designers and developers.OriginsThe origins of Tesler’s law can be traced back to the mid-1980s, when Larry Tesler, a computer scientist at Xerox PARC, was helping to develop the language of interaction design—a set of principles, standards, and best practices for defining the structure and behavior of interactive systems that was key to the development of the desktop computer and desktop publishing. Tesler realized that interface consistency would benefit not only users but also developers because standards could be encapsulated in shared software libraries. It was later in his career, while working on the Mac app object-oriented framework at Apple, that Tesler created an intermediate “generic application” that enabled developers to build their own applications by modifying the generic application in an object-oriented way. Tesler defined the law of conservation of complexity as a way to sell the idea to Apple management and independent software vendors with the express purpose of establishing standards in mass-market software, but also, more importantly, to reduce complexity for customers. Tesler reasoned that “if a million users each waste a minute a day dealing with complexity that an engineer could have eliminated in a week by making the software a little more complex, you are penalizing the user to make the engineer’s job easier.”1Complexity BiasIn Chapter 6 we talked about cognitive bias, which serves as a mental shortcut that increases our efficiency by enabling us to make quick decisions without the need to thoroughly analyze a situation. In essence, cognitive bias helps us reserve mental energy so we can use it when it matters most, e.g., for complex problem solving, creative thinking, etc. We get an incredible amount of benefit from our cognitive bias, but there are some downsides as well: it often leads to errors in memory, judgment, and decision making.Complexity bias is our tendency to favor complex and intricate solutions over straightforward ones, often because complexity is associated with intelligence, expertise, or depth of understanding.2 Simply put, we often give undue credit to complex concepts or view something that is easy to understand as complex and difficult when we are confused or haven’t taken the time to truly understand it. This fallacy was clearly demonstrated in a 1989 paper by Hilary H. Farris and Russell Revlin that studied how people make hypotheses.3 In one experiment, participants were given three numbers and asked to figure out a rule. They could ask if other number sequences followed the same rule, but the real rule was simple: list three numbers that go up. The participants could have said anything like “1, 2, 3” or “3, 7, 99” and been correct. Most didn’t guess it was that simple, opting instead for more complicated rules.Our inherent bias toward complexity can be especially problematic when we design because it can lead to more complex solutions. When we opt for more complex solutions, we sidestep the need to understand the underlying problem. The more complexity and assumptions a solution has, the greater the chance of failure. When we find ourselves favoring a more complex solution, it’s a good sign that we don’t have enough information or that we need to better understand the underlying problem. In these instances, we can avoid making unfounded assumptions and/or overly complex solutions by spending more time with the problem and deepening our understanding through observation and experience.ExamplesOne common way to illustrate Tesler’s law is through the humble email. When you write an email, there are two required pieces of information: who the message is from (you), and to whom it should be sent. The email cannot be sent if either of these is missing, and therefore it’s a necessary complexity. To reduce this complexity, a modern email client will do two things: pre-populate the sender (it can do this because it is aware of your email address), and provide suggestions for the recipient as you begin to type their address, based on prior emails and/or your contacts (Figure 9-1). The complexity isn’t entirely gone; it’s just abstracted away to reduce the effort required of the user. In other words, the experience of writing an email is made a little simpler by moving the complexity of filling in the sender’s and, if possible, the recipient’s address to the email client, which was designed and developed by a team that assumed that burden of complexity when building it.Figure 9-1. Modern email clients reduce complexity by populating the ‘from’ line and suggesting the ‘to’ line based on prior emails (source: Gmail, 2023)Taking that a step further, Gmail now leverages artificial intelligence (AI) within your emails through a feature called Smart Compose (Figure 9-2). This intelligent feature can scan what you’ve typed and use that content to suggest words and phrases to finish your sentences, thus saving you additional typing and time. It should be noted that Smart Compose is not the first time-saving feature introduced to Gmail by way of AI—there’s also Smart Reply, which scans an email for context and suggests several relevant quick-reply options.Figure 9-2. Example of Gmail’s Smart Compose feature (source: Gmail, 2023)Another place that Tesler’s law can commonly be observed is in the ubiquitous checkout process found on online shopping sites. Purchasing items online requires customers to provide lots of repetitive information, including billing and shipping details. To simplify this process for customers, it is common to see online stores enable users to have their shipping address inherit the information from their billing address (Figure 9-3). This option simplifies the checkout process for customers in many cases because it prevents them from having to enter duplicate information for shipping. The resulting experience for customers has been effectively simplified, while the complexity required to enable the feature has shifted to the designers and developers responsible for implementing it up front. Simplifying the checkout process even further are services such as Apple Pay (Figure 9-4), which makes paying for items both online and in person even easier for customers. Once they’ve set up an account, people using Apple Pay or similar payment services can purchase items simply by selecting the option during checkout and verifying the details of their purchase—no need to enter any additional information. The customer experience thus becomes significantly less complex, with the complexity again shifted to the designers and developers responsible for the service.Figure 9-3. The ability to inherit a shipping address from billing details within an ecommerce checkout simplifies the process and removes the need to type redundant informationFigure 9-4. Apple Pay makes the checkout process as easy as selecting the payment option and verifying your purchase (source: Apple, 2023)Retail is an area in which you can find many innovative ways to abstract complexity away from users. Take, for example, Amazon’s Go stores (Figure 9-5), which provide a checkout-free shopping experience. First appearing as an experiment in downtown Seattle, they are now popping up in major metropolitan areas all over the United States. With the Amazon Go app installed on their smartphone, a customer can simply check in with the app when they enter the store, grab what they need, and walk out, without ever needing to wait in line, scan their items, or even pay in the store. A little later, the customer receives a receipt, and their Amazon account is charged.Figure 9-5. The first Amazon Go store in Seattle (source: Wikipedia, 2019; photographer, Brianc333a)The dizzying array of technology involved in a checkout-free shopping experience like that found in Amazon Go stores is nothing short of astounding. Advanced technology like machine learning, computer vision, and AI must be deeply integrated to allow for people to simply walk into the store, grab the items they wish to purchase, and then walk out. While the friction of shopping is drastically reduced for customers, the complexity that comes along with it must be absorbed by the designers and developers responsible for ensuring it all works.Advancements in artificial intelligence (AI) are introducing a whole new interaction paradigm in computing history in which users can tell the computer what outcome they want via natural language. This intent-based paradigm sits in stark contrast to the command-based paradigm we’ve lived with for the last couple of decades, which requires commands via user actions within a graphical user interface (GUI), resulting in feedback from the system. With intent-based interaction, the complexity of the system is abstracted away from the user, enabling them to simply describe the outcome they’d like to see. Take, for example, Spark, from product analytics company Mixpanel, which enables users to conduct in-depth analyses of data by simply asking questions in natural language (Figure 9-6).Figure 9-6. Mixpanel’s natural language Spark feature (source: Mixpanel, 2023)Intent-based interaction via natural language lowers the barrier of knowledge required to interact with software, which is particularly effective with complex products with sophisticated feature sets. This interaction paradigm democratizes access to software and empowers users who know what they want to do but don’t know how to do it to simply describe the outcome they’d like. The barrier for entry required of users to reach “power user” status fades away while giving them access to the same powerful features.Paradox of the Active UserWhen it comes to designing software, there’s a very important consideration to remember: users never read software manuals but instead start using the software immediately. This happens because users are often motivated to complete their immediate tasks, and therefore they don’t want to spend time up front reading documentation. It is, of course, a paradox, because users will save time in the long term if they first take time to learn and optimize around the system.This paradox was first introduced by Mary Beth Rosson and John Carroll in 1987 to explain a common observation in several user studies done at the IBM User Interface Institute.4 They found that new users were not reading the manuals supplied with computers and instead would just get started using them, even if it meant getting into errors and running into roadblocks.The lesson here is that we must remember to not build products and services for an idealized, rational user, because people don’t always behave rationally in real life. Instead, we can account for this paradox by making guidance accessible throughout the product experience. We can design it to fit within the context of use so that it can help these active new users, no matter what path they choose to take (e.g., tooltips with helpful information).Managing Complexity with Progressive DisclosureProgressive disclosure is an interaction design technique that displays only important actions or content by default, while making additional features or content easily accessible. The result is a more streamlined interface that helps to keep the user’s attention focused by reducing clutter, confusion, and cognitive load. Anytime we use a dropdown, accordion, or toggle that reveals content that is hidden by default, we are utilizing progressive disclosure. This strategy is incredibly useful for simplifying designs because it enables us to defer less important actions, advanced features, or additional content to a secondary screen (like a dropdown, accordion, or content toggle).A great example of progressive disclosure can be found on Stripe’s website (Figure 9-7): when you hover the mouse over any item in the primary navigation, a menu will appear that reveals the various links in that category. Stripe has created a simple interface in which users can quickly scan and find relevant information without needing to dig through a mountain of content in the process.Figure 9-7. Progressive disclosure menu on Stripe.com (source: Stripe, 2023)ConclusionTesler’s law is important for designers to be aware of because it relates to a fundamental challenge we face throughout our work: how we manage complexity. We must first acknowledge that with any process, there will be a necessary amount of complexity that cannot be removed, no matter how simplified the process becomes as a result of the design process. Everything from a humble email to a highly sophisticated checkout process will have inherent complexity that must be managed. As designers, we have a responsibility to remove inherent complexity from our interfaces, or else we ship that complexity to our users. This can result in confusion, frustration, and a bad user experience. Where possible, designers and developers should handle complexity.Laws of UX Book, 2nd EditionA designer’s guide to using psychology to design better digital products and services.Learn MoreDan Saffer, Designing for Interaction: Creating Smart Applications and Clever Devices (Berkeley, CA: Peachpit Press, 2006), 56. ↩︎Shane Parrish, “Complexity Bias: Why We Prefer Complicated to Simple,” Farnam Street, January 8, 2018, https://oreil.ly/i9di1. ↩︎Hilary H. Farris and Russell Revlin, “Sensible Reasoning in Two Tasks: Rule Discovery and Hypothesis Evaluation,” Memory & Cognition 17, no. 2 (1989): 221–32, https://doi.org/10.3758/BF03197071. ↩︎John M. Carroll and Mary Beth Rosson, “Paradox of the Active User,” in Interfacing Thought: Cognitive Aspects of Human–Computer Interaction, ed. John M. Carroll (Cambridge, MA: MIT Press, 1987). ↩︎RelatedUX Psychology: Google SearchA closer look at the ubiquitous search utility.Peak-End RuleWhy designers should pay close attention to the key peak moments during an experience.The Psychology of DesignA look at how designers can leverage psychology to build more intuitive, human-centered products and experiences.NextUX Psychology: Google SearchBack to Top© Jon Yablonski 2024ContactOval 3triangleCombined ShapeRectangle 15Oval 9 CopyHick’s Law | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allHick’s LawThe time it takes to make a decision increases with the number and complexity of choices.The time it takes to make a decision increases with the number and complexity of choices.TakeawaysMinimize choices when response times are critical to decrease decision time.Break complex tasks into smaller steps in order to decrease cognitive load.Avoid overwhelming users by highlighting recommended options.Use progressive onboarding to minimize cognitive load for new users.Be careful not to simplify to the point of abstraction.ExamplesGoogle HomepageGoogle keeps the decisions required to enter a keyword to a minimum by eliminating any additional content that could distract from the act of typing a keyword or require additional decision-making.Apple TV RemoteApple TV remotes don’t require a substantial amount of working memory and therefore incurs much less cognitive load. By transferring complexity to the TV interface itself, information can be effectively organized and progressively disclosed within menus.Slack’s Progressive OnboardingInstead of dropping users into a fully featured app after enduring a few onboarding slides, Slack uses a bot to engage users and prompt them to learn the messaging feature consequence-free. To prevent new users from feeling overwhelmed, Slack hides all features except for the messaging input. Once users have learned how to message via Slackbot, they are progressively introduced to additional features.OriginsHick’s Law (or the Hick-Hyman Law) is named after a British and an American psychologist team of William Edmund Hick and Ray Hyman. In 1952, this pair set out to examine the relationship between the number of stimuli present and an individual’s reaction time to any given stimulus. As you would expect, the more stimuli to choose from, the longer it takes the user to make a decision on which one to interact with. Users bombarded with choices have to take time to interpret and decide, giving them work they don’t want.SourceFurther ReadingUX Psychology: Google SearchJon YablonskiThe Choice Overload Effect: Why simplicity is the key to perfecting your experienceJennifer Clinehens | MediumHick’s Law: Making the choice easier for usersMads Soegaard | Interaction Design FoundationHick’s Law — Quick Decision MakingAnton Nikolov | Medium.comThe Psychology Principles Every UI/UX Designer Needs to KnowThanasis Rigopoulos | MarvelHick’s Law on WikipediaWikipediaBuy Large Format Poster
Download free posterRelatedDoherty ThresholdProductivity soars when a computer and its users interact at a pace (<400ms) that ensures that neither has to wait on the other.Fitts’s LawThe time to acquire a target is a function of the distance to and size of the target.Miller’s LawThe average person can only keep 7 (plus or minus 2) items in their working memory.NextJakob’s LawBack to Top© Jon Yablonski 2024ContactRectangle 15Combined ShapetriangleOval 3Oval 9 CopyThe Psychology of Design | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishThe Psychology of DesignAs humans, we have an underlying “blueprint” for how we perceive and process the world around us, and the study of psychology helps us define this blueprint. And as designers, we can leverage psychology principles to build more intuitive products. But where to start? Author Jon Yablonski explains three essential theories of psychology, and provides real-world examples of how they can be used to benefit design. He also discusses the ethical implications of leveraging psychology in design, and what we should all keep in mind if we want to be ethical design citizens.October 5, 2018UXpsychologyIllustration by Dougal MacPhersonThis article was originally published on A List Apart.There are a number of debates about which additional skills designers should learn. Should designers code, write, or understand business? These skills are incredibly valuable but perhaps not essential. However, I would argue that every designer should learn the fundamentals of psychology.As humans, we have an underlying “blueprint” for how we perceive and process the world around us, and the study of psychology helps us define this blueprint. As designers, we can leverage psychology to build more intuitive, human-centered products and experiences. Instead of forcing users to conform to the design of a product or experience, we can use some key principles from psychology as a guide for designing how people actually are.But knowing where to start can be a challenge. Which principles from psychology are useful? What are some examples of these principles at work? In this article, I’ll cover the basics, and discuss the ethical implications of using psychology in design.Key principlesThe intersection of psychology and design is extensive. There’s an endless list of principles that occupy this space, but there are a few that I’ve found more ubiquitous than others. Let’s take a look at what these are and where they are effectively leveraged by products and experiences we interact with everyday.Hick’s LawOne of the primary functions we have as designers is to synthesize information and present it in a way that it doesn’t overwhelm users—after all, good communication strives for clarity. This directly relates to our first key principle: Hick’s Law. Hick’s Law predicts that the time it takes to make a decision increases with the number and complexity of choices available. It was formulated by psychologists William Edmund Hick and Ray Hyman in 1952 after examining the relationship between the number of stimuli present and an individual’s reaction time to any given stimulus.It turns out there is an actual formula to represent this relationship: RT = a + b log2 (n). Fortunately, we don’t need to understand the math behind this formula to grasp what it means. The concept is quite simple: the time it takes for users to respond directly correlates to the number and complexity of options available. It implies that complex interfaces result in longer processing time for users, which is important because it’s related to a fundamental theory in psychology known as cognitive load.Cognitive loadCognitive load refers to the mental processing power being used by our working memory. Our brains are similar to computer processors in that we have limited processing power: when the amount of information coming in exceeds the space available, cognitive load is incurred. Our performance suffers and tasks become more difficult, which results in missed details and even frustration.Hick’s Law ExamplesModified TV remotes that simplify the “interface” for grandparents.There are examples of Hick’s Law in action everywhere, but we’ll start with a common one: remote controls. As features available in TVs increased over the decades, so did the options available on their corresponding remotes. Eventually we ended up with remotes so complex that using them required either muscle memory from repeated use or a significant amount of mental processing. This led to the phenomenon known as “grandparent-friendly remote.” By taping off everything except for the essential buttons, grandkids were able to improve the usability of remotes for their loved ones, and they also did us all the favor of sharing them online.Apple TV remote, which simplifies the controls to only those absolutely necessary.In contrast, we have smart TV remotes: the streamlined cousin of the previous example, simplifying the controls to only those absolutely necessary. The result is a remote that doesn’t require a substantial amount of working memory and therefore incurs much less cognitive load. By transferring complexity to the TV interface itself, information can be effectively organized and progressively disclosed within menus.Screenshots from Slack’s progressive onboarding experience.Let’s take a look at another example of Hick’s Law. Onboarding is a crucial but risky process for new users, and few nail it as well as Slack. Instead of dropping users into a fully featured app after enduring a few onboarding slides, they use a bot (Slackbot) to engage users and prompt them to learn the messaging feature consequence-free. To prevent new users from feeling overwhelmed, Slack hides all features except for the messaging input. Once users have learned how to message via Slackbot, they are progressively introduced to additional features.This is a more effective way to onboard users because it mimics the way we actually learn: we build upon each subsequent step, and add to what we already know. By revealing features at just the right time, we enable our users to adapt to complex workflows and feature sets without feeling overwhelmed.Key takeawaysToo many choices will increase the cognitive load for users.Break up long or complex processes into screens with fewer options.Use progressive onboarding to minimize cognitive load for new users.Miller’s LawAnother key principle is Miller’s Law, which predicts that the average person can only keep 7 (± 2) items in their working memory. It originates from a paper published in 1956 by cognitive psychologist George Miller, who discussed the limits of short-term memory and memory span. Unfortunately there has been a lot of misinterpretation regarding this heuristic over the years, and it’s led to the “magical number seven” being used to justify unnecessary limitations (for example, limiting interface menus to no more than seven items).ChunkingMiller’s fascination with short-term memory and memory span centered not on the number seven, but on the concept of “chunking” and our ability to memorize information accordingly. When applied to design, chunking can be an incredibly valuable tool. Chunking describes the act of visually grouping related information into small, distinct units of information. When we chunk content in design, we are effectively making it easier to process and understand. Users can scan the content and quickly identify what they are interested in, which is aligned with how we tend to consume digital content.Miller’s Law ExamplesAn example of chunking with strings like phone numbers.The simplest example of chunking can be found with how we format phone numbers. Without chunking, a phone number would be a long string of digits, which increases the difficulty to process and remember it. Alternatively, a phone number that has been formatted (chunked) becomes much easier to interpret and memorize. This is similar to how we perceive a “wall of text” in comparison to well-formatted content with appropriate headline treatments, line-length, and content length.Chunking can organize content to help users process, understand, and memorize easily. At right, I’ve highlighted how Bloomberg grouped information.Another example of chunking being used effectively in design is with layout. We can use this technique to help users understand underlying relationships and hierarchy by grouping content into distinctive modules. Especially in information-dense experiences, chunking can be leveraged to provide structure to the content. Not only is the result more visually pleasing, but it’s more scannable.Key takeawaysDon’t use the “magical number seven” to justify unnecessary design limitations.Organize content into smaller chunks to help users process, understand, and memorize easily.Jakob’s LawThe last principle we’ll look at is Jakob’s Law (short for Jakob’s Law of Internet User Experience), which states that users spend most of their time on other sites, and they prefer your site to work the same way as all the other sites they already know. In 2000, it was put forth by usability expert Jakob Nielsen, who described the tendency for users to develop an expectation of design patterns based on their cumulative experience from other websites. This principle encourages designers to follow common design patterns in order to avoid confusing users, which can result in higher cognitive load.Mental modelsI know what you’re thinking: if all websites followed the same design patterns, that would make for quite the boring web. The answer is yes, that is probably true. But there is something incredibly valuable to be found in familiarity for users, which leads us to another fundamental concept in psychology that is valuable for designers: mental models.A mental model is what we think we know about a system, especially about how it works. Whether it’s a website or a car, we form models of how a system works, and then we apply that model to new situations where the system is similar. In other words, we use knowledge we already have from past experiences when interacting with something new.Mental models are valuable for designers, because we can match our user’s mental model to improve their experience. Consequently, users can easily transfer their knowledge from one product or experience to another without taking time to understand how the new system works. Good user experiences are made possible when the designer’s mental model is aligned with the user’s mental model. The task of shrinking the gap between our mental models and those of our users is one of our biggest challenges, and to achieve this we use a variety of methods: user interviews, personas, journey maps, empathy maps, and more. The point of all this is to gain a deeper insight into not only the goals and objectives of our users but also their pre-existing mental models, and how that applies to the product or experience we are designing.Jakob’s Law ExamplesHave you ever wondered why form controls look the way they do? It’s because the humans designing them had a mental model for what these elements should look like, which they based on control panels they were already familiar with in the physical world. Things like form toggles, radio inputs, and even buttons originated from the design of their tactile counterparts.Comparison between control panel elements and typical form elements.As designers, we must close the gap that exists between our mental models and that of our users. It’s important we do this because there will be problems when they aren’t aligned, which can affect how users perceive the products and experiences we’ve helped build. This misalignment is called mental model discordance, and it occurs when a familiar product is suddenly changed.Snapchat redesign before-and-after comparison.Take for example Snapchat, which rolled out a major redesign in early 2018. They launched a reformatted layout, which in turn confused users by making it difficult to access features they used on a daily basis. These unhappy users immediately took to Twitter and expressed their disapproval en masse. Even worse was the subsequent migration of users to Snapchat’s competitor, Instagram. Snapchat had failed to ensure the mental model of their users would be aligned with the redesigned version of their app, and the resulting discordance caused major backlash.Before and after comparison of YouTube redesign in 2017.But major redesigns don’t always have to result in backlash—just ask Google. Google has a history of allowing users to opt in to redesigned versions of their products like Google Calendar, YouTube, and Gmail. When they launched the new version of YouTube in 2017 after years of essentially the same design, they allowed desktop users to ease into the new Material Design UI without having to commit. Users could preview the new design, gain some familiarity, submit feedback, and even revert to the old version if they preferred it. As a result, the inevitable mental model discordance was avoided by simply empowering users to switch when they were ready.Key takeawaysUsers will transfer expectations they have built around one familiar product to another that appears similar.By leveraging existing mental models, we can create superior user experiences in which the user can focus on their task rather than learning new models.Minimize discordance by empowering users to continue using a familiar version for a limited time.RecapYou might be thinking, “These principles are great, but how do I use them in my projects?” While nothing will replace actual user research and data specific to our projects, we can use these psychological principles to serve as a guide for designing more intuitive, human-centered products and experiences. Being mindful of these principles helps us create designs that consider how people actually are, as opposed to forcing them to conform to the technology. To quickly recap:Hick’s Law can help guide us to reduce cognitive load for users by minimizing choice and breaking long or complex processes into screens with fewer options.Miller’s Law teaches us to use chunking to organize content into smaller clusters to help users process, understand, and memorize easily.Jakob’s Law reminds us that users will transfer expectations they have built around one familiar product to another that appears similar. Therefore, we can leverage existing mental models to create superior user experiences.We’ve covered some key principles that are useful for building more intuitive, human-centered products and experiences. Now let’s touch on their ethical implications and how easy it can be to fall into the trap of exploiting users with psychology.We’ve covered some key principles that are useful for building more intuitive, human-centered products and experiences. Now let’s touch on their ethical implications and how easy it can be to fall into the trap of exploiting users with psychology.A note on ethicsOn the one hand, designers can use psychology to create more intuitive products and experiences; on the other, they can use it to exploit how our minds work, for the sake of creating more addictive apps and websites. Let’s first take a look at why this is a problem, and then consider some potential solutions.ProblemOne doesn’t have to go far to see why the well-being of users being deprioritized in favor of profit is a problem. When was the last time you were on a subway, on a sidewalk, or in a car and didn’t see someone glued to their smartphone? There are some that would argue we’re in the middle of an epidemic, and that our attention is being held captive by the mini-computers that we carry with us everywhere.It wouldn’t be an exaggeration to say that the mobile platforms and social networks that connect us also put a lot of effort into how they can keep us glued, and they’re getting better at it every day. The effects of this addiction are beginning to become well-known: from sleep reduction and anxiety to deterioration of social relationships, it’s becoming apparent that the race for our attention has some unintended consequences. These effects become problematic when they start to change how we form relationships and how we view ourselves.SolutionAs designers, our responsibility is to create products and experiences that support and align with the goals and well-being of users. In other words, we should build technology for augmenting the human experience, not replacing it with virtual interaction and rewards. The first step in making ethical design decisions is to acknowledge how the human mind can be exploited.We must also question what we should and shouldn’t build. We can find ourselves on quite capable teams that have the ability to build almost anything you can imagine, but that doesn’t always mean we should—especially if the goals of what we are building don’t align with the goals of our users.Lastly, we must consider metrics beyond usage data. Data tells us lots of things, but what it doesn’t tell us is why users are behaving a certain way or how the product is impacting their lives. To gain insight into why, we must both listen and be receptive to our users. This means getting out from behind a screen, talking with them, and then using this qualitative research to inform how we evolve the design.ExamplesGoogle’s Digital Wellbeing initiative website.It’s been great to see companies taking the right steps when it comes to considering the digital well-being of users. Take for example Google, which just announced tools and features at their latest I/O event that focus on helping people better understand their tech usage, focus on what matters most, disconnect when needed, and create healthy digital habits. Features like an app dashboard that provides a usage overview, additional control over alerts and notifications, and Family Link for setting digital ground rules for the little ones all are geared towards protecting users.Screenshot from Facebook’s “News Feed FYI: Bringing People Closer Together” video.Some companies are even redefining their success metrics. Instead of time on site, companies like Facebook are defining success through meaningful interactions. This required them to restructure their news feed algorithm to prioritize the content that people actually find valuable over the stuff we mindlessly consume. Content from friends and family now takes precedence, even if the result means users spend a little less time in their app.These examples are just a glimpse into the steps that many companies are taking, and I hope to see many more in the coming years. The technology we play a part in building can significantly impact people’s lives, and it’s crucial that we ensure that impact is positive. It’s our responsibility to create products and experiences that support and align with the goals and well-being of users. We can make ethical design decisions by acknowledging how the human mind can be exploited, consider what we should and shouldn’t build, and talk with users to gain qualitative feedback on how the products and experiences we build affect their lives.ResourcesThere are tons of great resources we can reference for making our designs more intuitive for users. Here are a few I have referenced quite frequently:Laws of UX: A website I created for designers to learn more about psychological principles that relate to UX/UI design.Cognitive UXD: This hand-selected publication curated by Norbi Gaal is a great resource for anyone interested in the intersection of psychology and UX.Center for Humane Technology: A world-class team of former tech
insiders and CEOs who are advancing thoughtful solutions to change the culture, business incentives, design techniques, and organizational structures driving how technology hijacks our brains.The Design of Everyday Things: Revised and Expanded Edition: An absolute classic that explores the communication between object and user through design, how to optimize this communication, and ultimately how psychology plays a part in designing for how humans actually are.Designing for Emotion: A look at the importance of emotion when expressing a brand’s personality, and how designers can go beyond functionality, reliability, and usability to design for humans as opposed to machines.Hooked: How to Build Habit-Forming Products: A guide that provides insight into the behavioral techniques used by companies like Twitter, Instagram, and Pinterest.RelatedDesign Principles for Reducing Cognitive LoadA look at both the causes and ways to reduce extraneous mental processing for the user.Designing with Occam’s RazorHow a classic problem-solving principle can help improve our designs.NextDesigning with Occam’s RazorBack to Top© Jon Yablonski 2024ContactOval 3Combined ShapeRectangle 15triangleOval 9 CopyUX Psychology: Google Search | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishUX Psychology: Google SearchIn this series, we’ll take a look at various digital experiences and examine each by dissecting it step by step to identify relevant heuristics and concepts rooted in psychology. Kicking the series off will be Google Search — the ubiquitous utility that helps countless people find information in the vast expanse of the Internet every day. We’ll begin with the landing page and the process of searching before moving on to search results.August 6, 2020UXpsychologyThis article was originally published the blog of Jon Yablonski.In this series, we’ll take a look at various digital experiences and examine each by dissecting it step by step to identify relevant heuristics and concepts rooted in psychology. Kicking the series off will be Google Search — the ubiquitous utility that helps countless people find information in the vast expanse of the Internet every day. We’ll begin with the landing page and the process of searching before moving on to search results. Let’s begin!Landing PageGoogle’s landing page has only slightly changed in the 21+ years of its existence. The purpose of this page has remained singularly focused: provide a quick and easy way for people to search the Web. In fact, it’s done this so efficiently that the act of searching the web has become synonymous with the company name. A major contributor to the success of Google Search is its simplicity. The page consist primarily of a search input that’s positioned in the approximate center and is focused by default — ready to receive a search keyword. Once you begin typing, a list of predicted keywords based on what you’ve typed thus far appear below in input. This list of predicted keywords continues to update as you type and is designed to surface the keyword you’re likely to type before you’ve finished, therefore saving you keystrokes (and mental energy).Google Search predictionsUX PsychologyA key psychology heuristic in play on the landing page of Google Search is Hick’s Law, which states that the time it takes to make a decision increases with the number and complexity of choices. Google keeps the decisions required to enter a keyword to a minimum by eliminating any additional content that could distract from the act of typing a keyword or require additional decision-making. The design reinforces this single goal of keeping the page focused on the act of searching by prominently placing the search input, auto-focusing the search input by default and stripping away additional search options. Hick’s Law is once again demonstrated as you begin typing and predicted keywords appear, eliminating the need to spell out the entire word (assuming a match is found). Google’s goal is to initiate search based on a search query as quickly as possible and it supports this goal by removing any friction that could lead to additional decision-making.Search ResultsThe next step in Google Search is the search results page, which displays results it found based on your search query. The original search keyword is displayed prominently at the top of the page, along with additional options for filtering the results. Results are presented in a list and each one is visualized as discernible chunks of content that’s separated by ample spacing, so it’s easy to differentiate one result from the next. When appropriate, this page will also show a definition for the search term at the top of results as well as a sidebar card that links to more information regarding the term (typically on Wikipedia).Google results pageUX PsychologyHick’s Law is also carried into the search results page from the previous page. This is where you’ll find additional options for modifying your search, not on landing page where the goal is to remove as much friction as possible. It’s only once you’ve entered a search query that the additional options to filter the results and therefore additional decisions are made available.Another important design feature to point out on the search results page is that the original search query is still being shown, which is helpful due to the way our minds store information in memory. Working memory is the cognitive system that holds information temporarily and is important for reasoning and the guidance of decision-making and behavior. It’s limited in capacity, so the more decisions being made means the less likely we are to quickly remember items that previously set in working memory. You can think of each item on the page as being a potential decision point: people scan the page in search of information that relates to what they’re looking for, and mentally evaluates if the content resembles something that could help them achieve their goal. Regarding Google Search, it’s helpful to see the original search term in the case that they forget what was originally being searched.The next important key detail of Google Search is performance. Google Search is known for its speed in delivering results based on a query — it even displays the time in which it took to fetch those results at the top of the page. This directly relates to the Doherty Threshold, which states that productivity soars when a computer and its users interact at a pace (<400ms) that ensures that neither has to wait on the other. If the search results took a long time to return, it’s possible you could begin to think of something else. Instead, Google priortizes performance and returns the results as rapidly as possible. As a result, it ensures we are remaining focused on the task at hand and we have the results we need to learn more. Performance is a critical part of the overall user experience and Google understands this.Detail view of the search results pageNow let’s move on to the visual aspects of the search results page, which is optimized for scannability. As was already mentioned, each result is presented in a list and each one is visualized as a discernible chunk of content with ample spacing between other results. This not only makes it easier to differentiate one result from the next, but it also helps people quickly scan the results and identify which result is most likely to contain the information they’re looking for. The hierarchy of information in each result is clear, consistent and also lends itself to being easily scannable. This is closely related to the psychological concept of chunking, a process by which individual pieces of an information set are broken down and then grouped together in a meaningful whole. When applied to UX design, chunking helps to guide how we group and organize content. When we chunk content in design, we are effectively making it easier to comprehend. People can then scan the content, identify the information that aligns with their goals, and consume that information in an effort to achieve their goal.By structuring content into visually distinct groups with a clear hierarchy, we can align the information we present with how people evaluate and process digital content.Lastly, it’s impossible to dissect visual information without recalling Gestalt psychology and Google Search results demonstrates quite a few. One very noticeable Gestalt law in effect is the Law of Proximity, which states that objects that are near, or proximate to each other, tend to be grouped together. The spacing between each result contributes to the overall scannability of the page but also helps to effectively group each result as a related cluster of information. Additionally, the Law of Uniform Connectedness can also be seen with the border that surrounds specific items such as videos and ‘featured snippets’. This border helps to visually connect the content and also separate it from other results by giving it a bit more priority. It’s an additional layer of hierarchy on the page that helps once again with scannability.Google Search has been incrementally refined over it’s 21+ years of its existence in order to optimize people’s ability to quickly get information based on a search keyword. It has achieved this by eliminating friction, prioritizing performance and ensuring results are easily scannable. They’ve refined this experience to a science and as a result have made Google Search the ubiquitous utility that helps countless people find information in the vast expanse of the Internet every day.RelatedPeak-End RuleWhy designers should pay close attention to the key peak moments during an experience.The Psychology of DesignA look at how designers can leverage psychology to build more intuitive, human-centered products and experiences.Design Principles for Reducing Cognitive LoadA look at both the causes and ways to reduce extraneous mental processing for the user.NextPeak-End RuleBack to Top© Jon Yablonski 2024ContactRectangle 15triangleOval 9 CopyOval 3Combined ShapeMiller’s Law | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allMiller’s LawThe average person can only keep 7 (plus or minus 2) items in their working memory.The average person can only keep 7 (plus or minus 2) items in their working memory.TakeawaysDon’t use the “magical number seven” to justify unnecessary design limitations.Organize content into smaller chunks to help users process, understand, and memorize easily.Remember that short-term memory capacity will vary per individual, based on their prior knowledge and situational context.ExamplesChunkingChunking can organize content to help users process, understand, and memorize easily.OriginsIn 1956, George Miller asserted that the span of immediate memory and absolute judgment were both limited to around 7 pieces of information. The main unit of information is the bit, the amount of data necessary to make a choice between two equally likely alternatives. Likewise, 4 bits of information is a decision between 16 binary alternatives (4 successive binary decisions). The point where confusion creates an incorrect judgment is the channel capacity. In other words, the quantity of bits which can be transmitted reliably through a channel, within a certain amount of time.SourceFurther ReadingMiller’s Law, Chunking, and the Capacity of Working MemoryKhan AcademyDesign Principles for Reducing Cognitive LoadJon Yablonski | Medium.comThe Magical Mystery Four: How is Working Memory Capacity Limited, and Why?Nelson Cowan | NCBIMiller’s Law on WikipediaWikipediaThe Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing InformationGeorge A. MillerBuy Large Format Poster
Download free posterRelatedHick’s LawThe time it takes to make a decision increases with the number and complexity of choices.Aesthetic-Usability EffectUsers often perceive aesthetically pleasing design as design that’s more usable.Doherty ThresholdProductivity soars when a computer and its users interact at a pace (<400ms) that ensures that neither has to wait on the other.NextOccam’s RazorBack to Top© Jon Yablonski 2024ContacttriangleCombined ShapeOval 3Rectangle 15Oval 9 CopyZeigarnik Effect | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allZeigarnik EffectPeople remember uncompleted or interrupted tasks better than completed tasks.People remember uncompleted or interrupted tasks better than completed tasks.TakeawaysInvite content discovery by providing clear signifiers of additional content.Providing artificial progress towards a goal will help to ensure users are more likely to have the motivation to complete that task.Provide a clear indication of progress in order to motivate users to complete tasks.OriginsBluma Wulfovna Zeigarnik (1900 – 1988) was a Soviet psychologist and psychiatrist, a member of the Berlin School of experimental psychology and Vygotsky Circle. She discovered the Zeigarnik effect and contributed to the establishment of experimental psychopathology as a separate discipline in the Soviet Union in the post-World War II period. In the 1920s she conducted a study on memory, in which she compared memory in relation to incomplete and complete tasks. She had found that incomplete tasks are easier to remember than successful ones. This is now known as the Zeigarnik effect. She later began working at the Institute of Higher Nervous Activity which is where she would meet her next big influence Vygowsky, and become a part of his circle of scientists. It was also there that Zeigarnik founded the Department of Psychology. During that time, Zeigarnik received the Lewin Memorial Award in 1983 for her psychological research.SourceFurther ReadingEndowed progress effect: Give your users a head startCanvs Editorial | UX CollectiveMoving the Finish Line: The Goal Gradient HypothesisFarnam StreetThe Zeigarnik Effect: Why it is so hard to leave things incompleteAbhishek Chakraborty | Medium.comZeigarnik EffectCoglodeZeigarnik Effect on WikipediaWikipediaBuy Large Format Poster
Download free posterRelatedGoal-Gradient EffectThe tendency to approach a goal increases with proximity to the goal.Miller’s LawThe average person can only keep 7 (plus or minus 2) items in their working memory.Peak-End RulePeople judge an experience largely based on how they felt at its peak and at its end, rather than the total sum or average of every moment of the experience.NextAesthetic-Usability EffectBack to Top© Jon Yablonski 2024ContactOval 9 CopyCombined ShapetriangleOval 3Rectangle 15Tesler’s Law | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allTesler’s LawTesler’s Law, also known as The Law of Conservation of Complexity, states that for any system there is a certain amount of complexity which cannot be reduced.Tesler’s Law, also known as The Law of Conservation of Complexity, states that for any system there is a certain amount of complexity which cannot be reduced.TakeawaysAll processes have a core of complexity that cannot be designed away and therefore must be assumed by either the system or the user.Ensure as much as possible of the burden is lifted from users by dealing with inherent complexity during design and development.Remember to not build products and services for an idealized, rational user, because people don’t always behave rationally in real life.Make guidance accessible and fit within the context of use so that it can help these active new users, no matter what path they choose to take (e.g., tooltips with helpful information).OriginsWhile working for Xerox PARC in the mid-1980s, Larry Tesler realized that the way users interact with applications was just as important as the application itself. The book Designing for Interaction by Dan Saffer, includes an interview with Larry Tesler that describes the law of conservation of complexity. The interview is popular among user experience and interaction designers. Larry Tesler argues that, in most cases, an engineer should spend an extra week reducing the complexity of an application versus making millions of users spend an extra minute using the program because of the extra complexity. However, Bruce Tognazzini proposes that people resist reductions to the amount of complexity in their lives. Thus, when an application is simplified, users begin attempting more complex tasks.SourceFurther ReadingWhy Life Can’t Be SimplerFarnam Street8 Design Guidelines for Complex ApplicationsKate Kaplan | Nielsen Norman GroupExplaining the Law of Conservation of ComplexityMichael Calleia | Humanist.coControls are ChoicesDan Saffer | Medium.comSimplicity is OverratedGabriel Colombo | MarvelNobody Wants To Use Your ProductGoran Peuc | Smashing MagazineLaw of Conservation of Complexity on WikipediaWikipediaBuy Large Format Poster
Download free posterRelatedHick’s LawThe time it takes to make a decision increases with the number and complexity of choices.Law of PrägnanzPeople will perceive and interpret ambiguous or complex images as the simplest form possible, because it is the interpretation that requires the least cognitive effort of us.Postel’s LawBe liberal in what you accept, and conservative in what you send.NextVon Restorff EffectBack to Top© Jon Yablonski 2024ContactRectangle 15Oval 9 CopyOval 3triangleCombined ShapeLaw of Common Region | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allLaw of Common RegionElements tend to be perceived into groups if they are sharing an area with a clearly defined boundary.Elements tend to be perceived into groups if they are sharing an area with a clearly defined boundary.TakeawaysCommon region creates a clear structure and helps users quickly and effectively understand the relationship between elements and sections.Adding a border around an element or group of elements is an easy way to create common region.Common region can also be created by defining a background behind an element or group of elements.OriginsThe principles of grouping (or Gestalt laws of grouping) are a set of principles in psychology, first proposed by Gestalt psychologists to account for the observation that humans naturally perceive objects as organized patterns and objects, a principle known as Prägnanz. Gestalt psychologists argued that these principles exist because the mind has an innate disposition to perceive patterns in the stimulus based on certain rules. These principles are organized into five categories: Proximity, Similarity, Continuity, Closure, and Connectedness.SourceFurther ReadingThe Principle of Common Region: Containers Create GroupingsAurora Harley | Nielsen Norman GroupDesign Principles: Visual Perception And The Principles Of GestaltSteven Bradley | Smashing MagazineGestalt principlesScholarpediaBuy Large Format Poster
Download free posterRelatedLaw of ProximityObjects that are near, or proximate to each other, tend to be grouped together.Law of Uniform ConnectednessElements that are visually connected are perceived as more related than elements with no connection.Fitts’s LawThe time to acquire a target is a function of the distance to and size of the target.NextLaw of ProximityBack to Top© Jon Yablonski 2024ContactCombined ShapeOval 3triangleRectangle 15Oval 9 CopyGoal-Gradient Effect | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allGoal-Gradient EffectThe tendency to approach a goal increases with proximity to the goal.The tendency to approach a goal increases with proximity to the goal.TakeawaysThe closer users are to completing a task, the faster they work towards reaching it.Providing artificial progress towards a goal will help to ensure users are more likely to have the motivation to complete that task.Provide a clear indication of progress in order to motivate users to complete tasks.OriginsThe goal-gradient hypothesis, originally proposed by the behaviorist Clark Hull in 1932, states that the tendency to approach a goal increases with proximity to the goal. In a classic experiment that tests this hypothesis, Hull (1934) found that rats in a straight alley ran progressively faster as they proceeded from the starting box to the food. Although the goal-gradient hypothesis has been investigated exten-sively with animals (e.g., Anderson 1933; Brown 1948; for a review, see Heilizer 1977), its implications for human behavior and decision making are understudied. Further-more, this issue has important theoretical and practical implications for intertemporal consumer behavior in reward programs (hereinafter RPs) and other types of motivational systems (e.g., Deighton 2000; Hsee, Yu, and Zhang 2003; Kivetz 2003; Lal and Bell 2003).SourceFurther ReadingHow Uber uses psychology to perfect their customer experienceJennifer Clinehens | Choice HackingMoving the Finish Line: The Goal Gradient HypothesisFarnam StreetDesigning for motivation with the goal-gradient effectIan Batterbee | UX CollectiveThe Goal-Gradient Hypothesis Resurrected: Purchase Acceleration, Illusionary Goal Progress, and Customer RetentionRan Kivetz, Oleg Urminsky, Yuhuang Zheng | uchicago.eduThe importance of percent-done progress indicators for computer-human interfacesBrad A. Myers | Carnegie Mellon UniversityBuy Large Format Poster
Download free posterRelatedFitts’s LawThe time to acquire a target is a function of the distance to and size of the target.Law of Common RegionElements tend to be perceived into groups if they are sharing an area with a clearly defined boundary.Law of ProximityObjects that are near, or proximate to each other, tend to be grouped together.NextHick’s LawBack to Top© Jon Yablonski 2024ContactOval 9 CopytriangleOval 3Combined ShapeRectangle 15Design Principles for Reducing Cognitive Load | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishDesign Principles for Reducing Cognitive LoadEvery time you visit a website, a process of learning is initiated in the brain. Whether it’s the navigation, layout, or that auto-rotating image slider on the homepage, your brain has to learn how to use the site while keeping track of the reason you came there in the first place. The mental effort required during this time is called cognitive load. Now the catch: the working memory in which this information is processed and stored is limited. Your brain begins to slow down or even abandon the task at hand when it receives more information than it can handle. Although cognitive load isn’t entirely avoidable, designers must strive to manage and accommodate these limits.November 30, 2015psychologyUXprocessThis article was originally published the blog of Jon Yablonski.Every time you visit a website, a process of learning is initiated in the brain. Whether it’s the navigation, layout, or that auto-rotating image slider on the homepage, your brain has to learn how to use the site while keeping track of the reason you came there in the first place. The mental effort required during this time is called cognitive load. Now the catch: the working memory in which this information is processed and stored is limited. Your brain begins to slow down or even abandon the task at hand when it receives more information than it can handle. Although cognitive load isn’t entirely avoidable, designers must strive to manage and accommodate these limits.What Causes Cognitive LoadTo understand how to reduce cognitive load, we must first understand what causes it. Generally speaking, the causes of cognitive load can be traced back to three main factors:Too many choicesToo much thought requiredLack of clarityEach of these factors will require processing and takes up mental resources that doesn’t actually help users understand the content.Methods for Reducing Cognitive LoadNow that we know the factors that increase cognitive load, let’s take a look at how we can reduce it. This is by no means a comprehensive list, but instead a few common principles that can help inform design decisions.Avoid Unnecessary ElementsLike everything in design, less is more. Any element that isn’t helping the user achieve their goal is working against them because they must process it and store it in working memory, alongside the things that will help them. Avoiding excessive colors, imagery, design flourishes, or layouts that don’t add value is crucial. But simplicity comes with a caveat: don’t overvalue it at the cost of clarity.Leverage Common Design PatternsBy leveraging common design patterns when it makes sense, you are giving the user familiar elements which they already understand. This in turn reduces the amount of learning they need to do, thus enabling them to move right along and get closer to achieving their goal. My favorite sources for design pattern inspiration are Design Patterns on CodePen and the Blueprint Archives on Codrops.Eliminate Unnecessary TasksAnywhere you are asking the user to read content, remember information or make a decision contributes to cognitive load. Whenever possible, it is good to shift these tasks away from the user and make it easier for them to stay focused on their goal. While it isn’t possible to remove all tasks, there is usually an opportunity to offload some task by setting defaults that can be edited, or leveraging previously entered information. Some companies are even taking this a step further with anticipatory design.Minimize ChoicesAs previously mentioned, our working memory is limited. When confronted with too many choices, cognitive load will increase due to decision paralysis. It is important that we minimize the choices the user must make at any given moment, especially in places such as navigation, forms, and drop-downs.Display Choices as a GroupWhen choices are split into separate groups and hidden, users often mistake the options that are visible as the complete group. This means that users are likely to never find the additional choices, which not only limits what is available to them, but also makes it more difficult to decide on which option to select because they are not aware of the alternatives. Therefore, it is best to eliminate the resulting cognitive load by always displaying choices as a group.Strive for ReadabilityMaking our content legible isn’t enough — we need to make it readable. This means our typography must be aesthetically pleasing, appropriate for the content and easy to read while design remains relatively invisible. By doing this, we can ensure there are as little distractions as possible for the user, which results in a better understanding of the content by the user.Use Iconography with CautionResearch has shown that iconography can be hard to memorize and, contrary to intuition, can increase cognitive load by requiring mental processing to infer meaning or recognize. While universally understood icons work well (ie. print, close, play/pause, reply, tweet, share on Facebook), most are subject to the user’s understanding based on previous experience (in which there is no standard). When leveraging the power of iconography, it is best to accompany them with text labels to communicate the meaning and reduce ambiguity.By following the principles above, you can drastically reduce the user’s cognitive load and ensure their attention isn’t being wasted on elements that do not help them. It is important to remember that the user has a goal, whether it is to buy a product, understand something or simply to learn more about the content. The less they have to think about what they need to do to achieve their goal, the more likely it is they will achieve it.NextTesler’s LawBack to Top© Jon Yablonski 2024ContactCombined ShapeOval 3triangleOval 9 CopyRectangle 15Law of Prägnanz | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allLaw of PrägnanzPeople will perceive and interpret ambiguous or complex images as the simplest form possible, because it is the interpretation that requires the least cognitive effort of us.People will perceive and interpret ambiguous or complex images as the simplest form possible, because it is the interpretation that requires the least cognitive effort of us.TakeawaysThe human eye likes to find simplicity and order in complex shapes because it prevents us from becoming overwhelmed with information.Research confirms that people are better able to visually process and remember simple figures than complex figures.The human eye simplifies complex shapes by transforming them into a single, unified shape.OriginsIn 1910, psychologist Max Wertheimer had an insight when he observed a series of lights flashing on and off at a railroad crossing. It was similar to how the lights encircling a movie theater marquee flash on and off. To the observer, it appears as if a single light moves around the marquee, traveling from bulb to bulb, when in reality it’s a series of bulbs turning on and off and the lights don’t move it all. This observation led to a set of descriptive principles about how we visually perceive objects. These principles sit at the heart of nearly everything we do graphically as designers.SourceFurther ReadingDesign Principles: Visual Perception And The Principles Of GestaltSteven Bradley | Smashing MagazineThe Laws of Figure/Ground, Prägnanz, Closure, and Common FateMads Soegaard | Interation Design FoundationBuy Large Format Poster
Download free posterRelatedHick’s LawThe time it takes to make a decision increases with the number and complexity of choices.Law of Common RegionElements tend to be perceived into groups if they are sharing an area with a clearly defined boundary.Law of ProximityObjects that are near, or proximate to each other, tend to be grouped together.NextLaw of SimilarityBack to Top© Jon Yablonski 2024ContactOval 9 CopyCombined ShapeOval 3Rectangle 15triangleJakob’s Law | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allJakob’s LawUsers spend most of their time on other sites. This means that users prefer your site to work the same way as all the other sites they already know.Users spend most of their time on other sites. This means that users prefer your site to work the same way as all the other sites they already know.TakeawaysUsers will transfer expectations they have built around one familiar product to another that appears similar.By leveraging existing mental models, we can create superior user experiences in which the users can focus on their tasks rather than on learning new models.When making changes, minimize discord by empowering users to continue using a familiar version for a limited time.ExamplesForm ControlsThings like form toggles, radio inputs, and even buttons originated from the design of their tactile counterparts.YouTube RedesignWhen YouTube launched a new version in 2017 after years of essentially the same design, they allowed desktop users to ease into the new Material Design UI without having to commit. Users could preview the new design, gain some familiarity, submit feedback, and even revert to the old version if they preferred it. As a result, the inevitable mental model discordance was avoided by simply empowering users to switch when they were ready.OriginsJakob’s Law was coined by Jakob Nielsen, a User Advocate and principal of the Nielsen Norman Group which he co-founded with Dr. Donald A. Norman (former VP of research at Apple Computer). Dr. Nielsen established the ‘discount usability engineering’ movement for fast and cheap improvements of user interfaces and has invented several usability methods, including heuristic evaluation.SourceFurther ReadingJakob’s Law of Internet User ExperienceNielsen Norman GroupThe Power Law of Learning: Consistency vs. Innovation in User InterfacesNielsen Norman GroupTop 10 Mistakes in Web DesignNielsen Norman GroupEnd of Web DesignNielsen Norman GroupBuy Large Format Poster
Download free posterRelatedAesthetic-Usability EffectUsers often perceive aesthetically pleasing design as design that’s more usable.Doherty ThresholdProductivity soars when a computer and its users interact at a pace (<400ms) that ensures that neither has to wait on the other.Fitts’s LawThe time to acquire a target is a function of the distance to and size of the target.NextLaw of Common RegionBack to Top© Jon Yablonski 2024ContactCombined ShapeOval 3Oval 9 CopytriangleRectangle 15Pareto Principle | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allPareto PrincipleThe Pareto principle states that, for many events, roughly 80% of the effects come from 20% of the causes.The Pareto principle states that, for many events, roughly 80% of the effects come from 20% of the causes.TakeawaysInputs and outputs are often not evenly distributed.A large group may contain only a few meaningful contributors to the desired outcome.Focus the majority of effort on the areas that will bring the largest benefits to the most users.OriginsIts origins stem back to Vilfredo Pareto, an economist who noticed 80% of Italy’s land was owned by 20% of the population. Though it might seem vague, the 80/20 way of thinking can provide insightful and endlessly applicable analysis of lopsided systems, including user experience strategy.SourceFurther ReadingPrioritize Quantitative Data with the Pareto PrincipleEvan Sunwall | Nielsen Norman GroupThe 80/20 Rule in User ExperienceArin Bhowmick | MediumApplying the Pareto Principle to the User ExperienceJeff Sauro | Measuring UThe Pareto Principle and Your User Experience WorkInteraction Design FoundationPareto Principle on WikipediaWikipediaBuy Large Format Poster
Download free posterRelatedAesthetic-Usability EffectUsers often perceive aesthetically pleasing design as design that’s more usable.Occam’s RazorAmong competing hypotheses that predict equally well, the one with the fewest assumptions should be selected.Parkinson’s LawAny task will inflate until all of the available time is spent.NextParkinson’s LawBack to Top© Jon Yablonski 2024ContacttriangleOval 3Rectangle 15Combined ShapeOval 9 CopyOccam’s Razor | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allOccam’s RazorAmong competing hypotheses that predict equally well, the one with the fewest assumptions should be selected.Among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected.TakeawaysThe best method for reducing complexity is to avoid it in the first place.Analyze each element and remove as many as possible, without compromising the overall function.Consider completion only when no additional items can be removed.OriginsOccam’s razor (also Ockham’s razor; Latin: lex parsimoniae "law of parsimony") is a problem-solving principle that, when presented with competing hypothetical answers to a problem, one should select the one that makes the fewest assumptions. The idea is attributed to William of Ockham (c. 1287–1347), who was an English Franciscan friar, scholastic philosopher, and theologian.SourceFurther ReadingHow to Use Occam’s Razor Without Getting CutFarnam StreetDesigning with Occam’s RazorJon Yablonski | MediumOccam’s Razor: The Simplest Solution is Always the BestMads Soegaard | Interaction Design FoundationComplexity Bias: Why We Prefer Complicated to SimpleFarnam StreetOccam’s Razor: A Great Principle for DesignersWeb Designer DepotBuy Large Format Poster
Download free posterRelatedAesthetic-Usability EffectUsers often perceive aesthetically pleasing design as design that’s more usable.Pareto PrincipleThe Pareto principle states that, for many events, roughly 80% of the effects come from 20% of the causes.Parkinson’s LawAny task will inflate until all of the available time is spent.NextPareto PrincipleBack to Top© Jon Yablonski 2024ContactOval 9 CopyCombined ShapeOval 3Rectangle 15triangleDoherty Threshold | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allDoherty ThresholdProductivity soars when a computer and its users interact at a pace (<400ms) that ensures that neither has to wait on the other.Productivity soars when a computer and its users interact at a pace (<400ms) that ensures that neither has to wait on the other.TakeawaysProvide system feedback within 400 ms in order to keep users’ attention and increase productivity.Use perceived performance to improve response time and reduce the perception of waiting.Animation is one way to visually engage people while loading or processing is happening in the background.Progress bars help make wait times tolerable, regardless of their accuracy.Purposefully adding a delay to a process can actually increase its perceived value and instill a sense of trust, even when the process itself actually takes much less time.OriginsIn 1982 Walter J. Doherty and Ahrvind J. Thadani published, in the IBM Systems Journal, a research paper that set the requirement for computer response time to be 400 milliseconds, not 2,000 (2 seconds) which had been the previous standard. When a human being’s command was executed and returned an answer in under 400 milliseconds, it was deemed to exceed the Doherty threshold, and use of such applications were deemed to be “addicting” to users.Further ReadingThe Economic Value of Rapid Response TimeJim ElliottThis 70s UX gem still applies todayMichael Gugel | MediumThe Economic Value of Rapid Response TimeDave RupertThe importance of percent-done progress indicators for computer-human interfacesBrad A. MyersResponse time in man-computer conversational transactionsRobert B. MillerBuy Large Format Poster
Download free posterRelatedFitts’s LawThe time to acquire a target is a function of the distance to and size of the target.Hick’s LawThe time it takes to make a decision increases with the number and complexity of choices.Aesthetic-Usability EffectUsers often perceive aesthetically pleasing design as design that’s more usable.NextFitts’s LawBack to Top© Jon Yablonski 2024ContactCombined ShapeOval 9 CopytriangleRectangle 15Oval 3Peak-End Rule | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allPeak-End RulePeople judge an experience largely based on how they felt at its peak and at its end, rather than the total sum or average of every moment of the experience.People judge an experience largely based on how they felt at its peak and at its end, rather than the total sum or average of every moment of the experience.TakeawaysPay close attention to the most intense points and the final moments (the “end”) of the user journey.Identify the moments when your product is most helpful, valuable, or entertaining and design to delight the end user.Remember that people recall negative experiences more vividly than positive ones.ExamplesMailchimpMailchimp understands this is an important moment, especially for first-time users, so it goes beyond presenting a simple confirmation modal. By infusing a touch of brand character through illustration, subtle animation, and humor, the tool defuses what could potentially be a stressful moment.UberNegative events also provide emotional peaks and can contribute to a user’s lasting impression of an experience. By focusing on people’s perceptions of time and waiting, Uber was able to reduce its post-request cancellation rate and avoid what could easily become a negative emotional peak while using their service.OriginsA 1993 study titled “When More Pain Is Preferred to Less: Adding a Better End” by Kahneman, Fredrickson, Charles Schreiber, and Donald Redelmeier provided groundbreaking evidence for the peak–end rule. Participants were subjected to two different versions of a single unpleasant experience. The first trial had subjects submerge a hand in 14°C water for 60 seconds. The second trial had subjects submerge the other hand in 14°C water for 60 seconds, but then keep their hand submerged for an additional 30 seconds, during which the temperature was raised to 15 °C. Subjects were then offered the option of which trial to repeat. Against the law of temporal monotonicity, subjects were more willing to repeat the second trial, despite a prolonged exposure to uncomfortable temperatures. Kahneman et al. concluded that “subjects chose the long trial simply because they liked the memory of it better than the alternative (or disliked it less)”.SourceFurther ReadingPeak–End RuleJon YablonskiHow Uber uses psychology to perfect their customer experienceJennifer Clinehens | MediumThe Peak–End Rule: How Impressions Become MemoriesLexie Kane | Nielsen Norman GroupWhat is Peak-End Theory? A Psychologist Explains How Our Memory Fools UsPositive PsychologyHow do our memories differ from our experiences?The Decision LabPeak–End RuleWikipediaWhen More Pain Is Preferred to Less: Adding a Better EndDaniel Kahneman, Barbara L. Fredrickson, Charles A. Schreiber and Donald A. RedelmeierEvaluations of pleasurable experiences: The peak-end ruleAmy M. Do, Alexander V. Rupert & George WolfordBuy Large Format Poster
Download free posterRelatedSerial Position EffectUsers have a propensity to best remember the first and last items in a series.Miller’s LawThe average person can only keep 7 (plus or minus 2) items in their working memory.Von Restorff EffectThe Von Restorff effect, also known as The Isolation Effect, predicts that when multiple similar objects are present, the one that differs from the rest is most likely to be remembered.NextPostel’s LawBack to Top© Jon Yablonski 2024ContacttriangleRectangle 15Oval 3Combined ShapeOval 9 CopyAesthetic-Usability Effect | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allAesthetic-Usability EffectUsers often perceive aesthetically pleasing design as design that’s more usable.Users often perceive aesthetically pleasing design as design that’s more usable.TakeawaysAn aesthetically pleasing design creates a positive response in people’s brains and leads them to believe the design actually works better.People are more tolerant of minor usability issues when the design of a product or service is aesthetically pleasing.Visually pleasing design can mask usability problems and prevent issues from being discovered during usability testing.OriginsThe aesthetic-usability effect was first studied in the field of human–computer interaction in 1995. Researchers Masaaki Kurosu and Kaori Kashimura from the Hitachi Design Center tested 26 variations of an ATM UI, asking the 252 study participants to rate each design on ease of use, as well as aesthetic appeal. They found a stronger correlation between the participants’ ratings of aesthetic appeal and perceived ease of use than the correlation between their ratings of aesthetic appeal and actual ease of use. Kurosu and Kashimura concluded that users are strongly influenced by the aesthetics of any given interface, even when they try to evaluate the underlying functionality of the system.SourceFurther ReadingThe Aesthetic-Usability EffectKate Moran | Nielsen Norman GroupThe Aesthetic Usability Effect and Prioritizing Appearance vs. FunctionalityKathryn Whitenton | Nielsen Norman GroupAesthetic Usability EffectWikipediaThe Aesthetic-Usability Effect: Why Beautiful-Looking Products are Preferred Over Usable-But-Not-Beautiful OnesAbhishek Chakraborty | MediumA Neuropsychological Theory of Positive Affect and Its Influence on CognitionF. Gregory AshbyBuy Large Format Poster
Download free posterRelatedDoherty ThresholdProductivity soars when a computer and its users interact at a pace (<400ms) that ensures that neither has to wait on the other.Fitts’s LawThe time to acquire a target is a function of the distance to and size of the target.Hick’s LawThe time it takes to make a decision increases with the number and complexity of choices.NextDoherty ThresholdBack to Top© Jon Yablonski 2024ContactOval 3triangleOval 9 CopyCombined ShapeRectangle 15Postel’s Law | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allPostel’s LawBe liberal in what you accept, and conservative in what you send.Be liberal in what you accept, and conservative in what you send.TakeawaysBe empathetic to, flexible about, and tolerant of any of the various actions the user could take or any input they might provide.Anticipate virtually anything in terms of input, access, and capability while providing a reliable and accessible interface.The more we can anticipate and plan for in design, the more resilient the design will be.Accept variable input from users, translating that input to meet your requirements, defining boundaries for input, and providing clear feedback to the user.OriginsPostel’s Law (also known as the Robustness Principle) was formulated by Jon Postel, an early pioneer of the Internet. The Law is a design guideline for software, specifically in regards to TCP and networks, and states “TCP implementations should follow a general principle of robustness: be conservative in what you do, be liberal in what you accept from others”. In other words, programs that send messages to other machines (or to other programs on the same machine) should conform completely to the specifications, but programs that receive messages should accept non-conformant input as long as the meaning is clear.SourceFurther ReadingDesign Systems and Postel’s LawMark BoultonRobustness and Least PowerAdactioYour Website has Two FacesA List ApartDesign with Difficult DataSteven GarrityRobustness PrincipleWikipediaBuy Large Format Poster
Download free posterRelatedHick’s LawThe time it takes to make a decision increases with the number and complexity of choices.Law of PrägnanzPeople will perceive and interpret ambiguous or complex images as the simplest form possible, because it is the interpretation that requires the least cognitive effort of us.Tesler’s LawTesler's Law, also known as The Law of Conservation of Complexity, states that for any system there is a certain amount of complexity which cannot be reduced.NextSerial Position EffectBack to Top© Jon Yablonski 2024ContactOval 9 CopytriangleOval 3Rectangle 15Combined ShapeParkinson’s Law | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allParkinson’s LawAny task will inflate until all of the available time is spent.Any task will inflate until all of the available time is spent.TakeawaysLimit the time it takes to complete a task to what users expect it’ll take.Reducing the actual duration to complete a task from the expected duration will improve the overall user experience.Leverage features such as autofill to save the user time when providing critical information within forms. This allows for quick completion of purchases, bookings and other such functions while preventing task inflation.OriginsArticulated by Cyril Northcote Parkinson as part of the first sentence of a humorous essay published in The Economist in 1955 and since republished online, it was reprinted with other essays in the book Parkinson’s Law: The Pursuit of Progress (London, John Murray, 1958). He derived the dictum from his extensive experience in the British Civil Service.SourceFurther ReadingParkinson’s Law on WikipediaWikipediaParkinson’s Law: Why Constraints Are The Best Thing You Can Work WithLouis Chew | Medium.comBuy Large Format Poster
Download free posterRelatedAesthetic-Usability EffectUsers often perceive aesthetically pleasing design as design that’s more usable.Occam’s RazorAmong competing hypotheses that predict equally well, the one with the fewest assumptions should be selected.Pareto PrincipleThe Pareto principle states that, for many events, roughly 80% of the effects come from 20% of the causes.NextPeak-End RuleBack to Top© Jon Yablonski 2024ContactOval 3triangleCombined ShapeOval 9 CopyRectangle 15Law of Proximity | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allLaw of ProximityObjects that are near, or proximate to each other, tend to be grouped together.Objects that are near, or proximate to each other, tend to be grouped together.TakeawaysProximity helps to establish a relationship with nearby objects.Elements in close proximity are perceived to share similar functionality or traits.Proximity helps users understand and organize information faster and more efficiently.ExamplesGoogle Search ResultsThe spacing between each result on Google’s search results page contributes to the overall scannability of the page but also helps to effectively group each result as a related cluster of information.OriginsThe principles of grouping (or Gestalt laws of grouping) are a set of principles in psychology, first proposed by Gestalt psychologists to account for the observation that humans naturally perceive objects as organized patterns and objects, a principle known as Prägnanz. Gestalt psychologists argued that these principles exist because the mind has an innate disposition to perceive patterns in the stimulus based on certain rules. These principles are organized into five categories: Proximity, Similarity, Continuity, Closure, and Connectedness.SourceFurther ReadingGestalt Principles of Design — ProximityChris ButlerProximity Principle in Visual DesignAurora Harley | Nielsen Norman GroupLaws of Proximity, Uniform Connectedness, and ContinuationMads Soegaard | Interation Design FoundationThe Psychology Principles Every UI/UX Designer Needs to KnowThanasis Rigopoulos | MarvelDesign Principles: Visual Perception And The Principles Of GestaltSteven Bradley | Smashing MagazineBuy Large Format Poster
Download free posterRelatedLaw of Common RegionElements tend to be perceived into groups if they are sharing an area with a clearly defined boundary.Law of Uniform ConnectednessElements that are visually connected are perceived as more related than elements with no connection.Fitts’s LawThe time to acquire a target is a function of the distance to and size of the target.NextLaw of PrägnanzBack to Top© Jon Yablonski 2024ContactOval 3Oval 9 CopytriangleRectangle 15Combined ShapeDesigning With Occam’s Razor | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishDesigning With Occam’s RazorComplicating the simple is commonplace in web design — even the experienced designer will find themselves reaching for an overly complex solution from time-to-time. It’s easy to get carried away with details that we assume will enhance the user’s experience, when in reality they have the potential to distract and confuse them. The challenge is to make the complicated simple, and to do this we need a guiding principle; one that can cut through complexity and guide our decision making process.September 11, 2017UXprocessThis article was originally published the blog of Jon Yablonski.Complicating the simple is commonplace in web design — even the experienced designer will find themselves reaching for an overly complex solution from time-to-time. It’s easy to get carried away with details that we assume will enhance the user’s experience, when in reality they have the potential to distract and confuse them. The challenge is to make the complicated simple, and to do this we need a guiding principle; one that can cut through complexity and guide our decision making process.The PrincipleOccam’s Razor is a problem-solving principle attributed to William of Ockham, an English Franciscan friar and scholastic philosopher and theologian during the Medieval period. The name derives from Ockham’s surname plus ‘razor’, which refers to the distinguishing between two hypotheses either by shaving away unnecessary assumptions or cutting apart two similar conclusions. It states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected.Ockham didn’t invent “the razor”, but he used it to great extent in his own work. The principle has since been applied in a number of fields that include science, biology, medicine, probability theory and statistics.Applying Occam’s RazorSo what does this have to do with design? The answer lies in a modern interpretation of Occam’s Razor: “Entities must not be multiplied beyond necessity”. When applied to our work as designers, Occam’s Razor can be adopted as a guiding principle that informs our decisions and keeps us from reaching for a complex solution when a simpler one is sufficient.By only introducing complexity when it is necessary, we can ensure that our designs stay lean and void of superfluous elements that do not add value to the user’s experience.Keep It SimpleOne way to leverage the principle of Occam’s Razor is evaluate each and every design element based on it’s necessity. We must constantly ask ourselves when designing: “What is the minimum amount of UI that will allow the content to best found and effectively communicate to the user?”. It’s easy to make the mistake of thinking that you‘re enhancing the experience by sprinkling in delightful animations or hiding away navigation in an offscreen menu. The reality is you might be introducing unnecessary complexity that potentially can become an obstacle.While there’s techniques for reducing design complexity, the best approach is to avoid it in the first place. The key is to start with the simplest solution and only introduce complexity if needed. Our UI should reinforce the content message, eliminate any barriers, and not impede the ability to traverse the content.Good design is as little design as possible.Dieter RamsEdit RuthlesslyAnother way to apply the principle of Occam’s Razor is to be aggressive when editing your work. Every design element and pattern should be evaluated on it’s effectiveness, and edited if a simpler solution exists. If it doesn’t have meaning or provide value, it should be altogether removed.The most effective method I’ve found for evaluating my work is through design critiques. These iterative sessions provide an opportunity to initiate discussion and get feedback on design decisions from your peers. They force us to articulate why we made specific design decisions, and in the process strengthen our work by identifying spots that aren’t as clear or effective.Perfection is achieved not when there is nothing more to add, but when there is nothing left to take away.Antoine de Saint-ExupéryThis simple principle can help to inform our design decisions and keep us from reaching for a complex solution when a simpler one is sufficient. By shaving away complexity, our designs will have clarity and be more impactful. Users will appreciate that you’ve eliminated obstacles and streamlined the interface, allowing for them to find what they need faster and more efficiently.RelatedDesign Principles for Reducing Cognitive LoadA look at both the causes and ways to reduce extraneous mental processing for the user.NextDesign Principles for Reducing Cognitive LoadBack to Top© Jon Yablonski 2024ContacttriangleCombined ShapeOval 3Oval 9 CopyRectangle 15Artificial IntelligenceSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsArtificial Intelligence  These are technical guides for non-technical people. Whether youâve found yourself in need of knowing AI or have always been curious to learn more, this will teach you enough to dive deeper into the vast and deep AI ocean. The purpose of these explanations is to succinctly break down complicated topics without relying on technical jargon.What is artificial intelligence?Any system capable of simulating human intelligence and thought processes is said to have âArtificial Intelligenceâ (AI).Â Science fiction has done a fantastic job at warning us whatâs to come once machines are able to think as well as humans. Fortunately, the AIs often depicted in movies are far more advanced than what technology is capable of today (or any time soon, for that matter).While these aspirational systems â called artificial general intelligence â are far off, thereâs a lot of deserved buzz around artificial narrow intelligence, or weak AI. Narrow AI focuses on one, narrow task of human intelligence, and within it, there are two branches: rule-based AI and example based AI. The former involves giving the machine rules to follow while the latter giving it examples to learn from.Â AI takes many forms, like machine learning, computer vision, natural language processing, robotics, etc. Consequently, the term âAIâ is increasingly used as shorthand to describe any machines that mimic our cognitive functions such as âlearningâ and âproblem solvingâ.The safest working definition is the study of making systems capable of simulating human intelligence and thought processes, which comes in many forms.Note: This guide makes comparisons to human intelligence to make it easier to understand the basic concepts of machine cognition. Organic thought is obviously different from artificial thought, both technically and philosophically, but philosophy is not the purpose of this document. Our goal is to provide the most digestible and practical explanation of AI.Why use AI?AI can achieve higher quality outcomes faster than humanly possible.Â Today, AI is most often used to recognize patterns, make predictions, and provide insights previously out of reach due to the sheer amount of available data. Itâs able to do this because, unlike traditional computer technologies, AI is able to learn from examples as opposed to being explicitly programmed to execute specific instructions.These systems are meant to augment our own intelligence and maximize our confidence. In a growing number of fields, AI is serving as a companion for professionals to enhance performance and reduce the time required to become an expert. It will aid in the pursuit of knowledge, to further our expertise, and to improve the human condition.Â Common AI use casesAI is a powerful toolbox that has many applications in domains far and wide. The types of problems that the AI toolbox is best equipped to solve can be split into six core intents, as described on IBMâs Watson site:Accelerate research and discoveryEnrich your interactionsAnticipate and preempt disruptionsRecommend with confidenceScale expertise and learningDetect liabilities and mitigate riskSome of the most common tasks AI performs â and their corresponding subfields â include:Extracting information from pictures (computer vision)Transcribing or understanding spoken words (speech to text and natural language processing)Pulling insights and patterns out of written text (natural language understanding)Speaking whatâs been written (text to speech, natural language processing)Autonomously moving through spaces based on its senses (robotics)Generally looking for patterns in heaps of data (machine learning)How does AI work?It depends on several factors.â¨ Each of AI tasks mentioned has its own unique implementation, but it can be boiled down to roughly two approaches: specifying the rules that solve the problem versus giving the machine examples to find the pattern on its own.Rules-basedThe rules-based approach uses algorithms â a sequence of unambiguous instructions used by computers to solve problems. It tells a computer precisely what steps to take to solve a problem or reach a goal. The chosen algorithm(s) determine how the AI will âthinkâ about surfacing insights to address your problem space. Different algorithms have different goals, strengths, and weaknesses.Â  Choosing the right fit depends on your desired outcome and the nuances of the process.


Algorithm for repairing a broken lamp


Algorithm for troubleshooting a non-functioning lampExamples basedTheÂ examples-based approach usesÂ dataÂ to createÂ models.Â This data can take many forms: music, videos, weather conditions, user profiles, system logs, etc.Â Models are the result ofÂ trainingÂ an AI on data to find patterns. This is akin to you studying before a big exam â you started with little to no understanding, so youÂ ingestedÂ a bunch of study material so that you could go out into the world ready to apply your new knowledge.Â This way of problem solving is largely made possible by its subfield,Â machine learning.Â ThisÂ isÂ helpful in cases where specifying rigid rules (i.e. writing algorithms)Â is hard or abundant e.g. in stock trading, identifying cancer, predicting which video a user wants to see next, etc.Â Some helpful people at MIT created a flowchart that guides you through whether or not the thing youâre looking at is, in fact, AI.See for yourselfWatson AssistantThis person does not existBoston Dynamics roboticsPreviousTeam essentialsNextBasics: Machine learningPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




FairnessSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsFairnessAI must be designed to minimize bias and promote inclusive representation.AI provides deeper insight into our personal lives when interacting with our sensitive data. As humans are inherently vulnerable to biases, and are responsible for building AI, there are chances for human bias to be embedded in the systems we create. It is the role of a responsible team to minimize algorithmic bias through ongoing research and data collection which is representative of a diverse population.


Recommended actions01
Real-time analysis of AI brings to light both intentional and
unintentional biases. When bias in data becomes apparent, the
team must investigate and understand where it originated and how
it can be mitigated.02
Design and develop without intentional biases and schedule team
reviews to avoid unintentional biases. Unintentional biases can
include stereotyping, confirmation bias, and sunk cost bias.03
Instill a feedback mechanism or open dialogue with users to raise awareness of user-identified biases or issues. e.g. Woebot asks âLet me know what you think,â after suggesting a link.âBy progressing new ethical frameworks for AI and thinking critically about the quality of our datasets and how humans perceive and work with AI, we can accelerate the [AI] field in a way that will benefit everyone. IBM believes that [AI] actually holds the keys to mitigating bias out of AI systems â and offers an unprecedented opportunity to shed light on the existing biases we hold as humans.âBias in AI: How we Build Fair AI Systems and Less-Biased HumansTo considerDiverse teams help to represent a wider variation of experiences
to minimize bias. Embrace team members of different ages,
ethnicities, genders, educational disciplines, and cultural
perspectives.Your AI may be susceptible to different types of bias based on
the type of data it ingests. Monitor training and results in
order to quickly respond to issues. Test early and often.Questions for your teamHow can we identify and audit unintentional biases that we run
into during the design and development of our AI?The status quo changes over time. How do we instill methods to
reflect that change in our ongoing data collection?How do we best collect feedback from users in order to correct
unintentional bias in design or decision-making?Fairness exampleAfter sitting down with members of the hotelâs global
management, the team uncovers that diversity and inclusiveness
are important elements to the hotelâs values. As a result, the
team ensures that the data collected about a userâs race,
gender, etc. in combination with their usage of the AI, will not
be used to market to or exclude certain demographics.The team inherited a set of data about guests from the hotel.
After analyzing this data and implementing it into a build of
the agent, they realize that it has a degree of algorithmic bias
from the data. The team proceeds to take the time to train the
model further on a bigger, more diverse set of data.


PreviousEthics: ExplainabilityNextEthics: User data rightsPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




User data rightsSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsUser data rightsAI must be designed to protect user data and preserve the userâs power over access and uses.It is your teamâs responsibility to keep users empowered with control over their interactions. Pew Research recently found that being in control of our own information is âvery importantâ to 74% of Americans. The European Commission found that 71% of EU citizens find it unacceptable for companies to share information about them without their permission. These percentages will rise as AI is further used to either amplify our privacy or undermine it. Your company should be fully compliant with the applicable portions of EUâs General Data Protection Regulation and any comparable regulations in other countries, to make sure users understand that AI is working in their best interests.


Recommended actions01
Users should always maintain control over what data is being
used and in what context. They can deny access to personal data
that they may find compromising or unfit for an AI to know or
use.02
Allow users to deny service or data by having the AI ask for
permission before an interaction or providing the option during
an interaction. Privacy settings and permissions should be
clear, findable, and adjustable.03
Provide full disclosure on how the personal information is being
used or shared.04
Usersâ data should be protected from theft, misuse, or data
corruption.05
Forbid use of another companyâs data without permission when
creating a new AI service.06
Recognize and adhere to applicable national and international rights laws when designing for an AIâs acceptable user data access permissions.âIndividuals require mechanisms to help curate their unique identity and personal data in conjunction with policies and practices that make them explicitly aware of consequences resulting from the bundling or resale of their personal information.âThe IEEE Global Initiative
on Ethics of Autonomous and Intelligent SystemsTo considerEmploy security practices including encryption, access control
methodologies, and proprietary consent management modules to
restrict access to authorized users and to de-identify data in
accordance with user preferences.It is your responsibility to work with your team to address any
lack of these practices.Questions for your teamWhat types of sensitive personal datadoes the AI utilize and
how will this data be protected?What contractual agreements are necessary for data usage and
what are the local and international laws that are applicable
to our AI?How do we create the best user experience with the minimum
amount of required user data?â©Data rights exampleThe hotel provides guests with a consent agreement to utilize
the AI hotel assistant before they begin using the AIâs
services. This agreement clearly outlines to guests that the
hotel does not own their data and they have the right to purge
this data from the system at any time, even after checkout.During user interviews, the design researchers find that the
guests feel they should be provided with a summary of the
information that was acquired from them during their stay. At
checkout, they can instruct the hotel to remove this information
from the system if they wish.


PreviousEthics: FairnessNextConversation: OverviewPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




Conversation overviewSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsConversation overviewNow that machines, powered by analytics and cognitive capabilities, can technically understand, reason, learn and interact using natural language, what will they say when designers give them a voice?IntroductionChatbot and agent usesWhat is conversation?Crafting effective conversationHow does a bot interpret conversation?IntroductionWhereas traditional speech recognition systems understand what people say, todayâs sophisticated natural language systems understand what people mean. And yet, the experience must walk a fine line: the bot must act like a human, with very human attributes (such as empathy, curiosity, humor, compassion, and patience) while maintaining the transparency of being a robot.Chatbot and agent usesFor the sake of simplicity, we will be referring to both chatbots and conversational agents as âbotsâ henceforth. Successful bots must augment capabilities and expertise, while also being an extension of the brands they represent. Bots have some clear uses including:Natural language and understandingBots have the ability to engage in real conversation with users. The bot will be able to understand the userâs messages and context to provide a response that is relevant and useful.Engagement and personalizationBots provide personalization at scale. They can help companies automate one-on-one communications with their customers and personalize those communications using customer information and by asking meaningful questions to understand the customer. Bots with personality will build emotional connections between customers and brands to increase engagement.Integration and growthBots are omni-channel. Successful bots will not be standalone applications, but rather a set of common tools that operate like a central cognitive brain. These can be deployed across all of the channels consumers use â messaging, mobile, phone systems, web, chat applications and social media. Bots do not have to roll out entirely new versions in order to constantly update the content and they can be trained on the fly based off real user data.Scalability and consistencyA bot allows you to own the conversation and the dialog for every engagement and make that interaction available 24/7. You can offload questions that donât require human interference for an instant response.Education and entertainmentBots are great for educating users on topics that are relevant to a brand, product or conversation topic. Bots also are diverse enough to entertain the user with games, natural conversation, or other forms of interaction.Intelligent authentication and securityVoice biometrics allows consumers to easily and naturally authenticate their identity without having to type in a password or PIN by simply speaking a short passphrase. Voice biometrics significantly improves security over legacy authentication methods and prevents fraud.What is conversation?Since conversation is the bedrock foundation of meaningful relationships, a bot must be capable of holding an intelligent, two- way conversation. As social beings, we converse every day without giving it a second thought and our discourse is natural and autonomic. We tend to take that natural flow for granted. To utilize conversational technology to its full, game-changing potential, we must be consciously aware of how we communicate.If we can understand how we communicate with each other we can begin to replicate this with a machine. For our intents and purposes, conversation is the meaningful exchange of ideas and information between two or more individuals. The requisite parts of a conversation are topics, exchanges, and utterances.TopicsTopics provide context. They are the high-level subjects of a conversation at any given point.ExchangesExchanges communicate information. An exchange consists of two or more utterances. Everything said within an exchange is relevant to either the topic or previous messaging. Without this correlation, there is no basis for understanding one another in conversation.UtterancesUtterances are the individual statements articulated in an exchange and the building blocks for all conversation. These expressions are the atomic, single turns within an exchange. Here is an example conversation that we can identify topics, exchanges, and utterances within.Example Conversation


Crafting effective conversationKeep in mind that a bot will only provide one half of the conversation. It could be initiating an exchange, or providing a response. You wonât be able to control the userâs end of a conversation. Your job, as a designer, is to provide a delightful conversational experience to the user using a bot as the medium. The key is developing your bot in a way that, no matter the utterance, the bot sounds natural and provides a believable response.Preferred ResponsesTo provide a realistic conversation for your users, your bot must be relevant. A tacit expectation exists at the heart of every conversation. When we speak we are expecting a response that is relevant to the topic at hand, whether its good or bad. Yet, it goes a bit deeper than that. We are unknowingly hoping for a specific type of response in conversation. This is what we call a preferred response. The same goes for responses we hope we donât receive, aka non-preferred responses.Understanding what your users may view as preferred responses, then maximizing preferred responses in conversation is a key to natural, positive conversations. Another key is to develop satisfying, informative non-preferred responses that donât come across as negative to the user. These are aspects of the conversations that we as humans find to be the most rewarding. Many small, rewarding interactions like these can build relationships over time with the bot.RelevancyIn general, we expect a response of some kind when making an utterance. At the bare minimum we expect something back that is relevant to our initial utterance. This is how we anchor our conversations; we arenât just shouting random utterances at each other.Itâs most thrilling when we feel, just as in human-human conversation, that a bot âunderstandsâ us. In a botâs case, that means being stateful and contextually aware of the topic at hand. Itâs critical for your bot to make the user feel understood while also maintaining relevancy.RepairBots should be able to elegantly fail in nearly all situations. Itâs crucial for a bot to provide authentic and relevant acknowledgement to a user when failure occurs. Itâs okay for the bot to be wrong, but itâs not okay for it to be wrong and irrelevant. This will immediately take users out of the moment and will degrade perception of the botâs abilities and comes across as unnatural. The ability for a bot to jump across multiple topics of discussion, handle harassment, recognize when an utterance is irrelevant or nonsense, or just get back on topic will be critical. Part of the designerâs job is to identify where and when conversation could get messy and account for it beforehand.How does a bot interpret conversation?A bot interprets our conversation digitally by identifying the intents and entities in our utterances, which in turn will give it the information it needs to craft a proper response.IntentsIntent = The action or purpose behind their utterance. These are generally verbs.For example, in the utterance: âIâd like to order some tacos and beer,â the intent would be to order. In the utterance: âWhere is the bathroom?â the intent is to find a location.EntitiesEntities = An object that was mentioned in the utterance that is relevant to the userâs purpose. These are generally nouns. By recognizing the entities that are mentioned in the userâs input, the bot can choose the proper response.For example, in the utterance: âIâd like to order some tacos and beerâ. The entities would be:Tacos = foodBeer = drinkPreviousEthics: User data rightsNextConversation: PlanningPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




Conversation planningSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsConversation planning  Now that machines, powered by analytics and cognitive capabilities, can technically understand, reason, learn and interact using natural language, what will they say when designers give them a voice?Establish its purposeDetermine topic breadthDetermine topic depthDesign its personalityBuild your botEstablish its purposeNow that you understand more about bots and conversation, itâs time to start preparing for the actual building. Using the concepts form the learning phase, you will be developing a plan before sitting down in your tooling to write content.Six core AI intentsFirst and foremost, you must establish the purpose for your bot. This will be the basis of all of your conversational content and functionality. The most common reasons to use AI are to:Accelerate research and discoveryEnrich your interactionsAnticipate and preempt disruptionsRecommend with confidenceScale expertise and learningDetect liabilities and mitigate risksNarrowing your intent helps focus your work and accomplish a manageable number of tasks with higher quality. The probability of success is best correlated with how focused your bot is. Having a clear understanding of the focus also helps you communicate what exactly your bot can do so you avoid unrealistic expectations of the bot.Justify a bot as the solutionAlways remember that bots arenât an instant solution to problems facing your business or brand. The reasoning behind using a bot as a solution shouldnât be just because the technology exists. The reasoning must be based on the real value natural conversation would bring to your users and brand. Implementing conversation has its highest value when there is a need for engaging, contextual interaction, or a bot can accomplish something faster than traditional means.Before choosing a bot as a solution, ask yourself these questions.What is the userâs goal?How in-depth is the assistance the user will need?Is your domain something that is better off left in the hands of human assistance?How is a bot superior to âxâ (i.e. online documentation, contextual support, wizards, etcâ¦)?ExampleLetâs say one of your clients is a bank named Big Blue Bank. The bank has expressed interest in some sort of virtual agent that they can interact with when the bank is closed. This is not just for online banking, but to make users feel the same personal trust and connection they feel when speaking with a bank teller. Your botâs purpose would be to provide a trustworthy, personable bot that assists Big Blue Bank customers with any banking or customer service needs at any hour.Determine topic breadthThe primary goal of bot planning is to determine a botâs âMinimum Viable Knowledgeâ, or MVK. This is the minimum set of topics your bot will need to be able to proficiently discuss in order to be successful and fulfill its purpose. If you have those, then you set your bot up with a strong foundation.The steps to achieving your MVK is twofold: 1. Determining which topics are needed and 2. How deep each topic should be covered.First, list out all the possible topics you can think of for your bot. Then, prioritize. The fewer and more focused, the more likely your bot will be successful.ExampleAfter doing your research and deciding your botâs purpose it should start to become to clear what your topics will be. These are the subjects of the conversation. For Big Blue Bank, these could be some starter topics for an MVK.Opening a new accountMoney transfersDepositsWithdrawalsLoansBasic Self-serve Customer ServiceDetermine topic depthAfter determining which topics are of utmost importance given your botâs intent, itâs time to map out how fluently it should be able to speak about each one.Each topic will require you not only to design all possible ideal paths, but all possible precautions for when the bot fails to understand the user. In the moments where the user has strayed outside of your botâs capabilities, irritation and frustration can naturally follow. This ability to elegantly fail and repair the conversation is paramount for displaying provable authenticity and building trust.At this step, start with a topic and flesh out the individual turns between the human and bot until it reaches a dead end. It helps to start with the ideal path(s), and from there branch off into all of the possible ways mistakes or deviations can get made along the way.ExampleBig Blue Bank decides that opening a new account is the lowest hanging fruit. They diverge on all of the different paths a user might take to open an account, including places where it would be easier to be handed off to a human and places where errors can happen.Design your botâs personalityPersonality follows the MVK, because solving the userâs need is first priority. Also, without all of the proper planning, you will be ill-prepared to identify the proper personality for your bot. Since a botâs personality will be the âbeingâ that the user will interact with in the end product, it needs to properly reflect the conversational tendencies of its particular domain.You will need to establish a personality that best communicates your botâs purpose and representâs your brands values. By understanding how your personality would act and speak in a situation, you can write your conversation through their imaginary voice.Ask yourselves these questions when developing your botâs personality:How social is it?How open and up front is it?How agreeable is it?How thoughtful is it?How moody is it?How excitable is it?How professional is it?What kind of character is it?How would it react in negative or hostile situation?What medium will it utilize?What is it not like?There are lots of different ways to come up with a personality, and all of them are correct. You might consider thinking about personality mapping techniques including the Caliper Profile, or the Myers & Briggs Type Indicator.ExampleFor Big Blue Bank, you may consider striking a balance between an official tone and a friendly, trusting tone. Look at the most successful banking employees with great relationships with their customers. How do they act? In what situations do they joke around, and in what situations are they serious?PreviousConversation: OverviewPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




Everyday ethics for AISkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsEveryday ethics for AI  Ethical decision-making isnât just another form of technical problem solving. As designers and developers of AI systems, we hold a vast share of the collective influence and it is an imperative to understand the ethical considerations of our work. We are creating systems that will impact millions of people.IntroductionEveryday ethics for AI provides discussion points concerning:specific virtues that AI systems should possess;guidance for designers and developers training and building AI.Artificial intelligence is rapidly growing in capability, impact and influence. As designers and developers of AI systems, it is an imperative to understand the ethical considerations of our work. A tech-centric focus that solely revolves around improving the capabilities of an intelligent system doesnât sufficiently consider human needs.AI systems must remain flexible enough to undergo constant maintenance and improvement as ethical challenges are discovered and remediated. By adopting and practicing the five focal areas covered here, designers and developers can become more ethically aware, mitigate biases within these systems, and instill responsibility and accountability in those who work with AI. Constant improvement and assessment is key to ensuring that design and development teams address usersâ concerns.Stay up to dateWeâre always updating our ethics content to reflect our feedback from users and teams. Find this version in pdf form here.Five Ethical Focal AreasAccountabilityValue AlignmentExplainabilityFairnessUser Data RightsThese focal areas provide an intentional framework for establishing an ethical foundation for building and using AI systems. As much of what we do related to artificial intelligence is new territory for all of us, individuals and groups will need to further define criteria and metrics for evaluation to better allow for the detection and mitigation of any issues.The large-scale focus on AI ethics by groups like the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems, which will be referenced throughout this guide, should be mirrored in businesses and working groups of all sizes. The criteria and metrics for ethical AI systems will ultimately depend on the industry and use case they operate within.We hope this guide serves as a centralized source that helps teams establish best practices. Designers and developers should never work in a vacuum and must stay in tune with usersâ needs and concerns.Constant improvement and assessment is key to ensuring that design and development teams address usersâ concerns. This guide provides teams with a starting point and will surely evolve as AI capabilities continue to grow.The idea here is to start simple and iterate. Weâre dependent on you to experiment, play, use, and break what you find here and send us your feedback. As you work with your team and others, please share this guide with them. If you have questions, comments or suggestions please email edethics@us.ibm.com.Running exampleA hotel chain wants to embed artificial intelligence into an in-room virtual assistant/concierge to augment and personalize their usersâ stay. Weâll use the project team in charge of this effort as an example throughout the guide. This conversational agent will include capabilities such as:Agentive-style assistance.Introduction to their room and services in their preferred language.Control of room facilities through natural language.Sending a request directly to the service team through the in-room virtual assistant.


PreviousEthics: OverviewNextEthics: AccountabilityPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




IBM Design for AISkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsYour browser does not support the video tag.FundamentalsEthicsOur PracticeTo design for a relationship with AI, we need to know ourselves first. Our practice is built on IBMâs Principles for the AI Era as a resource for all designers and developers. This shared collection of ethics, guidelines, and resources ensures that IBM products share a unified foundation.FundamentalsBasicsEthicsConversationTeam EssentialsFundamentalsTeam EssentialsBasicsEthicsConversationGet in touchFor any questions, clarifications, or comments, please reach out to us at any time. Weâre open and available for ideas, guidance and support.Start Contributing âPreviousHomeNextFundamentalsPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




AccountabilitySkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsAccountabilityAI designers and developers are responsible for considering AI design, development, decision processes, and outcomes.Human judgment plays a role throughout a seemingly objective system of logical decisions. It is humans who write algorithms, who define success or failure, who make decisions about the uses of systems and who may be affected by a systemâs outcomes.Every person involved in the creation of AI at any step is accountable for considering the systemâs impact in the world, as are the companies invested in its development.


Recommended actions01
Make company policies clear and accessible to design and development teams from day one so that no one is confused about issues of responsibility or accountability. As an AI designer or developer, it is your responsibility to know.02
Understand where the responsibility of the company/software ends. You may not have control over how data or a tool will be used by a user, client, or other external source.03
Keep detailed records of your design processes and decision making. Determine a strategy for keeping records during the design and development process to encourage best practices and encourage iteration.04
Adhere to your companyâs business conduct guidelines. Also, understand national and international laws, regulations, and guidelines that your AI may have to work within. You can find other related resources in the IEEE Ethically Aligned Design document.âNearly 50% of the surveyed developers believe that the humans creating AI should be responsible for considering the ramifications of the technology. Not the bosses. Not the middle managers. The coders.âMark Wilson, Fast Company
on Stack Overflowâs Developer Survey Results 2018To considerUnderstand the workings of your AI even if youâre not personally developing and monitoring its algorithms.Refer to secondary research by sociologists, linguists, behaviorists, and other professionals to understand ethical issues in a holistic context.Questions for your teamHow does accountability change according to the levels of user influence over an AI system?Is the AI to be embedded in a human decision-making process, is it making decisions on its own, or is it a hybrid?How will our team keep records of our process?How do we keep track of ethical design choices and considerations after the launch of the AI?Will others new to our effort be able understand to our records?Accountability exampleThe team utilizes design researchers to contact real guests in the hotels to understand their wants and needs through face-to-face user interviews.The team considers their own responsibility when a hotel assistantâs feedback does not meet the needs or expectations of guests. They have implemented a feedback learning loop to better understand preferences and have highlighted the ability for a guest to turn off the AI at any point during their stay.


PreviousEthics: Everyday ethics for AINextEthics: Value alignmentPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




ExplainabilitySkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsExplainabilityAI should be designed for humans to easily perceive, detect, and understand its decision process.In general, we donât blindly trust those who canât explain their reasoning. The same goes for AI, perhaps  even more so. As an AI increases in capabilities and achieves a greater range of impact, its decision-making process should be explainable in terms people can understand. Explainability is key for users interacting with AI to understand the AIâs conclusions and recommendations. Your users should always be aware that they are interacting with an AI. Good design does not sacrifice transparency in creating a seamless experience. Imperceptible AI is not ethical AI.


Recommended actions01
Allow for questions. A user should be able to ask why an AI is
doing what itâs doing on an ongoing basis. This should be clear
and up front in the user interface at all times.02
Decision making processes must be reviewable, especially if the
AI is working with highly sensitive personal information data
like personally identifiable information, protected health
information, and/or biometric data.â¨03
When an AI is assisting users with making any highly sensitive
decisions, the AI must be able to provide them with a sufficient
explanation of recommendations, the data used, and the reasoning
behind the recommendations.04
Teams should have and maintain access to a record of an AIâs
decision processes and be amenable to verification of those
decision processes.âIBM supports transparency and data governance policies that will ensure people understand how an AI system came to a given conclusion or recommendation. Companies must be able to explain what went into their algorithmâs recommendations. If they canât, then their systems shouldnât be on the market.âData Responsibility at IBMTo considerExplainability is needed to build public confidence in disruptive technology, to promote safer practices, and to facilitate broader societal adoption.There are situations where users may not have access to the full decision process that an AI might go through, e.g. financial investment algorithms.Ensure an AI systemâs level of transparency is clear. Users should stay generally informed on the AIâs intent even when they canât access a breakdown of the AIâs process.â©Questions for your teamHow do we build explainability into our experience without
detracting from user experience or distracting from the task at
hand?Do certain processes or pieces of information need to be hidden
from users for security or IP reasons? How is this explained to
users?Which segments of our AI decision processes can be articulated
for users in an easily digestible and explainable fashion?Explainability examplePer GDPR (General Data Protection Regulation), a guest must explicitly opt in to use the hotel room assistant. Additionally, they will be provided with a transparent UI to show how the AI makes its recommendations and suggestions.A researcher on the team, through interviews with hotel guests, understands that the guests want a way to opt into having their personal information stored. The team enables a way for the AI to provide guests (through voice or graphic UI) with options and the ability for the system to gather pieces of information with consent.With permission, the AI offers recommendations for places to visit during their stay. Guests can ask why these recommendations are made and which set of data is being utilized to make them.


PreviousEthics: Value alignmentNextEthics: FairnessPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




AI design ethics overviewSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsAI design ethics overview  Weâve built our perspective on ethical AI design through conversations with our subject matter experts, our teams, our stakeholders, and by referencing publicly available material. The resources below offer additional context on our foundational knowledge and insight into how these directions will continue to evolve in the future.IBM Research Trusted AIIEEEâs Ethically Aligned DesignThe Partnership on AIOverviewEthical decision-making isnât just another form of technical problem solving. As designers and developers of AI systems, we hold a vast share of the collective influence and it is an imperative to understand the ethical considerations of our work. We are creating systems that will impact millions of people.âAn ethical, human-centric AI must be designed and developed in a manner that is aligned with the values and ethical principles of a society or the community it affects. Ethics is based on well-founded standards of right and wrong that prescribe what humans ought to do, usually in terms of rights, obligations, benefits to society, fairness, or specific virtues.âMarkkula Center for Applied EthicsWeâll add content and resources to this section of the site over time as we incorporate them into our design practice. Our goal here is transparency around what works for us and our users, and why.


ibm.bizEveryday Ethics for AIPreviousBasics: DataNextEthics: Everyday ethics for AIPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




Value alignmentSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsValue alignmentAI should be designed to align with the norms and values of your user group in mind.AI works alongside diverse, human interests. People make decisions based on any number of contextual factors, including their experiences, memories, upbringing, and cultural norms. These factors allow us to have a fundamental understanding of âright and wrongâ in a wide range of contexts, at home, in the office, or elsewhere. This is second nature for humans, as we have a wealth of experiences to draw upon.Todayâs AI systems do not have these types of experiences to draw upon, so it is the job of designers and developers to collaborate with each other in order to ensure consideration of existing values. Care is required to ensure sensitivity to a wide range of cultural norms and values. As daunting as it may seem to take value systems into account, the common core of universal principles is that they are a cooperative phenomenon. Successful teams already understand that cooperation and collaboration leads to the best outcomes.


Recommended actions01
Consider the culture that establishes the value systems youâre designing within. Whenever possible, bring in policymakers and academics that can help your team articulate relevant perspectives.02
Work with design researchers to understand and reflect your usersâ values. You can find out more about this process here.03
Consider mapping out your understanding of your usersâ values and aligning the AIâs actions accordingly with an Ethics Canvas. Values will be specific to certain use cases and affected communities. Alignment will allow users to better understand your AIâs actions and intents.âIf machines engage in human communities as autonomous agents, then those agents will be expected to follow the communityâs social and moral norms. A necessary step in enabling machines to do so is to identify these norms. But whose norms?âThe IEEE Global Initiative
on Ethics of Autonomous and Intelligent SystemsTo considerIf you need somewhere to start, consider IBMâs Standards of Corporate Responsibility or use your companyâs standards documentation.Values are subjective and differ globally. Global companies must take into account language barriers and cultural differences.Well-meaning values can create unintended consequences. e.g. a tailored political newsfeed provides users with news that aligns with their beliefs but does not holistically represent the gestalt.Questions for your teamWhich groupâs values are expressed by our AI and why?How do we agree on which values to consider as a team? (For more reading on moral alignment, check here.)How do we change or adjust the values reflected by our AI as our values evolve over time?â©Value alignment exampleThe team understands that for a voice-activated assistant to work properly, it must be âalways listeningâ for a wake word. The team makes it clear to guests that the AI hotel assistant is designed to not keep any data, or monitor guests, in both cases without their knowledge, even if it is listening for a wake word.The audio collected while listening for a wake word is auto-deleted every 5 seconds. Even if a guest opts in, the AI does not actively listen in on guests unless it is called upon.The team knows that this agent will be used in hotels across the world, which will require different languages and customs. They consult with linguists to ensure the AI will be able to speak in guestsâ respective languages and respect applicable customs.


PreviousEthics: AccountabilityNextEthics: ExplainabilityPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




Team essentialsSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsTeam essentials  Everyone can play a role in how their team innovates with AI.
Teams need a diverse set of minds and skill sets to create something useful, intuitive, and responsible. These courses will give you the language, knowledge, and actionable methods to work alongside technical and non-technical members of your team to create AI solutions.Apply design thinking to artificial intelligence.Teams need a diverse set of minds and skill sets to create something useful, intuitive, and responsible. Our course will give you the language, knowledge, and actionable methods to work alongside technical and non-technical members of your team to create AI solutions.In this course, youâll learn our AI Essentials Framework, work through a fictional case study to see how a team could use this framework, and collect resources that you can apply with your team immediately.Youâll explore what it means to design artificial intelligence systems as a team, guided by a clear intent and a focus on people. This course will give you the framework and tools you need to recognize responsible AI design, align your team, and work with data sources to start building an AI solution today.











AI Essentials FrameworkThe framework is a set of activities, tools, and principles that enable teams to design thoughtful, human-centered artificial intelligence solutions using Enterprise Design Thinking.The AI Essentials Framework is a specific grouping of activities to work through to align your team on strategy for an AI experience. There are five focal areas in the framework:Intent: Align on the business and user intent(s) for your solution.Data: Document the data you could use to make your idea a reality.Understanding: Determine what you will need to teach your AI.Reasoning: Bring your ideas down to earth.Knowledge: Brainstorm the direct and indirect effects of your AI.


Apply design thinking to artificial intelligence.Throughout this course, you will learn the AI Essentials Framework from experts, see an example in practice, and gather the resources you need to practice on your own project.


Enterprise Design Thinking for AIPreviousFundamentalsNextBasics: Artificial intelligencePrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




FundamentalsSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsFundamentalsArtificial intelligence (AI) is a mystery and a wonder. It can help us solve humanityâs most difficult problems. AI is also vastly misunderstood by most people. For some, AI is a magical black box with the intelligence of a PhD. It knows all about everything, you just bring your problems and, voilÃ¡, your problems are solved. For others, fears of AI uprisings, loss of human control and Terminator-like scenarios cloud their capability to understand the present utility of cognitive computing.IntroductionAI design foundationsCharacteristics of AIDesign factors for AIRelationship developmentAI ecosystemAI/human context modelIntroductionWhen looking for ways to apply this cutting-edge, revolutionary technology, AI can not only dazzle, but can blind us as well. The more buzz and hype, the greater the pressure becomes to rush to create something using whatever new capabilities are presented to us. The benefit of moments like this is the opportunity to discover, experiment, and learn.We must focus our design talents upon a new type relationship with machines - machines that can draw from vast stores of human knowledge, hold a conversation, and increase human understanding. What should these relationships look like? Designing for AI requires new considerations and new ways of thinking.When we find ourselves in such unfamiliar territory, the best way to begin is by reminding ourselves of the true purpose for any innovation: to improve the quality of human life.Consider what weâve learned living through the past few major technological innovations. The internet brought the worldâs information to our beck and call and taught us that whatever we want, whenever we want it is always a finger-length away. Mobile tech enabled humanity to take that information with us at all times. Social computing and messaging changed the foundations of how we communicate with each other and language itself.Each innovation provided a new context for communication and expanded (or changed) our understanding of the relationships we have with machines. AI requires us to take notice of new contexts yet again. This time, designers must account for a system that can understand, reason, learn, and interact.As a result, this changes the nature of our design considerations, some of which we take for granted based on the last 40+ years of software design. If weâve moved past typing into a text field and pressing âsubmit,â what does it mean to design for human/machine relationships?AI Design FoundationsAs Jared Spool says, design is the rendering of intent. This intent drives our outcomes. Itâs the âwhyâ behind what we do and the cause for us to affect change. Intentions require us to identify purposes and values for our efforts. Outcomes require going beyond ideas and create meaningful, trusted solutions for the people we serve.Design is more than a job or roleâitâs an essential part of what makes us human. The value of design is to improve lives and leave the world better than we found it. When designing for AI, our core intents are always rendered through the following lenses:PurposeThe reason for the user to engage with the system. This will evolve as the user and system grow with each other.ValueThe augmented capabilities provided by the system that tangibly improves a userâs life.TrustThe willingness of a user to invest in an emotional bond with the system. This trust is predicated on security of the systemâs data, the feeling of human control, and the quality of the results the system provides.Characteristics of AIAI is the simulation of human thought processes in a computerized model. AI involves self-learning systems that use data mining, pattern recognition and natural language processing to mimic the way the human brain works.These systems learn at scale, reason with purpose and interact with humans naturally. What search is to information retrieval, AI is to better, more-informed decision-making. In short, they help human experts make better decisions. We characterize AI as having four main qualities:UnderstandsAI deeply understands its domain. It does this primarily through data â structured and unstructured, text-based or sensory â in context and meaning, at speed and volume.ReasonsAI reasons towards specific goals. It has the ability to form hypotheses by making considered arguments and prioritized recommendations to help humans make better decisions.LearnsAI learns continuously through experience. In ingests and accumulates data and insight from every interaction at all times. It is trained, not programmed, by experts who enhance, scale and accelerate their expertise. Therefore, these systems get better over time.InteractsAI interacts naturally with people and systems. The interaction model of an AI is expected to flow unobtrusively while continuously building a sustainable relationship between itself and its users.Design factors for AIWhen it comes to designing for AI, our focus must be unwavering in providing experiences that put the user above all else.AI isnât about data, itâs about insights. Data is the fuel for the car, insights are the destinations. This is what people care about.AI is capable of delivering more human-like interactions with people â based on the mode, form, and quality each person prefers. It reasons through the sum total of structured and unstructured data to find what really matters but this isnât the full picture. Our solutions must primarily address user needs instead of being force-fit to accommodate technical capabilities or requirements.


MutualMarketing human dynamics overview. Builds on Debra M. Amidonâs âEvolution of ThoughtâPhilosophically and psychologically, we find purpose, value and trust in others when we can perceive intended meaning, consider this meaning from differing points of view, and acquire knowledge so that we can act to have an effect on one another. If a system has the capability to understand, reason, learn, and interact then it has the basis to form a relationship with a human.For AI to truly amplify humanity we must have and maintain meaningful relationships between humans and machines.To design authentic AI-based relationships requires us, as designers, to consciously understand ourselves before anything else. The more we understand of ourselves, the better we will be able to teach machines how to help our users be better.Relationship developmentAt this point, you might be asking yourself, âhow do I design a relationship?â You wouldnât be alone in this. For most people, forming and maintaining relationships is an autonomic process. We hardly give it a second thought. If you take a deeper look at the psychology behind relationships, youâll probably find Knappâs Relational Development Model.Mark Knapp is a teaching professor at the University of Texas and is known for his works in nonverbal communication research. His relationship model explains how relationships grow and last and also how they end. This model is categorized into ten different stages which come under two interrelating stages âcoming togetherâ and âcoming apart.â This helps to understand how a relationship progresses and deteriorates. For the purposes of our work with AI, we will focus on the âcoming togetherâ stages exclusively.


Knapp's relational development modelInitiatingA collection of first impressions and snap judgements are made. Even if these are inaccurate, they significantly influence if each party wants to continue to the next stage.ExperimentingIf thereâs a degree of mutual interest, the parties start exploring, looking for commonalities of interests, acquaintances and value.IntensifyingWith enough in common, we look for reciprocal sharing by the other person that signals their interest in deepening the relationship.IntegratingAI interacts naturally with people and systems. The AI interaction model is expected to flow unobtrusively while continuously building a sustainable relationship between itself and its users.BondingBoth parties are fully partnered through trust and mutual appreciation. The relationship is indefinite and only to be broken through a formal notice.


Establishing a human/machine relationshipA symbiotic relationshipSo what do we need to consider when one person in a relationship is replaced by a machine? By establishing tone and personality first, the system will have the means to endear itself to the user. As these systems are like âdigital toddlers,â the means to make an emotional connection with its users will be essential.


AI ecosystemArtificial intelligences are probabilistic systems. This means that they are taught instead of being programmed. Since they are being taught, they must have context to be able to utilize their learnings. An AI needs this context to understand its place and provide value.


AI ecosystemHumanThe person whose needs are ultimately being servedMachineThe system and its network of embodiments & connectionsContextThe holistic view of a complete human experience. Includes emotional, physical, system, and domain knowledge.BusinessThe business needs and market goals to be served by the systemWorldThe external factors that will both inform and educate the systemAI/human context model


AI/Human Context Model


AI/Human Context ModelIntentThe goals, wants, needs, and values of users and businesses. Intent provides your solutionâs purpose.Data and policyAll of the significant raw data a machine can collect from the user and the world and the policies that protect it.UnderstandingThe process of putting incoming structured and unstructured data in context of your domain. Also known as machine learning.ReasoningThe systemâs application of logic to decide on the best course(s) of action.KnowledgeThis is what the system knows. This is all past data, insights, and learned attributes measured up against the overall intent of the system.ExpressionHow the system delivers its response based on the content of the message and its understanding of the user.User reactionThis is the userâs genuine reaction to the systemâs expression. Based on the quality of the systemâs response.LearningThe user is continually teaching the system to improve through direct and indirect responses.OutcomeThe consequences of an actualized system used in the real world to solve real usersâ real problems.PreviousHomeNextTeam essentialsPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




DataSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsDataThese are technical guides for non-technical people. Whether youâve found yourself in need of knowing AI or have always been curious to learn more, this will teach you enough to dive deeper into the vast and deep AI ocean. The purpose of these explanations is to succinctly break down complicated topics without relying on technical jargon.What is data?Data is the fuel that powers artificial intelligence. Despite being critical to the AI equation, data often gets overlooked or minimizedâoften at enormous costs. It takes hard work to get data to the point where itâs usable for AI, but ultimately it comes down to hitting two big checkboxes: quantity and quality.Before taking the AI plunge, you need to have the right data and enough of it. This includes acquiring data, cleaning it, filling in the gaps, and in a majority of cases taking additional steps to render it useful. Those familiar with Rob Thomasâ AI Ladder will note that this takes place in the âCollectâ and âOrganizeâ steps.What follows are several of the key considerations with respect to collecting and using data.Data collectionSamplingSampling helps ensure your dataset matches the real world and that a given sliver of data is as representative of the whole as possible.Generally, in statistics and machine learning (ML), we want to know as much as possible about a certain population â a specific set of people with shared characteristics that make them interesting to us (e.g. new homebuyers in Montana, Yankee fans outside of New York, etc.).In an ideal world, weâd survey each and every individual in that population, or the majority of them. In the real world, thatâs expensive, tedious, and sometimes impossible. Instead, data collectors try to select a sliver of the population that best represents the population as a whole. It could look something like this.


Assuming you could only pick four people, thatâs probably the closest you could get to representing the population. Naturally, as the sample size grows closer to the population size, your sample characteristics will be closer to the true characteristics of the whole.In cases where the data wasnât properly sampled, youâll almost certainly come to the wrong conclusions about your population as a whole, meaning youâre not giving your users what they need. Assuming thatâs the case, itâs irreparable and unable to reconcile without going out and getting more data about your population.(Ease of) Acquiring dataThis is knowing what it takes to actually get the data. Data can take multiple different forms. Sometimes itâs in a database, sometimes itâs in a filing cabinet, sometimes itâs scattered across someoneâs desk. Some data is proprietary and some is public domain. Sometimes someone is positive that it exists, they just have to go find it.Wrangling data across disparate sources can take a substantial amount of time, and more so if it requires generating or digitizing the data.Data completenessData completeness indicates whether all the data that you need is available in your data resources and ensuring your data doesnât have gaps.If you buy a dozen eggs for a recipe, you donât want to get home and find that youâre missing one. If youâre working with a large dataset â even with millions of records â you donât want to find that your data has gaps or that certain fields are missing.In a contrived example, suppose youâre making a mood tracker and you import a table that looks like the one below. Your data doesnât tell you how John felt on Tuesday. In the real world, data specialists can sometimes fill gaps like this, though it isnât easy. Sometimes it renders the data unusable, requiring you to throw it out.DayJohnâs MoodSundayGoodMondayTuesdayBadData organizationConsolidating dataYou have your mountain of data pulled from several different piles digitized and sitting in front of you, now what? Likely itâll need to be combined and put in a single place, formatted a specific way. At this step you have to put all of your data in one place and make it work together.For example, letâs say you are trying to create a simple program to track your mood over time, along with the weather. Your journal entries are in a spreadsheet that you can export as a comma-separated value file (or .csv file). The weather data exists, but youâll have to use an API of some sort to pull it and pair it with your journal entries. Even though both piles of data exist and exist digitally, there is still work to pull them together in one place.Consistent dataTraining an AI is akin to training a toddler. That toddlerâs knowledge is dependent on you being consistent in your teaching. For example, you canât expect your toddler to ever master arithmetic if you say 1+1=2 and also teach 1+1=3 at the same time. You can expect the same out of your system. Ultimately this is making sure all of your data is saying the same thing.Data richnessData richness is when the quality of the data paints a vivid picture. This means that you have enough data to get to the essence of whatâs really going on. Itâs finding the necessary data points to ensure that youâre not conflating correlation with causation. Without data rich enough to describe the nature of your problem and environment, you run the risk of your AI missing the real connection.For example, letâs take a famous ice cream sales and murder rate correlation. An increase of ice cream sales is shown to coincide with an increase in homicides. If we left our observation there, we might try to â naively â ban the sale of ice cream. Of course weâd have no success, considering how these occurrences are only correlated; the missing variable being temperature, as ice cream sales and murder rates spike in hotter temperatures.Data collection and organizationDe-biased or bias transparent dataThis concern is one that needs to be top of mind, so that your AI doesnât optimize inequity. Bias â prejudice in favor of or against one thing, person, or group compared with another â can be introduced at many stages of the process. If we choose an unrepresentative sample, it skews the dataset in favor of the overrepresented. During the data entry, subjective, and often qualitative, fields are subject to the userâs interpretation, e.g. assessing how you feel on a day to day basis. Annotation, or tagging and labeling the data with pertinent information, brings with it the lenses each annotator sees the world through.Itâs worth noting explicitly right now, that even assuming data purity and removing all bias from it â which in many cases is nothing short of impossible â machine learning by its very nature is always a form of statistical discrimination.TakeawayWhen we get in our car, we think of the destination, rarely whatâs needed to get us there. Insights are the destination, data is the fuel. Consequently, before you set off on your AI journey, be mindful of what it takes to acquire enough useful and de-biased data.Even though itâs important to plan for where we want to land, itâs equally important to understand how to get there. Data is one half of the AI equation, and requires conscious consideration.PreviousBasics: Machine learningNextEthics: OverviewPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




AI design ethics overviewSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsAI design ethics overview  Weâve built our perspective on ethical AI design through conversations with our subject matter experts, our teams, our stakeholders, and by referencing publicly available material. The resources below offer additional context on our foundational knowledge and insight into how these directions will continue to evolve in the future.IBM Research Trusted AIIEEEâs Ethically Aligned DesignThe Partnership on AIOverviewEthical decision-making isnât just another form of technical problem solving. As designers and developers of AI systems, we hold a vast share of the collective influence and it is an imperative to understand the ethical considerations of our work. We are creating systems that will impact millions of people.âAn ethical, human-centric AI must be designed and developed in a manner that is aligned with the values and ethical principles of a society or the community it affects. Ethics is based on well-founded standards of right and wrong that prescribe what humans ought to do, usually in terms of rights, obligations, benefits to society, fairness, or specific virtues.âMarkkula Center for Applied EthicsWeâll add content and resources to this section of the site over time as we incorporate them into our design practice. Our goal here is transparency around what works for us and our users, and why.


ibm.bizEveryday Ethics for AIPreviousBasics: DataNextEthics: Everyday ethics for AIPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




Machine learningSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsMachine learning  These are technical guides for non-technical people. Whether youâve found yourself in need of knowing AI or have always been curious to learn more, this will teach you enough to dive deeper into the vast and deep AI ocean. The purpose of these explanations is to succinctly break down complicated topics without relying on technical jargon.What is machine learning?Machine learning (ML) is a subset of artificial intelligence (AI), that is all about getting an AI to accomplish tasks without being given specific instructions. In essence, itâs about teaching machines how to learn!AI is simulated human cognition, so letâs first think about how we learn. Hereâs a simple question: were we born with PhD level intelligence?Of course not! At the beginning of our lives, we have little understanding of the world around us, but over time we grow to learn a lot. We use our senses to take in data, and learn via a combination of interacting with the world around us, being explicitly taught certain things by others, finding patterns over time, and, of course, lots of trial-and-error.Â AI learns in a similar way. When itâs first created, an AI knows nothing; ML gives AI the ability to learn about its world.Note: This guide makes comparisons to human intelligence to make it easier to understand the basic concepts of machine cognition. Organic thought is obviously different from artificial thought, both technically and philosophically, but philosophy is not the purpose of this document. Our goal is to provide the most digestible and practical explanation of AI.Why use machine learning?AI is all about allowing a system to learn from examples rather than instructions. ML is what makes that possible.AIs are taught, not explicitly programmed. In other words, instead of spelling out specific rules to solve a problem, we give them examples of what they will encounter in the real world and let them find the patterns themselves.Â Allowing machines to find patterns is beneficial over spelling out the instructions when the instructions are hard or unknown or when the data has many different variables, for example treating cancer, predicting the stock market.


How does machine learning work?There are a few distinct ways that machines can learn. In most cases, itâll fall under one of three buckets: supervised learning, unsupervised learning, and reinforcement learning.Â Remember that we as humans also have discrete learning styles. Sometimes we learn by watching videos and reading books; other timesÂ we acquire knowledge based on hearing itÂ in context. There are also learning certain tasks that require a specific learning style.Â For example, we can always read about baseball, but if we want to hit a ball, thereâs no amount of reading that can substitute practicing swinging a bat.Â This separation in learning styles is the basic idea behind the different branches of ML.Supervised learningSupervised learning specializes in predicting the future. This is split further depending on whether itâs predicting a thing or a number, called classification or regression, respectively. To understand how this works, you start with the data. All supervised learning algorithms need whatâs called labeled data. This data is grouped into samples that have been tagged with one or more labels. In other words, applying supervised learning requires you to tell your model 1. what the key characteristics of a thing are (called features); and 2. what that thing actually is.Â To demonstrate the former, letâs take the example of teaching a child their shapes.Â This is classification problem and starts by giving the child a shapes sheet, which shows shapes and the shapeâs corresponding name (Fig. 1).Â 


(Fig. 1) Supervised learning uses labeled data


(Fig. 2) ML requires many examples in order to learn key patternsCircles are simple enough. Every circle is perfectly round (with infinite sides); this pieces of information is the key feature of a circle.Triangles are a little more complex. Based on the shapes sheet, your child might assume that all triangles have equal-length sides. In order for your child to better understand triangles, youâd have to show her or him more examples.Â Doing this would build their confidence in identifying triangular shapes (Fig. 2).After consuming these additional examples, your child would learn that the key feature of a triangle is having three sides, but also that those sides can be of varying lengths, unlike the square.Now letâs consider the other type of supervised learning: predicting a value. Letâs say youâre trying to predict how much your salary should be. Assume you could see everyone elseâs pay, along with their roles, experience, responsibilities, band level, and other relevant information. You could then use this data to see whose situations are closest to yours (ie. people with similar roles, experience, responsibilities, etc.), and determine what your salary range should look like based on what those folks are being paid. This is called aÂ regressionÂ problem.In a nutshell, supervised learning is about providing your AI with enough examples to make accurate predictions.Unsupervised learningUnsupervised learningÂ findsÂ commonalities and patterns in the input data on its own. By extension, itâs also commonly used to find outliers and anomalies in a dataset.Â Most unsupervised learning focuses on clusteringâthat is, grouping the data by some set of characteristics orÂ features. This is the sameÂ âfeaturesâÂ mentioned in supervised learning, although unsupervised learning doesnât use labeled data.Letâs use the example again of the child and the shapes. Suppose again that you had a child group similar shapes together. The child will likely group, (or cluster), by shape, color, or size. This mode of learning is great for surfacing hidden connections or oddities in oceans of data.


Reinforcement learningReinforcement learning is about rewarding positive behavior and punishing negative behavior. Over time, this can help your AI determine the optimal behavior for a particular environment or situation.Â Think back to your childhood. When you were at school or at home, what happened when you did something bad? You probably got scolded, grounded, or a long lecture. What happened when you did something good?Â  Maybe you got praise or gifts. Rewarding the ârightâ behavior and punishing the âwrongâ behavior is the cornerstone of reinforcement learning; that is you give your agent positive reinforcement for doing the right thing and negative reinforcement for the wrong things.Â The ingredients of a reinforcement learning problem are:Â an agent,Â its environment,Â a way for the agent to interact with its environment, andÂ a way for the agent to get feedback on its actions within the environment (called a reward function or feedback function).ML isnât magic; itâs math. Statistics, probability, linear algebra, and algorithms are what bring ML to life.Deep learning and neural networksDeep learning (DL) is a subset of machine learning, therefore everything you just learned still applies.Â The motivation is still trying to predict an output given a set of inputs, and either supervised learning or unsupervised learning can be used. The key differences are performance and how it works.Â For now, just know that deep learning is machine learning that uses a neural network with multipleÂ hidden layers.


Deep learning is a subset of ML, which is a subset of AI.DL is uniquely suited for making deep connections within the data because of neural networks. Neural networks come in many shapes and sizes, but are essential for making deep learning work. They take an input, and perform several rounds of math on its features for each layer, until it predicts an output. (Deep breath, the rules of ML still apply.) DL uses a specific subset of NN in order to work.The caveat to NN are that in order to be powerful, they need a lot of data and take a long time to train, thus can be expensive comparatively. Also because the human allows the machine to find deeper connections in the data, the process is near non-understandable and not very transparent.Some notable examples include the deep-fake videos, restoring black and white photos, self driving cars, video games AIs, and sophisticated robotics (e.g. Boston Dynamics).Â ML in the real worldÂ Visual recognitionÂ Despite seeing pictures on screens all the time, itâs surprising to know that machines had no clue what it was looking at until recently. Developments in ML has enabled us to supply pictures of, for example, a cat and over time, machines will begin to discern which pictures have cats in them from data it hasnât seen yet.Â Cancer treatmentWhen it comes to diagnosing and treating cancer, there are innumerable variables to account for. ML can look through historical patient records and treatment plans to suggest treatment plans for the current patient, thereby expediting the process dramatically.User leaving your productNo one wants to see a user go. Luckily in many cases, a user will demonstrate patterns indicative of an eminent departure. ML can classify a userâs behavior as one that will likely leave soon.Stock market predictionsPeople are serious about their money, especially when itâs their job. Those in the financial industry are always looking for a way to stay competitive and ahead of the curve. With decades of stock market data to pore over, companies have invested in having an AI determine what to do now based on the trends in the market its seen before. To buy or to sell â a classification problem. How much will this stock be valued tomorrow, a regression problem.See for yourselfWatson Personality Insights DemoWatson Natural Language UnderstandingMIT DeepmojiA visual introduction to machine learningPreviousBasics: Artificial intelligenceNextBasics: DataPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM




FundamentalsSkip to main contentIBMÂ Design for AISearchFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM.comIBM Event DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM iXCommunityIBM DesignFundamentalsTeam essentialsBasicsArtificial intelligenceMachine learningDataEthicsOverviewEveryday ethics for AIAccountabilityValue alignmentExplainabilityFairnessUser data rightsConversationOverviewPlanningCollapse navigation itemsFundamentalsArtificial intelligence (AI) is a mystery and a wonder. It can help us solve humanityâs most difficult problems. AI is also vastly misunderstood by most people. For some, AI is a magical black box with the intelligence of a PhD. It knows all about everything, you just bring your problems and, voilÃ¡, your problems are solved. For others, fears of AI uprisings, loss of human control and Terminator-like scenarios cloud their capability to understand the present utility of cognitive computing.IntroductionAI design foundationsCharacteristics of AIDesign factors for AIRelationship developmentAI ecosystemAI/human context modelIntroductionWhen looking for ways to apply this cutting-edge, revolutionary technology, AI can not only dazzle, but can blind us as well. The more buzz and hype, the greater the pressure becomes to rush to create something using whatever new capabilities are presented to us. The benefit of moments like this is the opportunity to discover, experiment, and learn.We must focus our design talents upon a new type relationship with machines - machines that can draw from vast stores of human knowledge, hold a conversation, and increase human understanding. What should these relationships look like? Designing for AI requires new considerations and new ways of thinking.When we find ourselves in such unfamiliar territory, the best way to begin is by reminding ourselves of the true purpose for any innovation: to improve the quality of human life.Consider what weâve learned living through the past few major technological innovations. The internet brought the worldâs information to our beck and call and taught us that whatever we want, whenever we want it is always a finger-length away. Mobile tech enabled humanity to take that information with us at all times. Social computing and messaging changed the foundations of how we communicate with each other and language itself.Each innovation provided a new context for communication and expanded (or changed) our understanding of the relationships we have with machines. AI requires us to take notice of new contexts yet again. This time, designers must account for a system that can understand, reason, learn, and interact.As a result, this changes the nature of our design considerations, some of which we take for granted based on the last 40+ years of software design. If weâve moved past typing into a text field and pressing âsubmit,â what does it mean to design for human/machine relationships?AI Design FoundationsAs Jared Spool says, design is the rendering of intent. This intent drives our outcomes. Itâs the âwhyâ behind what we do and the cause for us to affect change. Intentions require us to identify purposes and values for our efforts. Outcomes require going beyond ideas and create meaningful, trusted solutions for the people we serve.Design is more than a job or roleâitâs an essential part of what makes us human. The value of design is to improve lives and leave the world better than we found it. When designing for AI, our core intents are always rendered through the following lenses:PurposeThe reason for the user to engage with the system. This will evolve as the user and system grow with each other.ValueThe augmented capabilities provided by the system that tangibly improves a userâs life.TrustThe willingness of a user to invest in an emotional bond with the system. This trust is predicated on security of the systemâs data, the feeling of human control, and the quality of the results the system provides.Characteristics of AIAI is the simulation of human thought processes in a computerized model. AI involves self-learning systems that use data mining, pattern recognition and natural language processing to mimic the way the human brain works.These systems learn at scale, reason with purpose and interact with humans naturally. What search is to information retrieval, AI is to better, more-informed decision-making. In short, they help human experts make better decisions. We characterize AI as having four main qualities:UnderstandsAI deeply understands its domain. It does this primarily through data â structured and unstructured, text-based or sensory â in context and meaning, at speed and volume.ReasonsAI reasons towards specific goals. It has the ability to form hypotheses by making considered arguments and prioritized recommendations to help humans make better decisions.LearnsAI learns continuously through experience. In ingests and accumulates data and insight from every interaction at all times. It is trained, not programmed, by experts who enhance, scale and accelerate their expertise. Therefore, these systems get better over time.InteractsAI interacts naturally with people and systems. The interaction model of an AI is expected to flow unobtrusively while continuously building a sustainable relationship between itself and its users.Design factors for AIWhen it comes to designing for AI, our focus must be unwavering in providing experiences that put the user above all else.AI isnât about data, itâs about insights. Data is the fuel for the car, insights are the destinations. This is what people care about.AI is capable of delivering more human-like interactions with people â based on the mode, form, and quality each person prefers. It reasons through the sum total of structured and unstructured data to find what really matters but this isnât the full picture. Our solutions must primarily address user needs instead of being force-fit to accommodate technical capabilities or requirements.


MutualMarketing human dynamics overview. Builds on Debra M. Amidonâs âEvolution of ThoughtâPhilosophically and psychologically, we find purpose, value and trust in others when we can perceive intended meaning, consider this meaning from differing points of view, and acquire knowledge so that we can act to have an effect on one another. If a system has the capability to understand, reason, learn, and interact then it has the basis to form a relationship with a human.For AI to truly amplify humanity we must have and maintain meaningful relationships between humans and machines.To design authentic AI-based relationships requires us, as designers, to consciously understand ourselves before anything else. The more we understand of ourselves, the better we will be able to teach machines how to help our users be better.Relationship developmentAt this point, you might be asking yourself, âhow do I design a relationship?â You wouldnât be alone in this. For most people, forming and maintaining relationships is an autonomic process. We hardly give it a second thought. If you take a deeper look at the psychology behind relationships, youâll probably find Knappâs Relational Development Model.Mark Knapp is a teaching professor at the University of Texas and is known for his works in nonverbal communication research. His relationship model explains how relationships grow and last and also how they end. This model is categorized into ten different stages which come under two interrelating stages âcoming togetherâ and âcoming apart.â This helps to understand how a relationship progresses and deteriorates. For the purposes of our work with AI, we will focus on the âcoming togetherâ stages exclusively.


Knapp's relational development modelInitiatingA collection of first impressions and snap judgements are made. Even if these are inaccurate, they significantly influence if each party wants to continue to the next stage.ExperimentingIf thereâs a degree of mutual interest, the parties start exploring, looking for commonalities of interests, acquaintances and value.IntensifyingWith enough in common, we look for reciprocal sharing by the other person that signals their interest in deepening the relationship.IntegratingAI interacts naturally with people and systems. The AI interaction model is expected to flow unobtrusively while continuously building a sustainable relationship between itself and its users.BondingBoth parties are fully partnered through trust and mutual appreciation. The relationship is indefinite and only to be broken through a formal notice.


Establishing a human/machine relationshipA symbiotic relationshipSo what do we need to consider when one person in a relationship is replaced by a machine? By establishing tone and personality first, the system will have the means to endear itself to the user. As these systems are like âdigital toddlers,â the means to make an emotional connection with its users will be essential.


AI ecosystemArtificial intelligences are probabilistic systems. This means that they are taught instead of being programmed. Since they are being taught, they must have context to be able to utilize their learnings. An AI needs this context to understand its place and provide value.


AI ecosystemHumanThe person whose needs are ultimately being servedMachineThe system and its network of embodiments & connectionsContextThe holistic view of a complete human experience. Includes emotional, physical, system, and domain knowledge.BusinessThe business needs and market goals to be served by the systemWorldThe external factors that will both inform and educate the systemAI/human context model


AI/Human Context Model


AI/Human Context ModelIntentThe goals, wants, needs, and values of users and businesses. Intent provides your solutionâs purpose.Data and policyAll of the significant raw data a machine can collect from the user and the world and the policies that protect it.UnderstandingThe process of putting incoming structured and unstructured data in context of your domain. Also known as machine learning.ReasoningThe systemâs application of logic to decide on the best course(s) of action.KnowledgeThis is what the system knows. This is all past data, insights, and learned attributes measured up against the overall intent of the system.ExpressionHow the system delivers its response based on the content of the message and its understanding of the user.User reactionThis is the userâs genuine reaction to the systemâs expression. Based on the quality of the systemâs response.LearningThe user is continually teaching the system to improve through direct and indirect responses.OutcomeThe consequences of an actualized system used in the real world to solve real usersâ real problems.PreviousHomeNextTeam essentialsPrivacyTerms of UseIBM.comTwitterLast updated 06 December 2022Copyright Â© 2022 IBM





















Home | Smarter Patterns





      Skip to main content
    





Smarter Patterns


Main navigation


Home


Patterns




Home


Smarter Patterns is an interaction pattern library that provides solutions for common AI challenges.What are Smarter Patterns?Born out of extensive research into how artificial intelligence is being used and understood today, it is an evolving resource that considers the form and function of the patterns as well as the ethical challenges AI poses.
FeaturesTransparency & TrustWithout a clear concept of what it actually is, AI can be confusing and scary to users. How can we help them understand what the AI is being used for, how it’s being leveraged in their applications, and why it should matter to them?
Autonomy & ControlUsers don't necessarily want to use AI all the time. How can we empower them to choose the amount of AI they interact with, allowing them to decide when to enjoy the benefits of hands-off automation and when to take manual control?
Fairness & InclusivenessHow an application deals with users is just as important as how users deal with AI. Issues around dignity, respect, and how we value people deserve contemplation. How can we safeguard against harmful practices while building meaningful experiences?









People + AI Research - PatternsPeople + AI GuidebookmenuPatternsChaptersCase StudiesWorkshopGlossaryPeople + AI Researchopen_in_newPatternsOur design patterns highlight key design opportunities for AI products. Theyâre organized around common questions in the product development process to help you find what you need.Filter by questionarrow_drop_downFilter by questionarrow_drop_downFilter by questioncloseAll patterns (23)arrow_rightHow do I get started with human-centered AI? (5)arrow_rightWhen and how should I use AI in my product?  (3)arrow_rightHow do I onboard users to new AI features? (4)arrow_rightHow do I explain my AI system to users?  (5)arrow_rightHow do I responsibly build my dataset? (6)arrow_rightHow do I help users build and calibrate trust in my product? (7)arrow_rightWhat's the right balance of user control and automation? (5)arrow_rightHow do I support users when something goes wrong? (3)arrow_rightAll patterns23 patternsDetermine if AI adds valueexpand_moreAI is better at some things than others. Make sure that itâs the right technology for the user problem youâre solving.shareSee morekeyboard_arrow_downshareBefore you start building with AI, make sure the product or feature that you have in mind requires AI, or would be enhanced by it.AI is well-suited for applications like:Recommending different content to different users, such as movie suggestionsPredicting future events, such as weather events or flight price changesNatural language understandingImage recognitionA rule or heuristic-based solution may be better when:Maintaining predictability is importantUsers, customers or developers need complete transparencyPeople donât want a task automatedSee the User Needs chapter for more on when to use (or not) AI.Aim forUse AI when the predictive system can create a valuable  personalized experience that couldnât exist without it.AvoidDonât use AI just because you can.  Heuristics or manual control can often create better experiences. Here, using music preferences to suggest workouts will likely lead to a worse experience than letting people manually choose workouts.Learn more about these appsRelated chaptersUser Needs + Defining SuccessEven the best AI will fail if it doesnât provide unique value to users.Case studiesBenchSci open_in_newGoogle Photos open_in_newSet the right expectationsexpand_moreBe transparent with your users about what your AI-powered product can and cannot do.shareSee morekeyboard_arrow_downshareBecause AI systems are probabilistic, your system will probably give an incorrect or unexpected output at some point.This makes it critical that you help users calibrate their expectations about system functionality and output. Do this by being transparent about both its capabilities and limitations.For example, indicating a prediction could be wrong may cause the user to trust that particular prediction less. However, in the long term, users may use or rely on your product more, because theyâre less likely to over-trust your system and be disappointed.Aim forClarify the AIâs limitations, especially in high stakes situations.AvoidAvoid suggesting that the tech works perfectly in high-stakes situations if the tech isnât yet reliable.Learn more about these appsRelated chaptersMental ModelsIntroduce users to the AI system and set expectations for system-change over time.Explainability + TrustExplain the AI system and determine if, when, and how to show model confidence.Case studiesGoogle Flights open_in_newRead Along open_in_newExplain the benefit, not the technologyexpand_moreHelp users understand your productâs capabilities rather than whatâs under the hood.shareSee morekeyboard_arrow_downshareAI as a technology has unlocked a wide array of new, and often exciting, products and services. But no matter how novel your use of AI, when explaining your AI-powered product to your users, focus primarily on conveying how it makes part of the experience better or delivers new value, versus explaining how the underlying technology works.Run user studies to answer questions like:What do users need to know about how the system works to understand and use your product?Why is this knowledge useful to the users?The level of technical detail needed in your explanation will vary depending on the product and users.Aim forEmphasize how the app will benefit users.AvoidAvoid emphasizing the underlying technology.Learn more about these appsRelated chaptersMental ModelsIntroduce users to the AI system and set expectations for system-change over time.Explainability + TrustExplain the AI system and determine if, when, and how to show model confidence.Case studiesGoogle Flights open_in_newRead Along open_in_newBe accountable for errorsexpand_moreUnderstand the types of errors users might encounter and have a plan for resolving.shareSee morekeyboard_arrow_downshareFrom early in the product development process, plan for the fact that your AI system will make bad predictions at some point. This is an important part of confirming that AI is the right technology for your project.Think through the types of errors that your system could make, and their consequences. You should have an informed point of view about what's at stake for your user for a given error and expected impact of false positive and false negative predictions.Plan to remediate for such errors using approaches like:Setting users expectations about your system with explanationsProviding manual controls when the AI failsOffering high-touch customer supportProvide a way forwardProviding access to a person can be one way to make sure usersâ concerns and problems are directly addressed.Make changes to productSometimes the userâs error canât be directly remedied but actions can be taken to make sure other users donât encounter the same problem.Learn more about these appsRelated chaptersErrors + Graceful FailureIdentify and diagnose AI and context errors and communicate the way forward.Case studiesBenchSci open_in_newTune open_in_newInvest early in good data practicesexpand_moreThe better your data planning and collection processes, the higher quality your end output.shareSee morekeyboard_arrow_downshareAI-powered products can suffer without the right level of focus and resources on data from early on. We call such downstream effects âdata cascadesâ and they can be hard to diagnose and detect until your product experience is impacted.Good planning and scrutiny of your dataset can help you avoid issues downstream. Some actions that you can take include:Collect data in batchesEmbrace ânoisyâ dataPlan for data maintenancePartner with domain expertsRelated chaptersData Collection + EvaluationDecide what data are required to meet your user needs, source data, and tune your AI.Make precision and recall tradeoffs carefullyexpand_moreDetermine whether to prioritize more results or higher quality results based on your product's goals.shareSee morekeyboard_arrow_downshareWhen designing your AI-powered product, evaluate the tradeoffs between having the set of recommendations your system gives to be broad (prioritizing recall) or accurate (prioritizing precision). This decision will have a big impact on the end user experience.PrecisionNo false positives are classified, but some true positives are missed.RecallAll true positives are classified, but some false positives are captured.Prioritize precision: If you are building a product in a high stakes domain (such as healthcare), and the risks stemming from an error are high, you will likely want to be more conservative with your model output, and only give recommendations for the things the system is most confident of. This means prioritizing precision.Prioritize recall: if your product is in a lower stakes domain and itâs not a problem for users to sort through a longer list of recommendations (for example, music recommendations), you might prefer to prioritize recall. This means your user will get a larger set of results, offering the chance for surprising or serendipitous discoveries, but some of them may be less relevant.PrecisionEnable users to include results (true positives) that may have been excluded.RecallEnable users to exclude results (false positives) that may have been included.Learn more about these appsRelated chaptersUser Needs + Defining SuccessEven the best AI will fail if it doesnât provide unique value to users.Case studiesRead Along open_in_newBe transparent about privacy and data settingsexpand_moreFrom initial onboarding through ongoing use, continue to communicate about settings and permissions.shareSee morekeyboard_arrow_downshareMany AI systems rely on user data to personalize their recommendations or optimize the system.If you are collecting user data, proactively ask users for permissions early on, and make it easy for them to adjust their settings.Over time, you might also need to remind your users of the settings that theyâve chosen so that they can update to match their current preferences.When prompting users to set or review their permissions, explain what youâre using their data for  and why, and make sure your explanations are easily understandable.Aim forCommunicate what data is being collected and shared, and give users the ability to control their preferences.Learn more about these appsRelated chaptersExplainability + TrustExplain the AI system and determine if, when, and how to show model confidence.Feedback + ControlDesign feedback and control mechanisms to improve your AI and the user experience.Case studiesRead Along open_in_newMake it safe to exploreexpand_moreLet users test drive the system with easily reversible actions.shareSee morekeyboard_arrow_downshareAI systems often require access to some data or input from their users to provide them with personalized recommendations.Before asking new users what and how much data they are willing to share, give them the opportunity to test your system. For example, this can be done by offering an initial experimentation experience.This will help new users who are eager to get started, or who donât have time to fully consider and configure their preferences before diving in. It will also support users who are wary of sharing this information before they fully understand what the system offers in return.Even after onboarding is complete, continue to make user actions and decisions reversible where possible. User preferences and context are always changing. Giving piecemeal undo options allows them to manipulate preferences recommendations without needing to resort to a nuclear reset option.BeforeUsers can see the quality of recommendations without sharing their workout history.AfterUsers see how the recommendations change with shared history. This allows them to make an informed choice on whether to share data.Learn more about these appsRelated chaptersMental ModelsIntroduce users to the AI system and set expectations for system-change over time.Feedback + ControlDesign feedback and control mechanisms to improve your AI and the user experience.Case studiesRead Along open_in_newAnchor on familiarityexpand_moreAs you onboard users to a new AI-driven product or feature, guide them with familiar touchpoints.shareSee morekeyboard_arrow_downshareWith AI-driven products, there can be a temptation to communicate the ânewnessâ or âmagicâ of the systemâs predictions through its UI metaphors.However, unfamiliar UI touchpoints can make it harder for users to learn to use your system, potentially leading to degraded understanding of, or trust in, your product, no matter the quality of your AI output.Instead, anchor new users with familiar UI patterns and features. This will make it easier for them to focus on the key task at hand, which is building comfort with, and calibrating their trust in, your systemâs recommendations.Aim forUse familiar concepts from your productâs domain to help users set expectations and feel comfortable with the material.AvoidAvoid using clever and novel solutions just for the sake of it when a familiar solution will be more effective.Learn more about these appsRelated chaptersMental ModelsIntroduce users to the AI system and set expectations for system-change over time.Case studiesTune open_in_newBenchSci open_in_newAdd context from human sourcesexpand_moreHelp users appraise your recommendations with input from third-party sources.shareSee morekeyboard_arrow_downshareIn high stakes domains or when users are new, it can be useful to provide users with contextual information from other people  to help them determine the value of your recommendations. Sources of this kind of contextual information can include:third-party experts, whose information can help users vet the quality of your outputrelevant community groups, who can help users calibrate their trust through human-to-human connectionThis additional context, in tandem, with explanations and confidence displays, can help set user expectations about the quality of your recommendation.Third-party expertsReference third-party experts that the user trusts.Social proofProvide context from relevant communities that the user trusts.Learn more about these appsRelated chaptersExplainability + TrustExplain the AI system and determine if, when, and how to show model confidence.Determine how to show model confidence, if at allexpand_moreIf you decide to show model confidence, make sure itâs done in a way thatâs helpful to your users.shareSee morekeyboard_arrow_downshareIn some situations, you can help users gauge how much trust to put in the AI output with model confidence displays that explain how certain the AI is in its prediction, and the alternatives considered.However, in other contexts, confidence displays can be challenging for users to understand.If you decide to use them, test different types of displays early in the product development process to find what works best for your users.Aim forShow confidence in a way that is easier to interpret and understand when making a decision. Provide recourse for when the system is less than fully confident.AvoidDonât use numeric confidence in situations when itâs difficult to interpret. Consider how the percentage compares to other similar items. Also consider the alternative: In this case, thereâs an 18% likelihood the plant is dangerous.Learn more about these appsRelated chaptersExplainability + TrustExplain the AI system and determine if, when, and how to show model confidence.Case studiesGoogle Flights open_in_newExplain for understanding, not completenessexpand_moreFocus on giving your users the information they need in the moment, rather than a full run-down of your system.shareSee morekeyboard_arrow_downshareWhen explaining recommendations from your AI system, focus on sharing the information that users need to make decisions and move forward.  Donât attempt to explain everything thatâs happening in the system.Often, the rationale behind a particular prediction is unknown or too complex to be summarized in a simple phrase or sentence. Users may also not want to be overwhelmed or distracted by superfluous explanations as they use your product.The Explainability + Trust chapter offers examples of different approaches for crafting succinct, user-friendly explanations, which include partial explanations, progressive disclosure and model confidence displays.If youâd like to share longer or more detailed explanations of how the overall system works, do this outside of the active user flow, for example in marketing materials or onboarding content.Aim forExpose aspects that impact user trust and decision-making.AvoidDon't try to explain the entire system, especially when the rationale is complex or unknown.Learn more about these appsRelated chaptersExplainability + TrustExplain the AI system and determine if, when, and how to show model confidence.Case studiesGoogle Flights open_in_newGo beyond in-the-moment explanationsexpand_moreHelp users better understand your product with deeper explanations outside immediate product flows.shareSee morekeyboard_arrow_downshareIt can benefit your users and your product to provide deeper explanations of how your product works. This type of explanation can help users strengthen their understanding of how your system works, and how they can use it to best meet their needs. Having this level of understanding can also help them give you more robust feedback on your product.Deeper explanations work best when shared outside core product flows, where they can be distracting, and can include:Marketing copy, for example on your website or product packagingOnboarding materialsHelp center materials or educational content explaining how your product works (an example is this 5 minute video of how Google Search works)Remember to target these materials to their context, and to update them as your product evolves over time. For example, users have different goals when they are onboarding than when they are reading marketing materials.Such explanations will be different from or in-the-moment explanations, which should be short and optimized for understanding.OnboardingHelp users understand how the system works at a higher-level.Learn more about these appsRelated chaptersExplainability + TrustExplain the AI system and determine if, when, and how to show model confidence.Case studiesGoogle Flights open_in_newAutomate more when risk is lowexpand_moreConsider user trust and the stakes of the situation when determining how much to automate.shareSee morekeyboard_arrow_downshareWhen determining how much to automate your product flows, think about the stakes of your product, and the level of comfort that users may have with your type of product.In low risk, well-established products, like content recommendation systems, you might choose to prioritize a more heavily automated product flow where user control is available but optional.However, when onboarding to a new type of product, or in high-stakes situations, errors can be particularly problematic, and can corrode user trust and potentially cause dangerous situations. In such cases, design your system to give users more control over the system.Aim forBe more proactive with automation when failure tolerance is higher.AvoidAvoid automating without user control  in high-stakes situations.Learn more about these appsRelated chaptersExplainability + TrustExplain the AI system and determine if, when, and how to show model confidence.Errors + Graceful FailureIdentify and diagnose AI and context errors and communicate the way forward.Let users give feedbackexpand_moreGive users the opportunity for real-time teaching, feedback and error correction.shareSee morekeyboard_arrow_downshareWhen your AI-enabled system behaves in a way that a user doesnât expect or want, make sure that they have an option to share feedback. And, as much as possible, use that feedback to improve your model.Feedback in AI systems can take a range of forms, including,Giving a thumbs up or thumbs down on a recommendationHiding unwanted recommendationsFlagging or reporting problematic recommendationsMore traditional feedback flows, where a user manually reports a problem through a form or other mechanismOnce a user gives feedback, acknowledge that you received it. If possible, let them know how the system will respond to the feedback.Aim forAcknowledge user feedback and let users know when adjustments will happen.AvoidDonât just thank usersâreveal how feedback will benefit them. Theyâll be more likely to give feedback again.Learn more about these appsRelated chaptersFeedback + ControlDesign feedback and control mechanisms to improve your AI and the user experience.Errors + Graceful FailureIdentify and diagnose AI and context errors and communicate the way forward.Case studiesTune open_in_newBenchSci open_in_newGoogle Photos open_in_newLet users supervise automationexpand_moreMaintaining control over automation helps users build comfort and correct when things go wrong.shareSee morekeyboard_arrow_downshareAllow your users to supervise automation and take back control when needed, rather than automating across the board.This is helpful to users in a number of ways, including:Building comfort in new or high stakes situations with the support of controls to override the system if needed.Learning how the system works as they exercise their controls. For example, by manually confirming an appointment time recommendation, they become more familiar with the systemâs appointment recommendations.Giving them a way to complete their task when the system doesnât work as intended.Even in cases where users may not frequently exercise the option to take back control, it can be helpful to let them know that they have that option, and to help them build confidence in the system.Aim forEnable users to review and approve options.AvoidAvoid automating without giving users a way to undo, or allow users to make a choice in the first place.Learn more about these appsRelated chaptersFeedback + ControlDesign feedback and control mechanisms to improve your AI and the user experience.Errors + Graceful FailureIdentify and diagnose AI and context errors and communicate the way forward.Case studiesTune open_in_newGoogle Photos open_in_newAutomate in phasesexpand_moreProgressively increase automation under user guidance.shareSee morekeyboard_arrow_downshareAs you design your product, think critically about the balance of automation and control that you need to offer your users for them to use your product successfully.In some cases, it may make sense to offer multiple âlevelsâ of automation in your product (for example, partial automation and full automation), to help users with varying levels of comfort or familiarity with your product use it successfully.In such cases, start users with the lowest level of automation, and progressively increase automation. Make sure that users can easily adjust their choice, including dialing up or down their level of automation, and that the steps between levels are small and land well.Choosing the right level of automation depends heavily on your user and product needs and context. Research from Sheridan et al has demonstrated 10 levels of automation to consider.No automationUser is able to select from a number of options manually with no system intervention.Partial automationThe system provides recommendations to the user and allows her to choose among them.Full automationThe system makes decisions on behalf of the user in a fully autonomous way. Users should still have the ability to take control back as needed.Learn more about these appsRelated chaptersExplainability + TrustExplain the AI system and determine if, when, and how to show model confidence.Give control back to the user when automation failsexpand_moreGive your users a way to move forward even when the system fails or offers poor quality output.shareSee morekeyboard_arrow_downshareWhen an AI system fails or gives users a poor prediction, the easiest path forward is often to let the user take over in a non-automated way.Make it as easy and intuitive as possible for users to quickly pick up where the system leaves off. Give them all the information they need to take the reins:Awareness of the situationWhat they need to do nextHow to take their next actionIn difficult or high-stakes situations, you may even need to redirect users to a human for extra support.Aim forHelp users to take over when automation fails.Learn more about these appsRelated chaptersErrors + Graceful FailureIdentify and diagnose AI and context errors and communicate the way forward.Case studiesTune open_in_newGoogle Flights open_in_newGoogle Photos open_in_newDesign for your data labelersexpand_moreMake sure that data labelers have well designed tools and workflows.shareSee morekeyboard_arrow_downshareFor supervised learning, accurate data labels are a crucial ingredient to achieve relevant ML output. Labels can be added through automated processes or by people known as labelers.Labeling tools range from in-product prompts to specialized software. If youâre working with labelers, itâs worth investing time upfront in selecting or designing the tools, workflows, and instructions. The best way to do this is often in collaboration with the labelers themselves.When labelers understand what youâre asking them to label, and why, and they have the tools to do so effectively, theyâre more likely to label the data correctly. And as partners in the process, they can also help you improve your labeling tasks overall.Aim forUse multiple shortcuts to optimize key flows, provide easy access to labels, let raters change their minds, and auto-detect and display errors.Learn more about these appsRelated chaptersData Collection + EvaluationDecide what data are required to meet your user needs, source data, and tune your AI.Actively maintain your datasetexpand_moreMaintain the quality of your product experience by proactively maintaining the quality of your data.shareSee morekeyboard_arrow_downshareDevelop a data maintenance plan early on, and monitor and maintain your data over time to detect issues proactively, rather than relying on corrective measures when something goes wrong.Keep the following in mind for data maintenance:Similarities and differences between training and live dataWhen the data was gatheredAnything that may have changed since you first collected your training dataHow old is your training data? What has changed since you collected it?Related chaptersData Collection + EvaluationDecide what data are required to meet your user needs, source data, and tune your AI.Learn from label disagreementsexpand_moreUnderstand differences in how labelers interpret and apply labels to prevent problems later on.shareSee morekeyboard_arrow_downshareWhen you encounter labels that are âmessy," unexpected, or hard to reconcile, donât categorically discard them as ânoisy." Take time to investigate whether issues with labeler tools, workflows, instructions, or overall data strategy may be leading to such issues with labels.For example, say youâre training a model to flag toxic comments. Your labelers might apply different toxicity labels based on their personal experience, which can lead to discrepancies.These disagreements in labels offer an opportunity to identify deeper data and/or labeling issues that you may need to address to ensure data quality.Annotator 1Labels the plant without additional descriptors.Annotator 2Labels that the plant looks unhealthy. Dismissing this as noise misses opportunities in how your system can perform.Learn more about these appsRelated chaptersData Collection + EvaluationDecide what data are required to meet your user needs, source data, and tune your AI.Embrace ânoisyâ dataexpand_moreThe real world is messy! Expect the same from the data that you gather.shareSee morekeyboard_arrow_downshareAs you develop your training dataset, donât strive for something perfectly curated. Instead, allow some ânoiseâ to make the data as similar as possible to the real-world data you expect to get from your users.  This can help head off errors and poor quality recommendations once you release your model into the real world.To do this, think about the types of data that you expect to get from your users, and then ensure that data is represented in your training set.For example, for an image recognition system, consider the data you might get from you users. If itâs likely they will not have the time to take high-quality photographs and your model will have to work with blurry smartphone images, include blurry images in your training data.Aim forAllow for less-than-perfect results in your dataset because they will show up in real-world situations too.Learn more about these appsRelated chaptersData Collection + EvaluationDecide what data are required to meet your user needs, source data, and tune your AI.Get input from domain experts as you build your datasetexpand_moreBuilding partnerships with domain experts early can help reduce iterations on your dataset later on. shareSee morekeyboard_arrow_downshareWhen creating your own dataset, make time early on to observe a domain expert  your product aims to serve â for example, watch an accountant analyze financial data, or a botanist classify plants. This can give you valuable insights about the types of data that they use  to solve the problem your product is addressing.To identify the right partners, work with user researchers, or others with experience in identifying and interviewing domain experts.Aim for sustained relationships with domain experts throughout the project lifecycle (rather than one-off consultations), whenever possible.Do you have domain experts that can help highlight data issues throughout the development lifecycle?Related chaptersData Collection + EvaluationDecide what data are required to meet your user needs, source data, and tune your AI.Case studiesBenchSci open_in_newarrow_upwardlinkcloseApp conceptsWe created three hypothetical apps that featured different types of AI to show how patterns can be applied to productsÂ Â Â Â NextItem 1 of 4Google ResearchGoogle Design






















Glossary














People + AI Guidebook


menu



Patterns
Chapters
Case Studies
Workshop
Glossary



People + AI Researchopen_in_new






Overview
User Needs + Defining Success
Data Collection + Evaluation
Mental Models
Explainability + Trust
Feedback + Control
Errors + Graceful Failure




menu



Glossary





Aggregation
When you combine data from many different sources or times in order to lower the possibility of a single individual being identified.


Augment
When a machine, software, or function extends a personâs abilities or potential while maintaining their agency.


Automate
When a machine, software, or function performs a task without user involvement.


Binary Classification
Binary classification: when an ML model predicts if an example falls into one category or another based on a set of features.


Classification
When a machine learning model identifies an object. In response to an identification question, the simplest classification is “yes” or “no”. For example, if a model was shown a picture of a cat, it could classify it as “Cat”, or “Not a cat”. More complex classifications are sorting items into one of several groups.


Confidence Level, Model Confidence
The confidence level for a model is a statistical measure of how certain a prediction or outcome is.


Context Errors
Situations when the product output doesn’t make sense in the user’s current context. Often, this output is perceived as irrelevant by the user.


Counterfactuals
Rationale for why something is classified as not within the given class. Usually in the form of a statement of how the world would have to be different for a desirable outcome to occur.


Data Cascades
Compounding events that cause negative, downstream effects from data issues, and result in technical debt over time.


Data Collection and Labeling
How product teams get the data they need and apply meaningful labels to it. For example: acquiring millions of images of cats and dogs correctly labeled as “cat” or “dog”.


Data Distribution
Shows frequency of specific values within a dataset. For example, your could find that your data includes a high number of certain values, and lower numbers of others. Usually follows “normal” distribution, or a Gaussian curve.


Data Examples
Lines in a dataset or specific pieces of data, such as a photo of a shoe or run route.


Data Features
An individual measurable property or characteristic of an observable entity. Feature should be informative, discriminating, and independent.


Data Labels
Human-added descriptions for a piece of data, or example.


Explicit Data Collection
When you request information from users outright, like in feedback forms.


Explicit Feedback
Information solicited from users from within your app. For example: rating systems, review requests, forms, or surveys.


False Negatives
When the ML algorithm classifies an object as not in a certain category, when it actually is. For example, if it was searching for sneakers, and it didn’t return several true images of sneakers.


False Positives
When the machine learning algorithm classifies an object as belonging to a certain category, but it is not in that category. For example, if the algorithm incorrectly identified a sneaker as a llama.


Features
Distinct data sources or machine learning calculations that influence a prediction or outcome.


Folk Theories
Invented (and usually false) ideas of how a product works based on existing mental models and assumptions.


General System Explanations
Descriptions of general system functionality, i.e. how and why it uses inputs to generate outputs.


Heuristic-Based
Based on static if-then functions, or rules based on desired situation-result pairs. If a certain situation arises, the software produces a specific result, every time.


Implicit Data Collection
When you gather information about users passively, usually through logging behavior.


Implicit Feedback
Information about user behaviors, preferences, and needs that’s gathered from their interactions within your application or product. Often uses logging â records of what people do within your app.


Inter-labeler Reliability
A measure of consensus between different labelers performing the same task. Also known as inter-labeler agreement, or concordance.


Labeler
A person who labels the data used to train machine learning algorithms, specifically supervised learning models.
Synonym for rater.


Labeling/Labeled
A label is the description that is either given to a piece of data by a human or derived from user actions. For example, labeling a photo as “sneakers”, or run route as “hilly”.


ML Model
Mathematical algorithm that learns the statistical relationships among examples to make predictions in the future.


Machine Learning
Techniques and methods to program computers to execute tasks without super-specific rules. ML can help machines recognize patterns and adjust to unique situations.


Machine Learning (ML) Systems
Techniques and methods to develop AI, by getting computers to do something without being programmed with super-specific rules. ML can help machines recognize patterns and adjust to unique situations.


Mental Model
Usersâ internal explanations of how something works. They shape how users interact with a product or feature and it’s perceived value.


N-Best, N-Best Classifications, N-Best Lists
Refers to showing a certain number, “n”, top solutions or suggestions, such as the top 5 matches for an image search.


Network Effect
When a person starts or stops using a product or service because the majority of their network is using it or not.


Overfitting
When a model is optimized for predictive power for a training dataset that is narrower than the ML modelâs intended use.


Partial Explanations
Messages that explain one aspect of how the system works. Ideally, this is the most important aspect to the user.


Precision
The proportion of true positives correctly categorized out of all the true and false positives.


Predictive Power
A percentage that refers to an ML models’ ability to correctly predict outcomes given a certain input. A model with predictive power of 100 gives the correct prediction every time, 0 is purely random.


Probabilistic
Situations where there are multiple possible outcomes, each having varying degrees of certainty of its occurrence.


Progressive Disclosures
A practice in UX when more information is revealed in subsequent screens or interactions.


Qualitative Feedback
Non-numeric feedback about how a user feels about a certain experience. Can include measures of satisfaction, happiness, verbal responses or other qualities.


Quantitative Feedback
Feedback that is numeric or converted to a number. Both implicit and explicit feedback mechanisms can be quantitative. This feedback can be fed back into your model for tuning.


Rater
Synonym for labeler.


Recall
The proportion of true positives correctly categorized out of all the true positives and false negatives.


Redaction
When some pieces of a dataset or profile are removed to lower the possibility of identifying a single user based on their data profile. You can redact certain features of data to shrink the data profile, or redact examples for a certain amount of time.


Regressions
Also known as. linear regression algorithms, which try to find the best-fit line for a plot of data points on a graph. As new data points appear over time, the algorithm adjusts the line to fit.


Reward Function
Mathematical equation that your ML algorithm uses to optimize outputs. The function weighs some results as better than others, and optimizes for certain outcomes.


Second-order Effects
When the aggregate or outcomes or behaviors over time produces additional, unexpected outcomes.


Specific Output Explanations
Descriptions of how a system arrives at a specific output based on a certain input.


Supervised Learning
When you “teach” your algorithm on training data. Often this is based on examples manually labeled by humans to show ârightâ and âwrongâ answers.


Test Data
Datasets that you use to test your ML model to make sure its predictions work on data it hasn’t encountered before.


Training Data
Datasets that you use to teach your ML model which outcomes correspond to which inputs.


Transparency
Providing information about how a product works, including data sources, terms and conditions, privacy, permissions, and rationale behind system output.


True Negatives
When the machine learning algorithm classifies an object as NOT in a certain category and it is indeed not in that specific category. For example, it correctly classifies a llama as ânot a sneakerâ.


True Positives
When the machine learning algorithm classifies an object in a certain category, and the object is in that category.


Tuning
When developers adjust their machine learning algorithm based on feedback or errors to improve accuracy and performance.


Underfitting
When a model has a low predictive power across a more varied dataset.






Previous



Errors + Graceful Failure








People + AI Guidebook by People + AI Research team is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.Based on a work at pair.withgoogle.com.
						


















Machine Learning Has Already Transformed the Design Profession. How Do We Use It Ethically? – Eye on Design














































































Search


Related Articles
Something Different





















Machine Learning Has Already Transformed the Design Profession. How Do We Use It Ethically?


        Share: 
          Twitter
Facebook
Pinterest
Email




















Search


Related Articles
Something Different














Search
Menu
Social








      Graphic design  

Machine Learning Has Already Transformed the Design Profession. How Do We Use It Ethically?
In understanding machine learning, designers can engage with it as a design material and a creative force



      Words by
              Helen Armstrong          


Published onNovember 18th, 2021








AImoji. Process Studio (Martin Grödl, Moritz Resl) created these AI-generated emojis for the Vienna Biennale for Change 2019, using a Deep Convolutional Generative Adversarial Network (DCGAN). According to the studio, “with each AImoji, new, hitherto unknown ‘artificial’ emotions come to life 
that challenge us to interpret and interact with them.” Courtesy Princeton Architectural Press.

The following is an adapted excerpt from Helen Armstrong’s new book, Big Data, Big Design: Why Designers Should Care About Artificial Intelligence.
Why should a designer care about machine learning (ML)? Fair question, right? ML consists of algorithms—in essence a set of task-oriented mathematical instructions—that use statistical models to analyze patterns in existing data and then make predictions based upon the results. They use data to compute likely outcomes. But what do these algorithms and predictions have to do with you? The answer grows more self-evident by the day.
Machine learning is everywhere and has already transformed the design profession. To be honest, it’s going to steamroll right over us unless we jump aboard and start pulling the levers and steering the train in a human, ethical, and intentional direction. Here’s another reason you should care: you can do amazing work by tapping the alien powers of nonhuman cognition. 
Machine learning has changed the way humans relate to machines by enabling them to communicate with tech via language, gesture, movement, emotion, etc. These same capabilities will enable designers to engage with creative tools in more intuitive ways, supplanting the mouse, trackpad, and touchscreen. Simply asking software to perform an action—rather than clicking and dragging through a menu to find the right tool—will, for example, allow designers to bypass hours of busywork, not to mention perusing dense tutorials. Perhaps the very concept of a “tool” will grow irrelevant. The more natural and personalized the interaction, the more creative software might feel like an extension of ourselves—and our individual creative approaches—rather than a separate clunky software package.





				AImoji. Process Studio (Martin Grödl, Moritz Resl) created these AI-generated emojis for the Vienna Biennale for Change 2019, using a Deep Convolutional Generative Adversarial Network (DCGAN). According to the studio, “with each AImoji, new, hitherto unknown ‘artificial’ emotions come to life 
that challenge us to interpret and interact with them.” Courtesy Princeton Architectural Press.
				




				 Concept-i. Design and technology studio Tellart worked with Toyota’s Advanced Design team to create the user experience for this emotionally intelligent autonomous concept car. Through this work, Tellart delves into the warm relationships we might form with objects that can get to know us over time. Courtesy Princeton Architectural Press.
				




				Candy Hearts. Janelle Shane’s experiments playfully tease out all the ways algorithms can “get things wrong.” She jumps unafraid into the algorithmic training process, in this instance training a neural network to generate candy heart messages. Shane has also trained algorithms to invent recipes, paint colors, pick-up lines, and cat names. Courtesy Princeton Architectural Press.
				

Escape the Cubicle 
If design tools combine relational interaction with artificial intelligence’s (AI) growing awareness of context, designers could, at long last, escape desk and screen. We could design for the world as we stand in the world, creating while situated in augmented physical space. Silka Sietsma, Head of Emerging Design at Adobe, asserts, “We’re at the event horizon of a new era of spatial computing—a world where digital experiences mesh with physical reality. Immersive, 3D technologies like AR (augmented reality) and VR (virtual reality), along with voice and embedded sensors, are all converging into a new medium, powered by artificial intelligence.” It is within this new medium—this confluence of physical and digital, that our future design practice will evolve.
How else will ML impact design practice? Patrick Hebron, author of Machine Learning for Designers, suggests that we consider the future in terms of “scaffolding complexity.” While reflecting on CAD systems and the future of creative tools, he points out: “These tools make it possible to conceive of systems that are too grand and complex for any one individual to keep all of their big picture goals and specific details in mind simultaneously.” Hebron also notes, “The Florence Cathedral took about one hundred and forty years to go from initial conception to project completion. A much more complicated and recent building, the Burj Khalifa, took about five years.” Our tasks and aesthetic goals, he asserts, will continue to evolve as ML enables us to enter terrain that we could not even envision without AI. “Machine intelligence,” he explains, “will enable creatives to do even more and to think even bigger.”
Return of the Centaur
In such a vision, humans and intelligent machines work together to arrive at solutions unattainable by either alone. We can refer to this as a centaur: part human, part machine intelligence, one entity.  Rather than automating away the designer, designers join forces with AI, augmenting their abilities with ML—a fusing of intelligences. Matt Jones of Google AI argues that to truly take advantage of AI, we must accept its alien nature.
Alternative models of “intelligence” exist already in the natural world—specialized forms of cognition distributed across organisms, nerve cells, and root-fungi networks rather centralized in a single human brain. Myriad recent books have raised popular awareness of these alternatives, such as Peter Godfrey-Smith’s book, Other Minds: The Octopus, the Sea, and the Deep Origins of Consciousness and Peter Wohlleben’s treatise, The Hidden Life of Trees. As posited by posthuman theorists like N. Katherine Hayles and Donna Haraway, we should expand our understanding to other forms of cognition as we coevolve with our tools. In essence, we must recognize that integrating ML into design practice will not feel like adding a supersmart fake human to our creative team but, instead, will be something else entirely. Like bacteria, trees, or earthworms, AI will think differently than we do. 





				D.O.U.G._2. (Drawing Operations Unit: Generation 2). Artist and researcher Sougwen Chung explores how a human artist might collaborate with an ML system to symbiotically produce work. In this rendition, Chung trains an algorithmic system to learn from the visual style of an artist’s previous drawings and then translate that style into gesture and color palette. A robotic arm then pulls from this knowledge to draw in concert with the artist. Chung questions artistic identity and self-perception through such human-machine duets. Courtesy Princeton Architectural Press.
				




				D.O.U.G._2. (Drawing Operations Unit: Generation 2). Artist and researcher Sougwen Chung explores how a human artist might collaborate with an ML system to symbiotically produce work. In this rendition, Chung trains an algorithmic system to learn from the visual style of an artist’s previous drawings and then translate that style into gesture and color palette. A robotic arm then pulls from this knowledge to draw in concert with the artist. Chung questions artistic identity and self-perception through such human-machine duets. Courtesy Princeton Architectural Press.
				




				Synthetic Marine Creatures. Creatures generated from a dataset of two thousand images of multiple marine invertebrate zooplanktons, including Mollusca, Cnidaria, and arthropod larva. This specula morphology is created with StyleGAN2 to study generalized morphological patterns and proportions. Created by Danlei Huang as part of the RISD-Hyundai sponsored research project.
				

The Combo, Please
Since the 1960s, we have imagined that AI will take over form-making, serving up a multitude of form variations from which a designer can simply choose—a fast forwarding of the design process. But, it turns out, the most powerful application of ML is not speeding up our process to arrive at the same kind of conclusions. The most powerful applications combine machine intelligence with human intelligence to take us along new paths entirely. 
Artificial intelligence researcher Janelle Shane puts it simply: “Working with AI is a lot less like working with another human and a lot more like working with some kind of weird force of nature.” This force of nature will tirelessly work toward exactly the goal that we give it, so we have to figure out the right goal. And we shouldn’t expect it—or want it—to solve the problem like a human. Shane points to a project by David Ha, a researcher at Google Brain, in which Ha asked an AI to assemble some parts into a robot to move from Point A to Point B. Rather than solving the problem by assembling a nimble robot, as Ha intended, the AI combined the parts into a tower that could just fall over and land on Point B. As Hebron comments, “The world is full of human thinkers. And if we want human thinking, we should probably go to humans for it. There are a lot of them.” If we don’t waste time trying to force AI to think like a human, we can arrive at Point B—and Points C, D, and E—in fresh, alien ways. 
“Working with AI is a lot less like working with another human and a lot more like working with some kind of weird force of nature.”
Novel AI strategies, however, mean little without perspective and purpose. Humans do need to be part of the equation. Remember the human-AI chess teams that triumphed over solo humans or solo AI competitors? The confluence of human and machine is key. As Shane explains, “The AI has no understanding of the consequences.” Humans bring that understanding to the equation. We human designers must be there to frame the right problems—the problems that will move us toward future points that truly benefit humanity.
The Future?
The future is…fraught. Our profession stands on the cusp. Designers must strive to understand ML capabilities, so that we can engage with it as a design material and a creative force. If we do not, we will fall victim to it. We will create within the parameters that the technology sets for us, rather than the other way around.
Through ML we have amazing potential to provide emotional insight to those on the autism spectrum, to reduce gender and racial bias in hiring and lending practices, to springboard creatives into unexpected, wicked problem-solving spaces. However, we can also do the exact opposite—exploit the vulnerable, bias the future by relying upon the past, replace humans by automating away skills that we want and need to maintain autonomy and agency, relegate essential choices to a technology that has no understanding of human consequence. 
Questions around AI and humanity have been hotly debated since at least the middle of the twentieth century. As design professor and historian Molly Wright Steenson points out, “If we understand that we’ve been asking these questions for a long time, we might have better expectations about how hard it is to find answers.” These are complex questions with wide implications. 
The terrain is tricky. The future is uncertain. Exciting? Yes. Terrifying? Yes. We have many critical choices ahead. Let’s take on those choices together, thoughtfully, one design at a time.  
Read more in Helens new book, Big Data, Big Design: Why Designers Should Care About Artificial Intelligence, now available from Princeton Architectural Press.









Share:   Twitter
Facebook
Pinterest
Email


      Graphic design  










Related Articles










      Graphic design  

The Y2K Aesthetic is Fully Back, but Can It Stick Around?
When editor and consultant Casey Lewis started her newsletter digest on youth culture, After School, she instinctively gravitated towards pastel…










      Books  

“Exploring Unfamiliar Histories of Visual Culture” — Four Corners Books Shares Its Favorite Publications
Run by Richard Embray and Elinor Jansz, Four Corners Books is a London-based publishing house that seeks to bring art…










      Design + Music  

The Collaborative Spirit Behind Brian Eno’s Record Sleeve Designs
It was Brian Eno who invented the term ‘scenius,’ which counters the myth of the lone genius and credits the…










      Books  

Five Beautiful Book Covers and the Stories Behind Them
Artwork. Advertisement. Encapsulation. Billboard. Brand.  A book cover is many things — and the best ones tend to be all…










      Type Tuesday  

A Font Inspired by Egyptian Streets That Addresses a Problem for Arabic Designers
Name: Felfel Designer: Abdo Mohamed Foundry: Boharat Release Date: Initially 2021, but the font is still in progress Back Story: Independent type…










      Design History 101  

Steven Heller Gets Personal in His New Autobiography Growing Up Underground
This article is an excerpt from Growing Up Underground, the new coming-of-age memoir by Steven Heller published by Princeton Architectural…










      Design + Gender  

How Hjärta Smärta Challenged the Male-Dominated Status Quo in the Early 2000s
Long before higher education in art and design was within reach for me, and before my imagination stretched to even…










      Books  

Why Did So Many Mid-Century Designers Make Children’s Books?
What do you do when you’ve secured your legacy as one of the great creative minds of the 20th century?…










      Design History 101  

How the Maharaja Mascot Became Air-India’s Adventurous, Yet Controversial, Design Star
It is safe to say that for anyone who grew up in India in the decades following the 1950s, Air-India’s…










      Design + Education  

Creative Director and Teacher Forest Young on Designing a More Inclusive Future
This story is part of our Weekend Reads series, where we highlight a story we love from the archives. It…










      Magazines  

Open Manifesto—the Quiet but Persistent Australian Design Journal—Was Ahead of Its Time
You probably don’t need me to tell you that the publishing world is a tough business. While the internet —…










      AIGA Medalists  

Emily Oberman Shaped the Look of Pop Culture as We Know It
It was only 50 cents. But it was 50 cents that perhaps changed the look of pop culture as we…
















Eye on Design City Guides
 

AIGA Eye on Design Conference
 

Join AIGA
About
 



            @AIGAeyeondesign
          
















© Copyright 2023  ·  AIGA





About
 

Eye on Design City Guides
 







Would you like to subscribe to our newsletter?













































Machine Learning Has Already Transformed the Design Profession. How Do We Use It Ethically?


        Share: 
          Twitter
Facebook
Pinterest
Email




























Search


Something Different


Close

















Or Filter By Your Interest




Design


Books


Magazines


Illustration


Digital


Branding


Typography


Graphic design


Packaging design




Design +


Design + Art


Design + Sexuality


Design + Music


Design + Money


Design + Mental Health


Design + Diversity


Design + Politics


Design + Education




Design Series


Where Designers Work


First Thing I Ever Designed


Design Diary


Type Tuesday


Poster Picks


Love Letters


Happy Hour


Design History 101


Design Quotes




Countries


Australia


Canada


Central Europe


Eastern Europe


Japan


Mexico


Scandinavia


Southeast Asia


South America


U.S.


UK


Western Europe



















Loading …








Sorry, no results were found.








Results










      Graphic design  

Machine Learning Has Already Transformed the Design Profession. How Do We Use It Ethically?
The following is an adapted excerpt from Helen Armstrong’s new book, Big Data, Big Design: Why Designers Should Care About…























Design
Graphic design
Branding
Books
Magazines
Illustration
Digital
Typography
 

Design +
Design + Mental Health
Design + Money
Design + Art
Design + Diversity
Design + Education
Design + Sexuality
Design + Music
Design + Politics
Design + Gender
 

Design Series
Op-ed
Where Designers Work
Weekend With
Profiles
Happy Hour
First Thing I Ever Designed
Type Tuesday
Rejected Designs
Poster Picks
Satire
Design History 101
 

Community
Eye on Design City Guides
 



Video
About
 



















Close






Because we can read your mind, we think you'll be into:










      Graphic design  

The Y2K Aesthetic is Fully Back, but Can It Stick Around?
When editor and consultant Casey Lewis started her newsletter digest on youth culture, After School, she instinctively gravitated towards pastel…










      Books  

“Exploring Unfamiliar Histories of Visual Culture” — Four Corners Books Shares Its Favorite Publications
Run by Richard Embray and Elinor Jansz, Four Corners Books is a London-based publishing house that seeks to bring art…










      Design + Music  

The Collaborative Spirit Behind Brian Eno’s Record Sleeve Designs
It was Brian Eno who invented the term ‘scenius,’ which counters the myth of the lone genius and credits the…










      Books  

Five Beautiful Book Covers and the Stories Behind Them
Artwork. Advertisement. Encapsulation. Billboard. Brand.  A book cover is many things — and the best ones tend to be all…

























5 Steps to Design a Better Machine Learning User Experience










































 





SLAVO GLINSKY
Portfolio
About
Blog








Portfolio
About
Blog




















29. June 2021
5 Steps to Design a Better Machine Learning User Experience


When In 2017 I joined Merlon Intelligence, I quickly learned that designing for machine learning is different. Your static screens in Figma are more distant from the real world experiences than ever before. If you want to design great machine learning user experiences you need to design more than interfaces. You need to design how machine learning works.

Merlon Intelligence is an application for searching people and companies in databases for negative news. Like when you google somebody’s name before you start working with them and decide if the entity can cause some risk for you or your business. It uses machine learning to serve you the most relevant articles and highlight the information for easier decision making. As a team we worked really hard to ensure its accuracy and reliability. And as a designer I was learning a lot of how machine learning works and how it affects user experience.
Since then machine learning (ML) became an underlying theme of the products I have worked on. During this time I found that some things worked better than others. Many guides about ML are written by people speaking about technology details, often missing focus on the user experience. This guide is written with tips you can start using immediately after reading this article, so you can become more valuable designer and steer the decision-making process towards more human centered ML.
Shall we start?
1. Build a Data Sample
Data is the food for ML. It powers all the experiences people have in your application. Transform user needs into data needs. Data needs to be designed, too.
When you are designing enrich and fun experiences, your data should come from enrich and fun experiences. When you are creating outdoors experiences, your data should come from outdoors. If you are not sure where to start and what data you should include in your sample, use google dataset search, or a get free one at kaggle (registration required). Update data as the product changes.

Use Airtable, Google Spreadsheets or Excel to build your sample. Managing spreadsheets may not be in the designer's job description, but it helps you to understand possible experiences people would have with your application.
2. Define your ML Confidence Level
When people try to guess how old someone is, they often use phrases like "I think" or "maybe" to communicate a lack of confidence. “I think the person is 32 years old”. Machine predictions work similarly. The computer makes guesses and expresses them as a percentage. "I am 82.2% confident that this person is 35 years old". The confidence level is used by product teams in deciding an acceptable response. So if an ML confidence that the message is a spam is 97%, it’s worth moving it into a spam folder without bothering users.
To get your ML confidence, you have to make a prediction for each mail and then count the proportion of correct answers among the whole sample. Let’s say you have a data sample of 1000 mails. Your ML makes 970 good predictions out of 1000 examples: this means your ML confidence the mail will be labeled correctly is 97%. Although it’s a pretty high number, 3% chance of missing an important email from your colleagues or relatives needs to be handled well. For that case you have a spam folder always at hand.

If you don't know what your ML confidence level is, just start with 51% like a true skeptic with a grain of optimism. Update when you get the results.
3. Use Flowchart to Close the Feedback Loops
ML applications are diverse. But like in any application you have the opportunity to listen and observe the user's actions. Feedback helps ML to make better predictions. When you mark a mail from a shopping outlet as “Not Spam”, the machine can improve its prediction for the upcoming mails. There are 2 ways your ML can learn from the users - explicit and implicit feedback.
Explicit Feedback
Explicit feedback is information people provide in response to a specific request from the app. Be specific on what feedback you are asking for and always make it voluntary. Make it without feeling like extra work. Show familiar controls for corrections.
Good example could be favoriting songs to display more recommendations like this. Social feedback for expressing emotion is explicit feedback, too.
Allow people to dismiss your suggestion. Use specific words and provide multiple options when necessary. “Suggest less from Buzzfeed” or “Suggest more like Childish Gambino”.
Implicit Feedback
Implicit feedback is a by-product as people interact with your app. It gives you information about users’ behavior and preferences. Although incorporating implicit feedback isn't essential for a great machine learning app, the feedback can help you improve your app's user experience without asking people to do any extra work.
Rather than asking people if they liked the search results, you can measure their clicks. Each click on result is an implicit feedback of the result's relevance to the search. Implicit feedback can gather potentially sensitive information, so you must also make sure it doesn't violate user's privacy.
How to Design a Flowchart
To implement feedback in your app use the Flowchart. Flowchart allows you to maintain the high-level focus and think of the ways people interact with your application. Include points with explicit feedback. Request explicit feedback only when necessary and if you have an opportunity to go only with the implicit, go for it.

To make a flowchart, think of the user scenario. Beginning and end points have an oval shape. Decision trees in diamond shape. Use it for your ML confidence level. Tilted rectangle for explicit feedback. Keep it simple.
4. Stick to the Mental Models 
Mental models are the projections of your understanding of the world. Not only do they shape what we think and  our sense of understanding but also the connections and opportunities we see. People form mental models from everything they interact with, including products, people and places. Mental models help set expectations for what a product can and can’t do and what kind of value people can expect to get from your application. It can also serve as a bridge between experiences. For example, if you know how to steer a bicycle, you know something about how to steer a motorcycle.
Avoid AI on the UI
As humans, we do not want to feel inferior to any kind of intelligence. Although AI looks great on your sales presentation, it's toxic for the user experience. Learn from the most valuable tech company in the world - Apple. Apple uses ML and AI on every part of their products. It powers the search in photos, Siri suggestions, song recognition, handwashing timer, or accelerators in your CPU. Everything’s intuitive and works just great. However, if you search their promotional materials for the keyword AI, you barely find any mention. The best way to make AI disappear is to communicate its value and to stick to the mental models users already have.
People have certain expectations of how the applications should behave. Building a solid mental model is the combination of appropriate expectations and implementation. When it's done right, it just "feels natural", effortless and easy-to-use. To learn how to capture people's expectations, think about your product as a person for a second. Who would you hire for your job, an assistant or an advisor?
Assistant vs. Advisor
Assistants get things done. They take in your input and do the job. They're great for jobs that are difficult, unpleasant, or where there is a need for scale; especially ones where people, who currently do it, can agree on the “correct” way. Google Assistant controls your smart home and gets you the information you need.
Advisors are often skilled in observing the environment and provide options you can choose from. Empowering your senses and providing relevant information for better decision making. Use them for jobs that people enjoy doing, that carry social capital, or where people don’t agree on the “correct” way to do it. Let them make a decisions.
When we were designing a mental health voice journal Kintsugi, it was obvious for us that it should be an advisor. The application has a high emotional involvement. People are labeling voice entries themselves. They select labels as emotions "happy" or "sad". People don’t want to be told how they feel. This is why these labels are provided as suggestions for their voice entries. User action is an explicit feedback.
Read Next: How to Discover Machine Learning Opportunities in Your Product
5. Prototype Rapidly, Test Early
Prototypes are friends of every designer. And true friends get you through uncertain times. If you can put together a prototype, do it soon. Simulate a hands-on experience and get feedback on it. Test it by yourself, create prototypes for your team and do the user testing. More eyes, better feedback. If you find out your prototype doesn't perform well, revisit previous steps.
Learn how to create functional prototypes in Protopie, Framer or Origami. Protopie works great for input detection (text, voice, photo). Framer, in connection with s custom data set, works great for testing a content preview. How to build a prototype is a topic for another article. Let me know if you are interested in the comments.
—
P.S. Click Like if you enjoyed this article. I'm on Twitter too if you'd like to follow more of my stories.




Facebook

Share on Facebook



Twitter

Share on Twitter



LinkedIn

Share on LinkedIn






































Say hello!




hello@slavoglinsky.com












Portfolio






About






Blog









Dribbble






Behance






Twitter






Linkedin














































 
























 Design and machine learning || Matthew Ström, designer-leader























Matthew Ström


Writing
Reading

















            Design and machine learning
        
October 30, 2019 · 6 min read




Machine learning is a powerful tool that drives everything from curated content recommendations to optimized user interfaces. With Apple, Google, Facebook, and Amazon leading the charge, machine learning is becoming deeply integrated into everyday product experiences. This means that digital product designers need to get familiar with machine learning. Wielding machine learning might be a niche design skill today, but soon it will be hard to design without it. Or that’s how the argument usually goes.
Lots of articles do a good job of explaining what machine learning is. Many warn that designers who don’t start learning about ML will be left behind. But I haven’t seen one that has explored what design and machine learning have to offer each other.
Design and machine learning function like a flywheel: when connected, each provides value to the other. Together, they open up new product experiences and business value.
What can design do for machine learning?
Design helps machine learning gather better data.
Machine learning is a hungry beast. To deliver the best results, learning algorithms need vast amounts of detailed data, clean of any confounding factors or built-in biases.
To provide song recommendations, for example, Spotify’s algorithms need data on how users choose what to listen to. If the app’s browsing interface is difficult to navigate, users will be more likely to listen to the first few songs they see, regardless of their personal taste. So-called “noisy” signals result in less accurate recommendations.
Designers can help create user experiences that eliminate noise in data, leading to more accurate and efficient ML-powered applications.
Design helps set expectations and establish trust with users.
Twitter uses many, many machine learning algorithms. If you switch to the “top tweets” feed, an algorithm decides what order tweets appear. Algorithms decide when to show you tweets that your friends like, retweet, or reply to. A different set of algorithms chooses trending topics to display in the sidebar.
Often, Twitter users get confused as to why they’re seeing what they’re seeing. Social media marketers write long posts on how to take advantage of Twitter’s algorithms. Confusion and ambiguity lead to frustration and distrust.
Designers — specifically, UX writers, the unsung heroes of usability — can add clarity to ML-powered interfaces. When you see a tweet by someone you don’t follow in your timeline, Twitter’s designers have added a bit of text to explain why it’s there: “Matthew liked,” “Raquel replied,” “Freyja retweeted,” and so on. The trends in the sidebar are framed with the heading “Trends for you,” indicating that they are curated.
These design details build trust and understanding among users. Trust is a vital component in how ML achieves its goals. Google’s People + AI initiative has provided detailed guidance for building trust in ML-powered applications:

Because AI-driven systems are based on probability and uncertainty, the right level of explanation is key to helping users understand how the system works. Once users have clear mental models of the system’s capabilities and limits, they can understand how and when to trust it to help accomplish their goals. In short, explainability and trust are inherently linked.
- Google’s People + AI Guidebook

What can machine learning do for design?
Machine learning answers questions about user behavior.
Designers often have to make assumptions about users when building and iterating on interfaces. The trickiest assumptions usually come in the form of “if a user takes this action, some other behavior will result.” For instance: If a user adds a coupon to their order, they’ll be more likely to complete their checkout. These assumptions have a huge impact on business value, but often come down to tricky statistical analysis and — often, sadly — guesswork.
Machine learning can help simplify this process by making complex models of user behavior that are easy to experiment with. One variation on this technique is called a Bayesian network. Bayesian networks can answer questions like “what will happen if a user takes (or doesn’t take) an action?” Using machine learning like this helps designers make more confident decisions with fewer assumptions.
Machine learning customizes interfaces to users needs.
What if you could design a unique interface for every single user that opened your app? How would you tailor the experience to suit the use case of that person at that exact moment?
It’s strange to think of a designer manually tweaking the locations of buttons and menus for every user to make an app easier to use. But that’s one of the ways Facebook uses ML: in 2018, it began composing the nav bar in its app based on users’ most commonly used features.
The future of ML and design
The flywheel of design and machine learning is just getting started. Many designers are still in the process of learning what machine learning is, a task made more difficult by the breakneck speed of new developments in the field. Once machine learning becomes part of the core curriculum for design, the pace of innovation will accelerate.
Imagine Sketch, Figma, or Adobe XD predicting the usability of a mockup based on real user data. Tools like FullStory already capture what users see and do at every step of their session; an ML algorithm could be trained to mimic your users, even when given new screens or workflows.
Alternatively, consider a tool that could generate your app’s UI instantly based on a few high-level parameters. A designer could tweak a few knobs — shorter session length, higher conversion rate on a CTA, etc. — and an algorithm could make adjustments it thinks will accomplish the desired output. This kind of tool could make UI changes on the fly, in production, in response to real user behavior.
This kind of blue-sky thinking is part of the product innovation cycle. Designers are uniquely qualified to push the boundaries of what ML can do, and how algorithms can deliver real value to users as well as businesses.
Resources for designers
If you’d like to learn more about machine learning in general, UX Planet has a great list of resources, including one of my favorite introductions, A Visual Intro to Machine Learning.
For guidelines on how to design with machine learning, start with Google’s People + AI Guidebook. It contains tons of detailed guidance on how to utilize the potential of ML & AI in a user-centric way.
If you’re in the Bay Area, there’s even an ML + UX meetup! I recently attended a one-off New York version of this meetup, which is what inspired this post.





Older:
            September 24, 2019
Learning how to see


Newer: 
            November 12, 2019
Making an audio waveform visualizer with vanilla java script



Join the mailing list

        I'll send new posts to your inbox, along with links to related content
        and a song recommendation or two.
    


Don’t fill this out if you're human: 



Email


            Subscribe
        











Twitter · 
                    RSS ·
                    Email






Ethics & responsibilitiesSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsEthics & responsibilitiesEnsure that you and your team perform research that meets ethical standards.Clearly state objectivesYour team will conduct research for a specific reason known to both the team and the participant. Itâs your job to make participants aware of the research procedures and have them sign the appropriate forms to confirm their participation and consent. State any participant benefit or honoraria before the research session begins.Protect anonymity and confidentialityYou also need to inform participants of what data is being collected and how it will be used. Data collection should also be done in accordance with GDPR and any country-specific requirements. Remember that a participant can refuse or revoke consent at any time.Immediately after a research activity occurs, anonymize a participantâs name and other identifying information. When reporting research back to your team or in deliverables, do not use a participantâs or clientâs real name, demographics, contact information, etc.Preserve and strengthen client relationshipsOne way to formalize this process is with a Sponsor User Program. Sponsor Users are a core part of Enterprise Design Thinking and IBM Design Research. They help us design experiences for real target users rather than assumed needs. You can read more about Sponsor User Programs, including how to start and run one, below.Sponsor User ProgramRemove bias and judgementWhen conducting design research, your team will attempt to remove environmental, study, personal, and social biases. As you remove these biases, the research becomes more credible and honest. Some examples of everyday biases include:Environmental bias: âThe setup of hospital room we are in is different than the hospital room where the nurse normally works.âStudy bias: âHaving an observer in the room may change the way a user performs these tasks.âPersonal bias: âI donât like the color orange.âSocial bias: âTeenagers are bad driversâ or âAll researchers are introverts.âReport all insights and limitationsYour team should never hide or mislead research findings. Share back all negative and positive reports to stakeholders. This can be uncomfortable, but itâs your duty to report the truth. Give credit to other teams and authors. Additionally, state limitations and assumptions made, so as not to misrepresent the research.PreviousSponsor User Program: Wrapping upPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Guiding principlesSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsGuiding principlesCreate human experiences that matter. The principles of IBM Design Research guide diverse teams to continually increase their understanding of the people they serve and the world around them. When we pair our usersâ needs with those of the business, we win in the market.Stay curiousEmbrace the beginnerâs mindset. Always ask why. Look with an unbiased lens.Research as a teamEveryone has a responsibility to advocate for a deeper understanding of the end user.Make to learnSometimes the fastest path to understanding is through making.PreviousHomeNextGuiding principles: Stay curiousPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Plan for successSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsPlan for successA research plan is a document owned by the entire team that specifies what research will be conducted and how it will inform the teamâs work. Limit a planâs objectives to remove ambiguity and increase alignment. Research plans are not static, so remember to adjust as you learn.Creating your planStart by defining your learning objectives, hypotheses, and assumptions as a team. Once your research plan is established, the Guide will create corresponding research protocols. A research protocol includes all of the steps needed to conduct the research activity. Protocols are specific to a single research activity, such as a contextual inquiry, a usability test, or a user interview.Set expectationsClearly describe how the research plan relates to both business and user outcomes. Your research plan should inform or validate your Hills. Rely on your Guide. Be explicit about what your team plans to learn or test. Always share your research plans and protocols across the larger team. This will help you gain alignment and drives action quicker.This includes explaining in your research plan:learning objectivesparticipants screeningmethodologies and techniques for data collection, synthesis, and analysisbudget for conducting the researchsuccess metricsartifacts and deliverablesGet StartedIBM Design research plan templateIBM Design Research protocol templatePractice reflectionEmbrace critique from the larger design research community. Share your plans and deliverables to get feedback on your methodology choices, research insights, and planning process.When collecting feedback, ask these types of questions:Were the original research objectives clear?Did this research integrate with previously conducted research?How strong is the analysis?How actionable were the insights?What from the research was most memorable?What were the strengths and weaknesses of the research Playback?Assess, revise, and plan next stepsAt the end of a research activity, compare your insights against your original objectives. How well do they align? How have you reduced your teamâs questions and assumptions about your experience? Are the implications and path forward clear?The challenge of conducting research in the enterprise setting is speed. You donât have the luxury of months of ethnographic research. Aim to be nimble. Ask yourself as a team, âWhat can we build today? What can we do to advance our teamâs understanding?âWhere do you come in?Reflect together on what youâd like to learn.The Explorer:What can we build to test this assumption?How can I contribute to the research plan?What might I learn from this research?The Guide:What hypotheses is the experience built on?How well did we answer the objectives?How fast is the team continually learning?How does our experience measure up against the competition?PreviousResearch in practice: Focus on peopleNextResearch in practice: Craft insightsPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Research in practiceSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsResearch in practiceDesign research beginsâand endsâwith people. We practice IBM Design Research in order to better understand the people we serve, their lives, and how we can meet their needs. Whether you are observing, uncovering insights, or sharing findings, remember to place your users at the center of your work.Focus on peopleUser understanding starts with knowing a personâs behaviors, context, differences, and external influences.Plan for successFrom research plans to synthesis, set your research practice up for success.Craft insightsGreat research insights result from quality data, strong synthesis, and thoughtful recommendations.Find the storyCraft a meaningful story, rooted in real user insights, that is tailored to your audience.PreviousGuiding principles: Make to learnNextResearch in practice: Focus on peoplePrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Focus on peopleSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsFocus on peopleWorking with actual users helps us align on real opportunities, needs, and pain points. When you interact directly with the people you serve, you ensure the team is creating real value for real people. Make your users your North Star.Engage with different user typesTalking to one person is not enough to develop a broad understanding of all of your usersâ needs, especially in an environment where different types of users interact with one another. The more you interact, the better you will understand the range and outliers of their needs. Consider subdividing people into separate user groups. It may be easy to classify users by job role or demographic, but this can lead to overgeneralization. Instead, remember that a person is more than their job title. User understanding starts with knowing a personâs behaviors, motivations, context, individual differences, and external influences.Actions speak louder than wordsItâs hard to remember exactly what you were thinking or doing when you last experienced a problem. Human memory is prone to error and change. Consider not only what a user says but also what they do.Your heroâs journeyWhen seeking to understand your user, aim to understand their target end goals as well as the steps they take to reach them. Users experience a variety of pushes, pulls, and transformations along their journey. These interactions occur between users and the objects in their ecosystem.Motivations and attitudesMotivations are the reasons behind peopleâs actions. Why did they make that decision? What does your user hope to accomplish or learn? To what end?Attitudes speak to the perspective a person has about something. For example, some people will spend hours combing through documentation files to find out how to solve a problem themselves. You could classify them as âDIYâ individuals. You might also meet people that, rather than learn how to fix the problem themselves, ask a fellow coworker to solve the problem. This attitude of the âdelegatorâ clearly differs greatly from the âDIYâ attitude.Locations and environmentPeopleâs behaviors are greatly impacted by the context of their locationâboth physical and virtual. For example, youâre probably not the same person at work that you are in front of your parents or in front of your housemates. You may speak differently, act differently, or dress differently depending on these locations. The same goes for your users.Similarly, a personâs environment affects their behavior and reactions. For instance, is your userâs location noisy and full of distractions? Is your userâs location ever-changing because they travel for work? Geographic location is another factor that may have a key impact on culture. Every userâs experience is shaped by the world around them. As your team continually defines your users, keep in mind external industry or technological influences that may affect user perception and attitudes.Where do you come in?Reflect together on how you can learn more deeply about your users.The Explorer:When can I observe our users?What does my userâs environment look like?What is my userâs end goal?How can I help build empathy for the user?The Guide:How many user groups do we have?How do they interact?What other forces influence their behavior?Who can join me in the research?PreviousResearch in practice: OverviewNextResearch in practice: Plan for successPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Find the storySkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsFind the storyShare research insights to create empathy across your team. Craft a story with a meaningful plot, detailed visualizations, and attention to your audience. Create a sense of urgency for your work, and bring your user to life.Lead with empathyA successful research Playback makes your user the protagonist, so try to keep people at the center of your story. Communicate meaningful storiesânot just a series of unrelated artifacts. Remind your team who the experience impacts, what user pain points or opportunities you address, and the tasks your users need to perform. Itâs tempting to only share the negative, but remember to highlight positive moments in the userâs journey, too. See how a team changed the course of a project by centering on the realities of their users.Define the stakesTo create urgency for your team to take action, define whatâs at stake for the user. If a user canât perform this task successfully, what will happen? Communicate all the working parts and who might be affected. This is a great time to bring in competitive research.Focus on outcomesShow your team opportunities to help alleviate pain points, but donât stop there. Look for new ways to give users a positive outcome. Remember to not settle for average experiences. We aim to create exceptional experiences that impact our users and help us achieve our business goals.Consider your audienceA good storyteller tailors the narrative to their listener. Ask yourself:Where is the presentation happening?You may need a different medium depending on where the delivery happens, be it online, over the phone, or in person.Who are you presenting to?If you present to your team, perhaps a more hands-on or casual approach to a story is more effective.If you present to an executive or senior executive in the company, they might expect a more formal presentation.If you want to switch up conventions for the sake of the story, tell your audience ahead of time so they can prepare and adjust their expectations accordingly.Transfer research insightsAs you tell the usersâ stories, leave the audience with a few big takeaways. These research insights and recommendations will help focus the team. Ensure that the stories you tell have a visceral impact, create urgency to build, and are backed by evidence.Enhance meaning with visualsHelp others see what you see. Visually communicate research insights to elevate findings and increase value. You can read IBMâs guidance on data visualization here.Select a mediumThink about the environments in which your research will live. Will you present it to an audience? Will you send a report to your team through email? Will it live online in a shared document? Understanding where and how the research will be documented can create a strong outline and even help you work faster by allowing you to better construct files, templates, and other communication materials.Keep it simpleStart with the fundamentals. Balance, contrast, scale, dominance, similarity, and hierarchy will provide clarity in your compositions. These principles sound simple, but their combinations and applications are endless. When using visualizations like graphs or charts, think deeply about what you are trying to communicate. For example, while itâs easy to construct a Venn diagram, it may not be the right visual for the job.Establish a rhythmThink in patterns. When visually communicating your research, think in terms of relationships over time. What data relates to this insight? Where is this happening the journey? How does everything relate? Help your audience follow the storyline, characters, and relationships through visual cues and consistent layouts.Stay on brand to stay credibleVisual communication takes time, regardless of your expertise. Connect with those who are trained in visual design. Consider your offeringâs attributes and style guide. By adopting your offeringâs palette, appropriate type scale, and other brand-specific guidelines, you lessen your workload and reinforce the brand. Make your research deliverables look like they belong in your product or service family.Where do you come in?Reflect together on how you tell stories about your users.The Explorer:How can we solve this pain point for our user?How can we take advantage of this opportunity?How can we improve the userâs experience?What else could this impact?The Guide:Who is my audience? What will they care about?How can I improve the visual hierarchy of my presentation?Have I told described both the positive and negative?Have I created a sense of urgency?PreviousResearch in practice: Craft insightsNextSponsor User Program: OverviewPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




IBM Design ResearchSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsYour browser does not support the video tag.Guiding principlesResearch in practiceOur practice We are not our users. Design research guides teams to uncover insights and inform the experiences we create. It begins with the rigorous study of the people we serve and their context. This is the heart of Enterprise Design Thinking. While in the Loop, design research leads teams to continuously build understanding and empathy through observation, prototyping possible solutions, and reflecting on the feedback from our users themselves.Guiding principles


Research in practice


Ethics and Responsibility


Sponsor User Program


Guiding principles


Research in practice


Ethics and Responsibility


Sponsor User Program


Latest ArticlesMore than just medicine: how design thinking uncovered modern patient needsEnterprise Design Thinking1 minute readThe Total Economic Impactâ¢ Of IBMâs Design Thinking PracticeForrester60 minute readProject Monocle: a case for design researchEnterprise Design Thinking5 minute readPreviousHomeNextGuiding principles: OverviewPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




PlanningSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsPlanningThe first step is for your team to establish a solid research plan for your feedback program. Below is a checklist to get you started:Identify the research objectives and business goals of the program. What are you trying to learn or evaluate, and why?Determine your participant user groups. Which personas, segments, industries, or requirements do people need to match? How many do you need per group? This will become a screener to direct you to the right participants.Draft research questions and choose appropriate methods.Identify a rough time frame of when the program will start and end. Determine time expectations for client participants.Assign clear roles within the project team.â¯Discuss and answer questions like, âWho will secure clients for the program? Confirm agreements are in place? Run the kick-off meetings? Run the actual design sessions? Conduct the analysis? Report findings?â â¦ and so on.Decide where and how you will track program activities before you start. A central, online storage location helps the team find, reference, and share research artifacts.Pro tips:Download a research template.When assigning roles, keep in mind the client contact should be skilled in communication, organization, and interpersonal relationships.IBMâs Design Program Office recommends 5-8 users, total, from a variety of companies. However, this number will vary and should be tailored to the needs of your project and team.FAQsWhen should a team create their research plan?You should create the research plan as early as possible once a project has kicked off and the team has started drafting Hills. As your Hills are being formed, the plan will help you determine the personas and types of research you want to conduct with end users. Research plans should be revisited and updated as projects progress.PreviousSponsor User Program: OverviewNextSponsor User Program: StartingPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Sponsor User ProgramSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsSponsor User ProgramSponsor Users are a scaled approach to co-creation with end users. Sponsor Users are âclientsâ (customers, non-customers, business partners, end users, or organizations) who provide domain expertise to your team. Sponsor Users help you design experiences for real target users rather than for assumed needs.What is a Sponsor User Program?A Sponsor User Program formalizes and scales the relationship between your team and your users. The program derives insights from your users to inform your teamâs designed experience, roadmap, and Hills. It is not a channel for feature requests.Do I have to call them âSponsor Usersâ?No. The most important aspect of Enterprise Design Thinking is a relentless focus on human-centered outcomes. Working with end users helps us do just that, and this act of co-creation matters more than terminology. If you want to call it a feedback program, customer advisory council, or something else, feel free. Just remember: Stay focused on your users.Ready to get started?In the following sections, youâll find checklists and tips to help plan, start, run, and wrap up your feedback program.Planning your program Starting your program Running your program Wrapping up your program Where do you come in?Each team member can meaningfully contribute to the creation of a successful Sponsor User Program.The Explorer:What types of Sponsor Users should we be working with?What conferences or events might we attend to find new Sponsor Users?The Guide:Who are the Sponsor Users we need to focus on at this time?How many Sponsor Users do we need at this point in time?PreviousResearch in practice: Find the storyNextSponsor User Program: PlanningPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Research as a teamSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsResearch as a teamEveryone has the responsibility to champion for better understanding of the people we serve. As a team, ask yourselves: âHow do we make a difference for our users?âThe ExplorerAn Explorer has little applied research experience but participates and helps with research activities. Explorers use their domain and skills expertise to help identify what questions to askâand answer.Explorers can be developers, marketers, consultants, product owners, sales representatives, business analysts, other designers, and more. If you have yet to conduct design research in a professional setting or are just getting started, youâre probably an Explorer.Think like a touristWhen visiting a new place, you understand the local culture by immersing yourself in daily life and visiting popular attractions. Apply the same approach to design research: Embrace a tourist-like mentality by becoming an active participant in your teamâs design research.Share expertiseAs an Explorer, your superpower is your domain expertise. When collaborating with your team, share your knowledge with the Guides who are facilitating design research activities. This may mean participating in research analysis, accompanying the researcher on a site visit, or assisting in creating the research plan. The more you lean into the diverse skillsets and strengths of your team, the more successful you will be at fostering new ideas that improve your usersâ experience.Champion design researchIt is your responsibility to uphold and support the design research produced by your team. Stay up to date by actively participating in research Playbacks and activities.Explorers, where do you come in?Where can my expertise help?How can I support a research activity?What questions do we have?How can I ask better questions in research?The GuideGuides have deep design research experience. They facilitate the practice across their team. They regularly curate questions and assumptions from their team and identify methods to answer them. Guides craft and curate insights to inform the creation of better user experiences.Guides are often mid-career and beyond with backgrounds that emphasize the study of people and human behavior. Some examples include social scientists, academic researchers, communications professionals, or designers. If you have conducted human-centered research either professionally or academically over time, youâre most likely a Guide.Think like a hostGuides often make use of their experience, landmarks, and other tools to help people discover things they didnât know existed. As a Guide, help your team through uncertainty. Provide context to your usersâ world. Guides need to resist the urge to work alone. Aim to work hand-in-hand with your team.Facilitate connectionsEncourage your team to share domain expertise to fill in the gaps of knowledge among more junior members. Bring Explorers into research activities to provide new perspectives. The more that team members participate in research, the faster they will internalize important findings.Champion design researchBe the voice of the users. Uphold and support the design research produced on your team. Be aware of the research occurring around you and around the company. Advise your team on what resources and tools are needed to support and produce quality design research, insights, and outcomes.Guides, where do you come in?Who are the target user groups?How valid are our assumptions?How can I communicate insights?What can my team build now to advance our understanding?PreviousGuiding principles: Stay curiousNextGuiding principles: Make to learnPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Craft insightsSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsCraft insightsInspire action. Design research insights result from quality data, strong synthesis, thoughtful analysis, and articulate implications. High quality insights are never a travelog but should inform what the team will make next.Get in the loopAn assumption is something you think might be true but needs to be verified. Identifying and addressing assumptions is key to mitigating risk. Start with what you know and what you do not know. It can be easy to get bogged down in the âwhat ifsâ or the âneed to know everythingâ feeling. If that happens, try prioritizing what your assumptions and what you donât know.Address and evaluate your assumptions and questions using the Enterprise Design Thinking toolkit.Toolkit: Assumptions and QuestionsÂ Â With a prioritized list in hand, validate your questions by reframing them as testable statements. For example, a broad research objective might be, âHow long do users spend looking for content?â Try turning that into a provable statement such as: âUsers need a more contextual way to find answers to complete everyday tasks.â Then, you can collect evidence that proves or disproves that statement.If it is not testable, rewrite the statement until you can make a feasible research protocol. Assumptions need to be proven true or false with evidence to move your team forward with confidence.Collect quality dataData collections describe the gathering, measurement, and control of information within a research activity. Raw data exists in many mediums: sticky notes, photographs, recordings, objects, survey answers, academic articles, customer complaints, error logs, analytics, and more. Choose the appropriate data collection and research method based on the needs of your team.Keep this adage in mind : garbage in, garbage out. Gather data that reflects honest behaviors and reactions. Remember that the collection techniques used can influence how users respond. Asking users to answer difficult questions over the phone, face-to-face, or in a survey can elicit different answers.Make an effort to collect replicable and consistent data that encompasses a broad range of real user experiences, but donât ignore the outliers. While you cannot design for all extreme characteristics, your team can understand the entire spectrum of needs. With the outliers, you may find unexpected opportunities.Clean your data and reduce human error before using. For quantitative data, remove inaccuracies from your data sets. You can clean qualitative data by screening participants before inviting them to a study or by removing a participantâs data from the collection before itâs synthesized.Organize your data through synthesisData synthesis involves the organization, categorization, and description of a body of data. Try organizing your data in a few different waysâlike grouping, sorting, and tallyingâto clarify information.Sometimes, the right synthesis method can depend on the context and collection method used. For example, if you collected data through a series of phone interviews, you may choose affinity diagramming or coding to help you visually map the information in new ways. However, if you collected data through a quantitative method, a descriptive summary can be beneficial.As a design researcher, avoid creating artifacts just for the sake of creating them. For example, how many times have you created a user journey map that was viewed once and then stored away in an email? Instead, use artifacts to help you make sense of the data you collect. Aim to constantly inform your offeringâs roadmap. Bring research into the discussion rather than making it an item to complete on the teamâs to-do list.Seek patterns through data analysisData analysis seeks to uncover patterns and inferences from synthesized data and should breed quality insights your team can use.After you organize your data, interpret it in a meaningful, evidence-based way. Explain the data by looking for patterns. Make sure that you address the root cause, not the symptoms. Find the factors that contribute to the main problem. Sometimes, it can be helpful to look for contradictions in your data and explore why they might occur.There are a variety of tools and resources to help analyze data. One popular method for analyzing qualitative user data is an experience map. For quantitative data, try exploratory data analysis or inferential statistics.Get started with the Enterprise Design Thinking toolkit.Toolkit: As-is Scenario MapÂ Â Create powerful research insightsResearch insights come from your analyzed data. They should be original, non-obvious, and actionable. They often explain the âhowâ or âwhyâ rather than the âwhatâ or âwhenâ, and they might reveal peopleâs true motivations beyond just their actions.You will likely craft many insights as a result of your analyzed data. Prioritize the findings based on impact, and rank them to influence team decisions appropriately. Choose those insights that require the least expense but result in high impact. A team is limited in what it can deliver depending on bandwidth, skills, and resources and your prioritization might shift as understanding increases.Where do you come in?The Explorer:What assumptions or questions do I have?Are there any opportunities to help my team synthesize?Do these insights explain the âhowâ rather than the âwhat?âThe Guide:Is my team making decisions based on assumptions or questions?Could I write any testable statements today?Whatâs the best way of synthesizing this data?What patterns do I see?PreviousResearch in practice: Plan for successNextResearch in practice: Find the storyPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Make to learnSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsMake to learnPut the design in design research. Design is giving form to your ideas, which allows you to quickly learn, reflect, and iterate. By testing your ideas, you provide forward motion through the Loop and create momentum within the team.Make with your handsWhat is the lowest fidelity that communicates intent and can elicit feedback from your users? Depending on your goals and the stage in the project, this can range from a low-fidelity paper prototype to a high-fidelity interactive prototype. Invite your users to make with your team.Consider othersAt the end of the day, a real person will use what you make. Consider their needs, their environment, and the not-so-obvious impact of your ideas. How many people might it affect, and would it be a positive or negative outcome for those individuals?Measure successStart with the end in mind. How will your users measure success? Make sure to address both utility and emotion when you build. Start with the basic metrics of usable, useful, and desirable. Consistently measure your product or serviceâs experiences. Build upon these metrics to ensure your user experiences are continually improving.Never stop learningTest early and often. There are low-impact methods of making and testing as a team, such as an A/B testing, a service prototype, or a pilot. Perfect is the enemy of done. In order to test your experience in its true context, you have to ultimately release the offering.PreviousGuiding principles: Research as a teamNextResearch in practice: OverviewPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




IBM Design ResearchSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsYour browser does not support the video tag.Guiding principlesResearch in practiceOur practice We are not our users. Design research guides teams to uncover insights and inform the experiences we create. It begins with the rigorous study of the people we serve and their context. This is the heart of Enterprise Design Thinking. While in the Loop, design research leads teams to continuously build understanding and empathy through observation, prototyping possible solutions, and reflecting on the feedback from our users themselves.Guiding principles


Research in practice


Ethics and Responsibility


Sponsor User Program


Guiding principles


Research in practice


Ethics and Responsibility


Sponsor User Program


Latest ArticlesMore than just medicine: how design thinking uncovered modern patient needsEnterprise Design Thinking1 minute readThe Total Economic Impactâ¢ Of IBMâs Design Thinking PracticeForrester60 minute readProject Monocle: a case for design researchEnterprise Design Thinking5 minute readPreviousHomeNextGuiding principles: OverviewPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




RunningSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsRunningNow that your program has started, here is a checklist of things to keep in
mind:Set and stick to meeting agendas.Track your programâs activities and communications with users.Use your teamâs central file storage location. Make sure the appropriate permissions are in place to safeguard data privacy.Sponsor Users may agree to a particular time commitment or cadence of meetings, but be flexible if schedules change.Encourage users to interact with the product or service during research activities. This helps ground feedback and research in reality.Hold Playbacks for Sponsor Users so they can see how the experience has evolved based on their feedback. This will also help make them feel like part of the team.Share findings and recommendations to your team regularly via Playbacks.Pro Tips:Always be professional, courteous, and trustworthy. Remember, Sponsor Users are often existing or potential clients.Always be considerate of usersâ time and convey your gratitude for their participation.Personal Information (PI) should only be collected if relevant and necessary for your business purpose(s) and should only be made available to other project team members on a need-to-know basis. For more details on PI, see the FAQs below.Donât let too much time go by without communicating with you Sponsor Users. You donât want them to wonder if the program is still active.Stay up-to-date on each client and their potential issues.Donât make promises about features or release dates.FAQsIs there a limit on how many programs a Sponsor User can participate in?While there is no limit to the number of programs, IBM's Design Program Office recommendsâ¯individuals should only participate in one program at a time. An individualâs participation should last for no longer than six months. After their participation ends, sponsor users should have a six-month âno contactâ period before beginning a new program. These guidelines will help us avoid overburdening participants and diversify the opinions and clients represented in our programs.Does the feedback agreement have an expiration date?At IBM, the Feedback Program Agreement does not expire. It can be terminated at any time, however, by written notice from IBM or the client. If you are not an IBM employee, check with your legal or agreements teams to understand the specifics of your feedback agreement.What information should I track?Store your research plan, design or testing artifacts, schedule of user sessions, anonymized notes, or recorded session files from user sessions, client quotes, playbacks, etc. in your designated central storage place.What type of research information is considered personal information?Personal inform is information that can be used on its own or combined with other information to identify, contact, or locate a single person, or to identify an individual in context. Personally identifiable information is information that can be but is not limited to name, education, background, age, gender, company name, position (e.g. CEO), nationality, picture, video (of face), voice (audio), address, very specific interview content (particular projects, particular products), etc.What is anonymized personal information data?Personal information that is anonymized, aggregated, or de-identified so that it cannot be attributable to an individual is no longer considered personal information.Is there an expiration on how long we can store personal information?For now, only Germany has an expiration limit.Personal information needs to be deleted 2 years after the first interview has been conducted or first data has been collected and 2 years after the agreement has been signed.What do I do if a customer asks me about features or release dates?Committing to a particular feature or release date is not part of the Sponsor User discussions. If they ask, be prepared to diplomatically steer the conversation away from that topic.Are we allowed to record sessions with users?Yes, as long as the participant agrees. You should ask the user at the beginning of each and every session. NOTE: Ensure you follow local country guidelines for consent. E.g., In the European Union, an additional signed consent form is required.PreviousSponsor User Program: StartingNextSponsor User Program: Wrapping upPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Wrapping upSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsWrapping upYou know the saying: All great things must come to an end. Below are a few steps and tips to help you wrap up your program.Schedule a wrap-up call to thank your Sponsor Users and gauge their interest in participating in a future feedback program.Share a follow-up survey to get any remaining feedback on the product and the program.Clean up documentation and ensure all feedback is appropriately anonymized.Conduct a final research playback of findings and recommendations with your team.Pro TipsA wrap-up call and follow-up survey are great opportunities to gather any final supporting quotes about the program or product experience. They will also help you identify ways to improve the Sponsor User program in the future.If you want to go above and beyond, consider mailing a hand-written thank you note signed by your team.FAQsWhat do I do if a client decides they no longer wish to participate in my Sponsor User program or any in the future?Make sure to refer to any "opt out" process documented in your program's agreement. For example: "A representative from the client or our company can terminate program involvement at any time via written notice. This will then go into effect within 30 days."How long can I keep audio and video recordings of research sessions?Teams should destroy all audio and video files captured during client research sessions no later than two years after they were recorded.PreviousSponsor User Program: RunningNextEthics & responsibilitiesPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




StartingSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsStartingNow that your plan is complete, the team is aligned on goals, and roles have been determined, itâs time to start your program. Below is a checklist to get you started:Recruit Sponsor Users. Not sure where to start? See the Pro Tips and FAQs for more detailed guidance.Set expectations with potential Sponsor Users. Common activities may include Enterprise Design Thinking workshops, sneak peeks into our latest offerings, participatory design sessions, surveys, usability testing, contextual inquiries, and interviews. Time commitments can vary from 1-2 hours per quarter up to 5 hours per week. A good average is 60-90 min every couple of weeks.Have users opt in to the program. Their consent to participate should be formalized via a feedback agreement. Itâs okay to brief them on the program and benefits, but users are required to sign an agreement before confidential information is shared.All agreements should be tracked so other teams can see who is actively participating in your program.Hold a kick-off meeting with each user to ensure everyone is on aligned on program expectations, including goals, activities, and timeframe.Pro TipsWhen recruiting Sponsor Users, provide clients with program details and requirements to gauge their interest and availability.Ask Sales, Service, and Business Partners if you can âlisten inâ on their conversations with clients or join site visits.Keep a pipeline of Sponsor Users so you can collect a healthy mix of feedback for your offering.FAQsHow do I get Sponsor Users?There are a variety of ways to recruit Sponsor Users, ranging from recruiting through conferences or events to working with members of your broader product team. Most often, different members of your team may already have established relationships with users and clients. Communicating and building a relationship with these team members who have access to clients can help you recruit Sponsor Users.Whose responsibility is it to identify and sign up new Sponsor Users?There is no âone size fits allâ answer. Some business units have Sponsor User program managers. Other teams rely heavily on their product managers, research guides, or account teams. The most important thing is that your team identifies a person who has the bandwidth, access, and can be held accountable.Is there anyone with whom we cannot engage?There is a small number of clients on IBM's denied parties list (DPL) with whom employees cannot engage. If you are not an IBM employee, check with your legal or agreements team to inquire about specific restrictions your company may have.Who is covered by an agreement once signed?At IBM, once the client signs the agreement, it covers any user participant employed by that company. In most instances, you do not need individually-signed agreements for each user participant. There are some countries that require individual consent in addition to a larger, company-wide agreement. If you are not an IBM employee, check with your legal or agreements team to inquire about specific agreement requirements and guidelines.PreviousSponsor User Program: PlanningNextSponsor User Program: RunningPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Plan for successSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsPlan for successA research plan is a document owned by the entire team that specifies what research will be conducted and how it will inform the teamâs work. Limit a planâs objectives to remove ambiguity and increase alignment. Research plans are not static, so remember to adjust as you learn.Creating your planStart by defining your learning objectives, hypotheses, and assumptions as a team. Once your research plan is established, the Guide will create corresponding research protocols. A research protocol includes all of the steps needed to conduct the research activity. Protocols are specific to a single research activity, such as a contextual inquiry, a usability test, or a user interview.Set expectationsClearly describe how the research plan relates to both business and user outcomes. Your research plan should inform or validate your Hills. Rely on your Guide. Be explicit about what your team plans to learn or test. Always share your research plans and protocols across the larger team. This will help you gain alignment and drives action quicker.This includes explaining in your research plan:learning objectivesparticipants screeningmethodologies and techniques for data collection, synthesis, and analysisbudget for conducting the researchsuccess metricsartifacts and deliverablesGet StartedIBM Design research plan templateIBM Design Research protocol templatePractice reflectionEmbrace critique from the larger design research community. Share your plans and deliverables to get feedback on your methodology choices, research insights, and planning process.When collecting feedback, ask these types of questions:Were the original research objectives clear?Did this research integrate with previously conducted research?How strong is the analysis?How actionable were the insights?What from the research was most memorable?What were the strengths and weaknesses of the research Playback?Assess, revise, and plan next stepsAt the end of a research activity, compare your insights against your original objectives. How well do they align? How have you reduced your teamâs questions and assumptions about your experience? Are the implications and path forward clear?The challenge of conducting research in the enterprise setting is speed. You donât have the luxury of months of ethnographic research. Aim to be nimble. Ask yourself as a team, âWhat can we build today? What can we do to advance our teamâs understanding?âWhere do you come in?Reflect together on what youâd like to learn.The Explorer:What can we build to test this assumption?How can I contribute to the research plan?What might I learn from this research?The Guide:What hypotheses is the experience built on?How well did we answer the objectives?How fast is the team continually learning?How does our experience measure up against the competition?PreviousResearch in practice: Focus on peopleNextResearch in practice: Craft insightsPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Stay curiousSkip to main contentIBMÂ Design ResearchSearchSwitch sitesFoundationsIBM Brand CenterIBM Design LanguageImplementationCarbon Design SystemCarbon for IBM ProductsCarbon for IBM.comIBM Event DesignIBM Workplace DesignPracticesEnterprise Design ThinkingIBM AccessibilityIBM Design for AIIBM Design ResearchIBM Experience StandardsCommunityIBM DesignRacial Equity in DesignGuiding principlesOverviewStay curiousResearch as a teamMake to learnResearch in practiceOverviewFocus on peoplePlan for successCraft insightsFind the storySponsor User ProgramOverviewPlanningStartingRunningWrapping upEthics & responsibilitiesCollapse navigation itemsStay curiousThink back to the last time you discovered something surprising or unexpected. Did you have the desire to learn more? That feeling is curiosity, and like any other skill, it requires nurturing over time. When you think something should be explored, follow that impulse and see where it leads. Hunches can often lead you down new and rewarding paths.Keep asking whyAsk questions about the world around you. Be humble and honest about what you know and what you donât know. Identify unanswered questions to explore rather than just problems to solve. If you create an account on our Enterprise Design Thinking platform, you can try out our â5 Whysâ activity.Dig deeperIntentionally shift your point of view to see opportuntities more clearly. Go out, experience, and explore rather than simply reading about it. Observing is better than listening in most cases. Imagine trying to visualize a personâs daily routine based solely on a series of phone interviews versus spending the day with them.Enterprise systems are made of many working parts. Explore problems from multiple angles to view all possibilities. Go deep, but also zoom out and consider the entire ecosystem of users, environment, and needs. What is the end-to-end journey?Acknowledge biasPeople are inherently prone to bias, whether personal, cultural, social, or otherwise. Your view of the world is shaped by your experiences. When you put yourself in someone elseâs shoes, be aware that youâre still coloring their world with your perspective. Aim to keep your view of the world as unbiased as possible. Evaluate the research based on your usersâ outlook rather than your own.Where do you come in?As a team and individual, practice curiosity to ensure itâs a skill thatâs strengthened over time.The Explorer:Where does our experience fit within the larger user journey?What bias do I bring to my team?Where can I physically go to learn more?What questions and assumptions should we prioritize to answer?The Guide:What hunches have I ignored?What patterns emerge from this data?What are the research implications?How can I strive for unbiased research?PreviousGuiding principles: OverviewNextGuiding principles: Research as a teamPrivacyTerms of UseIBM.comTwitterMediumQuestions or comments? Start a conversation with us on Twitter at @IBMDesign #designresearch. If youâre an IBMer, join the conversation on Slack at #ibm-design-research on Slack.Last updated 05 December 2022Copyright Â© 2022 IBM




Google DesignSkip to contentShow all tagsShow less tags0 results  The UX of AIUsing Google Clips to understand how a human-centered design process elevates artificial intelligenceAs was the case with the mobile revolution, and the web before that, machine learning will cause us to rethink, restructure, and reconsider what’s possible in virtually every experience we build. In the Google UX community, we’ve started an effort called “human-centered machine learning” to help focus and guide that conversation. Using this lens, we look across products to see how machine learning (ML) can stay grounded in human needs while solving for them—in ways that are uniquely possible through ML. Our team at Google works across the company to bring UXers up to speed on core ML concepts, understand how to best integrate ML into the UX utility belt, and ensure we're building ML and AI in inclusive ways.Real moments of parents, kids, and pets captured by the Google Clips camera.Google Clips is an intelligent camera designed to capture candid moments of familiar people and pets. It uses completely on-device machine intelligence to learn to only focus on the people you spend time with, as well as to understand what makes for a beautiful and memorable photograph. Using Google Clips as a case study, we’ll walk through the core takeaways after three years of building the on-device models, industrial design, and user interface—including what it means in practice to take a human-centered approach to designing an AI-powered product.Clips allows you to select the perfect frame (above, left) and save it as a still (above, right). In this instance, I clipped the camera onto a basketball hoop to capture the moment just before my son made a basket.“If you aren’t aligned with a human need, you’re just going to build a very powerful system to address a very small — or perhaps nonexistent — problem.”Just getting more UXers assigned to projects that use ML won’t be enough. It’ll be essential that they understand certain core ML concepts, unpack preconceptions about AI and its capabilities, and align around best-practices for building and maintaining trust. Every stage in the ML lifecycle is ripe for innovation, from determining which models will be useful to build, to data collection, to annotation, to novel forms of prototyping and testing.
We developed the following truths as anchors for why it’s so important to take a human-centered approach to building products and systems powered by ML:

Machine learning won’t figure out what problems to solve. If you aren’t aligned with a human need, you’re just going to build a very powerful system to address a very small—or perhaps nonexistent—problem.
If the goals of an AI system are opaque, and the user’s understanding of their role in calibrating that system are unclear, they will develop a mental model that suits their folk theories about AI, and their trust will be affected.
In order to thrive, machine learning must become multi-disciplinary. It's as much–if not more so—a social systems challenge as it's a technical one. Machine learning is the science of making predictions based on patterns and relationships that've been automatically discovered in data. The job of an ML model is to figure out just how wrong it can be about the importance of those patterns in order to be as right as possible as often as possible. But it doesn't perform this task alone. Every facet of ML is fueled and mediated by human judgement; from the idea to develop a model in the first place, to the sources of data chosen to train from, to the sample data itself and the methods and labels used to describe it, all the way to the success criteria for the aforementioned wrongness and rightness. Suffice to say, the UX axiom “you are not the user” is more important than ever.
Three ways human-centered design elevates AI
Addressing a real human need
This year, people will take about a trillion photos, and for many of us, that means a digital photo gallery filled with images that we won’t actually look at. This is especially true with new parents, whose day-to-day experience is full of firsts. During moments that can feel precious and fleeting, users are drawn to their smartphone cameras in hopes of capturing and preserving memories for their future selves. As a result, they often end up viewing the world through a tiny screen instead of interacting using all their senses.As a new parent, your gallery might look a lot like mine did—tons of smartphone photos taken in rapid succession, in an effort to capture the perfect cute expression.What if we could build a product that helped us be more in-the-moment with the people we care about? What if we could actually be in the photos, instead of always behind the camera? What if we could go back in time and take the photographs we would have taken, without having had to stop, take out a phone, swipe open the camera, compose the shot, and disrupt the moment? And, what if we could have a photographer by our side to capture more of those authentic and genuine moments of life, such as my child’s real smile? Those moments which often feel impossible to capture even if one is always behind the camera. That’s what we set out to build.Guiding the intelligence
When we started the process, the most pressing question was: if people take tons of photos but don’t actually want to go back and curate them, how will we label ground truth? This is where the foundational “HCML exercise” was born: Describe the way a theoretical human “expert” might perform the task today. The theory was twofold: First, if a human can’t perform the task, then neither can an AI; second, by diving deep into the methods of an expert, we can find signal-to-guide data collection, labeling, and component model architecture.“If a human can’t perform the task, then neither can an AI.”The closest approximation I could think of was a wedding photographer, so I set out to interview and hire contractors using a sufficiently ambiguous job posting (secret project! photography!). We ended up discovering—through trial and error and a healthy dose of luck—a treasure trove of expertise in the form of a documentary filmmaker, a photojournalist, and a fine arts photographer. Together, we began gathering footage from people on the team and trying to answer the question, “What makes a memorable moment?”It's important for us to recognize the amount of nuance, aesthetic instincts, and personal history that we often take for granted when evaluating the quality of our photos and videos. For example, I crack up every time I watch my younger son exploring the subtleties of a twisty straw (far left) or trying to juke my kisses (middle). And I well up with pride when I watch my older son on his bike at the park (far right), because I remember that day as a turning point in his self-confidence to ride on his own.Building trust
The starting point for our work was an assumption that we could ‘show’ the model the stuff we thought was beautiful and interesting, and it would, y’know, learn how to find more. We had romanticized conversations about depth of field, rule of thirds, dramatic lighting, match cuts, storytelling … but what I learned was that we should never underestimate the profound human capability to wield common sense.
These early experiments exposed crucial technical and methodological gaps that helped us reassess our assumptions about what the product could realize, as well as take stock in the unprecedented nature of the work. We shifted our paradigm from putting ML on a pedestal to understanding that it can only learn effectively under quite reductionist framings. Basically, we were trying to teach English to a two-year-old by reading Shakespeare instead of Go, Dog. Go!. This was where the myth of the AI ‘monolith’ crashed hardest for me; the idea that there’s some singular ‘intelligence’ that understands all things and can generalize and transfer knowledge from context to context. Nope. Not even close.Back to basics
Consistency is the name of the game when trying to teach anything. It’s why we wait as long as possible to unleash the madness of O-U-G-H (e.g. tough, through, thorough) on children when teaching them how to read and speak English. Spelling and pronouncing words like cat, bat, and sat, with their predictable “at” sounds, is so much more consistent!
With consistency comes confidence. Think about how quick—and eager—most students are to point out incongruity when a teacher provides two examples that don’t seem to line up. Algorithms provide no such feedback. As far as an algorithm is concerned, everything they’re shown is of equal value unless directed otherwise. For Clips, that meant we not only needed consistency betweenexamples, but also within each example. Every individual frame needed to be representative of the specific prediction we’re trying to teach it to make. And often that can come in the form of teaching it what to ignore.
Capture
We needed to train models on what bad looked like: hands in front of the camera, quick and shaky movements, blurriness.We used examples like the above to train machine learning models to recognize when the camera was inside a pocket or purse (above, left), or when a finger or hand was in front of the lens (above, right). While it wasn’t immediately intuitive to train models to ignore things, over time it became a crucial strategic piece in our design. By ruling out the stuff the camera wouldn’t need to waste energy processing (because no one would find value in it), the overall baseline quality of captured clips rose significantly.Composition
We needed to train models about stability, sharpness, and framing. Without careful attention, a face detection model will appreciate a face at the edge of the frame just as much as one in the center.In an effort to train a model about subject continuity, it was important to specifically highlight examples. Compare the moment where my younger son stays in the shot the whole time (above, left) to the moment where my older son is only in focus and in frame for about five percent of the moment (above, right).Social norms
Familiarity is such a cornerstone of photography. You point a camera at someone and they offer implicit consent by smiling or posing. Moreover, you’re the one looking through the viewfinder framing and composing the shot. With an autonomous camera, we had to be extremely clear on who is actually familiar to you based on social cues like the amount of time spent with them and how consistently they’ve been in the frame.
Editing
Diversity and redundancy is something we take for granted in the way we shoot photos; there’s a little voice in the back of our head saying, “You haven’t seen anything like this!” Or, “You’ve got enough shots of your kid for now, relax.” But our models needed a lot of help.
We approached diversity along three different vectors:

Time: The simple value of time passing is an important signal to appreciate. Don’t go too long without capturing something.
Visual: Subtle or dramatic changes in color can tell a lot about changes in environment and activity. Try to capture moments that have distinct aesthetic qualities.
People:Are you in a big group or a small group or alone? Understanding how many different familiar faces you’re encountering is a crucial part of feeling like you haven’t missed important moments.
I put Clips at the edge of a bookshelf pointing down, which provided a cool angle to watch my kids building together. It also meant I was showing the camera a bunch of very similar content over a lengthy chunk of time. Avoiding unwanted redundancy without missing too many moments was—and continues to be—a wonderfully complex UX challenge.Trust and self-efficacy
One of the reasons we invested in Clips was because of how deeply important it was to demonstrate the importance of on-device and privacy-preserving machine learning to the world—not to mention its remarkable capabilities (e.g. it uses less power, which means devices don’t get as hot, and the processing can happen quickly and reliably without needing an internet connection). A camera is a very personal object, and we’ve worked hard to ensure it—the hardware, the intelligence, and the content—ultimately belongs to you and you alone. Which is why everything—and I mean everything—stays on the camera until the user says otherwise.
Concept budgeting
With an eye on trust and self-efficacy, we were also very intentional in the way we approached UI design. At the start of the project, that meant working through a few of our own funny assumptions about how “out-there” an AI-powered product needed to be.
When we reach into our brains for future-tech reference points, many designers will jump to the types of immersive experiences seen in movies like Minority Report and Blade Runner. But just imagine of how crazy it’d be to actually explain something like the UI in Minority Report to users: Here, just extend your arm out, wait two seconds, grasp at thin air, then fling wildly to the right while rotating your hand counter-clockwise. It’s easy! Almost every sci-fi faux UI is guilty of something similar; as if the complexity of an interaction model needs to keep pace with the complexity of the system it’s driving. But that’s sort of where we were for awhile during our early design phase, and we got away with it in large part for three reasons:

We were showing people fake content in an obviously simulated environment, where they had no real connection to the imagery. Note that this issue isn’t unique to AI; it’s often one of the confounding factors when you bring people into the usability lab.
We were surrounded by people every day who were all speaking the same language; thinking deep thoughts about AI-enabled futures. We were making the mistake of losing touch with the reference points that everyone elsewould bring to the table.
We thought our new designs were super cool, so we gave ourselves a healthy amount of forgiveness when people didn’t immediately get it.
Most products have at least some learning curve, but with the added overhead of AI hype, it’s especially important to ‘spend’ wisely on your user’s cognitive load. When the context of use is novel to the user [figure A], bias for dependability. When there are a lot of new UI tricks to learn [figure B], make sure the primary use cases are super relatable. And when the functionality of the product is especially dynamic [figure C] , your UI should be flush with familiar patterns.Over time, we snapped out of it. We began fiercely reducing complexity in the UI, and made control and familiarity cornerstones of our experiential framework. We added a software viewfinder and a hardware capture button to the camera. We made sure that the user had the final say in curation; from the best still frame within a clip to its ideal duration. And we showed users more moments than what we necessarily thought was just right, because by allowing them to look a bit below the ‘water line’ and delete stuff they didn’t want, they actually developed a better understanding of what the camera was looking for, as well as what they could confidently expect it to capture in the future.“The hardware, the intelligence, and the content ultimately belong to you and you alone.”Through this process we discovered another critically important finding for testing an AI-powered product: fake it till you make it. If forced to choose, it’s leaps-and-bounds more useful to prototype your UX with a user’s real content than it is to test with real ML models. The latter takes an incredibly long time to build and instrument (and is far less agile or adaptive than traditional software development, so it’s more costly to swing and miss), while the former affords you genuine insights into the way people will derive value and utility from your (theoretical) product.Users preview their clips by streaming them from the camera. On the far left, users choose which clips they want saved to their phone. In the middle, users can toggle on a “suggested” view. On the right, users can pinpoint the exact frame they want to save as a still photo.In the context of subjectivity and personalization, perfection simply isn’t possible, and it really shouldn’t even be a goal. Unlike traditional software development, ML systems will never be “bug-free” because prediction is an innately fuzzy science. But it’s precisely this fuzziness that makes ML so useful! It’s what helps us craft dramatically more robust and dynamic ‘if’ statements, where we can design something to the effect of “when something looks sort of like x, do y.” And in that departure from rigid logic rules, we also needed to depart from traditional forms of measuring engagement. Success with Clips isn’t just about keeps, deletes, clicks, and edits (though those are important), it’s about authorship, co-learning, and adaptation over time. We really hope users go out and play with it.Designing with purpose
By re-orienting the conventional AI  paradigm from finding ways to make the machine smarter, to exploring ways to augment human capability, we can unlock far greater potential in machine learning. It can become a tool for unprecedented exploration and innovation; a tool to help us seek out patterns in ourselves and the world around us. As human-centered practitioners, we have a tremendous opportunity to shape a more humanist and inclusive world in concert with AI, and it starts by remembering our roots: finding and addressing real human needs, upholding human values, and designing for augmentation, not automation.
The role of AI shouldn’t be to find the needle in the haystack for us, but to show us how much hay it can clear so we can better see the needle ourselves.
For more on Google’s approach to UX for AI, check out our full collection of articles*.*Privacy & TermsAI UX design: A New Way Of Designing  Our ProjectsSolutions  Create MVPFrom nothing to a research-backed no-code prototype: you'll be sure to impress investors.Improve ProductReached PMF? We help you to scale your product without scaling the problems.Customer researchKnow your (potential) users better than they know themselves.DesignStream SubscriptionUnlimited UX / UI TasksUnlimited Revisions2 Days Turnaround TimeProject Management ⚡ AI UX Design Review -40% Get a 60+ page review of your product to eliminate all UX issues & skyrocket conversion, activation and retention.IndustriesFintechMaking financial products crystal clearAIDefining the future of humanity & digital experienceSaaSDesigning analytics, AI platforms, dashboardsEdtechMaking educational products fun and engagingAbout UsOur Story & Why UsOur UX Design ProcessUX ResourcesAI + UX eBookMaximize Your AI KnowledgeUX BlogArticles and StoriesSee All DownloadsUX Templates, Checklists & GuidesUX PilotYour AI-UX AssistantBook a CallUX ServicesResearch & UX / UI DesignUnlimited SubscriptionAI UX ReviewCase StudiesPast ProjectsIndustriesAIFintechSaaSAbout UsOur Story & Why UsUX ResourcesUX BlogDownloads10x your product experience:Contact UsBlogUX Design... viewsAI UX design: A New Way Of DesigningAdam FardAdam FedyniukAI is changing how we design products and systems. And while some people remain skeptical, UX designers and developers are reaping the benefits. Namely, AI helps to identify users’ needs and behaviors. The results? A vastly improved user experience.  We recently launched UX Pilot an AI-UX assistantAll UX Tools You Need in One Place:Interview stakeholdersAnalyze projects and extract insightsReview designsGenerate workshops and more!Check UX Pilot for FREE ->UX and AI: Current State of Things & What's to ComePractical Applications to UX ProcessAI is becoming increasingly applicable to the UX design process, and our team is actively using it to accelerate our design process. In this article, we will look at some of the most practical AI tools available today: ChatGPT and Midjourney.AI UX Case StudyB2B SaaS AI Platform DesignSee how we designed an AI-powered analytics platform from scratchSee Case StudyChatGPT ChatGPT is an AI tool that allows you to have a conversation with it. While the opportunities seem limitless, there are some limitations to keep in mind. Firstly, ChatGPT can only generate text-based deliverables (with some limited formatting). Secondly, if the answer is too large, ChatGPT will eventually break off, even though there is no official limit to the number of characters in its output. Lastly, GPT has access to internet information up to 2021. Despite these limitations, we have tested what ChatGPT can do and found the following use cases:User Persona A useful hack is to ask ChatGPT to create a UX persona for a specific user type in an industry. Create a UX persona for {user-type} in {industry}Of course, the more information you give the better, but it's a good start. To get better information, you can ask about specific things that interest you. For instance, we've gotten good results with questions such as Explain the {user type's} like if I was a UX researcher.Within seconds, you get a persona file. However, the question is whether it's of good quality. To test the quality of ChatGPT personas, we compared them to the personas we developed traditionally. Here's what we found:For general industry knowledge questions, ChatGPT's answers match the answers stakeholders give by 80-90%.The same applies to the core features a user might need for a given product.ChatGPT's output works best for protopersonas. The more iterations you put into your persona, and the more detailed information you require, the less potent ChatGPT becomes.The optimal way to use ChatGPT, in this case, is to use it at the early stages of product development as a baseline protopersona.That notwithstanding, you should always double-check the results, There are occasional hiccups.Competitor Analysis Knowing which features your competitors have and which they do not can be helpful, but it can be time-consuming to browse through and document dozens of tools online. ChatGPT can offer a quick solution, but the AI tool cannot tell the difference between a feature, a group of features, and features that are identical in functionality but have different names. Therefore, we need to establish feature standardization. You can save time with feature name standardization if you use resources like getapp.com.With the information you found on getapp, here's the most efficient prompt for doing competitor research:"What are the features in this list {paste-the-list} that are not present in this list {paste-another-list}?"The comparison also goes beyond features. You can also ask for a SWOT analysis. Or a USP. Or anything else you can think of.This prompt saves a lot of time, and if you ask nicely, ChatGPT can also present the results as a table.Requirements Documents We fed some initial client requirements into the chat and asked it to create a requirements document around it, but the output always ended up being too generic to be of any use. We believe you would be better off creating this deliverable yourself.Utilizing AI for Effective InterviewsGetting the scoop from stakeholders and users is like piecing together a puzzle. You want every piece, every bit of insight. And hey, AI is here to make that easier.Formulating questions. The less you know about users, the more difficult it is to come up with good questions. The good news is that you don't always have to. Early user interviews are often very open-ended where you encourage users to speak wherever the conversation takes you. However, it does sometimes help to prepare a few directions to steer the conversation in advance. You can do that with the User Interviews UX Pilot ModuleRecording Interviews: Zoom is your go-to. It's like having a digital recorder that never misses a beat. Record your sessions, and you've got every word, every reaction right there.Transcribing Interviews: Next up, let’s bring in Otter.ai or a similar AI transcription tool. It’s like having a super-fast typist turning your spoken words into text. No more frantic note-taking!Working with Transcripts in ChatGPT: Once you've got your transcripts, it’s time for some AI magic with ChatGPT. Convert those transcripts into a PDF and upload them using the AskYourPDF plugin. Now, you can directly query your document, pull out key quotes, and save heaps of time. It's like having a personal assistant to sift through the details for you.Conducting Industry Surveys with AIDiving into industry research with AI is like having a crystal ball that actually works. It’s all about getting deeper insights and building a solid base for your product development.Using AI Prompts for Industry Analysis: Pose the right questions to AI, and you'll get more than just answers; you'll get a perspective. For instance, ask AI to explain a specific process in your industry. It’s like having an expert by your side, guiding you through the complexities.Forming Preliminary Hypotheses: With AI, you're not just gathering data; you're starting to see patterns. Say your product is facing a challenge. Ask AI for solutions. It's like brainstorming with a room full of experts, all focused on your product goal.Utilizing AI for Insightful QueriesTapping into AI to understand industry trends and processes is like having a key to unlock a treasure trove of insights. It's not just about asking questions; it's about asking the right ones.Crafting the Perfect Prompt: Imagine you're in a room with the smartest industry analyst. What would you ask? That's your prompt for AI. It’s about being specific yet open-ended enough to invite comprehensive responses. For instance, if you're in fintech, you might ask, "What are the emerging trends in mobile payment security?" It's like directing a spotlight on exactly what you need to know.Customizing for Context: Every industry has its nuances. Tailor your prompts to fit the unique context of your field. If you’re in healthcare, a prompt like, “Explain the impact of AI on patient data management” will yield insights tailored to the intricacies of healthcare data security and management.Using Prompts for Predictive Analysis: Go beyond the present. Use AI to not just report what is, but to predict what could be. Ask about future trends, potential disruptions, or emerging technologies. For example, “Predict the future of e-commerce post-COVID-19.” It’s like having a window into the future, giving you a strategic edge.Midjourney At first glance, Midjourney might seem like a substitute for an illustrator, with no connection to UX design. However, we have found two practical ways to utilize the app:Moodboards Conveying the mood you want your app to have is challenging, and arriving at a solution everyone likes might take a while. Midjourney can help shorten that time drastically. Designers, clients, and other team members can generate many solutions in minutes. We've uploaded a simple Node-based interface into Midjourney, and asked it to generate new ideas.With Midjourney, you just need to enter a specific prompt (you can even upload a piece of UI as a reference), and voila! You can help the client articulate their likes and dislikes early on.Icon Sets We discovered this use case quite unexpectedly. We were just brainstorming on what other uses Midjourney could have beyond moodboards, and we realized that we could generate a lot of unique icons very quickly. All you need to do is enter the prompt specifying what icons you need and what style you're going for. Then, you just need to remove the background and use whichever tool you like (e.g., Adobe Illustrator, vectorizer.com or a Figma plugin) to vectorize the PNG. It may seem hard to control AI-generated output, but you can have more control if you include prompts that are very detailed.Voila, you have a complete unique icon set. Here's an example of what we ended up with 👇Last but not least, you can not only generate system icons but app icons as well. Here are a few examples we generated.Now that we've seen how to use AI to enhance the UX process, let's take a look at how to design better AI products.On Designing AI-Powered ProductsWhile it’s one thing to have AI as a supporting layer, it’s another thing entirely to use this technology as the core value proposition. At Adam Fard, we’ve handled projects where the value boils down to using AI to forecast changes in supply and demand and adjust prices accordingly. From our experience designing AI-powered products, we have established a few best practices. Here’s a closer look.TrustWhen dealing with this type of project, building trust is key. In many cases, AI sounds too good to be true. As a result, this can breed skepticism and distrust. Therefore, it’s the UX designer’s job to foster trust with users.This is harder than it sounds. That said, we have found a few ways to gain users’ trust. The first is education. Showing users how AI works behind the scenes is a highly effective trust-building exercise. This can be done through a demo during the onboarding process.Now, let’s delve into the idea of trust-building a bit more.Mikael Eriksson Björling and Ahmed H. Ali, senior designers at Ericsson, deconstruct trust down to 4 pillars:Competence Benevolence and opennessIntegrityCharismaSourceWith these 4 pillars in mind, an AI-based product should successfully:Communicate and demonstrate its capabilitiesResonate with the users in its communicationShow a degree of flexibilityDemonstrate its ethical integrityBefore moving on, we want to touch on the idea of ethical integrity. AI has given designers the tools to build much more potent products. Having said that, just because something can be built doesn’t mean it should. As such, UX designers need to be more ethically aware than ever. As the saying goes, knowledge is power. Therefore, they have an ethical responsibility to consider the consequences of the products they are building.Summing up, trust is an integral factor in designing AI products. This trust can be built through proper user education, clear communication, flexibility, and integrity. Usability TestingUsability testing sessions are fundamental in ensuring you end up with a usable product. However, with AI-based projects, the AI engine is often not complete when it comes to testing your design solutions. Fortunately, there are ways to address this issue. An example of a remote usability tesitng.For example, you could have someone manually provide the system answers. Alternatively, you could talk to the user beforehand to have the answers ready. Naturally, such an approach doesn't account for mistakes an implemented AI might make. However, a slightly flawed usability testing session is definitely better than none at all.Explain what’s AI and what’s notUsers want to feel part of the products and systems they use. This means they want to know exactly what is AI and what isn’t. As such, when the system presents AI-generated information, we recommend making sure that users understand this. SourceIn doing so, you eliminate the potential for confusion. For instance, if the system provides forecasts, users could be perplexed about where this information comes from. Simply put, clearly highlighting what AI is and isn’t will make users feel more comfortable with your product.  This is just the tip of the iceberg. AI can do more.If we have to sum this argument up in a nutshell, it’s this:AI is already helping UX design - but not nearly to its full potential.Here’s what we know.Aside from ChatGPT and Midjourney, there’s a plethora of AI design tools already. The problem is that they’re tools that help parts of the design process (sidegrades for existing UX processes) and therefore don’t cover the full range of possibilities that AI may offer in this field.What’s more, there’s a distinct lack of awareness of what that full potential might look like.The main concern here is that the current usage of AI in UX is focused on specific tasks rather than the UX process at large. This not only hinders it from reaching its full potential (and designers from even understanding how far AI can go in design), but it also reinforces the low-impact and side-grade nature of AI in UX.Let’s take a look at some examples of AI tools and their specific tasks:Khroma: creates limitless color palettesFontjoy: coherent font pairingUIzard: scans design sketches and transform them into editable digital designsCopy.ai: creates all sorts of copy based on the brand, product name, and a short descriptionRecently, we designers got a better taste of what AI is capable of with the launch of ChatGPT. This chat-based tool has proven extremely useful in doing research and collecting and sorting available data.A big part of this argument is centered around negative bias.  Negative bias is a set of predispositions, beliefs, and behaviors which affects our ability to judge something or someone objectively. How does negative bias show up in AI? It may appear in the shape of outlining the potentially negative social implications of AI (job losses, etc.) or honing in on the fear of not being “in control” of these tools.Don’t just take our word for it.The article ”I Lead, You Help But Only with Enough Details: Understanding the User Experience of Co-Creation with Artificial Intelligence” reveals a lot about negative bias in this space. The article looks at how users collaborate when using an AI-powered drawing tool. Basically, the drawing tool works by collaborating with the users. The users can start to draw something, and the AI would finish the drawing (or vice versa) in the same style as the user.  Source: ”I Lead, You Help But Only with Enough Details: Understanding the User Experience of Co-Creation with Artificial Intelligence”Examples of two of the many communication styles possible in DuetDraw | SourceThe feedback from the users was overwhelmingly positive, with most describing the experience as fun, efficient, and useful. It also appeared to enhance users’ creativity–when the AI was prompting the user, it led to less common outputs (even though users did prefer having the initiative at all times).What does this tell us? The main message seems to be that designers are more prone to adopt AI as a virtual assistant to facilitate practice and increase process efficiency rather than as a creative collaborator. In addition, it indicates that people (read: designers) tend to trust AI more when they feel in command and understand what the product does and what it offers. Therefore, having concrete examples and a deep understanding of what AI tools can do could be the answer to improving the adoption of AI in the UX field.Our two centsThe optimization of the UX process through AI means it’s now within our grasp and will happen in near future. The question is not how but when (with existing technology). However, there are challenges ahead. The mere possibility of AI taking over the industry is enough to create a negative bias toward these tools. But the moment people try using these tools in a cooperative manner, all the genetically and socially ingrained mechanisms of cognition start to change our perspective on AI in UX design. Via fleeting attempts at humanizing these experiences, we become more positive about this technology and, at the same time, well-versed in its employment.AI advancements = more UX process optimizationThe second argument aboils down to the following:AI improvements will enhance UX in a specific manner–UX process optimization.Let us elaborate.AI advancements look set to optimize the UX process by reducing the time spent acquiring and analyzing data and on the creation of AI-embedded interfaces. We already briefly touched on the impact AI can have on UX process optimization at large. The idea is to use AI to pinpoint statistical means to predict timeframes of phases and activities within a UX project.While at the same time allowing for AI oversight over the progress of the project (e. g., project management with time tracking that has to predict a specific timeline may be completed with more precision) and improvement s of designs in more detail.How can mouse-tracking AI impact design?The article “User Experience Evaluation Using Mouse Tracking and Artificial Intelligence” refers to an experiment where user experience evaluation was carried out through a mouse-tracking AI.This was the hierarchy of the variables used to facilitate the formulation of the rules that described the UX evaluation process statistically through mouse-tracking. (Source)The results? Since it was overseen by mouse-tracking AI, when users reported bad UX, this could also be proven by statistical means through their performance during the task. In other words, bad UX can be diagnosed by statistical meaning with the help of AI.Numbers 1-21 are the users participating in the experiment. The image shows that the users who reported having a good UX also had a positive evaluation through the mouse-tracking system | SourceCan AI be used to enhance the creation of AI-embedded interfaces? The simple answer is yes.By cooperating with AI, a designer can get the proverbial best of both worlds.Designers can reach new heights of consistency, faster generation of designs, and have complete oversight of all variables that need to be taken into account.What impact does AI have on the time spent on data acquisition, analysis, and visualization?The impact is huge. AI greatly reduces the time spent on these tasks. To prove this, we’ve carried out a test using ChatGPT’s new tool. ChatGPT is a tool from the organization OpenAI, which uses artificial intelligence to deliver an instant-message chatting experience (using Reinforcement Learning from Human Feedback as its learning model).Firstly, we sent the AI a list of issues a client shared with us. It contained mixed inputs, such as pain points, issues, and business requirements. Then, we asked ChatGPT to classify the sentiment of all inputs to sort for pain points versus technical specifications. Needless to say, it’s a clear asset when working on research in a UX project, especially if you’re dealing with large data sets. It essentially reduces hours of work into seconds.In the image below, you can see the inputs classified as “negative” or “neutral”:In this second image, only the negative inputs are presented:Our two centsNow we’re going to weigh in. By creating a relationship with an AI system, the UX specialist can tremendously shorten the amount of time spent on completing tasks. Moreover, it means that there is less error, more consistency, and better adherence to all outlined and detected variables that must be taken into account when designing a system. It’s also a powerful means of supervising the full processes in UX projects. We can easily gauge the tempo of the generation of designs and oversee project iterations. On top of this, we can predict the next steps in the project and define more accurate timelines for the completion of highly dynamic projects that include discovery work.Artificial Intelligence + Human Expertise = 😀We can sum up the third argument on AI and UX with the following statement:Combining AI with human expertise will always be better than one or the other alone. Cooperation brings out the best of both worlds and will have a lasting impact on both sides.Put simply, for best results, combine human intelligence with AI.How can humans and AI cooperate in UX?Let’s start with the role of human expertise. Humans are the vision behind a UX project or design.We work with varied subjective and objective inputs to combine them into design solutions. For instance, let's say the stakeholders have a specific product, company vision, values, or needs. It’s the designer’s work to translate these subjective inputs together with objective inputs, such as business requirements, into design solutions. AI will ensure that all objective inputs are accounted for, while designers make sure that the subjective side is fully realized in the designs.Effectively, only humans can convey the majority of pivotal and impactful qualities within the design process (such as creativity and empathy). Therefore, these remain human domains. Meanwhile, repetitive and low-level tasks become automated and performed by AI.How can machine learning impact UX design?Many studies show that leveraging machine learning to optimize interfaces for time-saving is the best use of its power. When it comes to the subjective substrate of user experience, the reception of the system, and holistic-focused facets of using the system, humans reign supreme. That said, machine learning can do wonders for reducing the time designers spend on menial, repetitive tasks. This basically means that it’s easier for AI to optimize for time rather than for happiness, which remains a factor for UX people to work on.This is based on an image from here.Will AI make 80% of designers’ tasks obsolete? – Yes.Is that a bad thing? – Absolutely not.Taking time-consuming, low-level tasks off designers’ plates frees up time and space for highly creative work. With highly developed machine learning technologies and the automation of repetitive tasks, the bulk of designers’ workload would become the creative, visionary work that they love the most.So, when we combine AI’s time-saving and process-optimizing capabilities with human creativity and emotional expertise, we have the best of both worlds.Our two centsHere’s where we stand on this argument.This level of cooperation could result in an unforeseen shift in the perspective of designers. Designers could rely on AI to ensure complete adherence to the specifications, inputs, and needs in UX projects.What’s more, AI will highlight any divergence from the design process that could negatively impact the project or results. Basically, human designers will change how they think about the UX process while working in tandem with an artificial designer that never forgets a single thing and can multitask without sacrificing efficiency or quality. That all-important human touch minus human error.  OutroAI and UX design are a powerful combination with a lot of promise for the future. AI is already improving UX design by offering ways to identify and satisfy specific user needs. As a result, AI-infused products are more efficient and client-centric. And this is just the beginning.In the future, AI-powered products will continue to evolve and offer deeper insights into human behavior. However, with great power comes great responsibility. As the scope of what’s possible expands, designers must find the right balance between UX and ethics. YOUR AI-UX ASSISTANTAll UX Tools You Need in One PlaceFrom Discovery to Visual Design: Interview stakeholders, Analyze projects, Review designs, Generate workshopsCheck UX Pilot for FREEDon't forget to share this post:Twitter iconFacebook iconLinkedIn iconNeed help designing your AI app?We help you to resolve Usability, Retention Rate and Conversion issues:Book a CallDon't forget to share this post:Twitter iconFacebook iconLinkedIn iconRelated StoriesArtificial Intelligence (AI)... viewsAI Impact: Pros and Cons of AI in Business Are you ready to harness the power of AI in your business? Explore the Pros and Cons of AI in business, and uncover how it reshapes operational efficiency, decision-making, and customer interactions. This comprehensive guide offers insights into navigating the challenges and leveraging AI's transformative potential for competitive advantage. Artificial Intelligence (AI)... viewsHow to Use AI for AI Startup IdeasEver thought about how AI can transform your startup idea into reality? Learn the secrets of using AI to innovate, automate, and dominate your industry. Get expert insights and actionable advice on navigating the AI startup landscape effectively.Artificial Intelligence (AI)... viewsAI in Podcasting: Transforming Podcast with AI TechnologyIs AI transforming podcasting? Explore how AI in Podcasting is revolutionizing content creation, enhancing audio quality, and personalizing listener experiences. Dive into the future of podcasts with our in-depth analysis, where technology meets creativity.Exclusive UX Articles & Strategiesfor Startups, UX Designers & EntrepreneursConnect with us onLinkedInYoutubeBehanceTikTok©2024 All Rights Reserved.Privacy PolicySolutionsFintech DesignAI DesignSaaS DesignEdtech DesignUX ConsultingUX ServicesUX Design SubscriptionUX AgencyUX ProjectsUX Design ProcessAbout UsContact UsGrowthSocial Media MarketingLinksCareers UX BlogDownloadsAI Color GeneratorStartup Ideas GeneratorShare:Twitter icon

Google DesignSkip to contentShow all tagsShow less tags0 results  Predictably SmartMachine learning works best when users don’t have to think twiceMachine learning is the science of helping computers discover patterns and relationships in data. Two of the most common ways products use machine learning (ML) today are predictive recommendations and personalization. If you’ve checked out a recommended video on YouTube, then you’ve already experienced these features for yourself. And if you’re a UXer, perhaps you’re already incorporating ML into your own designs.
At their best, ML-driven recommendations and personalized features save time and effort by proactively delivering the content users want without forcing them to navigate an interface or search. However, with the wrong execution, providing even the most accurate suggestion or the most relevant list of recommended items could actually require more time and effort from the user.
To understand why this happens, and how to avoid this pitfall in your own designs, start by embracing a phenomenon known as habituation.To habituate is human
Habituation is what happens when a behavior becomes so ingrained that you can perform it without having to think about it. It’s knowing the exact location of the dishes in your kitchen or which pedals to push in a car. It’s the ability to read a paragraph without having to first sound out every letter, combine letters into syllables, syllables into words, and words into phrases.
Habituation is the result of a neural process called long-term potentiation (LTP). When the same neural pathways in your brain are repeatedly activated, it triggers physical and chemical changes to neurons to make the transmission of signals along that pathway more efficient.“More efficient pathways = more efficient cognitive processing = less attention and thinking required”It feels good when we can move through environments and accomplish tasks without thinking. This is because it was (and still is) adaptive for humans to automate as many actions and decisions as possible, so we always have plenty of cognitive resources at the ready to address any spontaneous new problems that arise. Thousands of years ago that spontaneous new problem was figuring out how to keep your tribe safe from wild animals; today it’s dealing with a tricky budgeting issue at work or navigating a new route home because of construction. (If you're interested in digging deeper, there's an entire field of study dedicated to this phenomenon called behavioral economics, pioneered largely by psychologist Daniel Kahneman.)
Habituation also helps us get into a flow state (a phenomenon first described by psychologist Mihaly Csikszentmihalyi in 1988), in which we’re fully immersed in what we’re doing—to the point of losing track of time—rather than how we’re doing it. It’s in flow state that we often do our best work.Interface habituation + ML
As UXers, habituation is something we aspire to achieve in our designs, and something that the best designers seem to grasp intuitively. Great UIs facilitate habituation by providing consistent, simple ways for the user to navigate so that they can very quickly learn to perform UI actions without thinking.
For example, the original iPhone’s simple press → swipe → tap revolutionized the way users navigated UI on their smartphones by removing the complex, redundant, hierarchical menus that made habituation a challenge on some phones. Similarly, gamers can effortlessly navigate UI across multiple generations of the Playstation and Xbox consoles thanks to the consistent use of one button for “OK / Confirm” and another button for “Cancel / Back.” Moreover, the nearly identical physical position of these buttons on each system’s controller makes it easy for gamers to habituate to playing on either system.The consistent placement of buttons for “OK / Confirm” and “Back / Cancel” on Playstation and Xbox controllers help people habituate to multiple generations of a gaming system. Players can easily navigate the UI, release after release, without having to think.To see how ML features could trip up habituation, let’s contrast a “traditional” interface with a “smart” one driven by machine learning. Imagine a mobile interface that contains a set of 20 items, labeled A–T, and arranged in a grid that scrolls vertically. If the user needs item J, then the first time they use the interface they’ll examine all the items, scroll, then examine some more until they finally find and tap item J. This is four steps in total–examine, scroll, examine, tap.
After a few uses, though, the user learns the location of item J, so the “examine” steps go away. This reduces the navigation to two steps–scroll, tap. Once fully habituated, the user becomes faster at physically performing the scroll and tap gestures and can do so without thinking, which further reduces time and effort. Thanks, habituation!In a traditional interface (shown above), the user must first carefully evaluate the UI but can eventually navigate to each item without thinking—thanks to habituation.Now imagine that you want to use machine learning to personalize the UI for the user and make navigation easier. In this new interface, an algorithm first predicts which items the user is likely to want at a given moment and rearranges the interface accordingly, putting the strongest predictions at the top.
In this “smart” interface, even though the scrolling step goes away when ML has made the right prediction, the examining step never disappears. This is because the UI is essentially new to the user each time. Even if the algorithm gets smarter over time, such that the desired items frequently appear at the top, the user must still examine the UI to verify that the desired item is indeed there—instead of tapping automatically.If a machine learning algorithm re-sorts the items in a list—even if the most useful ones end up at the top—the user still has to evaluate the interface anew every time.Evaluating new information and performing a visual search are inherently effortful mental operations that can’t be automated. For habituation and automation to occur, it’s critical that the exact same pathways in the brain are activated again and again. If the UI looks different every time a user sees it, then the automation process is blocked.
The pushback I often hear to prioritizing habituation at the expense of ML is, “Yeah, but when the machine learning algorithm works perfectly it’s amazing because the thing you want is right there!” Unfortunately, machine learning algorithms will never reach perfect accuracy, because they’re prediction tools by nature. Therefore, perfect prediction shouldn’t be used as the baseline for evaluating experiences. Even if the algorithm is highly accurate, the user will still have to evaluate the UI to check the predictions. Having “evaluate” as a step in the navigation process will always prevent the user from fully habituating to the UI, and removing the magic of habituation will never make for a truly “amazing” experience.Using ML wizardry without losing the magic of habituation
It’s easy to feel like new ML technologies cause us to rethink everything about UX design, but that’s not quite true. The emergence of ML doesn’t change the fact that the most usable, delightful UIs are those that embody principles of good design—like habituation—that many designers and researchers (Don Norman, Jakob Nielsen, Steve Krug, and Jeff Johnson to name a few) have been writing about for years. To help you get started, here are four principles to consider when introducing ML features into a UI:
1. Count decisions as navigation steps
If your ML designs aim to remove navigation steps for users, but then require them to stop and evaluate all of the ML-generated suggestions, you haven’t really saved the user any steps (or time). Evaluating recommendations or visually searching the interface for content counts as a navigation step, just like a tap or click.
2. A predictable UI is necessary when the stakes are high
If the user is coming to your product to perform important, time-sensitive tasks, like quickly updating a spreadsheet before a client presentation, don’t include anything in your UI that puts habituation at risk. No ML-based suggestion will be “helpful” enough to offset breaking your user’s flow state and muscle memory. But if you’re confident that the user has a more open-ended goal like exploration, you have more leeway to put dynamic, ML-based features at the forefront of your UI.
Let’s look at an example. Google Play Music strikes a good balance between habituation-friendly UI and algorithmically-generated recommendations. A music app UI could present users with an alphabetical library of hundreds of thousands of options (arduous, yet habituate-able), but because the user’s goal is often to browse until they find something they feel like listening to, Google Play Music dedicates the vast majority of its UI to surfacing music recommendations that change based on your listening habits and factors like the time of day. There’s also a navigation sidebar that never changes, so the user can still habituate to performing basic tasks like finding a saved playlist.
3. Be predictably unpredictable
If your ML algorithm is going to make recommendations or try to personalize the interface for users, consider dedicating a specific place in the UI for this to happen, rather than building the entire UI around it.
For example, Google Drive created a feature called Quick Access, which uses machine learning to surface a few documents you're likely to need at a given moment. Rather than reordering all your content based on ML predictions, the design team created a constrained, dedicated space for Quick Access at the top of the screen. The rest of the UI remains unchanged, and you can turn the feature off if your prefer to search or navigate files without ML assistance.
4. Make failure your baseline
ML algorithms will make bad predictions. Try to imagine what a user’s process for completing the action without ML assistance would be, as well as the user’s process to correct a potential ML failure. If it’s more work for the user to correct a failure than it is for them to complete the process without having the assistance of ML in the first place, then machine learning is not actually creating a better experience.
Gmail’s Smart Reply, for example, uses machine learning to suggest short replies to your email messages. The UI makes these suggestions unobtrusive and easy to ignore if you prefer to write your own. Imagine an alternative design in which the reply is instead inserted into the message text field, forcing you to erase or edit if it's not helpful. This would be far more work than manually writing a reply without ML assistance, and it would be impossible for you to habituate to the reply-writing process.Keep it simple
People will always enjoy experiences that make something easier. Machine learning can delight users by predicting exactly what's needed at a given moment, be it a snappy reply to a colleague’s email or the seemingly serendipitous discovery of a favorite new song, but it can also disrupt habituation (arguably a delightful experience unto itself) by introducing randomness and distraction. As designers, our job is to understand the difference, knowing how to harness the “magic” of the human brain and when to task a machine with the more difficult work—ensuring that the people who use our products can effortlessly get to the things they care about.
Kristie J. Fisher, PhD, is a UX researcher at Google who’s worked on Hardware and G Suite, including ML productivity tools like the@meet bot. She’s currently working on the Ads Planning team and is based in Venice Beach, CA.
For more on how to take a human-centered approach to designing with ML and AI, visit ourfull collection.Privacy & Terms









Asilomar AI Principles - Future of Life Institute































































Skip to content

Our mission
Cause areasCause area overviewArtificial IntelligenceBiotechnologyNuclear Weapons
Our workOur work overviewPolicyFuturesOutreachGrantmakingFeatured projectsBan DeepfakesOutreachThe Elders Letter on Existential ThreatsFutures, OutreachRealising Aspirational Futures – New FLI Grants OpportunitiesFuturesStrengthening the European AI ActPolicy

Our contentArticles, Podcasts, Newsletters, Resources, and more.
About usAbout us overviewOur peopleCareersDonateFinancesFAQsContact us
Take action





Search for:



Take action




Home
»


Asilomar AI Principles 

All Open LettersAsilomar AI PrinciplesThe Asilomar AI Principles, coordinated by FLI and developed at the Beneficial AI 2017 conference, are one of the earliest and most influential sets of AI governance principles.Signatures5720Add your signaturePublishedAugust 11, 2017These principles were developed in conjunction with the 2017 Asilomar conference (videos here), through the process described here.
Click here to see this page in other languages:  Chinese    German Japanese    Korean     Russian
Artificial intelligence has already provided beneficial tools that are used every day by people around the world. Its continued development, guided by the following principles, will offer amazing opportunities to help and empower people in the decades and centuries ahead.

Research Issues
1) Research Goal: The goal of AI research should be to create not undirected intelligence, but beneficial intelligence.
2) Research Funding: Investments in AI should be accompanied by funding for research on ensuring its beneficial use, including thorny questions in computer science, economics, law, ethics, and social studies, such as:

How can we make future AI systems highly robust, so that they do what we want without malfunctioning or getting hacked?
How can we grow our prosperity through automation while maintaining people’s resources and purpose?
How can we update our legal systems to be more fair and efficient, to keep pace with AI, and to manage the risks associated with AI?
What set of values should AI be aligned with, and what legal and ethical status should it have?

3) Science-Policy Link: There should be constructive and healthy exchange between AI researchers and policy-makers.
4) Research Culture: A culture of cooperation, trust, and transparency should be fostered among researchers and developers of AI.
5) Race Avoidance: Teams developing AI systems should actively cooperate to avoid corner-cutting on safety standards.
Ethics and Values
6) Safety: AI systems should be safe and secure throughout their operational lifetime, and verifiably so where applicable and feasible.
7) Failure Transparency: If an AI system causes harm, it should be possible to ascertain why.
8) Judicial Transparency: Any involvement by an autonomous system in judicial decision-making should provide a satisfactory explanation auditable by a competent human authority.
9) Responsibility: Designers and builders of advanced AI systems are stakeholders in the moral implications of their use, misuse, and actions, with a responsibility and opportunity to shape those implications.
10) Value Alignment: Highly autonomous AI systems should be designed so that their goals and behaviors can be assured to align with human values throughout their operation.
11) Human Values: AI systems should be designed and operated so as to be compatible with ideals of human dignity, rights, freedoms, and cultural diversity.
12) Personal Privacy: People should have the right to access, manage and control the data they generate, given AI systems’ power to analyze and utilize that data.
13) Liberty and Privacy: The application of AI to personal data must not unreasonably curtail people’s real or perceived liberty.
14) Shared Benefit: AI technologies should benefit and empower as many people as possible.
15) Shared Prosperity: The economic prosperity created by AI should be shared broadly, to benefit all of humanity.
16) Human Control: Humans should choose how and whether to delegate decisions to AI systems, to accomplish human-chosen objectives.
17) Non-subversion: The power conferred by control of highly advanced AI systems should respect and improve, rather than subvert, the social and civic processes on which the health of society depends.
18) AI Arms Race: An arms race in lethal autonomous weapons should be avoided.
Longer-term Issues
19) Capability Caution: There being no consensus, we should avoid strong assumptions regarding upper limits on future AI capabilities.
20) Importance: Advanced AI could represent a profound change in the history of life on Earth, and should be planned for and managed with commensurate care and resources.
21) Risks: Risks posed by AI systems, especially catastrophic or existential risks, must be subject to planning and mitigation efforts commensurate with their expected impact.
22) Recursive Self-Improvement: AI systems designed to recursively self-improve or self-replicate in a manner that could lead to rapidly increasing quality or quantity must be subject to strict safety and control measures.
23) Common Good: Superintelligence should only be developed in the service of widely shared ethical ideals, and for the benefit of all humanity rather than one state or organization.
Add your name to the listDemonstrate your support for this open letter by adding your own signature to the list:Signature correctionsIf you believe your signature has been added in error or have other concerns about its appearance, please contact us at letters@futureoflife.org.Signatories
To date, the Principles have been signed by 1200 AI/Robotics researchers and 2342 others. Learn how these principles were developed here and join the discussion of them here. Find the full list of signatories here. The list of signatories includes:



AI/Robotics Researchers:
You need javascript enabled to view the open letter signers.


Other Endorsers:
You need javascript enabled to view the open letter signers.




Read More
 
CloseHow does verification work?Verified signatures are those which we have taken one or more extra steps to confirm as legitimate:• Direct contact - We have been in direct contact with this person to verify that they have signed the letter.• Declaration URL - This person has made a public declaration of signing the open letter which can be viewed online.All published signatures, ‘verified’ or otherwise, are subject to several forms of verification: email verification, spam and duplicate filters, and a review by a member of our data vetting team.

OPEN LETTERSRelated postsIf you enjoyed this, you also might like:Our Open LettersSignatories2672Open letter calling on world leaders to show long-view leadership on existential threatsThe Elders, Future of Life Institute and a diverse range of co-signatories call on decision-makers to urgently address the ongoing impact and escalating risks of the climate crisis, pandemics, nuclear weapons, and ungoverned AI.February 14, 2024SignatoriesClosedAI Licensing for a Better Future: On Addressing Both Present Harms and Emerging ThreatsThis joint open letter by Encode Justice and the Future of Life Institute calls for the implementation of three concrete US policies in order to address current and future harms of AI.October 25, 2023Signatories31810Pause Giant AI Experiments: An Open LetterWe call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4.March 22, 2023Signatories998Open Letter Against Reckless Nuclear Escalation and UseThe abhorrent Ukraine war has the potential to escalate into an all-out NATO-Russia nuclear conflict that would be the greatest catastrophe in human history. More must be done to prevent such escalation.October 18, 2022

Sign up for the Future of Life Institute newsletterJoin 40,000+ others receiving periodic updates on our work and cause areas.

View previous editionsSteering transformative technology towards benefitting life and away from extreme large-scale risks.Cause areasArtificial Intelligence
Biotechnology
Nuclear Weapons
Our workPolicy
Outreach
Grantmaking
Futures
Our contentArticles
Podcasts
Newsletters
Open letters
About usOur people
Careers
Donate
Finances
FAQs
Contact us
Privacy Policy
Accessibility
Report a broken link
Internal
Privacy Policy
Accessibility
Report a broken link
Internal
© 2024 Future of Life Institute. All rights reserved.Visit our FacebookVisit our TwitterVisit our LinkedInVisit our YouTube channel



check-circleangle-downcloudmagnifiercrossarrow-uparrow_backarrow_forwardbusiness_centerclosekeyboard_arrow_downmemoryattach_moneymode_editmonetization_onwifi_tetheringmaillive_helpav_timerlibrary_booksrecent_actorsaccount_balance_walletfingerprintgavellanguage








linkedin





facebook



pinterest



youtube



rss



twitter



instagram





facebook-blank



rss-blank



linkedin-blank



pinterest



youtube



twitter



instagram




























We use cookies to ensure that we give you the best experience on our website. If you continue to use this site we will assume that you are happy with it.OkayPrivacy policy















Principles of Bot Design: Successful Chatbot Design in 2021 [+Tips]




































































			Intercom Home		







					Sign up for our newsletter				


					Subscribe				





Close iconA cross icon used to close notifications

					Close Notification icon				








				Menu			





Latest Articles


Featured in Latest Articles


 

The Ticket: Fueling the AI machine with the knowledge it needs



Liam Geraghty 

				Audio Content Producer, Intercom			





Editors picks


Farewell to the customer service Frankenstack


Response Time: Vol. 24


Your first 30-60-90 days using AI for customer service


Intercom on Product: The evolution of product management in the age of AI


Response Time: Vol. 23

See all articles 




Watch and listen

Listen to our podcasts
Watch our videos




Customer Service


Featured in Customer Service


 

Farewell to the customer service Frankenstack



Anthony Lopez 

				Director of Support Operations, Intercom			





Editors picks


Your first 30-60-90 days using AI for customer service


The Ticket: How AI is transforming customer service tech stacks


Understanding the changing economics of customer service in the age of AI


What I’ve discovered implementing an AI-driven customer service strategy


Crossing the threshold: Exploring Intercom’s Customer Service Trends Report for 2024

See all articles 




Watch and listen

Listen to our podcasts
Watch our videos




AI & Automation


Featured in AI & Automation


 

Intercom on Product: Product strategy in the age of AI



Des Traynor 

				Co-founder & Chief Strategy Officer, Intercom			





Editors picks


Understanding AI: How we taught computers natural language


Five key takeaways about AI product management


Intercom on Product: Riding the AI wave in 2024


Intercom on Product: The evolution of product management in the age of AI


A new age of UX: Evolving your design approach for AI products

See all articles 




Watch and listen

Listen to our podcasts
Watch our videos




Customer Engagement


Featured in Customer Engagement


 

The father of customer journey mapping, Chip Bell, talks driving innovation through customer partnership



Liam Geraghty 

				Audio Content Producer, Intercom			





Editors picks


Becoming Fin: The story behind the name of our AI chatbot


The ultimate marketing technology stack


4 ways to personalize your marketing messaging and boost engagement


Behavioral economics expert Melina Palmer on unlocking the science of consumer behavior


Emojis mean business: The characters transforming business messaging

See all articles 




Watch and listen

Listen to our podcasts
Watch our videos




Product & Design


Featured in Product & Design


 

Intercom on Product: The evolution of product management in the age of AI



Liam Geraghty 

				Audio Content Producer, Intercom			





Editors picks


Five key takeaways about AI product management


A new age of UX: Evolving your design approach for AI products


Intercom on Product: Riding the AI wave in 2024


All that glitters is not gold: Angel investor Christoph Janz on finding the right opportunities in AI


Shopify UX Director Elizabeth McGuane on why design should start with words

See all articles 




Watch and listen

Listen to our podcasts
Watch our videos




Engineering


Featured in Engineering


 

10 engineering lessons from 6 years at Intercom



Kuba Niechciał 

				Director, Engineering, Intercom			





Editors picks


Understanding AI: How we taught computers natural language


Managing high availability at Intercom


How our infrastructure scales alongside our customers


Why Intercom is supporting the Embroider Initiative to update Ember


Intercom’s product principles: Shaping the solution to maximize customer value

See all articles 




Watch and listen

Listen to our podcasts
Watch our videos




News & Updates


Featured in News & Updates


 

Intercom’s new and improved reporting features



Gus Aldaya 

				Senior Product Marketing Manager, Intercom			





Editors picks


Our AI chatbot Fin now supports your customers in 45 languages


Announcing ‘The Ticket’ and ‘Intercom on Product’: Get the content you’re looking for


Welcoming our new President, Archana Agrawal


Announcing ‘The Intercom Customer Service Trends Report for 2024’


Fin is now in the inbox: Meet your support team’s new AI assistant

See all articles 




Watch and listen

Listen to our podcasts
Watch our videos




Podcasts




 


Customer Service
25 min watch

The Ticket: Fueling the AI machine with the knowledge it needs




 


AI & Automation
38 min watch

Intercom on Product: The evolution of product management in the age of AI




 


AI & Automation
27 min watch

The Ticket: How AI is transforming customer service tech stacks

See all podcasts 









			Search the blog		



Submit
Intercom Topbar SearchIntercom Topbar Search Icon




Explore More

Books & Guides
Meet Fin
Product Principles
Intercom on Product


Follow us




X
X icon



				Follow Us on X - This link opens in a new window			




LinkedInLinkedIn Icon

				Follow Us on Linkedin - This link opens in a new window			






				Like Us on Facebook - This link opens in a new window			




InstagramInstagram Icon

				Follow Us on Instagram - This link opens in a new window			




YouTubeYouTube Icon

				Follow Us on Youtube - This link opens in a new window			







							About Intercom						





















 


				Principles of bot design			





Emmet Connolly 

				VP Product Design, Intercom			

@thoughtwax






					Main illustration: 
									  Shawna X 

Share this article



X
X icon



					Share this page on X - this link opens in a new window				




LinkedInLinkedIn Icon

					Share this page on LinkedIn - this link opens in a new window				






					Share this page on Facebook - this link opens in a new window				





Despite plenty of excitement it’s still unclear how conversational UIs can be made to work in a practical sense.
But opinionated design principles can help us push past the hype, and design something real people will want to use every day.
We’re not lacking for self-assured sermons on how conversational UIs are the future. Much less is written about the practicalities of actually designing chatbot interactions.
Yet it seems like this is precisely what we now need. Early attempts at chatbots have fallen flat in their execution, mostly because they have relied too much on natural language processing or A.I. capabilities that simply don’t yet exist. Others have jumped on the bandwagon and tried to shoehorn unsuitable use cases into this new pattern.
In all the excitement of diving into this new technology most of us seem to have forgotten about the most important actor in this enterprise: the human being who is expected to talk to the bot.
So how do we go about designing bots? When are they useful? Should they be friendly and simple like Slackbot, or fake yet smart like Facebook M? Should they allow for free text input or create IVR-like options? These are not insurmountable questions, but the truth is we’re still exploring how to use this new medium to build great experiences.
Situations like these call for strong opinions, weakly held. When you’re tackling a domain like chatbots that are still very much in flux, it’s essential to be guided by clear design principles.
What are design principles?
All great, category-defining products are opinionated. Design principles lock these opinions in place upfront.
At their simplest, design principles are a list of strongly-held opinions that an entire team agrees on. They force clarity and reduce ambiguity, and represent a north star for everyone to aim for.
There’s an art to coming up with good design principles. They can’t be mere truisms. If they are, everyone will simply nod in agreement, but they won’t help you to make actual decisions.
For example, “We don’t make our designs too complex” is a terrible principle – nobody would realistically argue the opposite position. Truisms cannot guide your decision-making in any meaningful way.
“We favor simplicity over power”, on the other hand, is a great design principle. The opposite principle could also be argued – “We add complexity so our users can do cool things”. Opinionated principles like these will help you make consistent decisions throughout your design process.
With that in mind, let’s lay out some principles that will allow us to make progress on designing conversational interfaces.
Principles of chatbot design
1. Don’t pretend to be a human
Playing bait-and-switch with a user can make them feel that they have been duped, or that they don’t understand how a system works; both are bad user experiences. Don’t pull the rug out from under your users. This means not using “is-typing” indicators or artificial delays to make the user interface seem more human. On the contrary, conversation flows and bot messages should be styled differently and be clearly labeled in a way that communicates they are not human. This doesn’t preclude us from giving the bot personality.
2. Keep it incredibly simple
Chatbot conversations should be bounded to very particular subjects and follow linear conversation flows; we avoid complicated branching paths. We’re not trying to create a general, self-aware artificial intelligence here. It’s okay to expose and explain limitations. BASAAP. Individual bot designers shouldn’t have to account for tricky failure cases. Users will tire of complicated passages of dialogue.
3. Respect the chat medium
One advantage of smart messaging apps is that we can strip away a lot of apps and interface and reduce the interaction to a simple chatbot experience. It would therefore be pointless to turn around and drop an entire app directly into a conversation. Keep everything native to the conversational back-and-forth. Every bot interaction is about call and response, with the bot publishing comments into the chat thread and the end user responding in the reply area. Bots can’t modify conversations in ways that humans can. At the same time, make use of conventions: rather than printing out an ungainly URL in a bot response, show a nicely-formatted card previewing the linked page.
4. Optimise for the end user
Bots should be used to improve the end user experience, not just to make life easier for customer support teams. UX designers should ask themselves: would a human be better for the end user? If the answer is yes, you shouldn’t be using a bot. Bots should not attempt to replace what humans are good at; rather they should attempt to improve what humans are slow at. Machines should work; people should think.
5. Use sparingly
Bot interactions should be short and precise. It should be impossible to get into a protracted back and forth conversation with a bot; anything above two inputs feels laborious.
6. Provide an escape hatch
Always have a human fallback option, allowing the user to express “I’d rather wait and talk to a real human, make this robot thing go away”.
7. Use structured input when possible
The more alleyways a conversation can go down, the greater the potential for dead ends. Don’t place users in a situation where they need to guess the correct incantation required to proceed. Custom soft keyboards permit a limited range of input and can save a bunch of typing. For example, rather than asking the end user to type “yes” or “no,” show them two mutually exclusive buttons. Or validate structured text like email addresses before sending. In this way you can keep responses on track and sidestep the complications of parsing unpredictable plain text input.
8. Everyone sees the same thing
Bots don’t only appear to the end user. The humans behind the bots need a record of the conversation’s context too – how a bot replied and how end users responded accordingly. Common or lengthy bot messages may be displayed in a collapsed state in the admin view for the sake of neatness. Cases in which bot messages are private to an admin and are only internally visible are an exception.
Obey the principles without being bound by them
It’s important to note that these principles will almost certainly evolve, due to new technical possibilities or the simple fact that some of them were misguided. We should allow for both.
But having them in place makes things so much simpler from here. We’ve got a stake in the ground. Now we just need to apply these rules consistently and methodically. Without principles you’re just randomly firing ideas in any direction and hoping you’ll hit something that works.

If you’re as excited as we are about how chatbots can grow your business, you can get started right here.










Most Popular













 





Product & Design
6 min read






				RICE: Simple prioritization for product managers			



Prioritization is a perennial challenge when building a product roadmap. How do you decide what to work on first? If…




Sean McBride 

				Former Product Manager, Intercom			
















 





Product & Design
5 min read






				How to make product improvements to existing products			



Product improvement is the process of making meaningful product changes that result in new customers or increased benefits for existing customers.




Des Traynor 

				Co-founder & Chief Strategy Officer, Intercom			
















 





Customer Engagement
20 min read






				The complete guide to onboarding customers for long-term success			



Great onboarding is critical for every stage of a customer’s lifecycle – from first-use to activation to longer term engagement. Learn how to craft a comprehensive onboarding strategy for your business.




Phil Byrne 

				Director, Audience Engagement, Intercom			











					Sign up for our newsletter				


					Subscribe				





Close iconA cross icon used to close notifications

					Close Notification icon				





















Company

About
Customers
Careers
Press Resources
Contact Us
Terms
Privacy



Features

Automated answers
Inbox
Help Center Articles



Use Cases

Support
Engage
Convert



Follow us




X
X icon



				Follow Us on X - This link opens in a new window			




LinkedInLinkedIn Icon

				Follow Us on Linkedin - This link opens in a new window			






				Like Us on Facebook - This link opens in a new window			




InstagramInstagram Icon

				Follow Us on Instagram - This link opens in a new window			




YouTubeYouTube Icon

				Follow Us on Youtube - This link opens in a new window			






Back to top



















      Machine Learning for Designers â OâReilly     





















































Skip to main content












Sign In
Try Now




Teams

For business
For government
For higher ed


Individuals
Features

All features
Courses
Certifications
Interactive learning
Live events
Answers
Insights reporting


Blog
Content sponsorship

Close
Search













Radar / Design 
Machine Learning for Designers

This report introduces contemporary machine learning systems, but also provides a conceptual framework to help you integrate machine-learning capabilities into your user-facing designs.








                By Patrick Hebron 



              June 22, 2016            






                    Les machines de l'Ã®le (source: By Traaf on Flickr) 





This is the full ebook "Machine Learning for Designers," by Patrick Hebron. 


Introduction
Since the dawn of computing, we have dreamed of (and had nightmares about) machines that can think and speak like us. But the computers weâve interacted with over the past few decades are a far cry from HAL 9000 or Samantha from Her. Nevertheless, machine learning is in the midst of a renaissance that will transform countless industries and provide designers with a wide assortment of new tools for better engaging with and understanding users. These technologies will give rise to new design challenges and require new ways of thinking about the design of user interfaces and interactions.
To take full advantage of these systemsâ vast technical capabilities, designers will need to forge even deeper collaborative relationships with programmers. As these complex technologies make their way from research prototypes to user-facing products, programmers will also rely upon designers to discover engaging applications for these systems.







      Learn faster. Dig deeper. See farther.
    


Join the O'Reilly online learning platform. Get a free trial today and find answers on the fly, or master something new and useful.
Learn more


In the text that follows, we will explore some of the technical properties and constraints of machine learning systems as well as their implications for user-facing designs. We will look at how designers can develop interaction paradigms and a design vocabulary around these technologies and consider how designers can begin to incorporate the power of machine learning into their work.


Why Design for Machine Learning is Different

A Different Kind of Logic
In our everyday communication, we generally use what logicians call fuzzy logic. This form of logic relates to approximate rather than exact reasoning. For example, we might identify an object as being âvery small,â âslightly red,â or âpretty nearby.â These statements do not hold an exact meaning and are often context-dependent. When we say that a car is small, this implies a very different scale than when we say that a planet is small. Describing an object in these terms requires an auxiliary knowledge of the range of possible values that exists within a specific domain of meaning. If we had only seen one car ever, we would not be able to distinguish a small car from a large one. Even if we had seen a handful of cars, we could not say with great assurance that we knew the full range of possible car sizes. With sufficient experience, we could never be completely sure that we had seen the smallest and largest of all cars, but we could feel relatively certain that we had a good approximation of the range. Since the people around us will tend to have had relatively similar experiences of cars, we can meaningfully discuss them with one another in fuzzy terms.
Computers, however, have not traditionally had access to this sort of auxiliary knowledge. Instead, they have lived a life of experiential deprivation. As such, traditional computing platforms have been designed to operate on logical expressions that can be evaluated without the knowledge of any outside factor beyond those expressly provided to them. Though fuzzy logical expressions can be employed by traditional platforms through the programmerâs or userâs explicit delineation of a fuzzy term such as âvery small,â these systems have generally been designed to deal with boolean logic (also called âbinary logicâ), in which every expression must ultimately evaluate to either true or false. One rationale for this approach, as we will discuss further in the next section, is that boolean logic allows a computer programâs behavior to be defined as a finite set of concrete states, making it easier to build and test systems that will behave in a predictable manner and conform precisely to their programmerâs intentions.
Machine learning changes all this by providing mechanisms for imparting experiential knowledge upon computing systems. These technologies enable machines to deal with fuzzier and more complex or âhumanâ concepts, but also bring an assortment of design challenges related to the sometimes problematic nature of working with imprecise terminology and unpredictable behavior.


A Different Kind of Development
In traditional programming environments, developers use boolean logic to explicitly describe each of a programâs possible states and the exact conditions under which the user will be able to transition between them. This is analogous to a âchoose-your-own-adventureâ book, which contains instructions like, âif you want the prince to fight the dragon, turn to page 32.â In code, a conditional expression (also called an if-statement) is employed to move the user to a particular portion of the code if some pre defined set of conditions is met.
In pseudocode, a conditional expression might look like this:
if ( mouse button is pressed and mouse is over the 'Login'
button ),
then show the 'Welcome' screen
Since a program comprises a finite number of states and transitions, which can be explicitly enumerated and inspected, the programâs overall behavior should be predictable, repeatable, and testable. This is not to say, of course, that traditional programmatic logic cannot contain hard-to-foresee âedge-cases,â which lead to undefined or undesirable behavior under some specific set of conditions that have not been addressed by the programmer. Yet, regardless of the difficulty of identifying these problematic edge-cases in a complex piece of software, it is at least conceptually possible to methodically probe every possible path within the âchoose-your-own-adventureâ and prevent the user from accessing an undesirable state by altering or appending the programâs explicitly defined logic.
The behavior of machine learning systems, on the other hand, is not defined through this kind of explicit programming process. Instead of using an explicit set of rules to describe a programâs possible behaviors, a machine learning system looks for patterns within a set of example behaviors in order to produce an approximate representation of the rules themselves.
This process is somewhat like our own mental processes for learning about the world around us. Long before we encounter any formal description of the âlawsâ of physics, we learn to operate within them by observing the outcomes of our interactions with the physical world. A child may have no awareness of Newtonâs equations, but through repeated observation and experimentation, the child will come to recognize patterns in the relationships between the physical properties and behaviors of objects.
While this approach offers an extremely effective mechanism for learning to operate on complex systems, it does not yield a concrete or explicit set of rules governing that system. In the context of human intelligence, we often refer to this as âintuition,â or the ability to operate on complex systems without being able to formally articulate the procedure by which we achieved some desired outcome. Informed by experience, we come up with a set of approximate or provisional rules known as heuristics (or ârules of thumbâ) and operate on that basis.
In a machine learning system, these implicitly defined rules look nothing like the explicitly defined logical expressions of a traditional programming language. Instead, they are comprised of distributed representations that implicitly describe the probabilistic connections between the set of interrelated components of a complex system.
Machine learning often requires a very large number of examples to produce a strong intuition for the behaviors of a complex system.
In a sense, this requirement is related to the problem of edge-cases, which present a different set of challenges in the context of machine learning. Just as it is hard to imagine every possible outcome of a set of rules, it is, conversely, difficult to extrapolate every possible rule from a set of example outcomes. To extrapolate a good approximation of the rules, the learner must observe many variations of their application. The learner must be exposed to the more extreme or unlikely behaviors of a system as well as the most likely ones. Or, as the educational philosopher Patricia Carini said, âTo let meaning occur requires time and the possibility for the rich and varied relationships among things to become evident.â1
While intuitive learners may be slower at rote procedural tasks such as those performed by a calculator, they are able to perform much more complex tasks that do not lend themselves to exact procedures. Nevertheless, even with an immense amount of training, these intuitive approaches sometimes fail us. We may, for instance, find ourselves mistakenly identifying a human face in a cloud or a grilled cheese sandwich.


A Different Kind of Precision
A key principle in the design of conventional programming languages is that each feature should work in a predictable, repeatable manner provided that the feature is being used correctly by the programmer. No matter how many times we perform an arithmetic operation such as â2 + 2,â we should always get the same answer. If this is ever untrue, then a bug exists in the language or tool we are using. Though it is not inconceivable for a programming language to contain a bug, it is relatively rare and would almost never pertain to an operation as commonly used as an arithmetic operator. To be extra certain that conventional code will operate as expected, most large-scale codebases ship with a set of formal âunit testsâ that can be run on the userâs machine at installation time to ensure that the functionality of the system is fully in line with the developerâs expectations.
So, putting rare bugs aside, conventional programming languages can be thought of as systems that are always correct about mundane things like concrete mathematical operations. Machine learning algorithms, on the other hand, can be thought of as systems that are often correct about more complicated things like identifying human faces in an image. Since a machine learning system is designed to probabilistically approximate a set of demonstrated behaviors, its very nature generally precludes it from behaving in an entirely predictable and reproducible manner, even if it has been properly trained on an extremely large number of examples. This is not to say, of course, that a well-trained machine learning systemâs behavior must inherently be erratic to a detrimental degree. Rather, it should be understood and considered within the design of machine-learning-enhanced systems that their capacity for dealing with extraordinarily complex concepts and patterns also comes with a certain degree of imprecision and unpredictability beyond what can be expected from traditional computing platforms.
Later in the text, we will take a closer look at some design strategies for dealing with imprecision and unpredictable behaviors in machine learning systems.


A Different Kind of Problem
Machine learning can perform complex tasks that cannot be addressed by conventional computing platforms. However, the process of training and utilizing machine learning systems often comes with substantially greater overhead than the process of developing conventional systems. So while machine learning systems can be taught to perform simple tasks such as arithmetic operations, as a general rule of thumb, you should only take a machine learning approach to a given problem if no viable conventional approach exists.
Even for tasks that are well-suited to a machine learning solution, there are numerous considerations about which learning mechanisms to use and how to curate the training data so that it can be most comprehensible to the learning system.
In the sections that follow, we will look more closely at how to identify problems that are well-suited for machine learning solutions as well as the numerous factors that go into applying learning algorithms to specific problems. But for the time being, we should understand machine learning to be useful in solving problems that can be encapsulated by a set of examples, but not easily described in formal terms.



What Is Machine Learning?

The Mental Process of Recognizing Objects
Think about your own mental process of recognizing a human face. Itâs such an innate, automatic behavior, it is difficult to think about in concrete terms. But this difficulty is not only a product of the fact that you have performed the task so many times. There are many other often-repeated procedures that we could express concretely, like how to brush your teeth or scramble an egg. Rather, it is nearly impossible to describe the process of recognizing a face because it involves the balancing of an extremely large and complex set of interrelated factors, and therefore defies any concrete description as a sequence of steps or set of rules.
To begin with, there is a great deal of variation in the facial features of people of different ethnicities, ages, and genders. Furthermore, every individual person can be viewed from an infinite number of vantage points in countless lighting scenarios and surrounding environments. In assessing whether the object we are looking at is a human face, we must consider each of these properties in relation to each other. As we change vantage points around the face, the proportion and relative placement of the nose changes in relation to the eyes. As the face moves closer to or further from other objects and light sources, its coloring and regions of contrast change too.
There are infinite combinations of properties that would yield the valid identification of a human face and an equally great number of combinations that would not. The set of rules separating these two groups is just too complex to describe through conditional logic. We are able to identify a face almost automatically because our great wealth of experience in observing and interacting with the visible world has allowed us to build up a set of heuristics that can be used to quickly, intuitively, and somewhat imprecisely gauge whether a particular expression of properties is in the correct balance to form a human face.


Learning by Example
In logic, there are two main approaches to reasoning about how a set of specific observations and a set of general rules relate to one another. In deductive reasoning, we start with a broad theory about the rules governing a system, distill this theory into more specific hypotheses, gather specific observations and test them against our hypotheses in order to confirm whether the original theory was correct. In inductive reasoning, we start with a group of specific observations, look for patterns in those observations, formulate tentative hypotheses, and ultimately try to produce a general theory that encompasses our original observations. See Figure 1-1 for an illustration of the differences between these two forms of reasoning.

Figure 1-1. Deductive reasoning versus inductive reasoning
Each of these approaches plays an important role in scientific inquiry. In some cases, we have a general sense of the principles that govern a system, but need to confirm that our beliefs hold true across many specific instances. In other cases, we have made a set of observations and wish to develop a general theory that explains them.
To a large extent, machine learning systems can be seen as tools that assist or automate inductive reasoning processes. In a simple system that is governed by a small number of rules, it is often quite easy to produce a general theory from a handful of specific examples. Consider Figure 1-2 as an example of such a system.2

Figure 1-2. A simple system
In this system, you should have no trouble uncovering the singular rule that governs inclusion: open figures are included and closed figures are excluded. Once discovered, you can easily apply this rule to the uncategorized figures in the bottom row.
In Figure 1-3, you may have to look a bit harder.

Figure 1-3. A more complex system
Here, there seem to be more variables involved. You may have considered the shape and shading of each figure before discovering that in fact this system is also governed by a single attribute: the figureâs height. If it took you a moment to discover the rule, it is likely because you spent time considering attributes that seemed like they would be pertinent to the determination but were ultimately not. This kind of ânoiseâ exists in many systems, making it more difficult to isolate the meaningful attributes.
Letâs now consider Figure 1-4.

Figure 1-4. An even more complex system
In this diagram, the rules have in fact gotten a bit more complicated. Here, shaded triangles and unshaded quadrilaterals are included and all other figures are excluded. This rule system is harder to uncover because it involves an interdependency between two attributes of the figures. Neither the shape nor the shading alone determines inclusion. A triangleâs inclusion depends upon its shading and a shaded figureâs inclusion depends upon its shape. In machine learning, this is called a linearly inseparable problem because it is not possible to separate the included and excluded figures using a single âlineâ or determining attribute. Linearly inseparable problems are more difficult for machine learning systems to solve, and it took several decades of research to discover robust techniques for handling them. See Figure 1-5.

Figure 1-5. Linearly separable versus linearly inseparable problems
In general, the difficulty of an inductive reasoning problem relates to the number of relevant and irrelevant attributes involved as well as the subtlety and interdependency of the relevant attributes. Many real-world problems, like recognizing a human face, involve an immense number of interrelated attributes and a great deal of noise. For the vast majority of human history, this kind of problem has been beyond the reach of mechanical automation. The advent of machine learning and the ability to automate the synthesis of general knowledge about complex systems from specific information has deeply significant and far-reaching implications. For designers, it means being able to understand users more holistically through their interactions with the interfaces and experiences we build. This understanding will allow us to better anticipate and meet usersâ needs, elevate their capabilities and extend their reach.


Mechanical Induction
To get a better sense of how machine learning algorithms actually perform induction, letâs consider Figure 1-6.

Figure 1-6. A system equivalent to the boolean logical expression, “AND”
This system is equivalent to the boolean logical expression, âAND.â That is, only figures that are both shaded and closed are included. Before we turn our attention to induction, letâs first consider how we would implement this logic in an electrical system from a deductive point of view. In other words, if we already knew the rule governing this system, how could we implement an electrical device that determines whether a particular figure should be included or excluded? See Figure 1-7.

Figure 1-7. The boolean logical expression AND represented as an electrical circuit
In this diagram, we have a wire leading from each input attribute to a âdecision node.â If a given figure is shaded, then an electrical signal will be sent through the wire leading from Input A. If the figure is closed, then an electrical signal will be sent through the wire leading from Input B. The decision node will output an electrical signal indicating that the figure is included if the sum of its input signals is greater than or equal to 1 volt.
To implement the behavior of an AND gate, we need to set the voltage associated with each of the two input signals. Since the output threshold is 1 volt and we only want the output to be triggered if both inputs are active, we can set the voltage associated with each input to 0.5 volts. In this configuration, if only one or neither input is active, the output threshold will not be reached. With these signal voltages now set, we have implemented the mechanics of the general rule governing the system and can use this electronic device to deduce the correct output for any example input.
Now, let us consider the same problem from an inductive point of view. In this case, we have a set of example inputs and outputs that exemplify a rule but do not know what the rule is. We wish to determine the nature of the rule using these examples.
Letâs again assume that the decision nodeâs output threshold is 1 volt. To reproduce the behavior of the AND gate by induction, we need to find voltage levels for the input signals that will produce the expected output for each pair of example inputs, telling us whether those inputs are included in the rule. The process of discovering the right combination of voltages can be seen as a kind of search problem.
One approach we might take is to choose random voltages for the input signals, use these to predict the output of each example, and compare these predictions to the given outputs. If the predictions match the correct outputs, then we have found good voltage levels. If not, we could choose new random voltages and start the process over. This process could then be repeated until the voltages of each input were weighted so that the system could consistently predict whether each input pair fits the rule.
In a simple system like this one, a guess-and-check approach may allow us to arrive at suitable voltages within a reasonable amount of time. But for a system that involves many more attributes, the number of possible combinations of signal voltages would be immense and we would be unlikely to guess suitable values efficiently. With each additional attribute, we would need to search for a needle in an increasingly large haystack.
Rather than guessing randomly and starting over when the results are not suitable, we could instead take an iterative approach. We could start with random values and check the output predictions they yield. But rather than starting over if the results are inaccurate, we could instead look at the extent and direction of that inaccuracy and try to incrementally adjust the voltages to produce more accurate results. The process outlined above is a simplified description of the learning procedure used by one of the earliest machine learning systems, called a Perceptron (Figure 1-8), which was invented by Frank Rosenblatt in 1957.3

Figure 1-8. The architecture of a Perceptron
Once the Perceptron has completed the inductive learning process, we have a network of voltage levels which implicitly describe the rule system. We call this a distributed representation. It can produce the correct outputs, but it is hard to look at a distributed representation and understand the rules explicitly. Like in our own neural networks, the rules are represented implicitly or impressionistically. Nonetheless, they serve the desired purpose.
Though Perceptrons are capable of performing inductive learning on simple systems, they are not capable of solving linearly inseparable problems. To solve this kind of problem, we need to account for interdependent relationships between attributes. In a sense, we can think of an interdependency as being a kind of attribute in itself. Yet, in complex data, it is often very difficult to spot interdependencies simply by looking at the data. Therefore, we need some way of allowing the learning system to discover and account for these interdependencies on its own. This can be done by adding one or more layers of nodes between the inputs and outputs. The express purpose of these âhiddenâ nodes is to characterize the interdependencies that may be concealed within the relationships between the dataâs concrete (or âvisibleâ) attributes. The addition of these hidden nodes makes the inductive learning process significantly more complex.
The backpropagation algorithm, which was developed in the late 1960s but not fully utilized until a 1986 paper by David Rumelhart et al.,4 can perform inductive learning for linearly inseparable problems. Readers interested in learning more about these ideas should refer to the section Going Further.


Common Analogies for Machine Learning

Biological systems
When Leonardo da Vinci set out to design a flying machine, he naturally looked for inspiration in the only flying machines of his time: winged animals. He studied the stabilizing feathers of birds, observed how changes in wing shape could be used for steering, and produced numerous sketches for machines powered by human âwing flapping.â
Ultimately, it has proven more practical to design flying machines around the mechanism of a spinning turbine than to directly imitate the flapping wing motion of birds. Nevertheless, from da Vinci onward, human designers have pulled many key principles and mechanisms for flight from their observations of biological systems. Nature, after all, had a head start in working on the problem and we would be foolish to ignore its findings.
Similarly, since the only examples of intelligence we have had access to are the living things of this planet, it should come as no surprise that machine learning researchers have looked to biological systems for both the guiding principles and specific design mechanisms of learning and intelligence.
In a famous 1950 paper, âComputing Machinery and Intelligence,â5 the computer science luminary Alan Turing pondered the question of whether machines could be made to think. Realizing that “thought” was a difficult notion to define, Turing proposed what he believed to be a closely related and unambiguous way of reframing the question: “Are there imaginable digital computers which would do well in the imitation game?â In the proposed game, which is now generally referred to as a Turing Test, a human interrogator poses written questions to a human and a machine. If the interrogator is unable to determine which party is human based on the responses to these questions, then it may be reasoned that the machine is intelligent. In the framing of this approach, it is clear that a systemâs similarity to a biologically produced intelligence has been a central metric in evaluating machine intelligence since the inception of the field.
In the early history of the field, numerous attempts were made at developing analog and digital systems that simulated the workings of the human brain. One such analog device was the Homeostat, developed by William Ross Ashby in 1948, which used an electro-mechanical process to detect and compensate for changes in a physical space in order to create stable environmental conditions. In 1959, Herbert Simon, J.C. Shaw, and Allen Newell developed a digital system called the General Problem Solver, which could automatically produce mathematical proofs to formal logic problems. This system was capable of solving simple test problems such as the Tower of Hanoi puzzle, but did not scale well because its search-based approach required the storage of an intractable number of combinations in solving more complex problems.
As the field has matured, one major category of machine learning algorithms in particular has focused on imitating biological learning systems: the appropriately named Artificial Neural Networks (ANNs). These machines, which include Perceptrons as well as the deep learning systems discussed later in this text, are modeled after but implemented differently from biological systems. See Figure 1-9.

Figure 1-9. The simulated neurons of an ANN
Instead of the electrochemical processes performed by biological neurons, ANNs employ traditional computer circuitry and code to produce simplified mathematical models of neural architecture and activity. ANNs have a long way to go in approaching the advanced and generalized intelligence of humans. Like the relationship between birds and airplanes, we may continue to find practical reasons for deviating from the specific mechanisms of biological systems. Still, ANNs have borrowed a great many ideas from their biological counterparts and will continue to do so as the fields of neuroscience and machine learning evolve.


Thermodynamic systems
One indirect outcome of machine learning is that the effort to produce practical learning machines has also led to deeper philosophical understandings of what learning and intelligence really are as phenomena in nature. In science fiction, we tend to assume that all advanced intelligences would be something like ourselves, since we have no dramatically different examples of intelligence to draw upon.
For this reason, it might be surprising to learn that one of the primary inspirations for the mathematical models used in machine learning comes from the field of Thermodynamics, a branch of physics concerned with heat and energy transfer. Though we would certainly call the behaviors of thermal systems complex, we have not generally thought of these systems as holding a strong relation to the fundamental principles of intelligence and life.
From our earlier discussion of inductive reasoning, we may see that learning has a great deal to do with the gradual or iterative process of finding a balance between many interrelated factors. The conceptual relationship between this process and the tendency of thermal systems to seek equilibrium has allowed machine learning researchers to adopt some of the ideas and equations established within thermodynamics to their efforts to model the characteristics of learning.
Of course, what we choose to call “intelligence” or “life” is a matter of language more than anything else. Nevertheless, it is interesting to see these phenomena in a broader context and understand that nature has a way of reusing certain principles across many disparate applications.


Electrical systems
By the start of the twentieth century, scientists had begun to understand that the brainâs ability to store memories and trigger actions in the body was produced by the transmission of electrical signals between neurons. By mid-century, several preliminary models for simulating the electrical behaviors of an individual neuron had been developed, including the Perceptron. As we saw in the Biological systems section, these models have some important similarities to the logic gates that comprise the basic building blocks of electronic systems. In its most basic conception, an individual neuron collects electrical signals from the other neurons that lead into it and forwards the electrical signal to its connected output neurons when a sufficient number of its inputs have been electrically activated.
These early discoveries contributed to a dramatic overestimation of the ease with which we would be able to produce a true artificial intelligence. As the fields of neuroscience and machine learning have progressed, we have come to see that understanding the electrical behaviors and underlying mathematical properties of an individual neuron elucidates only a tiny aspect of the overall workings of a brain. In describing the mechanics of a simple learning machine somewhat like a Perceptron, Alan Turing remarked, âThe behavior of a machine with so few units is naturally very trivial. However, machines of this character can behave in a very complicated manner when the number of units is large.â6
Despite some similarities in their basic building blocks, neural networks and conventional electronic systems use very different sets of principles in combining their basic building blocks to produce more complex behaviors. An electronic component helps to route electrical signals through explicit logical decision paths in much the same manner as conventional computer programs. Individual neurons, on the other hand, are used to store small pieces of the distributed representations of inductively approximated rule systems.
So, while there is in one sense a very real connection between neural networks and electrical systems, we should be careful not to think of brains or machine learning systems as mere extensions of the kinds of systems studied within the field of electrical engineering.



Ways of Learning
In machine learning, the terms supervised, unsupervised, semi-supervised, and reinforcement learning are used to describe some of the key differences in how various models and algorithms learn and what they learn about. There are many additional terms used within the field of machine learning to describe other important distinctions, but these four categories provide a basic vocabulary for discussing the main types of machine learning systems:
Supervised learning procedures are used in problems for which we can provide the system with example inputs as well as their corresponding outputs and wish to induce an implicit approximation of the rules or function that governs these correlations. Procedures of this kind are âsupervisedâ in the sense that we explicitly indicate what correlations should be found and only ask the machine how to substantiate these correlations. Once trained, a supervised learning system should be able to predict the correct output for an input example that is similar in nature to the training examples, but not explicitly contained within it. The kinds of problems that can be addressed by supervised learning procedures are generally divided into two categories: classification and regression problems. In a classification problem, the outputs relate to a set of discrete categories. For example, we may have an image of a handwritten character and wish to determine which of 26 possible letters it represents. In a regression problem, the outputs relate to a real-valued number. For example, based on a set of financial metrics and past performance data, we may try to guess the future price of a particular stock.
Unsupervised learning procedures do not require a set of known outputs. Instead, the machine is tasked with finding internal patterns within the training examples. Procedures of this kind are âunsupervisedâ in the sense that we do not explicitly indicate what the system should learn about. Instead, we provide a set of training examples that we believe contains internal patterns and leave it to the system to discover those patterns on its own. In general, unsupervised learning can provide assistance in our efforts to understand extremely complex systems whose internal patterns may be too complex for humans to discover on their own. Unsupervised learning can also be used to produce generative models, which can, for example, learn the stylistic patterns in a particular composerâs work and then generate new compositions in that style. Unsupervised learning has been a subject of increasing excitement and plays a key role in the deep learning renaissance, which is described in greater detail below. One of the main causes of this excitement has been the realization that unsupervised learning can be used to dramatically improve the quality of supervised learning processes, as discussed immediately below.
Semi-supervised learning procedures use the automatic feature discovery capabilities of unsupervised learning systems to improve the quality of predictions in a supervised learning problem. Instead of trying to correlate raw input data with the known outputs, the raw inputs are first interpreted by an unsupervised system. The unsupervised system tries to discover internal patterns within the raw input data, removing some of the noise and helping to bring forward the most important or indicative features of the data. These distilled versions of the data are then handed over to a supervised learning model, which correlates the distilled inputs with their corresponding outputs in order to produce a predictive model whose accuracy is generally far greater than that of a purely supervised learning system. This approach can be particularly useful in cases where only a small portion of the available training examples have been associated with a known output. One such example is the task of correlating photographic images with the names of the objects they depict. An immense number of photographic images can be found on the Web, but only a small percentage of them come with reliable linguistic associations. Semi-supervised learning allows the system to discover internal patterns within the full set of images and associate these patterns with the descriptive labels that were provided for a limited number of examples. This approach bears some resemblance to our own learning process in the sense that we have many experiences interacting with a particular kind of object, but a much smaller number of experiences in which another person explicitly tells us the name of that object.
Reinforcement learning procedures use rewards and punishments to shape the behavior of a system with respect to one or several specific goals. Unlike supervised and unsupervised learning systems, reinforcement learning systems are not generally trained on an existent dataset and instead learn primarily from the feedback they gather through performing actions and observing the consequences. In systems of this kind, the machine is tasked with discovering behaviors that result in the greatest reward, an approach which is particularly applicable to robotics and tasks like learning to play a board game in which it is possible to explicitly define the characteristics of a successful action but not how and when to perform those actions in all possible scenarios.


What Is Deep Learning?
From Alan Turingâs writings onwards, the history of machine learning has been marked by alternating periods of optimism and discouragement over the fieldâs prospects for applying its conceptual advancements to practical systems and, in particular, to the construction of a general-purpose artificial intelligence. These periods of discouragement, which are often called AI winters, have generally stemmed from the realization that a particular conceptual model could not be easily scaled from simple test problems to more complex learning tasks. This occurred in the 1960s when Marvin Minsky and Seymour Papert conclusively demonstrated that perceptrons could not solve linearly inseparable problems. In the late 1980s, there was some initial excitement over the backpropagation algorithmâs ability to overcome this issue. But another AI winter occurred when it became clear that the algorithmâs theoretical capabilities were practically constrained by computationally intensive training processes and the limited hardware of the time.
Over the last decade, a series of technical advances in the architecture and training procedures associated with artificial neural networks, along with rapid progress in computing hardware, have contributed to a renewed optimism for the prospects of machine learning. One of the central ideas driving these advances is the realization that complex patterns can be understood as hierarchical phenomena in which simple patterns are used to form the building blocks for the description of more complex ones, which can in turn be used to describe even more complex ones. The systems that have arisen from this research are referred to as âdeepâ because they generally involve multiple layers of learning systems which are tasked with discovering increasingly abstract or âhigh-levelâ patterns. This approach is often referred to as hierarchical feature learning.
As we saw in our earlier discussion of the process of recognizing a human face, learning about a complex idea from raw data is challenging because of the immense variability and noise that may exist within the data samples representing a particular concept or object.
Rather than trying to correlate raw pixel information with the notion of a human face, we can break the problem down into several successive stages of conceptual abstraction (see Figure 1-10). In the first layer, we might try to discover simple patterns in the relationships between individual pixels. These patterns would describe basic geometric components such as lines. In the next layer, these basic patterns could be used to represent the underlying components of more complex geometric features such as surfaces, which could be used by yet another layer to describe the complex set of shapes that compose an object like a human face.

Figure 1-10. Hierarchical feature layers of an image recognition convolutional neural network (image courtesy of Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson, “Understanding neural networks through deep visualization,” presented at the Deep Learning Workshop, International Conference on Machine Learning (ICML), 2015)
As it turns out, the backpropagation algorithm and other earlier machine learning models are capable of achieving results comparable to those associated with more recent deep learning models, given sufficient training time and hardware resources. It should also be noted that many of the ideas driving the practical advances of deep learning have been mined from various components of earlier models. In many ways, the recent successes of deep learning have less to do with the discovery of radically new techniques than with a series of subtle yet important shifts in our understanding of various component ideas and how to combine them. Nevertheless, a well-timed shift in perspective, coupled with diminishing technical constraints, can make a world of difference in exposing a series of opportunities that may have been previously conceivable but were not practically achievable.
As a result of these changes, engineers and designers are poised to approach ever more complex problems through machine learning. They will be able to produce more accurate results and iterate upon machine-learning-enhanced systems more quickly. The improved performance of these systems will also enable designers to include machine learning functionality that would have once required the resources of a supercomputer in mobile and embedded devices, opening a wide range of new applications that will greatly impact users.
As these technologies continue to progress over the next few years, we will continue to see radical transformations in an astounding number of theoretical and real-world applications from art and design to medicine, business, and government.



Enhancing Design with Machine Learning

Parsing Complex Information
Computers have long offered peripheral input devices like microphones and cameras, but despite their ability to transmit and store the data produced by these devices, they have not been able to understand it. Machine learning enables the parsing of complex information from a wide assortment of sources that were once completely indecipherable to machines.
The ability to recognize spoken language, facial expressions, and the objects in a photograph enables designers to transcend the expressive limitations of traditional input devices such as the keyboard and mouse, opening an entirely new set of interaction paradigms that will allow users to communicate ideas in ever more natural and intuitive ways.
In the sections that follow, we will look more closely at some of these opportunities. But before doing so, it should be noted that some of the possibilities we will explore currently require special hardware or intensive computing resources that may not be practical or accessible in all design contexts at this time. For example, the Microsoft Kinect, which allows depth sensing and body tracking, is not easily paired with a web-based experience. The quickly evolving landscape of consumer electronics will progressively deliver these capabilities to an ever wider spectrum of devices and platforms. Nevertheless, designers must take these practical constraints into consideration as they plan the features of their systems.


Enabling Multimodal User Input
In our everyday interactions with other people, we use hand gestures and facial expressions, point to objects and draw simple diagrams. These auxiliary mechanisms allow us to clarify the meaning of ideas that do not easily lend themselves to verbal language. They provide subtle cues, enriching our descriptions and conveying further implications of meaning like sarcasm and tone. As Nicholas Negroponte said in The Architecture Machine, âit is gestures, smiles, and frowns that turn a conversation into a dialogue.â7
In our communications with computers, we have been limited to the mouse, keyboard, and a much smaller set of linguistic expressions. Machine learning enables significantly deeper forms of linguistic communication with computers, but there are still many ideas that would be best expressed through other meansâvisual, auditory, or otherwise. As machine learning continues to make a wider variety of media understandable to the computer, designers should begin to employ âmultimodalâ forms of human-computer interaction, allowing users to convey ideas through the optimal means of communication for a given task. As the saying goes, âa picture is worth a thousand wordsââat least when the idea is an inherently visual one.
For example, letâs say the user needed a particular kind of screwdriver but didnât know the term âPhillips head.â Previously, he might have tried Googling a variety of search terms or scouring through multiple Amazon listings. With multimodal input, the user could instead tell the computer, âIâm looking for a screwdriver that can turn this kind of screwâ and then upload a photograph or draw a sketch of it. The computer would then be able to infer which tool was needed and point the user to possible places to purchase it.
By conducting each exchange in the most appropriate modality, communication is made more efficient and precise. Interactions between user and machine become deeper and more varied, making the experience of working with a computer less monotonous and therefore more enjoyable. Complexity and nuance are preserved where they might otherwise have been lost to a translation between media.
This heightened expressivity, made possible by machine learningâs ability to extract meaning from complex and varied sources, will dramatically alter the nature of human&8#211;computer interactions and require designers to rethink some of the longstanding principles of user interface and user experience design.


New Modes of Input

Visual Inputs
The visible world is full of nuanced information that is not easily conveyed through other means. For this reason, extracting information from images has been one of the primary applied goals throughout the history of machine learning. One of the earliest applications in this domain is optical character recognitionâthe task of decoding textual information, either handwritten or printed, from photographic sources (see Figure 1-11). This technology is used in a wide range of real-world applications from the postal serviceâs need to quickly decipher address labels to Googleâs effort to digitize and make searchable the worldâs books and newspapers. The pursuit of optical character recognition systems has helped to drive machine learning research in general and has remained as one of the key test problems for assessing the performance of newly invented machine learning algorithms.

Figure 1-11. Handwritten â8â digits from the MNIST database
More recently, researchers have turned their attention to more complex visual learning tasks, many of which center around the problem of identifying objects in images. The goals of these systems range in both purpose and complexity. On the simpler end of the spectrum, object recognition systems are used to determine whether a particular image contains an object of a specific category such as a human face, cat, or tree. These technologies extend to more specific and advanced functionality, such as the identification of a particular human face within an image. This functionality is used in photo-sharing applications as well as security systems used by governments to identify known criminals.
Going further, image tagging and image description systems are used to generate keywords or a sentence that describes the contents of an image (see Figure 1-12). These technologies can be used to aid image-based search processes as well as assist visually impaired users to extract information from sources that would be otherwise inaccessible to them. Further still, image segmentation systems are used to associate each pixel of a given image with the category of object represented by that region of the image. In an image of suburban home, for instance, all of the pixels associated with the patio floor would be painted one color while the grass, outdoor furniture and trees depicted in the image would each be painted with their own unique colors, creating a kind of pixel-by-pixel annotation of the imageâs contents.

Figure 1-12. Example outputs from a neural network trained to produce image descriptions (image courtesy of Karpathy, Andrej, and Li Fei-Fei, “Deep visual-semantic alignments for generating image descriptions,” proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015)
Other applications of machine learning to visual tasks include depth estimation and three-dimensional object extraction. These technologies are applicable to tasks in robotics and the development of self-driving cars as well as the automated conversion of conventional two-dimensional movies into stereoscopic ones.
The range of visual applications for machine learning is too vast to enumerate fully here. In general, though, a great deal of machine learning research and applied work has and will continue to be directed to the numerous component goals of turning once impenetrable pixel grids into high-level information that can be acted upon by machines and used to aid users in a wide assortment of complex tasks.


Aural Inputs
Like visual information, auditory information is highly complex and used to convey a wide range of content ranging from human speech to music to bird calls, which are not easily transmitted through other media. The ability for machines to understand spoken language has immense implications for the development of more natural interaction paradigms. However, the diverse vocal characteristics and speech patterns of different speakers makes this task difficult for machines and even, at times, human listeners. Though a highly reliable speech-to-text system can greatly benefit humanâcomputer interactions, even a slightly less reliable system can result in great frustration and lost productivity for the user. Like visual learning systems, immense progress in the complex task of speech recognition has been made in recent years, primarily as a result of breakthroughs in deep learning research. For most applications, these technologies have now matured to the point where their utility generally outweighs any residual imprecision in their capabilities.
Aside from speech recognition, the ability to recognize a piece of music aurally has been another popular area of focus for machine learning research. The Shazam app allows users to identify songs by allowing the software to capture a short snippet of the audio. This system, however, can only identify a song from its original recording rather than allowing users to sing or hum a melody they wish to identify. The SoundHound app offers this functionality, though it is generally less reliable than Shazamâs functionality. This is understandable because Shazam can utilize subtle patterns in the recorded audio information to produce accurate recognition results, whereas SoundHoundâs functionality must attempt to account for the potentially highly imprecise or out-of-tune approximation of the recording by the userâs own voice. Both systems, however, provide users with capabilities that would hard to supplant through other means – most readers will be able to recall a time in which they hummed a melody to friends, hoping someone might be able to identify the song. The underlying technologies used by these systems can also be directed towards other audio recognition tasks such as the identification of a bird from its call or the identification of a malfunctioning mechanical system from the noise it makes.


Corporeal Inputs
Body language can convey subtle information about a userâs emotional state, augment or clarify the tone of a verbal expression, or be used to specify what object is being discussed through the act of pointing. Machine learning systems, in conjunction with a range of new hardware devices, have enabled designers to provide users with mechanisms for communicating with machines through the endlessly expressive capabilities of the human body. See Figure 1-13.

Figure 1-13. Skeleton tracking data produced by the Microsoft Kinect 2 for Windows
Devices such as the Microsoft Kinect and Leap Motion use machine learning to extract information about the location of a userâs body from photographic data produced by specialized hardware. The Kinect 2 for Windows allows designers to extract 20 3-dimensional joint positions through its full-body skeleton tracking feature and more than a thousand 3-dimensional points of information through its high-definition face tracking feature. The Leap Motion device provides high-resolution positioning information related to the userâs hands.
These forms of input data can be coupled with machine-learning-based gesture or facial expression recognition systems, allowing users to control software interfaces with the more expressive features of their bodies and enabling designers to extract information about the userâs mood.
To some extent, similar functionality can be produced using lower-cost and more widely available camera hardware. For the time being, these specialized hardware systems help to make up for the limited precision of their underlying machine learning systems. However, as the capabilities of these machine learning tools quickly advance, the need for specialized hardware in addressing these forms of corporeal input will be diminished or rendered unnecessary.
In addition to these input devices, health tracking devices like Fitbit and Apple Watch can also provide designers with important information about the user and her physical state. From detecting elevated stress levels to anticipating a possible cardiac event, these forms of user input will prove invaluable in better serving users and even saving lives.


Environmental Inputs
Environmental sensors and Internet-connected objects can provide designers with a great deal of information about usersâ surroundings, and therefore about the users themselves. The Nest Learning Thermostat (Figure 1-14), for instance, tracks patterns in homeownersâ behaviors to determine when they are at home as well as their desired temperature settings at different times of day and during different seasons. These patterns are used to automatically tune the thermostatâs settings to meet user needs and make climate control systems more efficient and cost-effective.

Figure 1-14. Nest Learning Thermostat
As Internet-of-Things devices become more prevalent, these input devices will provide designers with new opportunities to assist users in a wide assortment of tasks from knowing when they are out of milk to when their basement has flooded.


Abstract Inputs
In addition to physical forms of input, machine learning allows designers to discover implicit patterns within numerous facets of a userâs behavior. These patterns carry inherent meanings, which can be learned from and acted upon, even if the user is not expressly aware of having communicated them. In this sense, these implicit patterns can be thought of as input modalities that, in practice, serve a very similar purpose to the more tangible input modes described above.
Mining behavioral patterns through machine learning can help designers to better understand users and serve their needs. At the same time, these patterns can also help designers to understand the products or services they offer as well as the implicit relationships between these offerings. Behavioral patterns can be mined in relation to an individual user or aggregated from the collective behaviors of numerous users.
One form of pattern mining that can be useful in serving an individual user as well as improving the overall system is the discovery of frequently coupled behaviors within the sequence of actions performed by the user. For example, a user may purchase milk whenever he buys breakfast cereal. Noticing this pattern gives designers the opportunity to construct interface mechanisms that will allow the user to address his shopping needs more easily and efficiently. When the user adds cereal to the shopping cart, a modal interface suggesting the purchase of milk could be presented to him. Alternately, these two items could be shown in proximity to one another within the interface, despite the fact that these two products would generally be situated within two different areas of the store. Rather than presenting the user with separate interfaces for each item, the system could instead dynamically generate a single interface element that would allow the user to purchase these frequently coupled items with one click. In addition to benefiting the userâs shopping experience and enabling multiuser recommendation engines, the systemâs knowledge of these correlated behaviors can be used to make the system itself more efficient, aiding business processes like inventory estimation.
Mining user behavior patterns can also help businesses to better understand who their customers are. If a user frequently purchases diapers, for instance, it is a near certainty that the user is a parent. This kind of auxiliary knowledge of the user can help designers to produce interfaces that better address their target customer demographics and influence business and marketing decisions such as the determination of which advertising venues will yield the greatest influx of new customers. Designers should be careful, however, to not make assumptions about users that may embarrass or offend them by characterizing them in ways that conflict with the public persona they wish to convey.
In one famous incident, the retailer Target used purchasing patterns to determine whether a given user was pregnant so that the store could better target this much sought-after category of customer.8 Though this practice may be welcomed by some, in at least one case it created an uncomfortable situation when an angry father came to a Target store demanding to know why his high-school-aged daughter had received numerous coupons targeted at expectant mothers. The man had not been aware that his daughter was pregnant and upon learning the truth from his daughter, apologized to the retailer. Nevertheless, these kinds of customer insights can be unsettling and require great care in their treatment by designers. Issues of this kind will be discussed in greater detail in the section Mitigating Faulty Assumptions.
When handled with care, however, user insights can provide great value to customers and businesses alike. Understanding a userâs behavioral patterns can also aid security processes such as the detection of fraudulent use of a customerâs account information. Credit card companies and some retailers regularly use consumer purchasing patterns to assess whether a given purchase is fraudulent by checking whether the geographic location of the transaction and the items purchased are in line with the customerâs history. If an anomaly is detected, the transaction will be blocked and the customer will be notified that their financial information may be compromised.



Creating Dialogue
Conventional user interfaces tend to rely upon menu systems as the primary means of organizing the set of features available to the user. One positive aspect of this approach is that it provides a clear and explicit mechanism for the user to explore the system and learn what is possible within it. Hierarchical menus enable users to quickly focus their search for a specific feature by curating the systemâs functionality into neatly delineated, domain-specific groupings. If the user is unaware of a particular feature, its proximity to other more familiar functions may lead the user to experiment with it, expanding her knowledge of the system in an organic manner.
The downside to hierarchical menu systems, however, is that once users have learned the systemâs capabilities, they still have to spend a great deal of time navigating menus in order to reach commonly used features. This tedious labor is sometimes mediated by the softwareâs offering of keyboard shortcuts. But there is a limit to the number of shortcuts that can be plausibly utilized, and this approach is not easily embedded in web and mobile interfaces.
With each additional feature, conventional menu systems become increasingly complex and hard to navigate. For professional tools like 3D-modeling and video-editing software, it may be reasonable to expect the user to commit to a steep learning curve. But for intelligent assistants and other applications with broad feature sets aimed at the average user, it would be impractical or counterproductive to present the systemâs functionality through a menu system. Imagine what Siri would look like if it were to take this approach!
Programmers may be familiar with a different mechanism for facilitating interaction: the âread-evaluate-print loopâ (or REPL). In this kind of interface, the programmer issues a specific textual command, the machine performs it, prints the output, and waits for the user to issue another command. This back-and-forth dialogue takes the familiar form of a messaging app and allows programmers to work more quickly and dynamically by circumventing the need for the tedious and incessant navigation of menu hierarchies.
This conversational format also provides an ideal medium for facilitating the kinds of multimodal interactions described in the previous section. In this machine-learning-enhanced context, we can imagine many vibrant and varied exchanges between the user and machine. Much like a whiteboarding session held by human collaborators, the user and software would take turns addressing aspects of the task at hand, solving its component problems and clarifying their ideas through an assortment of verbal expressions, diagrams, and gestures.

Assisting Feature Discovery
Despite its many advantages, an open-ended dialogue does little to make the systemâs capabilities known to the user. To make the most of a REPL programming interface, the user must hold prior knowledge of the available features or make frequent reference to the documentation, which is likely to negate any efficiency gains over menu-based workflows. For intelligent interfaces, offloading the process of feature discovery to auxiliary documentation would be even less practical.
The potential limitations of a conversational user interface can be seen in our interactions with first-generation intelligent assistants such as Siri, Cortana, and Echo(Figure 1-15). In this context, feature discovery often consists of the user scouring his or her mind for phrases that might lead to some amusing or useful response from the software.

Figure 1-15. Amazonâs Echo
One solution to the problem of feature discovery that is offered by many intelligent assistants is to provide the user with a set of example inputs that demonstrate a variety of features available within the system. The computational knowledge engine WolframAlpha embeds examples directly into its interface, helping new users to become acquainted with the systemâs mode of interaction and the kinds of knowledge it is able to access. These well-curated examples continue to engage even seasoned users, inviting further exploration into the entertaining or informative pathways they reveal.
Demonstrating an applicationâs full range of features through a series of embedded examples can, however, begin to make the software look suspiciously like a reference manual. Rather than handpicking a static group of examples, machine learning or conventional programmatic logic can be used to dynamically select examples that are contextually relevant to the userâs activity. Going further, machine intelligence could be used to generate speculative extensions of the userâs trajectory, providing a series of possible next steps in a range of conceptual directions for the user to consider. This mechanism would not only extend the userâs understanding of the interface and its possibilities, but also enrich his or her fluency with the task or domain of interest at hand.
Another common mechanism for helping users to locate features within a conversational interface is to offer suggested meanings when their statements are not clear to the system. This can be helpful in correcting the improperly formed expression of a command that is already more-or-less known to the user. But if the user is completely unaware of some potentially advantageous feature, he will not think to ask for it in the first place, and this mechanism can provide no assistance.
We could, in theory, defer the problem of feature discovery to the march of progress in technology and assume that computers will eventually be intelligent enough to perform any task that could conceivably be asked of them. Yet, the machineâs ability to handle any request would not inherently translate to the userâs awareness of every possible request that might prove useful to his goals. Furthermore, the user may not be familiar enough with the problem domain to develop a set of goals in the first place.
Think for a moment about what question you might ask a Nobel laureate in chemistry. Without a strong working knowledge of the field, you would be unlikely to formulate a question that took full advantage of her expertise. To make the most of this opportunity, you would like need some guidance in finding an entry point to a fruitful line of inquiry.
To assist users in performing complex or domain-specific tasks, designers should strive to build systems that not only respond to user requests but also enrich the userâs understanding of the domain itself. It is not enough for intelligent interfaces to offer an infinite variety of features; they must also find ways of connecting the user with the possibilities they contain.


Getting Acquainted
Perhaps the greatest challenge of any conversation is knowing where to begin. When you meet someone new, you cannot be sure that your personal experiences, professional background, or even the idioms and gestures you use will overlap with theirs. For this reason, we often begin with simple pleasantries and then attempt to establish common ground by posing basic questions about the other personâs interests, line of work, and family before diving into more specific subjects and inquiries.
Similarly, in designing conversational user interfaces, we must establish common ground with users and introduce them to the systemâs capabilities and modes of interaction, since they are not explicitly detailed by a menu system.
A blank page can be stifling and may lead some users to lose interest immediately. For this reason, it is important to have the user get his feet wet as quickly as possible. Rather than simply showcasing example inputs that demonstrate a few basic features, the application could instead ask the user to perform a simple task that employs one of these features. This gives the user an initial confidence boost and helps to get the conversational juices flowing.
As the user gains traction through these initial exercises, the software can gradually become less proactive in soliciting specific actions and allow the user to explore the tool on his or her own terms. Over time, the system can continue to suggest new features to the user. But designers should be careful not to bombard users with too many new ideas as they become acquainted with the system.
Once acclimated, the userâs own explorations and activities can help the system to understand what features would be most useful to her. Subsequently, if the user is idle or appears to be at an impasse, the system can suggest contextually relevant new activities or features that have never been explored by the user. This form of assistance will be discussed further in the section Designing Building Blocks.
The user should, of course, always have the ability to opt out of these suggestions or redirect them toward more relevant functionality. Before leaving these introductory exercises, it is also important to make sure that users know how to get help from the system when they need it. Many new users will be eager to dive into the software as quickly as possible, leading them to rush through these important on-boarding exercises. In a conversational interface, an obvious and natural mechanism for seeking assistance from the system would be to use a keyword like âHelp!â In some cases, however, the userâs confusion may come from a lack of familiarity or comfort with the open-ended nature of a conversational interface. For this reason, it may be valuable to provide a concrete and persistent interface element such as a help button that allows the user to quickly and unambiguously reach out for assistance.


Seeking Clarity
In an open-ended dialogue with an intelligent interface, it is only natural and perhaps even desirable for the user to develop the impression that anything is possible within the system. In most instances, however, this will not be the case. Though intelligent assistants give the appearance of broad conceptual versatility, their true capabilities are generally still limited to one or a handful of specific domains of functionality. Their ability to comprehend human language and map it to a particular function is also often somewhat brittle.
Designers can help to mediate these technical limitations by providing conversational cues that lead the user away from broad or ambiguous statements, which cannot be easily parsed by the machine. A key component of this is to design for interactions that establish realistic expectations from the user and clearly indicate the kind of information that is being requested either through example or brief description.
If an application prompted you to âsay whatâs on your mind,â it would be disappointing or embarrassing to dive into a longwinded and enthusiastic description of your ideas only to have the machine respond with a terse âIâm sorry, I donât understand.â
Helping the user to focus on a specific task or to communicate a singular point of information is often most difficult at the beginning of a new interaction. The user may have several impressionistic or partially formed goals, but may not have sufficient clarity to articulate a clear point of entry to the system. The absence of accumulated contextual information that could otherwise be derived from the userâs most recent actions also makes it more difficult for the machine to infer the userâs intent at the outset of an interaction.
Rather than starting with an open-ended question, the system could instead pose a specific yet basic one that will help to establish context and get the conversation going so that further details can be solicited in subsequent exchanges. In many cases, it may be helpful to provide users with a few categorical options that will localize their goals to a specific subset of the systemâs overall functionality. In the context of an e-commerce site, the system might open the conversation by asking whether the user is looking to purchase a specific item, browse for items in a particular section of the store, or make a return. Once the broad context has been established, the system can seek further details from the user by posing questions that extend organically from this point of entry. If the user indicated an interest in buying a specific item, the system might pose a series of questions about the desired size, materials, or optional accessories associated with that item.
There is nothing more discouraging than having your ideas fall flat with no indication of what was confusing or how to better communicate your intended meaning. Perhaps the userâs expression was completely outside the machineâs domain of understanding. Or perhaps a single word choice or change of phrasing would have made the statement clear. But without any feedback from the machine, the user will be left in frustration to guess at the problem.
When the userâs input has been understood, the system should restate what it has understood before moving on to subsequent exchanges. If the system has not understood the user, it should try to indicate the nature of the problem to the best of its ability.
Many machine learning and natural language processing platforms can be configured to return multiple speculative interpretations of the userâs expression alongside confidence scores that numerically indicate the machineâs certainty about the correctness of each interpretation it offers. Whenever possible, intelligent applications should try to correlate these speculative interpretations with broader contextual knowledge of the userâs activities in order to eliminate the least plausible options. If this approach does not uncover a single unambiguous meaning, designers should consider presenting a handful of the most highly ranked interpretations to the user directly. Exposing users to these speculative interpretations will help them to understand the nature of the problem and rephrase or redirect a statement.


Breaking Interactions into Granular Exchanges
One of the most important things designers can do to facilitate successful exchanges between users and intelligent interfaces is to the help users break multistage workflows and their component interactions into small conceptual parcels. Simple expressions that communicate an individual command or point of information are more easily understood by machine learning and natural language processing systems than complex, multifaceted statements. Designers can help the user to deliver concise statements by creating interfaces and workflows that lead the user through a series of simple exercises or decision points that each address a single facet of a much larger and more complex task.
An excellent example of this approach is 20Q, an electronic version of the game Twenty Questions. Like the original road trip game, 20Q asks the user to think of an object or famous person and then poses a series of multiple choice questions in order to discover what the user has in mind (see Figure 1-16).
The first question posed in this process is always:
âIs it classified as Animal, Vegetable, Mineral, or Concept?â
Subsequent questions try to uncover further distinctions that extend from the information that has already been provided by the user. For example, if the answer to the first question were âAnimal,â then the next question posed might be âIs it a mammal?â If instead the first answer were âVegetable,â the next question might be âIs it usually green?â Each of these subsequent questions can be answered with one of the following options: Yes, No, Unknown, Irrelevant, Sometimes, Maybe, Probably, Doubtful, Usually, Depends, Rarely, or Partly.

Figure 1-16. A learning decision tree for the game 20Qâ
20Q guesses the correct person, place, or thing 80% of the time after 20 questions and 98% of the time after 25 questions. This system uses a kind of machine learning algorithm called a learning decision tree (or classification tree) to determine the sequence of questions that will lead to the correct answer in the smallest number of steps possible. Using the data generated by previous usersâ interactions with the system, the algorithm learns the relative value of each question in removing as many incorrect options as possible so that it can present the most important questions to the user first.
For example, if it were already known that the user had a famous person in mind, it would likely be more valuable for the next question to be whether the person is living than whether the person has written a book, because only a small portion of all historic figures are alive today but many famous people have authored a book of one kind or another.
Though none of these questions individually encapsulates the entirety of what the user has in mind, a relatively small number of well-chosen questions can uncover the correct answer with surprising speed. In addition to aiding the systemâs comprehension of usersâ expressions, this process can benefit the users directly in their ability to communicate ideas more clearly and purposefully. This process can also make the task of communicating an idea more playful and engaging for the user.
Aside from guessing games, designers may find this approach to be useful in a wide range of human-computer interactions. At its core, this process can be seen as a mechanism for discovering an optimal path through a large number of interrelated decisions. From this perspective, we can imagine applying this approach to processes like the creation of a financial portfolio or the discovery of new music.
In developing a financial portfolio, users would be presented with a series of questions that relate to their financial priorities and constraints in order to find a set of investments that are well-suited to their long-term goals, risk tolerance, and spending habits. In the context of music or movie discovery, this process may help to overcome some of the limiting factors associated with standard recommendation engines. For example, a user may give a particular film a high rating because it stars one of his favorite actors, even though the film is of a genre that is generally of no interest to the user. From this rating, a recommendation engine is likely to suggest similar films without giving the user the opportunity to point out that the actor rather than the genre was the key factor in his rating. Using an interactive decision tree process, this important distinction could be more easily uncovered by the system.



Designing Building Blocks
The kinds of machine-learning-enhanced workflows described above can provide designers with powerful new tools for making complex tasks more comprehensible, efficient, and enjoyable for the user. At the same time, enabling these modes of interaction may require designers to diverge from at least some of the longstanding conventions of user interface and user experience design.
In the section Mechanical Induction, we discussed inductive learning as a search process. Similarly, any task for which the user has some desired end-state in mind and must discover a series of operations that will reach this goal can be seen as a kind of search. From this perspective, let us imagine a very large map in which each possible end-state as well as our starting point is represented by a unique set of coordinates.
In this map, each feature of the software can be seen as a road that takes us a certain distance in a particular direction. To navigate this space, we must find a sequence of actions or driving directions that lead from our starting position to the desired destination (see Figure 1-17). A low-level feature would be equivalent to a local road in the sense that it moves us only a short distance within the map, whereas a high-level feature would be more like a highway.

Figure 1-17. A sequence of low-level features related to the design of a wine glass
The nice thing about highways is that they take us great distances with a relatively small number of component actions (see Figure 1-18). The problem, however, is that highways only have exit ramps at commonly visited destinations. To reach more obscure destinations, the driver must take local roads, which requires a greater number of component actions. Ideally, a new highway would be constructed for us whenever we leave home so that we could arrive at any possible destination with a small number of actions (see Figure 1-19). But this is not possible for pre-built high-level interfaces.

Figure 1-18. A higher-level feature

Figure 1-19. A potentially desirable, but non-existent feature
Machine learning allows us to extrapolate a great deal of information about users and what they wish to achieve through the observation of their behaviors. Rather than trying to anticipate the userâs needs through a set of prebuilt high-level interfaces, we can instead design systems that learn from the userâs engagement with the software. For example, we can discover commonly used sequences of low-level features and then dynamically combine these low-level features into custom, purpose-built features related to the userâs current activity within the system.
The behavioral patterns used in the automated production of custom high-level features can be mined from individual users or across many users. Somewhat like recommendation systems that suggest music or movies based on the similarities of usersâ tastes, the discovery of patterns across numerous users can be employed to suggest relevant features to an individual based on the workflows he or she tends to utilize. This will allow designers to better address the diversity of users and their varied ways of digesting information, making decisions, and interacting with software. It allows designers to meet users where they are rather than asking them to adapt to a singular preordained mentality or workflow offered by a more conventional, static user interface. Additionally, by extrapolating behavioral patterns across many users, designers can better understand the implicit relationships between the features offered within their systems, providing important insights as to how the software can be further developed to better serve the needs of their users.
The high-level features generated through this process can be presented to users in a variety of ways. Based on the recent trajectory of a userâs actions, a modal interface offering one or several possible next steps could be presented to the user through a mechanism somewhat like the autocomplete feature offered by some text editing applications. Alternately, a custom-generated feature could be associated with a conventional interface element such as a button. This approach, however, raises questions as to how the user would be made aware of the effect that this newly generated feature would have. In conventional interfaces, buttons are generally associated with a text label or icon that indicates the featureâs purpose. For custom-generated features that bundle the functionality of several more granular features, producing labels or icons of this kind may be challenging. Furthermore, it would likely be difficult for the user to keep track of the large and ever-changing iconography of the interface.
To circumvent this challenge, rather than indicating the effect of a given feature through a label or icon, when the user hovers over the interface element associated with the feature, the system could demonstrate its effect directly. For example, a user purchasing a car online might opt to change the paint color. In doing so, a button could be generated so that when the user hovered over it, the view of the car would show a preview of a set of suggested additional changes, such as to the upholstery fabric, trim, and so forth. If the user clicked the button, these changes would be made, but if the user chose not to click the button and moved the cursor away, the preview of the car would remove these changes.
By adopting this methodology, the designerâs role would shift away from the overall curation of high-level functionality and toward the creation of more granular interface elements. The overall curation would emerge from the aggregation of individual points of information communicated by the user. This movement from preset rule systems and interfaces to implicit, intelligently generated ones means that designers would be relinquishing some control of certain aspects of the design. Doing so, however, would enable users to address tasks that have not been explicitly anticipated by the softwareâs designer. This paradigmatic shift would greatly further the most important goal of design: to serve the needs of users.


Acquiring Training Data
A machine learning system is only as good as the data it is trained upon. No matter how powerful an algorithm may be, it cannot extract meaningful patterns if those patterns are not represented by the data. In fact, in some cases, a more powerful machine learning algorithm may produce especially erroneous results from poor training data because, in absence of meaningful patterns, the system may direct its power towards the learning of irrelevant patterns that exist within the datasetâs noise.
In general, the quality of a given dataset relates to the following characteristics:
Completeness: The extent to which the data is indicative of the full range of behaviors that is possible within the represented system. For instance, temperature data for a given city would be highly incomplete if it were only recorded on rainy days.
Accuracy: The extent to which the data is true to the real-world behaviors it represents. In other words, the recorded temperature on a particular day should exactly match what the actual temperature was.
Consistency: The extent to which various data points within the set do not conflict with one another. This means that there should not be more than one recorded temperature in the data set for the same time period and location.
Timeliness: The extent to which the data is relevant to the current state of the system. For example, temperature data for a given city from 1900 may not be indicative of more recent patterns in the cityâs weather.
To achieve these characteristics within a dataset, a great deal of human labor is often required. Accuracy, consistency, and timeliness require careful data collection, curation and maintenance. Completeness is often achieved in part through the sheer volume of examples within the dataset. With a greater number of examples, it is more likely the dataset will account for the full range of possible behaviors. For this reason, it is not uncommon for the datasets used by large-scale machine learning systems to contain hundreds of thousands or millions of training samples. The ImageNet dataset (see Figure 1-20), used to train Googleâs image classification system, contains over 14 million images, each of which is accompanied by a textual label that identifies which one of over 22,000 categories of objects the image depicts.9

Figure 1-20. A selection of images from the ImageNet dataset
For certain machine learning problems that have received significant attention from the industry and research community, large and well-curated datasets are freely available on the Web. Resources for finding these datasets can be found in the section Going Further. But for machine learning problems that have not been as widely studied, the availability of usable data has been one of the biggest bottlenecks in the advancement of applied machine learning systems.


The Intelligence Feedback Loop
In the previous section, we discussed how interface design can aid users in clearly communicating ideas and information to machine-learning-enhanced systems. Conversely, these same mechanisms can be employed to improve machine learning systemsâ ability to learn from user-generated data. Through this symbiotic relationship, the aptitudes of machine learning systems and human users can build upon one another, elevating the capabilities of both parties to new heights. One significant example of this symbiosis at work can be seen in the reCAPTCHA system (Figure 1-21), with which many readers will already be familiar.

Figure 1-21. An example reCAPTCHA
CAPTCHAs were developed as a mechanism for verifying that users trying to access a website are human, doing so by asking them to perform tasks that cannot be easily deciphered by machines. Realizing that the performance of these menial tasks would collectively represent a great deal of wasted human effort, Luis von Ahn and several other researchers at Carnegie Mellon University designed a system called reCAPTCHA that would put this effort to good use.
In its early versions, the reCAPTCHA system would present the user with the image of a word that had failed to be deciphered by an optical character recognition system tasked with digitizing printed texts. This image was often paired with the image of a âcontrolâ word that had already been deciphered. To gain access to the website, the user would be asked to type the two words. If they correctly entered the control word, it was assumed that the userâs entry was valid and they would be given access to the site. Their entry for the previously undeciphered word would then be compared against entries for the same image performed by several other users. If multiple usersâ entries for a specific image were in agreement, the entry was assumed to be correct and would be inserted into the digitized version of the originating text.
Google later acquired this technology, which played an important role in the digitization of the New York Times archives and the contents of several university libraries under the Google Books project. More recently, reCAPTCHAs have been used to improve the performance of Googleâs image recognition system by presenting users with a grid of thumbnail images and asking them to select only the images that depict a particular category of object.
This clever idea provides greater security to websites while simultaneously aggregating small bits of human effort to improve the capabilities of machine learning systems that will in turn benefit human users. reCAPTCHA is a relatively straightforward idea, but a powerful and efficient one. The underlying spirit of this idea can be adapted by designers to a wide variety of applications in the development of machine-learning-enhanced systems. Designers can create symbiotic relationships between users and computational systems that benefit both parties while streamlining the arduous task of data collection and cleaning for system developers.



Dealing with Challenges

Designing for Uncertainty
An unreliable system is often worse than no system at all. In our daily lives, we rely upon countless systems that aid us in tasks related to everything from keeping track of our schedules to keeping our families safe. Whatever services these systems may offer, they are only valuable to us if they work consistently. The detrimental effects of a single failure may far outweigh the benefit produced by a thousand instances of the system working correctly.
Designing a flawless system is a tall order in any context. But it is particularly challenging in the context of machine learning, where a systemâs behaviors are defined probabilistically through the machineâs experiential training on a finite number of discrete examples. The machine has no way of knowing whether these training examples are indicative of every possible circumstance it may encounter in real-world usage. Furthermore, if the machine does encounter unfamiliar conditions, rather than proclaiming its inability to deal with the situation, it may attempt to fit the new data into its existing model and return its results to the user without any indication that something is amiss.
If a machine learning system has been designed to return confidence scores alongside of its predictions, it is likely that the systemâs attempt to fit incongruous data into an existing model will yield a low confidence score, giving designers the opportunity to catch erroneous results before they reach the user. Unfortunately, though, there can be no explicit guarantee that a perfect storm of conditions, which obfuscates the incongruousness of a particular data sample, will not arise.
Though conventional computer programs can contain bugs, their explicitly encoded logic provides relatively strong assurances that their behaviors will be predictable and repeatable. As computers have become indispensable parts of our daily lives, we have become increasingly accustomed to their predictability and reliability. As we move towards the adoption of intelligent systems, it will be difficult for users to shift their expectations of reliability, even if their reduced reliability comes with the promise of far more advanced functionality.
To mitigate the risks associated with the erroneous behaviors of machine learning systems and provide users with the best possible experiences, designers should take the following steps before releasing their software to the public:

Design for interactions in which the system explicitly restates its understanding of the tasks it has been asked to perform, giving users the chance to catch errors and redirect the systemâs behavior.
When possible, provide fallback mechanisms through conventional user interfaces that allow users to circumvent machine-learning-enhanced functionality and perform tasks using explicit logic and interfaces.
Perform rigorous testing of the software in as many environments and usage scenarios as possible to uncover possible faults or inconsistencies that may arise from conditions that differ from those of the original development environment. Limited release to an audience of more knowledgeable and error-tolerant testers may help to uncover circumstantial inconsistencies before wider release to the public.
Use all available metrics, namely confidence scores, to assess the validity of included features. Set realistic expectations in how you present a feature and its effectiveness to the user.
Resist the temptation to include an impressive-sounding feature if its behavior is too unreliable. This assessment should weigh the complexity and potential value of the feature against the likelihood of its failure. If a feature offers some potentially revolutionary new capability, users may be more willing to accept that it only works 90% of the time.
Make users aware of any risks that might accompany their use of the software or a particular feature and allow them to decide for themselves whether these risks are outweighed by the potential benefits of the systemâs functionality.
In cases where a system failure may have extraordinarily serious consequences such as irrevocable damage to the userâs property, injury, or death, the value of a featureâs inclusion should be weighed with extreme caution and a lawyer should be consulted to assess the risks and liabilities as well as to formulate any necessary disclaimers that will be presented to users.



Mitigating Faulty Assumptions
We all feel uncomfortable having anyone, human or otherwise, make a decisive characterization of our identity that conflicts with the way we see ourselves or wish to be perceived by others. As machine learning continues to reach further into the domain of personality insights and customer preferences, the ability to connect users with products they are likely to find interesting will lead to better customer experiences and more efficient markets, but also open the door to many possible awkward situations.
It is one thing to say to the user, âI think youâll enjoy this upcoming Barry Manilow concert.â It is quite another thing to say, âYour tastes are aligned with our âold fartâ user category, therefore I think youâll enjoy this Barry Manilow concert.â Rather than explicitly characterizing the user, we can leave the machine learning systemâs statistical correlations in the statistical realm and behind the scenes. We can make suggestions about things that the user might find interesting without stating what lead the machine to believe the user would be interested.
Nevertheless, the statistical bases upon which such recommendations are made may inadvertently reflect cultural biases or other faulty assumptions about the user. In the last few years, machine learning systems have made incredible progress in their ability to perform complex tasks like image tagging. The creators of these systems have been excited to share their work with the world as quickly as possible, even when the software was still in an early stage of development. Yet, it is difficult to guard against or even foresee all possible failings of these nascent technologies and, as a result, several embarrassing or offensive incidents have occurred. In the most serious of these incidents, Googleâs Photos app tagged several black users as âGorillas.â
The upset caused by this incident is more than understandable. However, it is important to remember that the machine learning system involved has no access to or awareness of the complex societal concepts that make this error offensive. The error is owed in part to an imbalance in the set of images used to train the system, a circumstance which Google and other technology companies should seek to rectify. But, as the machine learning expert Andrew Ng said, ââ¦ itâs obvious this is an innocent rather than deliberate mistake, and just one of millions of mistakes that learning algorithms undoubtedly make every day.â10
Regardless of the machineâs innocence, this error revealed a flaw which created hard feelings, and we should do everything we can to prevent similar incidents from occurring in the future. One component of this is to strive for ever more accurate machine learning models. Another is to work at discovering any implicit biases that may be in the datasets we provide the machines ahead of time. Yet, given their experiential isolation from the human world, it is unlikely that machines will be able to circumvent all possible cultural prejudices in the foreseeable future. Therefore, we must find ways of preventing such errors through design. For instance, designers should consider offering users explicit mechanisms for flagging offensive content, providing guidance as to how they wish to be characterized, or opting out of particular features that are likely to produce faulty assumptions.


Creating Sanity Checks
Since machine learning models have no inherent means of detecting gaps or biases in their own knowledge, designers should look to outside mechanisms in safeguarding against potentially offensive or erroneous behaviors. This may prove difficult in many instances, because one of the primary motivations for using machine learning in the first place is the capacity of these systems to work with information that is too complex or subtle for the explicit logic of conventional computer programs. However, conventional code can provide at least some assistance in spotting obvious issues like the evocation of overtly derogatory language.
Around the time of this writing, Microsoft released a chatbot called Tay, which was designed to respond to users on Twitter and other messaging services. Within a day, the bot was taken offline after posting an astounding number of inflammatory messages. Perhaps the most surprising thing about this incident was that the messages in question did not contain subtly offensive innuendo or easily misconstrued associations; they instead contained overtly derogatory language and sentiments, using widely known racist and sexist terminology as well as references to Adolph Hitler and the like.
As it turns out, the system was trained on user-generated content and was targeted by people who hoped to produce this outcome by inducing the system to learn from their own hateful statements. Yet, this outcome could have been at least partially avoided if the systemâs designers had used code to check the botâs messages against a dictionary of offensive words before posting to Twitter. This approach can turn into something of a cat-and-mouse game, because users wishing to subvert such safeguards often resort to inventive spellings of words or tactics like replacing the letter “e:” with the numeral “3” so that their use of flagged terminology will go undetected. It is worth noting, however, that many of the offensive terms used in Tayâs messages were spelled correctly and could have been easily caught by even most basic of safeguarding mechanisms.
Though somewhat counterintuitive, another approach that might have been taken in this scenario would have been to use a secondary machine learning system that had been specifically trained for the detection of offensive content. Systems of this kind are used for spam filtering in services like email and user forums. They are also used by marketers in the sentiment analysis tools they employ to better understand comments about their products posted on social networks.
Though neither of these approaches can completely solve the problem, they can at least guard against the most blatant abuses. Aside from these mechanisms, designers should rely upon the collective intelligence of their user base by providing explicit interface elements that allow users to flag offensive or erroneous content for review by system administrators and subsequent integration into the machine learning model. This approach, more than any automated one, will help designers to stay ahead of malicious users and flawed datasets.



Working with Machine Learning Platforms
In theory, machine learning can be applied to any kind of information that contains patterns, so long as those patterns can be sufficiently exemplified by a set of training data. In practice, however, some forms of information can be more readily accessed and applied to real-world design problems than others. For more common machine learning tasks like image tagging and speech-to-text functionality, designers may utilize turn key solutions offered by a variety of Machine-Learning-as-a-Service (MLaaS) platforms, which enable straightforward integration with user-facing systems through RESTful APIs and design patterns. In many cases, these MLaaS platforms will also enable the relatively straightforward deployment of machine learning systems trained on custom datasets provided by the designer. For more exotic or domain-specific use cases, designers may look to more customizable open source machine learning toolkits or even fully customized software, which tend to require a deeper technical understanding of the underlying algorithms as well as of the technical issues related to the deployment of such technologies within large-scale user-facing systems.

Machine-Learning-as-a-Service Platforms
Several large technology companies and startups offer high-level machine learning platforms, which provide designers with straightforward access to turnkey solutions or customized training on designer-provided data. The list of MLaaS platforms is growing quickly. Some of the most popular platforms include: IBM Watson, Amazon Machine Learning, Google Prediction API, Microsoft Azure, BigML, and ClarifAI.
Despite the many advantages of these systems, there are several important downsides that may factor into a designerâs decision of whether to use a platform of this kind in building their system. First, the use of these systems comes with recurring costs that will grow with a wider user base. Though the cost of an individual query is generally quite low and bulk rates are available, for a sufficiently large user base, these costs can become prohibitive without a viable revenue model to support the product. Additionally, these platforms generally do not provide a straightforward path for moving a system developed within one MLaaS platform to a competing platform. This platform lock-in may contribute to the long-term cost of ownership and may constrain future innovation within a designerâs system. Finally, systems built on top of MLaaS platforms tend to require the userâs device to have internet connectivity in order to query the remotely hosted model. This may be limiting in some applications and may incur data usage costs for the user. However, the models associated with many complex machine learning may be too large or computationally intensive to run on user devices, making cloud-based deployment the only viable route regardless of whether a MLaaS or custom machine learning solution has been used.

Turnkey Solutions
If the machine-learning-based functionality you wish to offer within your design is specifically supported by a turnkey feature of one of these platforms, this approach will offer the quickest and easiest path to a deployable user-facing product. Though the specific features offered will differ by platform, many MLaaS platforms offer turnkey solutions for tasks including natural language parsing, language translation, speech-to-text, personality insights, sentiment analysis, image classification and tagging, face detection, and optical character recognition.
The creators of these systems have put a great deal of work into the development and testing of their underlying algorithms as well as the gathering of large and well-cleaned datasets that will ensure robust functionality. These turnkey features can be utilized without any further knowledge of the underlying algorithms or datasets using straightforward API calls in an assortment of languages.
For example, an image classification query can be performed using the Node interface of the IBM Watson platform with the code used in Figure 1-22.

Figure 1-22. A Watson image classification query in Node
Watson would subsequently return the JSON response in Figure 1-23, which can be easily parsed by the client system and integrated into the user-facing design:

Figure 1-23. An easily parsed JSON response to a Watson image classification query


Custom-Trained Systems
Aside from the areas of turn key functionality listed above, MLaaS platforms can be used in a wide range of machine learning problems that require custom, designer-supplied datasets. In such cases, designers may circumvent the arduous process of building, testing and deploying the machine learning system itself. They will, however, still need to devote time and resources to ensuring that the datasets they provide to these systems are clean and well-curated, though many MLaaS platforms offer substantial assistance in streamlining these processes as well.
Though the specific functionality offered will differ by platform, many MLaaS platforms provide functionality related to user behavior prediction, customer analytics and insights, inventory trends, recommendation engines, content personalization, fraud and anomaly detection, and any other supervised learning problem.
The training process for these systems generally involves the designer uploading a spreadsheet or formatted data to the platform, waiting for the model to be trained in the cloud, and then testing its behavior before deploying the functionality within a user-facing design. For most supervised learning problems, the data spreadsheet supplied to the MLaaS platform would contain at least two columns: one or more columns to represent the input attributes for a particular example and another column to represent the desired output associated with that input. As with any training process, a larger number of examples (or spreadsheet rows) is likely to result in a more robust model. Once trained, queries to the model are performed in a similar manner to the example shown above for turn-key features.



Open Source Machine Learning Toolkits
For some machine learning problems and user-facing platforms, particularly native applications designed for offline usage, it may be necessary to deploy technologies outside of the MLaaS platforms described above. In such instances, designers may avoid at least some aspects of the lengthy development processes associated with fully customized solutions by building on top of one of a growing list of open source machine learning toolkits, which are available for a variety of programming languages and platforms. Some popular toolkits of this kind include: TensorFlow, Torch, Caffe, cuDNN, Theano, Scikit-learn, Shogun, Spark MLlib, and Deeplearning4j.
These lower-level toolkits generally require more programming experience than is necessary for the use of MLaaS platforms. Additionally, deeper knowledge of specific machine learning algorithms and their associated training techniques will likely be required for their effective use. While the MLaaS platforms listed above tend to include automated training processes, these toolkits will require designers to tune algorithmic hyperparameters such as the learning rate to align with the specific characteristics of their chosen dataset. This tuning process is aided by a deeper knowledge of mathematics and often involves at least some time-intensive trial-and-error to find suitable values.
Training a machine learning system tends to be a highly computationally intensive process, and for large or complex datasets, it is often impractical or even impossible to perform this process on a single consumer-grade machine. Many of the toolkits mentioned above are designed for use on large-scale hardware systems that use numerous CPUs or high-performance GPUs to perform training. This hardware can be cost-prohibitive and may require specialized knowledge related to the performance-enhancement mechanisms employed by a specific toolkit.
Once trained, the system will still need to be deployed to the desired user-facing platform. In most instances for which these toolkits are applicable, the user-facing platform will have little in common with the large-scale system utilized during the training process. This means that designers must navigate two separate sets of technical and infrastructural challenges in developing their systems and making them available to users.
Despite these challenges, these toolkits offer a viable pathway for designers wishing to add customized machine learning functionality to user-facing systems. Many of these tools are backed by large technology companies, who have a vested interest in their wider adoption and are working to progressively make their tools more accessible to a wider audience of designers and developers.
One additional selling point of these toolkits over MLaaS platforms is that the tools themselves are free to use and deploy, though training them on a large-scale platform may require designers to either acquire their own costly hardware or pay for the use of a cloud-based system.
Like MLaaS platforms, the trained models developed using a toolkit of this kind may not be easily transferred for use with a different toolkit. However, in most cases, these customizable toolkits provide a more straightforward path for doing so than would be possible for a system backed by one of the MLaaS platforms.


Fully Customized Machine Learning Tools
The open source toolkits listed above strive to provide thoroughly tested implementations of proven machine learning algorithms and techniques. As a result, these tools may not include more experimental algorithms coming from recent research that has not yet been thoroughly reviewed and field tested. In some instances, these advances may provide incremental improvements to existing algorithms and in other cases may offer revolutionary new functionality. Integrating these technologies into user-facing systems will almost always require custom implementation work involving the translation of algorithms from their mathematical notation in formal research papers to working code. Rigorous testing as well as additional implementation work related to the performance and scaling of the system would also likely be required. This work generally requires a large team of developers with advanced knowledge of theoretical machine learning as well as deployment technologies. For these reasons, this approach is not advisable in most instances. Designers who are interested in working with experimental machine learning technologies should consider joining larger teams, which are better suited to the multifaceted task of making these emerging technologies ready for production.


Machine Learning Prototyping Tools
Prototyping is an essential component of many design processes. It helps designers to sketch the basic functioning of their systems, test assumptions about how users will interact with planned features, and fine-tune those features before turning to more costly and time-intensive implementation processes. Unfortunately, the complex architectures and computationally intensive training processes associated with machine learning present challenges for the rapid prototyping of machine-learning-enhanced systems. In cases where a turnkey MLaaS solution is applicable, designers may be able to prototype their ideas with relative ease. But in instances where the desired functionality requires a custom dataset or code, producing even a basic prototype can take substantial time, effort, and knowhow. Presently, there are a limited number of tools available for assisting the prototyping of machine learning systemsâa circumstance that will hopefully change over the next few years.
In the meantime, several existing tools may help to ease the prototyping process. From the programming-free Wekinator to the Mathematica interface and the more programming-intensive Keras, the series of tools presented below can serve as stepping stones for students and designers wishing to prototype solutions to real-world design problems while becoming acquainted with machine learning systems and workflows in a hands-on way.

Wekinator
Wekinator is a free, open source tool created by Rebecca Fiebrink. It allows users to develop experimental gesture recognition systems and interface controllers for a wide range of input devices including webcams, microphones, game controllers, Kinect, Leap Motion, physical actuators (through an Arduino), keyboards, and mice. Unlike many machine learning workflows, Wekinator requires no programming or wrangling of datasets. Instead, the software walks the designer through an interactive process in which she defines a particular gesture by demonstrating it to the machine and then associates the gesture with a desired output action. To aid prototyping and integration with other software, a trained Wekinator model can be set to broadcast its output events using the popular OSC protocol. Though Wekinator is only geared toward a specific domain of machine learning functionality, it provides a powerful medium for prototyping and designing machine-learning-enhanced multimodal user interfaces. See Figure 1-24.

Figure 1-24. A workflow for designing event triggers with Wekinator
Wekinator can be downloaded from: http://www.wekinator.org.


Mathematica
The popular technical computing platform Mathematica has added a wide range of automated machine learning features to its most recent version, Mathematica 10. This tool features a polished user interface and does not require a deep understanding of programming, though some basic familiarity with text-based scripting will be helpful to new users. Its machine learning features can be applied to a wide range of data types and its automatic data preprocessing and model selection features will help users to get good results without a great deal of trial-and-error or deep knowledge of a particular modelâs training parameters. Mathematica provides turnkey support for a range of common machine learning tasks such as image recognition, text classification, and classification or regression of generic data. Datasets can be loaded through an interactive, visual interface. Mathematica is extremely well documented and embeds assistive tools like feature suggestion and autocompletion directly into its interface. See Figure 1-25.

Figure 1-25. Classifying handwritten digits in Mathematica
Mathematical can be purchased from https://www.wolfram.com/mathematica.


Keras
This tool requires a deeper knowledge of programming as well as familiarity with command-line-based installation processes, but provides a relatively user-friendly wrapper for the high-performance machine learning toolkits TensorFlow and Theano. Though it requires programming, Keras is geared towards the rapid prototyping of highly customized machine learning systems. It provides a high-level API and modular components that will help users to assemble common machine learning architectures such as convolutional and recurrent neural networks. This tool is not intended for new users, but may help to bridge the gap between the tools listed above and more open-ended platforms such as those listed in the following section, Open Source Machine Learning Toolkits.
Keras installation instructions can be found at http://keras.io.



Incorporating Machine Learning into Design Processes
In thinking about how to teach a person a complex task, it can be difficult to break the task down into a series of well-defined, discrete steps. The same problem can arise when designing machine-learning-enhanced systems. We might think, âthe intelligent assistant should read the userâs emotional state and respond accordingly.â But what does this mean? Though the answer may seem relatively clear in human terms, it is less so in computational ones. Is the userâs emotional state defined by his word choice? If so, how are we deciding what words are correlated with which emotions?
The first step in bringing machine learning to a design project should always be to try to define the learning problem as clearly and fully as possible. What are the input parameters we will provide the machine? What kinds of outputs are we looking for? What kind of training data will exemplify the correlations between these inputs and outputs?
Once you feel confident that the learning problem has been well-defined, it may be helpful to set aside the technical details for a moment and treat the machine learning component as a black box function within the overall architecture of your system. This means that, much like a mathematical operation such as a square root, you know what the input and corresponding output should be, but you do not necessarily know how the square root is actually computed within this function. In this way, as you sketch out the user and data flows of your system, a machine learning component can be treated like any other feature of the software. An image recognition component, for instance, could be thought of as a box that takes an image as input and outputs a list of words. This approach allows designers to incorporate machine learning features into their systems without getting bogged down in technical details during the important ideation and sketching stages, which often require fluid thinking.
Unlike a simple mathematical function, however, it is much more difficult to be certain that a machine learning feature will do what you need it to or that you will be able to find the appropriate training data to achieve the desired behavior. Therefore, this sketching process should be treated with care. If a machine-learning-enhanced feature is critical to the softwareâs overall behavior and its efficacy is in doubt, it will be important to prototype the black box functionality to test assumptions before getting too far into designing other features around this machine learning functionality. The prototyping tools listed in the previous section may provide some assistance in getting a sense of whether the functionality will be achievable.
This process of prototyping and validating assumptions can be quite labor intensive. It may require the procurement and cleaning of a dataset, the selection of a machine learning model and a lengthy training process to see any preliminary results whatsoever. Over time, however, as you work more with machine learning systems, you will develop an intuition for what is likely to work and what kinds of learning problems may be more touchy or brittle. It is important to jump in and get your hands dirtyâgetting as much first-hand experience as possible is crucial. Collaboration is also of great importance. If you are working with machine learning engineers, try to form your own opinion of whether a particular idea will work and then ask for the engineerâs opinion. If her opinion conflicts with yours, ask questions. Which of your assumptions were faulty? What factors did you not consider? Machine learning may be a rigorous science, but it is still something for which you can build an intuition.
As you work toward this intuition, start from simpler mechanisms and build towards more complex ones. It will not be easy to intuit how a Jeopardy-playing AI might be constructed, for example. In truth, IBMâs Watson is not comprised of one machine learning systemârather, it is many interconnected components. As you introduce machine learning features into your designs, think about them as individual components. If you cannot reason clearly about what a particular component should do and what data it should be trained on, then most likely the machine wonât be able to figure this out either.
Learning is an abstract phenomenon, but its role within an individual component of a design need not be abstract. In any design process, itâs necessary to think back and forth between the high-level purpose of a feature and its specific technical constraints in order to balance the many interrelated properties of a complex system. For machine-learning-enhanced features, finding this balance can be difficult. But designers can meet this challenge if they are willing to experiment, question their own thinking, and in so doing, continually strengthen their intuition for the essence of machine learning.



Conclusions
In many ways, machine learning is a solution in search of a problem. Machine learning algorithms are capable of discovering complex patterns in the data presented to them, but they are only useful if they have been trained to notice something useful. For some fields, such as finance and medicine, there are clear connections between the fieldâs existing needs and the capabilities of machine learning systems. Financial institutions have always had a need for tools that help to predict the future behaviors of markets based on their past performance. Medical institutions have always had a need for tools that can predict patient outcomes. Machine learning simply provides more effective mechanisms for achieving these goals.
In the coming years, countless other fields will be transformed by machine learning. In many cases, however, this transformation will not be about connecting existing goals with new mechanisms for achieving them. It will require the discovery of new premises and mindsetsâones that expose entirely new opportunities and goals that can only be seen through the perspective of machine learning.
In his book Operating Manual for Spaceship Earth, the visionary designer Buckminster Fuller wrote, âIf you are in a shipwreck and all the boats are gone, a piano top buoyant enough to keep you afloat that comes along makes a fortuitous life preserver. But this is not to say that the best way to design a life preserver is in the form of a piano top. I think that we are clinging to a great many piano tops in accepting yesterdayâs fortuitous contrivings as constituting the only means for solving a given problem.â11
In looking at the history of digital design tools themselves, we may see countless piano tops. Many of the features offered by video editing software, for instance, reference the preceding vocabulary of flatbed film editors. Though these references were helpful in transitioning a generation of filmmakers to a digital workflow, they did little to uncover new possibilities within the emerging medium of video. Discovering the unique possibilities of a medium requires experimentation, a fresh pair of eyes, and a willingness to think outside of the existing paradigms. It is here that designers will prove essential to the future of machine learning.
In order to fully capitalize on the technical possibilities of machine learning systems, designers will be somewhat reliant upon programmers. But programmers must also rely upon designers to find groundbreaking applications and ways of thinking about these general-purpose tools. To facilitate collaboration with programmers and develop novel applications, designers do not necessarily need to understand all of the mathematical details associated with machine learning techniques. Still, to think freely and inventively about the possibilities of a medium, it is important to understand its underlying properties and constraints. As Bob Dylan said, âto live outside the law, you have to be honest.â In other words, you have to understand the rules to know which are worth bending or breaking.
To that end, for the field of machine learning to expand and thrive into the future, it will be essential for designers to immerse themselves in the possibilities of this technology, transforming it through their ways of seeing and thinking about the world.


Going Further

Staying Up-to-date with Advancements in the Field

arXiv
arXiv (pronounced âarchiveâ) is a repository of prepress scientific papers. Many cutting-edge advancements in the field of machine learning are posted to arXiv first. Keeping an eye on the latest papers posted to arXiv is one of the best ways to keep up with the latest advancements. But, with thousands of papers in a wide range of field posted to the site each month, finding papers relevant to your specific interests is not always easy.
arXiv Machine Learning: http://arxiv.org/list/stat.ML/recent
arXiv Neural and Evolutionary Computing: http://arxiv.org/list/cs.NE/recent
arXiv Artificial Intelligence: http://arxiv.org/list/cs.AI/recent


CreativeAI
Finding relevant papers on arXiv can be challenging. The site CreativeAI curates a collection of machine learning projects that are directly relevant to design and the arts. The projects featured on this site include written papers, videos, and even code samples. CreativeAI highlights some of the many inspirational possibilities for incorporating machine learning into creative applications.
CreativeAI: http://www.creativeai.net


Reddit
Another great way to keep track of important advancements that have been posted to arXiv and other sources is to keep an eye on the conversations happening within the Machine Learning and Artificial Intelligence sections of the Reddit discussion forum. Readers will find links to recently published articles as well as a wide range of discussions on topics that will be of interest to any machine learning researcher or designer.
Reddit Machine Learning: https://www.reddit.com/r/machinelearning
Reddit Artificial Intelligence: https://www.reddit.com/r/artificial


Deep Learning News & Hacker News
The recently established Deep Learning News site offers topical discussions on machine learning in a similar vein to the Reddit forums discussed above. The more general purpose Hacker News discussion forum also provides many relevant conversations about state-of-the-art machine learning technologies.
Deep Learning News: http://news.startup.ml
Hacker News: https://news.ycombinator.com



Resources for Further Study of Machine Learning

Online Courses
âMachine Learning for Musicians and Artistsâ taught by Rebecca Fiebrink:
https://www.kadenze.com/courses/machine-learning-for-musicians-and-artists/info
âMachine Learningâ taught by Andrew Ng:
https://www.coursera.org/learn/machine-learning
âNeural Networks for Machine Learningâ taught by Geoffrey Hinton:
https://www.coursera.org/course/neuralnets


Math for Machine Learning
âSome Basic Mathematics for Machine Learningâ by Iain Murray and Angela J. Yu:
http://www.cogsci.ucsd.edu/~ajyu/Teaching/Cogs118A_wi10/Refs/basic_math.pdf
âMath for Machine Learningâ by Hal DaumÃ© III:
http://www.umiacs.umd.edu/~hal/courses/2013S_ML/math4ml.pdf
âMachine Learning Math Essentials Part I & IIâ by Jeff Howbert:
http://courses.washington.edu/css490/2012.Winter/lecture_slides/02_math_essentials.pdf
http://courses.washington.edu/css490/2012.Winter/lecture_slides/06a_math_essentials_2.pdf
âImmersive Linear Algebraâ by J. StrÃ¶m, K. ÃstrÃ¶m, and T. Akenine-MÃ¶ller:
http://immersivemath.com/ila/index.html
âLinear Algebraâ by Khan Academy:
https://www.khanacademy.org/math/linear-algebra
âProbability and Statisticsâ by Khan Academy:
https://www.khanacademy.org/math/probability
âDifferential Calculusâ by Khan Academy:
https://www.khanacademy.org/math/differential-calculus


Tutorials
âDeep Learning Tutorialsâ:
http://deeplearning.net/reading-list/tutorials
âA Deep Learning Tutorial: From Perceptrons to Deep Networksâ:
https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks
âDeep Learning From the Bottom Upâ:
https://www.metacademy.org/roadmaps/rgrosse/deep_learning



Technical Resources

Machine-Learning-as-a-Service Platforms
IBM Watson: http://www.ibm.com/smarterplanet/us/en/ibmwatson
Amazon Machine Learning: https://aws.amazon.com/machine-learning
Google Prediction API: https://cloud.google.com/prediction
Microsoft Azure: https://azure.microsoft.com/en-us/services/machine-learning
BigML: https://bigml.com
ClarifAI: https://www.clarifai.com/


Open Source Machine Learning Toolkits
TensorFlow (C++, Python): https://www.tensorflow.org
Torch (C, Lua): http://torch.ch
Caffe (C++): http://caffe.berkeleyvision.org
cuDNN (C++, CUDA): https://developer.nvidia.com/cudnn
Theano (Python): http://deeplearning.net/software/theano
Scikit-learn (Python): http://scikit-learn.org
Shogun (C++, Python, Java, Lua, others): http://www.shogun-toolbox.org
Spark MLlib (Python, Java, Scala): http://spark.apache.org/mllib
Deeplearning4j (Java, Scala): http://deeplearning4j.org


Datasets
UCI Machine Learning Repository: http://archive.ics.uci.edu/ml
MNIST Database of Handwritten Digits: http://yann.lecun.com/exdb/mnist
CIFAR Labeled Image Datasets: http://www.cs.toronto.edu/~kriz/cifar.html
ImageNet Image Database: http://www.image-net.org
Microsoft Common Objects in Context: http://mscoco.org/home




1Patricia F. Carini, On Value in Education (New York, NY: Workshop Center, 1987).
2Zoltan P. Dienes and E. W. Golding, Learning Logic, Logical Games (Harlow [England] ESA, 1966).
3Frank Rosenblatt, “The perceptron: a probabilistic model for information storage and organization in the brain,” Psychological Review 65, no. 6 (1958): 386.
4David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams, “Learning representations by back-propagating errors,” Cognitive Modeling 5, no. 3 (1988): 1.
5Turing, A. M. “Computing Machinery and Intelligence.” Mind 59.236 (1950): 433-60.
6Alan Mathison Turing, “Intelligent Machinery,” in Mechanical Intelligence, ed. D. C. Ince (Amsterdam: North-Holland, 1992), 114.
7Negroponte, Nicholas. The Architecture Machine. Cambridge, MA: M.I.T., 1970. 11. Print.
8http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html
9http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf
10https://plus.google.com/113710395888978478005/posts/dZ7pd4zdaiJ
11R. Buckminster Fuller, Operating Manual for Spaceship Earth (Carbondale, IL: Southern Illinois University Press, 1969).






      Post topics: Design

                Share:
                

Tweet 

Share 


 




















About OâReilly

Teach/write/train
Careers
OâReilly news
Media coverage
Community partners
Affiliate program
Submit an RFP
Diversity
OâReilly for marketers





Support

Contact us
Newsletters
Privacy policy

linkedin-logo
youtube-logo


International

Australia & New Zealand
Hong Kong & Taiwan
India
Indonesia
Japan





Download the O’Reilly App
Take O’Reilly with you and learn anywhere, anytime on your phone and tablet.






Watch on your big screen
View all O’Reilly videos, Superstream events, and Meet the Expert sessions on your home TV.






Do not sell my personal information






© 2024, O’Reilly Media, Inc.  All trademarks and registered trademarks appearing on oreilly.com are the property of their respective owners.
Terms of service â¢ Privacy policy â¢ Editorial independence

















Applications Of Machine Learning For Designers — Smashing MagazineSkip to main content
Start reading the article
Jump to list of all articles
Jump to all topicsArticlesBooksWorkshopsConferencesMembershipJob BoardNewsletterPodcastsWrite for usAdvertise with us
More
Less
Menu
LessArticlesBooksWorkshopsConferencesMembershipJob BoardNewsletterPodcastsWrite for usAdvertise with us

Clear SearchAccessibilityUXCSSJavaScriptPerformanceDesignFigmaWallpapersReactVueRound-UpsWeb DesignGuidesBusinessCareerPrivacyJump to all articles ↬Lassi LiikkanenApr 24, 20170 commentsApplications Of Machine Learning For Designers26 min readCoding,
Process,
Product Strategy,
Experience Design,
Machine LearningShare on Twitter, LinkedInAbout The AuthorLassi A Liikkanen is a digital tinkerer and advocate of user-centricity for almost twenty years. Lassi currently works as Data-driven design specialist in SC5 …
More about
Lassi ↬Email NewsletterYour (smashing) email
Weekly tips on front-end & UX.Trusted by 200,000+ folks.
Accessibility for Designers, with Stéphanie Walter
Register!
Advanced Modern CSS Masterclass, with Manuel Matuzović
Design Token and UI Component Architecture, with Nathan Curtis
Smart Interface Design Patterns, 10h video + UX training
Deploy Fast. Deploy SmartAs a designer, you will be facing more demands and opportunities to work with digital systems that embody machine learning. To have your say about how best to use it, you need a good understanding about its applications and related design patterns. In this article, Lassi Liikkanen illustrates the power of machine learning through the applications of detection, prediction and generation. To help you get started, he has included two non-technical questions that will help with assessing whether your task is ready to be learned by a machine.This article illustrates the power of machine learning through the applications of detection, prediction and generation. It gives six reasons why machine learning makes products and services better and introduces four design patterns relevant to such applications. To help you get started, I have included two non-technical questions that will help with assessing whether your task is ready to be learned by a machine.Meet Touch Design for Mobile Interfaces, Steven Hoober’s brand-new guide on designing for mobile with proven, universal, human-centric guidelines. 400 pages, jam-packed with in-depth user research and best practices.Jump to table of contents ↬Big Data, Small IntelligenceBig data and big promises. We are expecting a great many things to happen once the big data deluge has been funnelled into a nurturing stream of bits. Data can be used in many ways. One is to build smart products, and another is to make better design and business decisions. The latter also, ultimately, trickle into products.Machine learning is a very promising approach radically shaping future product and service development. Machine learning is a branch of artificial intelligence. It employs many methods: Deep learning and neural networks are two well-known instances.Machine learning means that, instead of programmers providing computers with very detailed instructions on how to perform a task, computers learn the task by themselves. A recent, remarkable milestone was when Google’s AlphaGo software learned to master the game of Go at the level of a world champion!"Pretty much anything that a normal person can do in <1 sec, we can now automate with AI."
– Andrew Ng (@AndrewYNg), 19 October 2016This story will lead you into problem discovery through examples of what sorts of problems machines today readily chew on. A basic understanding of machine learning, commonly known as ML, will help. If you are unfamiliar with ML, I suggest you read Nvidia’s clear explanation of the differences between ML, AI and deep learning.Why Do I Need To Understand The Applications Of Machine Learning?As a designer, you will be facing more demands and opportunities to work with digital systems that embody machine learning. As the hype around machine intelligence intensifies, this will lead to technology-driven pressure to extensively utilize machine learning. This may happen with little understanding of its actual benefits and its impact on product desirability and customer experience.Stay On Top Of the Machine-Intelligence Game!As a designer, to have your say about any plans for machine intelligence and how it is best implemented on the human interface layer, you need to know what it can do and how digital services can utilize it. This post provides an overview of applications, with concrete examples, as well new design guidelines that you can put to work. This will help with making actual design decisions and identifying the right design patterns, including situations when no directly applicable solution exists and you must transfer ideas across domains.Get To The Core Of The ProblemTo exploit the capability of machine learning, you must grasp the nature of a task as a computer might see it. The concept I’ll use to describe it is the core problem of learning. This refers to defining what exactly we would like the computer to learn in order for it to complete the task we have assigned to it. These goals are not always evident at the practical, holistic level of a finished product (say, Tesla’s autopilot function). This story will help you to see what goes on under the surface.Say you want the computer to drive your car.This is a very high abstraction level learning goal. We need to go further down and break it into smaller chunks. We need to ask questions such as, can the computer accelerate and decelerate, and can the machine recognize red and green lights? To identify the core problem is already a move towards understanding whether the overarching task is a good fit for a machine to learn. Once the core problem of learning is defined well, then it is possible to say whether the ML computers of today can solve it with adequate accuracy and in a decent amount of time. This is what matters most for actually making the application work.Small autonomous buses (in the background) started operating on Aalto University Espoo campus in autumn 2016. The street sign warns about their presence, reminiscent of the first automobiles in the 19th century. (Picture of Project Sohjoa demonstration in Espoo. Copyright Metropolia UAS, used with permission.) (View large version)What Good Will Machines Do For You?Suppose you manage to teach some skill to a machine. How would your product or service benefit from it? Here are six possible benefits:augment,automate,enable,reduce costs,improve safety,create.In rare cases, machine learning might enable a computer to perform tasks that humans simply can’t perform because of speed requirements or the scale of data. But most of the time, ML helps to automate repetitive, time-consuming tasks that defy the limits of human labor cost or attentional span. For instance, sorting through recycling waste 24⁄7 is more reliably and affordably done by a computer.In some areas, machine learning may offer a new type of expert system that augments and assists humans. This could be the case in design, where a computer might make a proposal for a new layout or color palette aligned with the designer’s efforts. Google Slides already offers this type of functionality through the suggested layouts feature. Augmenting human drivers would improve traffic safety if a vehicle could, for example, start braking before the human operator could possibly react, saving the car from a rear-end collision.(Large preview)Google Slides provides design assistance via the Explore function. Right pane demonstrates the variations it has generated from elements initially composed by the user.What Have Machines Learned So Far?In 2016, the most celebrated milestone of machine learning was AlphaGo’s victory over the world champion of Go, Lee Sedol. Considering that Go is an extremely complicated game to master, this was a remarkable achievement. Beyond exotic games such as Go, Google Image Search is maybe the best-known application of machine learning. Search feels so natural and mundane when it effectively hides away all of the complexity is embeds. With over 30 billion search queries every day, Google Image Search constantly gets more opportunities to learn.There are already more individual machine learning applications than are reasonable to list here. But a major simplification is not sufficient either, I feel. One way to appreciate the variety is to look at successful ML applications from Eric Siegel’s book Predictive Analytics from 2013. The listed applications fall under the following domains:marketing, advertising and the web;financial risk and insurance;healthcare;crime fighting and fraud detection;fault detection for safety and efficiency;government, politics, nonprofit and education;human-language understanding, thought and psychology;staff and employees, human resources.His cross-industry collection of examples is a powerful illustration of the omnipresence of predictive applications, even though not all of his 147 examples utilize machine learning as we know it. However, for a designer, knowing whether your problem domain is among the nine listed will give an idea of whether machine learning has already proven to be useful or whether you are facing a great unknown.Machines Learn Detection, Prediction And CreativityAs I see it, the power of learning algorithms comes down to two major applications: detection and prediction. Detection is about interpreting the present, and prediction is about the way of the future. Interestingly, machines can also do generative or “creative” tasks. However these are still a marginal application.Three main categories of ML applications and their common use cases (View large version)When you combine detection and prediction, you can achieve impressive overall results. For instance, combine the detection of traffic signs, vehicles and pedestrians with the prediction of vehicular and pedestrian movements and of the times to vehicle line crossings, and you have the makings of an autonomous vehicle!This is my preferred way of thinking about machine learning applications. In practice, detection and prediction are sometimes much alike because they don’t yet cut into the heart and bones of machine learning (recall the basics of machine learning), but I believe they offer an appropriate level of abstraction to talk about machine learning applications. Let’s clarify these functions through examples.The Varieties Of DetectionThere are at least four major types of applications of detection. Each deals with a different core learning problem. They are:text and speech interpretation,image and sound interpretation,human behavior and identity detection,abuse and fraud detection.Text And Speech InterpretationText and speech are the most natural interaction and communication methods. Thus, it has not been feasible in the realm of computers. Previous generations of voice dialling and interactive voice response systems were not very impressive. Only in this decade have we seen a new generation of applications that take spoken commands and even have a dialogue with us! This can go so smoothly that we can’t tell computers and humans apart in text-based chats, indicating that computers have passed the Turing test.Dealing with speech, new systems such as personal assistant Siri or Amazon’s Echo device are capable of interpreting a wide range of communications and responding intelligently. The technical term for this capability is natural language processing (NLP). This indicates that, based on successful text and speech detection (i.e. recognition), computers can also interpret the meaning of words, spoken and written, and take action.Text interpretation enables equally powerful applications. The detection of emotion, or sentiment, from text means that large masses of text can be automatically analyzed to reveal what people in social media think about brands, products or presidential candidates. For instance, Google Translate just recently witnessed significant quality improvements by switching to an ML approach to translations.Amazon Echo Dot is surfacing as one of the best-selling speech-recognition-driven appliances of early 2017. (View large version)"Jeff Bezos says the Echo “isn’t about” getting people to shop on Amazon, and he may be right pic.twitter.com/erodS8hoJg"
– BI Tech (@SAI) 13 February 2017Image And Sound InterpretationComputer vision gives metaphorical eyes to a machine. The most radical example of this is a computer reconstruction of human perception from brain scans! However, that is hardly as useful an application as one that automates the tagging of photos or videos to help you explore Google Photos or Facebook. The latter service recognizes faces to an even scary level of accuracy.Image interpretation finds many powerful business applications in industrial quality control, recording vehicle registration plates, analyzing roadside photos for correct traffic signs, and monitoring empty parking spaces. The recent applications of computer vision to skin cancer diagnosis have actually proven more proficient than human doctors, leading to the discovery of new diagnostic criteria!A search for “dog” in my personal Google Photos collection brings up several correct instances of dogs I’ve chanced upon, but also a few false positives. However, I’ve never tagged a single dog, so the noise is acceptable given the added value of finding any dogs. (Screenshot from February 2017, edited to remove personal information (albums).) (View large version)Speech was already mentioned, but other audio signals are also well detected by computers. Shazam and SoundHound have for years provided reliable detection of songs either from a recording fragment or a sung melody. The Fraunhofer Institute developed the Silometer, an app to detect varieties of coughs as a precursor to medical diagnosis. I would be very surprised if we don’t see many new applications for human and non-human sounds in the near future.Human Behavior And Identity DetectionGiven that computers are seeing and hearing what we do, it is not surprising that they have became capable of analyzing and detecting human behavior and identity as well — for instance, with Microsoft Kinect recognizing our body motion. Machines can identify movements in a football game to automatically generate game statistics. Apple’s iPad Pro recognizes whether the user is using their finger or the pencil for control, to prevent unwanted gestures. A huge number of services detect what kind of items typically go together in a shopping cart; this enables Amazon to suggest that you might also be interested in similar products.In the world of transportation, it would be a major safety improvement if we could detect when a driver is about to fall asleep behind the steering wheel, to prevent traffic accidents. Identity detection is another valuable function enabled by several signals. A Japanese research institute has developed a car seat that recognizes who’s sitting in it. Google’s reCAPTCHA is a unique system that tells apart humans from spam bots. Perhaps the most notorious example of guessing people’s health was Target’s successful detection of expectant mothers. This was followed by a marketing campaign that awkwardly disclosed the pregnancy of Target customers, resulting in much bad publicity.Google’s reCAPTCHA has simplified spam-fighting in web forms with the help of micro-intelligence from machine learning.Anti-Virus, Anti-Spam, Anti-MalwareMachine learning is also used to detect and prevent fraudulent, abusive or dangerous content and schemes. It is not always major attacks; sometimes it is just about blocking bad checks or preventing petty criminals from entering the NFL’s Superbowl arena. The best successes are found in anti-spam; for instance, Google has been doing an excellent job for years of filtering spam from your Gmail inbox.I will conclude with a good-willed detection example from the normal human sphere. Whales can be reliably recognized from underwater recordings of their sounds — once more, thanks to machine learning. This can help human-made fishing machinery to avoid contact with whales for their protection.This humpback whale would be all the merrier if all fishing boats were equipped with machine-learning technology to detect their signals. (View large version)Design Pattern: Suggested FeaturesText and speech prediction have opened up new opportunities for interaction with smart devices. Conversational interfaces are the most prominent example of this development, but definitely not the only one. As we try to hide the interface and underlying complexity from users, we are balancing between what we hide and what we reveal. Suggested features help users to discover what the invisible UI is capable of.Graphical user interfaces (GUIs) have made computing accessible for the better part of the human race that enjoys normal vision. GUIs provided a huge usability improvement in terms of feature discovery. Icon and menus were the first useful metaphors for direct manipulation of digital objects using a mouse and keyboard. With multitouch screens, we have gained the new power of pinching, dragging and swiping to interact. Visual clues aren’t going anywhere, but they are not going to be enough when interaction modalities expand.How Does A User Find Out What Your Service Can Do?Haptic interaction in the first consumer generation of wearables and in the foremost conversational interfaces presents a new challenge for feature discovery. Non-visual cues must be used that facilitate the interaction, particularly at the very onset of the interactive relationship. Feature suggestions — the machine exposing its features and informing the user what it is capable of — are one solution to this riddle.In the case of a chatbot employed for car rentals, this could be, “Please ask me about available vehicles, upgrades and your past reservations.”Specific application areas come with specific, detailed patterns. For instance, Patrick Hebron’s recent ebook from O’Reilly contains a great discussion of the solutions for conversational interfaces.Species Of PredictionSeveral generations of TV watchers have been raised to watch weather forecasts for fun, ever since regular broadcasts began after the Second World War. The realm of prediction today is wide and varied. Some applications may involve non-machine learning parts that help in performing predictions.Here I will focus on the prediction of human activities, but note that the prediction of different non-human activities is currently gaining huge interest. Predictive maintenance of machines and devices is one such application, and more are actively envisioned as the Internet of Things generates more data to learn from.Predicting different forms of human behavior falls roughly into the following core learning challenges and applications:recommendations,individual behavior and condition,collective behavior prediction.Different types of recommendations are about predicting user preferences. When Netflix recommends a movie or Spotify generates a playlist of your future favorite music, they are trying to predict whether you will like it, watch it or listen through to the end of the piece. Netflix is on the lookout for your rating of the movie afterwards, whereas Spotify or Pandora might measure whether you are returning to enjoy the same song over and over again without skipping. This way, our behaviors and preferences become connected even without our needing to express them explicitly. This is something machines can learn about and exploit.In design, predicting which content or which interaction models appeal to users could give rise to the personalization of interfaces. This is mostly based on predicting which content a user would be most interested in. For a few years now, Amazon has been heavily personalizing the front page, predicting what stuff and links should be present in anticipation of your shopping desires and habits.Recommendations are a special case of predicting individual behavior. The scope of predictions does not end with trivial matters, such as whether you like Game of Thrones or Lady Gaga. Financial institutions attempt to predict who will default on their loan or try to refinance it. Big human-resource departments might predict employee performance and attrition. Hospitals might predict the discharge of a patient or the prognosis of a cancer. Rather more serious humans conditions, such as divorce, premature birth and even death within a certain timeframe, have been all been predicted with some success. Of course, predicting fun things can get serious when money is involved, as when big entertainment companies try to guess which songs and movies will top the charts to direct their marketing and production efforts.Microsoft’s ML platform demonstrator How Old Do I Look? guesses age (a human condition) based on any uploaded photo or search.The important part about predictions is that they lead to individual assessment that are actionable. The more reliable the prediction and the weightier the consequences, the more profitable and useful the predictions become.Predicting collective behavior becomes a generalization of individuals but with different implications and scope. In these cases, intervention is only successful if it affects most of the crowd. The looming result of a presidential election, cellular network use or seasonal shopping expenditure can all be subject to prediction. When predicting financial risk or a company’s key performance indicators, the gains of saving or making money are noticeable. J.P. Morgan Chase was one of the first banks to increase efficiency by predicting mortgage defaulters (those who never pay back) and refinancers (those who pay back too early). On the other hand, the recent US presidential election is a good reminder that none of this is yet perfect.In a close resemblance to tools for antivirus and other present dangers, future trouble is also predictable. Predictive policing is about forecasting where street conflicts might happen or where squatters are taking over premises, which would help administrators to distribute resources to the right places. A similar process is going on in energy companies, as they try to estimate the capacity needed to last the night.Design Pattern: PersonalizationOnce a computer gets to know you and to predict your desires and preferences, it can start to serve you in new, more effective ways. This is personalization, the automated optimization of a service. Responsive website layouts are a crude way of doing this.The utilization of machine learning features with interfaces could lead to highly personalized user experiences. Akin to giving everyone a unique desktop and homescreen, services and apps will start to adapt to people’s preferences as well. This new degree of personalization presents opportunities as well as forces designers to flex their thoughts on how to create truly adaptive interfaces that are largely controlled by the logic of machine learning. If you succeed in this, you will reward users with a superior experience and will impart a feeling of being understood.Amazon.com’s front page has been personalized for a long time. The selection offered to me looks somewhat relevant, if not attractive. (View large version)Currently, personalization is foremost applied in order to curate content. For instance, Amazon carefully considers which products would appeal to potential buyers on its front page. But it will not end with that. Personalization will likely lead to much bigger changes across UIs — for instance, even in the presentation of the types of interactive elements a user likes to use.Questions To Ask In Considering The Fit Of Machine LearningSay you are now convinced that your users and customers would benefit from a ML-boosted service. Next, you must consider the business and technology perspectives. The first question to ask is, If ML works at least as well as you want, what value would it add to your product? Be honest: Traditional business logic applies here, too.If machine learning doesn’t create value, then it is probably a waste of resources. Marketing people might fancy your new implementation, but the business folks will not necessarily fund your next machine learning experiment unless you have a business case for why machine learning would improve the customer experience or revenue directly.OK, suppose you’ve cleared the viability check box. I expect you also have at least a hypothesis of the core learning challenge. This might be, for example, Can a computer learn to predict when the user would need to take an umbrella or a waterproof jacket when they leave the house in the morning.Next, you’ll need to figure out whether you can expect the machine to learn the job you wish to get done. We’ve come to matters of data. Data broadly refers to any information you can feed the computer: weather data, shopping data for umbrellas and waterproof gear, social media updates and so forth.Here are two simple diagnostic questions to assess the data situation:Do we have enough examples for the machine to learn from?Are there patterns in the teaching material that can be recognized by a human expert?The first question looks easy but is difficult to answer in advance. You need both good quality and a sufficient quantity of data. Some signals are noisy (that is, have poor quality). You might need more examples in these cases than in others. Some features are very prominent and easy to learn, such as in the case of detecting nighttime or daytime in photos. This can be solved with as few as 30 training images!Typical applications require thousands of instances of input data and possibly the desired answers. The more complicated the task, the more material will be needed. AlphaGo learned to master the game after analyzing a staggering 30 million games and then playing some against itself! This is likely excessive in most situations, but it gives you an idea of the scale of what computers can and may need to swallow — from 30 to 30 million. This is one of the reasons why increasing computing capacity and certain hardware really makes computers smarter by speeding up the learning of truly big data.The complexity of Go pushed machine learning capacity to its extremes. Playing the game at random, or by brute force, would be futile. (Image: YouTube) (View large version)The second question is, Are there patterns in the teaching material that can be recognized by a human expert? If a human can do the task, then there’s a fair chance that there are regularities in the data that might be picked up by the computer as well.If you have a positive answer to least one of the questions, you can go forward with some confidence that machine learning might indeed be of use to you. What you’d do after this discovery is mostly beyond the scope of this article.In order to build a machine learning solution, it is best to boldly go and prototype your desired functionality. If you have enough samples, your data scientist teammate will quickly discover whether the machine shows proficiency in the learning task (particularly if you use scalable could computing). If not, you’ll need to get more data.What follows is a series of iterations on the learning mechanisms and a process of integrating it with the product or service. The appearance of intelligent applications can be achieved by carefully putting together several pieces of machine learning and even conventional programming. This is called an ensemble approach. What at best appears as a seamless interactive experience for the user may in fact be the product of a very complex rubric of different machine learning components working together.Human intelligence is heavily needed to tweak the learning algorithms. Such was the architecture underlying Watson, the Jeopardy-winning artificial intelligence system created by IBM and the algorithm that claimed the Netflix Prize. In the latter competition, several teams combined their individual tweaks during the final months of the competition to eventually exceed the criteria for success. This is also what the Google Translate team did to ascend to the next level. And that work is something I consider to fall under the domain of traditional software development.New Design Patterns For Creating Interfaces Of Machine Learning Applications!Illustration: Joonas Haverinen, SC5 (Large preview)Thus far, I’ve talked about the possibilities of machine learning and given some practical advice on how to figure out its feasibility. I’ve also introduced two general design patterns that are tightly connected to machine learning. However, they are not enough.A designer engaged in service and interface design will have several questions concerning interaction in their mind by now. How can we and will we communicate machine intelligence to users, and what kinds of new interfaces will machine learning call for?This entails both opportunities to do things in a new way, as well as requirements for new designs. To me, this means we will need a rise in importance of several design patterns or, rather, abstract design features, which will become important as services get smarter. They include:suggested features,personalization,shortcuts versus granular controls,graceful failure.I have already covered suggested features and personalization as a part of detection and prediction, but what are granularity and graceful failure?Design Pattern: Shortcuts Versus GranularityPhotoshop is an excellent example of a tool with a steep learning curve and a great deal of granularity in controlling what can be done. Most of the time, you work on small operations, each of which has a very specific influence. The creative combination of many small things allows for interesting patterns to emerge on a larger scale. Holistic, black-box operations such as transformative filters and automatic corrections are not really the reason why professionals use Photoshop.What will happen when machines learn to predict what we are doing repeatedly? For instance, I frequently perform certain actions in Photoshop before uploading my photos to a blog. While I could manually automate this, creating yet another user-defined feature among thousands already in the product, Photoshop might learn to predict my intentions and offer a more prominent shortcut, or a highway, to fast-forward me to my intended destination. As Adobe currently puts effort into bringing AI into Creative Cloud, we’ll likely see something even more clever than this very soon. It is up to you to let the machine figure out the appropriate shortcuts in your application.A mockup of a possible implementation of “predictive history” in Photoshop CC. The application suggests a possible future state for the user based on the user’s history and preceding actions and on the current image. (View large version)A funny illustration of a similar train of thought comes from Cristopher Hesse’s machine-learning-based image-to-image translation, which provides interesting content-specific filling of doodles. Similar to Photoshop’s content-aware fill, it creates most hilarious visualizations of building facades, cats, shoes and bags based on minimal user input.The edges2cats algorithm employs machine learning to finish your cat doodle as a photorealistic cat monster. (View large version)Design Pattern: Graceful FailureI call the final pattern graceful failure. It means saying “sorry, I can’t do what you want because…” in an understandable way.This is by no means unique to machine learning applications. It is innately human, but something that computers have been notoriously bad at since the time that syntax errors were repeatedly echoed by Commodore computers in the 1980s. But with machine learning, it’s slightly different. Because machine learning takes a fuzzy-logic approach to computing, there are new ways that the computer could produce unexpected results — that is, things could go very bad, and that has to be designed for. Nobody seriously blames the car in question for the death that occurred in the Tesla autopilot accident in 2016.The other part is that building applications that rely on modern machine learning is still in its infancy. Classic software development has been around for so long that we’ve learned to deal with its insufficiencies better. As Peter Norvig, famous AI researcher and Google’s research director, puts it like this:"The problem here is the methodology for scaling this up to a whole industry is still in progress.… We don’t have the decades of experience that we have in developing and verifying regular software."The nature of learning is such that computers learn from what is given to them. If the algorithm has to deal with something else, then the results will not be to your liking. For example, if you’ve trained a system to detect animal species from pet photos and then start using it to classify plants, there will be trouble. This is more or less why Microsoft’s Twitterbot Tay had to be silenced after it picked up the wrong examples from malicious users when exposed to real-world conditions.The uncertainty in detection and prediction should be taken into consideration. How this is done depends on the application. Consider Google Search. No one is offended or truly hurt, but merely amused or frustrated, by bad search results. Of course, bad results will eventually be bad for business. However, if your bank started using a chatbot that suddenly could not figure out your checking account’s balance, you would be rightfully worried and should be offered a quick way to resolve your trouble.To deal with failure, interfaces would do well to help both parties adjust. Users can tolerate one or two “I didn’t get that, please say that again” prompts (but no more) if that’s what it takes to advance the dialogue. For services that include machine learning, extensive testing is best. Next comes informing users about the probability and consequences of failure, and instructions on what the user might do to avoid it. The good practices are still emerging.SummaryWith machine learning, our vision of tomorrow is quickly becoming today’s reality.Overall, there hardly seems to be an application that machine learning could not be used to detect or predict. I’ve introduced plenty of examples of deploying machine learning to varying success. In all of the examples, I’ve tried to illustrate some core learning challenge to help you understand what sorts of tasks machines respond to. Now it is time to face the question of what machine learning can do for you!I don’t expect that this guide alone will suffice for radical innovation in the sphere of intelligent products and services. I do hope that it will open the eyes of several designers to the opportunities that machine learning solutions afford us today. It is important to understand approximately what you can realistically ask from a machine. In the near future, good questions will become ever more important, so that the answer will be, “Yes, Dave. I can do that.”Thanks to Max Pagels, Janne Aukia, Antti Rauhala, Teemu Kinnunen and Patrick Hebron for discussing the topic.Other Resources“Experience Design in the Machine Learning Era,” Fabien Girardin“Machine learning for product managers,” Article by Neal Lathia“Artificial Intelligence is the New Electricity,” Andrew Ng (Video)Ng talks of product management, but his insights are relevant to design as well.Further ReadingAlgorithm-Driven Design: How Artificial Intelligence Is Changing DesignConversational Design Essentials: Tips For Building A ChatbotDoes Conversation Hurt Or Help The Chatbot UX?Conversational Interfaces: Where Are We Today? Where Are We Heading?
(rb, yk, al, il, mrn)Explore more onCodingProcessProduct StrategyExperience DesignMachine LearningSmashing NewsletterTips on front-end & UX, delivered weekly in your inbox. Just the things you can actually use.Front-End & UX Workshops, OnlineWith practical takeaways, live sessions, video recordings and a friendly Q&A.TypeScript in 50 LessonsEverything TypeScript, with code walkthroughs and examples. And other printed books.Browse All Smashing Magazine TopicsAccessibilityBest practicesBusinessCareerChecklistsCSSData VisualizationDesignDesign PatternsDesign SystemsE-CommerceFigmaFreebiesHTMLIllustratorInspirationJavaScriptMobilePerformancePrivacyReactResponsive DesignRound-UpsSEOTypographyToolsUIUsabilityUXVueWallpapersWeb DesignWorkflowWith a commitment to quality content for the design community.Founded by Vitaly Friedman and Sven Lennartz. 2006–2024.Smashing is proudly running on Netlify, TinaCMS and Swell.Fonts by Latinotype.✎ Write for usContact usAbout us (Impressum)Privacy policyMembership loginDelivery timesAdvertiseBack to top


### apple.txt

Machine learning
Machine learning is a powerful and versatile tool that can help you improve existing experiences and create new ones that people love.

A sketch of an eye, suggesting intelligence. The image is overlaid with rectangular and circular grid lines and is tinted blue to subtly reflect the blue in the original six-color Apple logo.

In addition to providing familiar features like image recognition and content recommendations, your app can use machine learning to forge deep connections with people and help them accomplish more with less effort.
Planning your design

Machine learning apps use models to perform tasks like recognizing images or finding relationships among numerical data. A great machine learning app depends on well-designed models as much as it depends on a well-designed UI and user experience. For insight into the process of designing models, see Create ML.

As you design your models, keep the intended experience of your app in mind. It can take a long time to adjust the behavior of models, so be prepared to change the way you use data and metrics if the app experience needs to change.

Designing the UI and user experience of a machine learning app can be uniquely challenging. Because a machine learning app bases its behavior on the data it receives — reacting to changing information and conditions — you can’t design specific reactions to a static set of scenarios. Instead, you design the experience by teaching the app how to interpret data and react accordingly.

To help you meet this challenge, first consider the role that machine learning plays in your app. Defining the role of machine learning in your app can help you discover areas in which you can explore the ways machine learning can affect the experience your app provides.

Use the machine learning role you identify to help you define ways your app can receive and display data. There are several patterns — grouped into inputs and outputs — that provide guidance in areas such as getting feedback, displaying data, handling mistakes, and supporting corrections. Use the guidance in these patterns to help you integrate machine learning into your app in ways that people appreciate.
The role of machine learning in your app

Machine learning systems vary widely, and the ways an app can use machine learning vary widely, too. As you approach the design of your app, think about how its features use machine learning in each of the following areas.
Critical or complementary

If an app can still work without the feature that machine learning supports, machine learning is complementary to the app; otherwise, it’s a critical dependency. For example:

    The keyboard uses machine learning to provide QuickType suggestions. Because the keyboard still works without these suggestions, machine learning plays a complementary role in the app.

    Face ID relies on machine learning to perform accurate face recognition. Without machine learning, Face ID would not work.

In general, the more critical an app feature is, the more people need accurate and reliable results. On the other hand, if a complementary feature delivers results that aren’t always of the highest quality, people might be more forgiving.
Private or public

Machine learning results depend on data. To make good design decisions, you need to know as much as possible about the types of data your app feature needs. In general, the more sensitive the data, the more serious the consequences of inaccurate or unreliable results. For example:

    If a health app misinterprets data and incorrectly recommends a visit to the doctor, people are likely to experience anxiety and may lose trust in the app.

    If a music app misinterprets data and recommends an artist that people don’t like, they’re likely to view the result as an inconsequential mistake.

As with critical app features, features that use sensitive data must prioritize accuracy and reliability. Regardless of the sensitivity of the data, all apps must protect user privacy at all times.
Proactive or reactive

A proactive app feature provides results without people requesting it to do so. Proactive features can prompt new tasks and interactions by providing unexpected, sometimes serendipitous results. In contrast, a reactive app feature provides results when people ask for them or when they take certain actions. Reactive features typically help people as they perform their current task. For example:

    QuickType suggests words in reaction to what people type.

    Siri Suggestions can proactively suggest a shortcut based on people’s recent routines.

Because people don’t ask for the results that a proactive feature provides, they may have less tolerance for low-quality information. To reduce the possibility that people will find proactive results intrusive or irrelevant, you may need to use additional data for the feature.
Visible or invisible

Apps may use machine learning to support visible or invisible features. People are usually aware of visible app features because such features tend to offer suggestions or choices that people view and interact with. For example, a visible keyboard feature tries to guess the word that people are typing and presents the most likely words in a list from which people choose.

As the name suggests, an invisible feature provides results that aren’t obvious to people. For example, the keyboard learns how people type over time so it can optimize the tap area for each key and help them make fewer typing mistakes. Because this app feature improves the typing experience without requiring people to make choices, many people aren’t aware that the feature exists.

People’s impression of the reliability of results can differ depending on whether a feature is visible or invisible. With a visible feature, people form an opinion about the feature’s reliability as they choose from its results. It’s harder for an invisible feature to communicate its reliability — and potentially receive feedback — because people may not be aware of the feature at all.
Dynamic or static

All machine learning models can improve, but some improve dynamically, as people interact with the app feature, and others improve offline and affect the feature only when the app updates. For example:

    Face ID improves dynamically as people’s faces gradually change over time.

    Photos improves its object recognition capabilities with every new iOS release.

In addition to the frequency of app updates, static or dynamic improvements can affect other parts of the user experience, too. For example, dynamic features often incorporate forms of calibration and feedback (either implicit or explicit), whereas static features might not.
Explicit feedback

Explicit feedback provides actionable information your app can use to improve the content and experience it presents to people. Unlike implicit feedback — which is information an app gleans from user actions — explicit feedback is information people provide in response to a specific request from the app.

An illustration of a menu above a screen representing presented content on iPhone. The menu includes a variety of options for interacting with the content on screen, including an option to 'Love' the presented content, and an option to 'Suggest Less Like This.'

Favoriting — marking an item for quick access in the future — and social feedback — expressing emotions towards others — are common user interactions that seem like mechanisms that supply explicit feedback. However, these tools actually provide implicit feedback because they don’t support app-specific requests. People use favoriting and social feedback to accomplish their own goals and apps can gather implicit feedback from these interactions.

Request explicit feedback only when necessary. People must take action to provide explicit feedback, so it’s best to avoid requesting it if possible. Instead, consider using implicit feedback to learn how people interact with your app without asking them to do extra work.

Always make providing explicit feedback a voluntary task. You want to communicate that explicit feedback can help improve the experience without making people feel that providing it is mandatory.

Don’t ask for both positive and negative feedback. Good suggestions don’t require any feedback, so you don’t want to imply that people need to give positive feedback on all the results they like. Instead, give people the opportunity to provide negative feedback on results they don’t like so that you can improve the experience.

Use simple, direct language to describe each explicit feedback option and its consequences. Avoid using imprecise terms such as dislike because such terms don’t convey consequences and can be hard to translate. Instead, describe each option in a way that helps people understand what happens when they choose the option, such as:

    Suggest less pop music

    Suggest more thrillers

    Mute politics for a week

Add icons to an option description if it helps people understand it. Icons can help clarify or emphasize part of an option description. Avoid using an icon by itself, because it might not be clear enough to communicate granularity or consequences.

Consider offering multiple options when requesting explicit feedback. Providing multiple options can give people a sense of control and help them identify unwanted suggestions and remove them from your app. To help people provide feedback, consider offering options that become progressively more specific so that it’s easy for people to clarify their response.

Act immediately when you receive explicit feedback and persist the resulting changes. For example, if people identify content they don’t want to see, that the content instantly disappears from their view and doesn’t appear elsewhere in your app. When you react immediately to feedback and show that your app remembers it, you build people’s trust in the value of providing it.

Consider using explicit feedback to help improve when and where you show results. For example, people might like a result, but they may not want to see it at certain times or in certain contexts. Explicit feedback on when and where to show results can help you fine-tune the experience people have in your app.
Implicit feedback

Implicit feedback is information that arises as people interact with your app’s features. Unlike the specific responses you get from explicit feedback, implicit feedback gives you a wide range of information about user behavior and preferences. Although incorporating implicit feedback isn’t required for a great machine learning app, the feedback can help you improve your app’s user experience without asking people to do any extra work.

A screenshot of a Workout app screen on Apple Watch. The screen includes text that reads 'It looks like you're working out', above buttons in a scrolling list. The two visible buttons are titled 'Record Outdoor Run' and 'Record Indoor Run'.

Always secure people’s information. Implicit feedback can gather potentially sensitive user information, so you must be particularly careful to maintain strict controls on user privacy.

Help people control their information. As an app developer, you know that the more you understand about the behavior of your users — both within your app and in other apps — the more you can improve the experience your app provides. Although most people understand the benefits of making their information available to multiple apps, they may still be surprised when things they do in one app affect experiences they have in a different app. Worse, people may assume that apps are sharing their private information, which can cause them to lose trust in the apps. It’s important to tell people how your app gets and shares their information and to give people ways to restrict the flow of their information.

Don’t let implicit feedback decrease people’s opportunities to explore. Implicit feedback tends to reinforce people’s behavior, which can improve the user experience in the short term, but may worsen it in the long term. For example, it might seem like a good idea to give people a set of suggestions that matches all the things they’re interested in now, but doing so doesn’t encourage them to explore new things.

When possible, use multiple feedback signals to improve suggestions and mitigate mistakes. Implicit feedback is indirect, so it can be difficult to discern a person’s actual intent in the information you gather. For example, if someone views a photo, shares it in a message, and adds it to a shared album, it doesn’t necessarily mean they have positive feelings about the photo. Incorporate implicit feedback from multiple sources and interactions to help you avoid misinterpreting people’s intentions.

Consider withholding private or sensitive suggestions. People often share their accounts and devices with others, or switch from using a personal device to a communal one. If your app receives implicit feedback related to private or sensitive topics, avoid offering recommendations based on that feedback.

Prioritize recent feedback. People’s tastes can change frequently, so base your recommendations on recent implicit feedback. For example, Face ID prioritizes recent facial input because it’s most likely to represent what the person looks like now. If recent feedback isn’t available, you can fall back to historical feedback.

Use feedback to update predictions on a cadence that matches the person’s mental model of the feature. For example, people expect typing suggestions to update immediately as they’re typing. On the other hand, giving people continuously updated song recommendations makes it hard to consider individual songs and could make them feel rushed or overwhelmed.

Be prepared for changes in implicit feedback when you make changes to your app’s UI. Even small UI changes can lead to noticeable changes in the amount and types of implicit feedback. For example, changing the location of a button can affect how people use it, even if there’s no change in the benefit they get from the button’s action. Take such changes into account when interpreting the implicit feedback you receive from interactions in your app.

Beware of confirmation bias. Implicit feedback is constrained by what people can actually see and do in your app and other apps — it rarely gives you insight into new things they might like to do. Avoid relying solely on implicit feedback to inform your results.
Calibration

Calibration is a process during which people provide information that an app feature needs before it can function. To use Face ID, for example, a person must first scan their face.

A screenshot of the Face ID setup screen on iPhone. A face appears inside the circular frame and tick marks around the frame show that a face scan hasn't begun yet. Text below the frame explains how to perform a scan, and appears above a 'Get Started' button.

In general, only use calibration when your feature can’t function without that initial information. If your feature can work without calibration, consider using other ways to gather the information you need, such as implicit feedback or possibly explicit feedback.

Always secure people’s information. During calibration, people may provide sensitive information and you must make sure it remains secure.

Be clear about why you need people’s information. Typically, calibration is required before people can use a feature, so it’s essential that they understand the value of providing their information. As you briefly describe how people can benefit from your feature, emphasize what it does rather than how it works.

Collect only the most essential information. Designing a unique experience that requests a minimal amount of information can make people more comfortable participating in the process and increase their trust in your app.

Avoid asking people to participate in calibration more than once. Also, it’s best when calibration occurs early in the user experience. As people continue using your app or feature, you can use implicit or explicit feedback to evolve your information about them without asking them to participate again. An exception is a feature that needs calibration with an object instead of a person. For example, an app that helps people improve their baseball swing might need to calibrate with each new baseball field.

Make calibration quick and easy. Even a brief calibration experience takes time and requires effort from people. An ideal calibration experience makes it easy for people to respond, without compromising the quality of the information they provide. The following guidelines can help you create a streamlined calibration experience.

    Prioritize getting a few pieces of important information and infer the rest from other sources or by getting people’s feedback.

    Avoid asking for information that most people would have to look up.

    Avoid asking people to perform actions that might be difficult.

Make sure people know how to perform calibration successfully. After people decide to participate in calibration, give them an explicit goal and show their progress towards it. For example, Face ID calibration briefly describes what people need to do and changes the appearance of the tick marks encircling the face as people progress through scanning.

Immediately provide assistance if progress stalls. When progress stalls, people can feel stuck or powerless, and they may lose trust in your app. In this situation, it’s crucial to give people actionable recommendations that quickly get them back on track. As you provide this guidance, never imply that something’s wrong or that people are at fault, and never leave people without a clear next step.

Confirm success. The moment people successfully complete calibration, reward their time and effort by giving them a clear path towards using the feature. Providing an explicit completion to the calibration experience reinforces the unique nature of the experience and helps people switch their focus to your feature.

Let people cancel calibration at any time. Make sure you give people an easy way to cancel the experience at any point and avoid implying any judgement about their choice. There’s no need to provide any messaging that mentions the canceled calibration, because the next time people attempt to use the feature, they’ll have another chance to participate.

Give people a way to update or remove information they provided during calibration. Letting people edit their information gives them more control and can lead them to have greater trust in your app. Although the calibration experience can help people edit their responses, it’s a good idea to let people edit their information outside of the calibration experience so that they feel free to make changes at any time.
Corrections

People use corrections to fix mistakes that apps make. For example, if a photo app automatically crops a photo in a way people don’t like, they can correct the mistake by cropping the photo in a different way.

A screenshot of the Camera app on iPhone showing a photo of a flower in editing mode. The crop and straighten function is selected, revealing grab bars on all edges of the photo. The tilt wheel button below the photo shows that someone chose a small tilt in the positive direction.

Give people familiar, easy ways to make corrections. When your app makes a mistake, you don’t want people to be confused about how to correct it. You can avoid causing confusion by showing the steps your app takes as it performs the automated task. For example, Photos highlights the controls it uses to auto-crop a photograph so that people can use the same controls to refine or undo the results.

Provide immediate value when people make a correction. Reward people’s effort by instantly displaying corrected content, especially when the feature is critical or you’re responding to direct user input. Also, be sure to persist the updates so people don’t have to make the same corrections again.

Let people correct their corrections. Sometimes, people make a correction without realizing that they’ve made a mistake. As you do with all corrections, respond immediately to an updated correction and persist the update.

Always balance the benefits of a feature with the effort required to make a correction. People may not mind when a feature that automates a task makes a mistake, but they’re likely to stop using the feature if it seems easier to perform the task themselves.

Never rely on corrections to make up for low-quality results. Although corrections can reduce the impact of a mistake, depending on them may erode people’s trust in your app and reduce the value of your feature.

Learn from corrections when it makes sense. A correction is a type of implicit feedback that can give you valuable information about ways your app doesn’t meet people’s expectations. Before you use a correction to update your models, make sure that the correction will lead to higher quality results.

When possible, use guided corrections instead of freeform corrections. Guided corrections suggest specific alternatives, so they require less user effort; freeform corrections don’t suggest specific alternatives, so they require more input from people. An example of guided correction is a speech-to-text feature that gives people a list of alternative text completions from which to choose. In contrast, Photos offers freeform correction so that people can adjust the auto-cropping of a photo as they see fit. If it makes sense in your app, you can support a combination of guided and freeform corrections.
Mistakes

It’s inevitable that your app will make mistakes. Although people may not expect perfection, mistakes can damage their experience and decrease their trust in your app. To help you avoid negative consequences, it’s crucial to:

    Anticipate mistakes. As much as possible, design ways to avoid mistakes and mitigate them when they happen.

    Help people handle mistakes. Mistakes can have a wide range of consequences, so the tools you provide to handle a mistake must be able to address those consequences.

    Learn from mistakes when doing so improves your app. In some cases, learning from a mistake might have undesirable effects, such as causing unpredictability in the user experience. When it makes sense, use each mistake as a data point that can refine your machine learning models and improve your app.

There are several machine learning patterns that can help you address mistakes:

    Limitations help you set people’s expectations about the accuracy of your suggestions.

    Corrections give people a way to be successful even when your results are wrong.

    Attribution gives people insight into where suggestions come from, which can help them understand mistakes.

    Confidence helps you gauge the quality of your results, which can impact how you present them.

    Feedback — both explicit and implicit — lets people tell you about mistakes that you might not be aware of.

Understand the significance of a mistake’s consequences. For example, incorrect keyboard suggestions might annoy people, but suggesting a travel route that results in a missed flight is a serious inconvenience. Show empathy by providing corrective actions or tools that match the seriousness of the mistake.

Make it easy for people to correct frequent or predictable mistakes. If you don’t give people an easy way to correct mistakes, they can lose trust in your app.

Continuously update your feature to reflect people’s evolving interests and preferences and help avoid mistakes. For example, you can use implicit feedback to discover changes in people’s tastes and habits. It’s also a good idea to update your feature with domain-specific information, such as current trends in popular entertainment. Ideally, people don’t have to do any work to benefit from improvements in your app.

When possible, address mistakes without complicating the UI. Some patterns, such as corrections and limitations, tend to integrate seamlessly with an app’s UI, whereas others, like attributions, can be harder to integrate. Balance a pattern’s effect on the UI with its potential for compounding the mistake. For example, if you update the UI with an attribution that turns out to be wrong, the effect of the original mistake is magnified.

Be especially careful to avoid mistakes in proactive features. A proactive feature — like a suggestion based on people’s behaviors — promises valuable results without asking people to do anything to get them. However, because people don’t request a proactive feature, they often have less patience with its mistakes. Mistakes made by proactive features can also cause people to feel that they have less control.

As you work on reducing mistakes in one area, always consider the effect your work has on other areas and overall accuracy. For example, optimizing an image-recognition app to improve how it recognizes dogs might result in a decreased ability to recognize cats. As your models evolve, be prepared for mistakes to evolve, too. Use what you know about people’s preferences to help you determine the areas to work on.
Multiple options

Depending on the design of your feature, it might work best to present a single result or multiple results from which people can choose. Providing multiple options can give people a greater sense of control and can help bridge the gap between your model’s predictions and what people actually want. Multiple options can also encourage people to have realistic expectations about the types of results your app generates.

A screenshot of the Maps app on Mac, displaying the San Francisco Bay Area. The map shows three different routes between San Francisco and Apple Park.

You might present multiple options to people in the following contexts:

    Suggested options, a proactive feature that suggests content to people based on the their past interactions. For example, For You recommendations from Apple Music.

    Requested options, a reactive feature that suggests potential next steps to people based on their recent actions. For example, Quick Type suggestions.

    Corrections, which are actions people take to fix mistakes your app has made when it’s acting on their behalf. For example, the Photos Auto-Crop feature.

Prefer diverse options. When possible, balance the accuracy of a response with the diversity of multiple options. For example, Apple Maps generally suggests more than one route to a destination, such as a route without tolls, a scenic route, or a route that uses highways. Providing different types of options helps people choose the one that they prefer and can also suggest new items that might interest them.

In general, avoid providing too many options. People must evaluate each option before making a choice, so more options increases cognitive load. When possible, list options on one screen so people don’t have to scroll to find the right one.

List the most likely option first. When you know how your confidence values correlate with the quality of your results, you might use them to rank the options. You might also consider using contextual information, such as the time of day or the current location, to help you determine the most likely option. If it makes sense in your app, select the first option by default so people can quickly achieve their goals without reading through every option.

Make options easy to distinguish and choose. For example, in a routing app, people often need to make route choices quickly to avoid going the wrong way. When options look similar, help people distinguish between them by providing a brief description of each one and taking particular care to highlight the differences. In cases where there are too many options to display in a single view, such as with content recommendations, consider grouping options in categories that people can scan rapidly.

Learn from selections when it makes sense. People give you implicit feedback every time they make a selection. When it doesn’t adversely affect the user experience, use this feedback to refine the options you provide and increase the chance that you’ll present the most likely option first. In general, continuing to offer incorrect results is likely to decrease people’s trust in the quality of your app’s predictions.
Confidence

Confidence indicates the measure of certainty for a result. Not all models produce confidence values by default, so you might consider generating them if you can use them to improve the user experience of your app.

A screenshot of a flight tracker app on iPhone. The screen displays a flight from SFO to LAX from June 3rd through June 7th. The screen shows the current lowest flight cost with a recommendation to watch over the next four weeks for a lower price. The screen includes buttons labeled 'Track' and 'View Flights', and a search field to find new dates for comparison. The active tab on the screen is titled 'Track', and there are other tabs titled 'Search' and 'Flights.'

Although it might seem like higher confidence produces a higher quality result — and therefore a better user experience — it doesn’t necessarily work that way. You need to verify that your confidence values correspond to the quality of your results. For example, you might review values for multiple confidence thresholds or compare values across multiple versions of your app. If you’re not sure how your confidence values correlate with the quality of your results, it’s not a good idea to convey confidence to people.

Know what your confidence values mean before you decide how to present them. For example, people may forgive low-quality results from critical or complementary features — especially when results are accompanied by attribution or other contextual information — but presenting low-quality results in a prominent way is likely to erode trust in your app.

In general, translate confidence values into concepts that people already understand. Simply displaying a confidence value doesn’t necessarily help people understand how it relates to a result. For example, a feature that suggests new music based on a person’s listening habits might calculate that there’s a 97% match between a new song and the songs they usually listen to. However, displaying “97% match” next to the new song as an attribution doesn’t communicate enough information to help people make a choice. In contrast, providing an attribution that clearly identifies the behavior — such as “Because you listen to pop music” — can be more actionable.

In situations where attributions aren’t helpful, consider ranking or ordering the results in a way that implies confidence levels. If you must display confidence directly, consider expressing it in terms of semantic categories. For example, a feature that predicts travel prices might replace ranges of confidence numbers with categories like “high chance” and “low chance” to give context to the values and help people understand and compare the results.

In scenarios where people expect statistical or numerical information, display confidence values that help them interpret the results. For example, weather predictions, sports statistics, and polling numbers are often accompanied by specific values that express the accuracy of the data as an interval or a percentage.

Whenever possible, help people make decisions by conveying confidence in terms of actionable suggestions. Understanding people’s goals is key to expressing confidence in ways that help them make decisions. For example, if your feature predicts when an item will be at its lowest price, you know that people want to optimize how they spend their time and money. For a feature like this, displaying percentages or other numerical confidence values would be less valuable than providing actionable suggestions like “This is a good time to buy,” or “Consider waiting for a better price.”

Consider changing how you present results based on different confidence thresholds. If high or low levels of confidence have a meaningful impact on the ways people can experience the results, it’s a good idea to adapt your presentation accordingly. For example, when confidence is high, the face recognition feature in Photos simply displays the photos that contain a specific person, but when confidence is lower, the feature asks people to confirm whether the photos contain the person before showing more.

When you know that confidence values correspond to result quality, you generally want to avoid showing results when confidence is low. Especially when a feature is proactive and can make unbidden suggestions, poor results can cause people to be annoyed and even lose trust in the feature. For suggestions and proactive features, it’s a good idea to set a confidence threshold below which you don’t offer results.
Attribution

An attribution expresses the underlying basis or rationale for a result, without explaining exactly how a model works. Depending on the design of your app, you might want to use attributions to impart transparency and give people insight into your results. For example, if your app suggests books for people to read, you might use an attribution like “Because you’ve read mysteries” when you suggest books in the “thrillers” category.

An illustration of a screen on iPhone, which shows an area that contains recommended videos. The area is labeled 'For You' and includes a row of two video icons. A third video icon is partially visible on the right side of the screen, hinting at additional recommendations.

To help you decide whether to include attributions in your app, consider how you want them to affect people. For example, you might want attributions to:

    Encourage people to change what they do in your app

    Minimize the impact of mistakes

    Help people build a mental model of your feature

    Promote trust in your app over time

Consider using attributions to help people distinguish among results. For example, if you present a set of results as multiple options, including attributions can help people choose an option based on their understanding of the premise that led to it, such as “New books by authors you’ve read.”

Avoid being too specific or too general. Overly specific attributions can make people feel like they have to do additional work to interpret the results, whereas overly general attributions typically don’t provide useful information. In apps that make content recommendations, general attributions can make people feel like your app is not treating them as individuals, but overly specific attributions can make people think that your app is watching them too closely. The best attributions strike a balance between these extremes.

Keep attributions factual and based on objective analysis. To be useful, an attribution needs to help people reason about a result; you don’t want to provoke an emotional response. Don’t provide an attribution that implies understanding or judgment of people’s emotions, preferences, or beliefs. For example, an app that recommends new content to people can use an attribution like “Because you’ve read nonfiction” instead of an attribution like “Because you love nonfiction.”

In general, avoid technical or statistical jargon. In most situations, using percentages, statistics, and other technical jargon doesn’t help people assess the results you provide. The exception to this is when the result itself is of a statistical or technical nature, such as information in the areas of weather, sports, polling and election results, or scientific data.
Limitations

Every feature — whether it’s based on machine learning or not — has certain limitations to what it can deliver. In general, there are two types of limitations: things a feature can’t do well and things a feature can’t do at all. When there’s a mismatch between people’s expectations about a feature and what the feature can actually accomplish, a limitation can seem like a defect. For example, people might expect:

    Photos to perform a search that covers every category they can imagine

    Siri to respond to queries that aren’t well defined, like “What is the meaning of life?”

    FaceID to work from every angle

An important part of the design process is to identify the scenarios where limitations impact the user experience and design ways to help people work with them. For example:

    Set people’s expectations before they use the feature.

    Show people how to get the best results while they’re using the feature.

    When inferior results occur, explain why so that people can understand the feature better.

A screenshot of the Memoji recording sheet on iPhone. The app shows a person's Memoji, above a message that reads 'Low light', which helps convey that additional light is required for a high-quality recording.

Help people establish realistic expectations. When a limitation may have a serious effect on user experience but happens rarely, consider making people aware of the limitation before they use your app or feature. You might describe the limitation in marketing materials or within the feature’s context so that people can decide how they want to rely on the feature. If the effects of a limitation aren’t serious, you can help set people’s expectations by providing attributions.

Demonstrate how to get the best results. If you don’t provide guidance for using a feature, people may assume it’ll do everything they want. When you proactively show people how to get good results, you help them benefit from the feature and establish a more accurate mental model of the feature’s capabilities. There are many ways to show people the best ways to use a feature, such as:

    Use placeholder text to suggest input. In Photos, the search bar displays the text “Photos, People, Places…” to help people understand what they can search for before they begin typing. Photos also displays a description of how it scans the photo library to offer search suggestions.

    As people interact with the feature, provide feedback on their actions to guide them towards a result without overwhelming them. For example, while people are interacting with Animoji, the feature responds to current conditions and suggests how people can improve their results by adjusting the lighting or moving closer to the camera.

    Suggest alternative ways to accomplish the goal instead of showing no results. To do this successfully, you need to understand the goal well enough to suggest alternatives that make sense. For example, if people ask Siri to set a timer on a Mac, Siri suggests setting a reminder instead, because timers aren’t available in macOS. This suggestion makes sense because people’s goal is to receive an alert at a certain time.

Explain how limitations can cause unsatisfactory results. People can get frustrated when it seems that your feature works intermittently. Ideally, your feature can recognize and describe the reasons for poor results to make people aware of the limitations and help them to adjust their expectations. For example, Animoji tells people that it doesn’t work well in the dark.

Consider telling people when limitations are resolved. When people use a feature frequently, they learn to avoid the interactions that fail because of the feature’s limitations. When you update your app to remove a limitation, you might want to notify people so that they can adjust their mental model of your feature and return to interactions they’d previously avoided.
Platform considerations

No additional considerations for iOS, iPadOS, macOS, tvOS, visionOS, or watchOS.
Resources
Developer documentation

Create ML
Videos
Build dynamic iOS apps with the Create ML framework
Explore the Action & Vision app
Designing Great ML Experiences
Change log

Date
	

Changes

October 24, 2023
	

Added art to Corrections section.

May 2, 2023


### fitts.txt

Fitts’s Law | Laws of UXdown arrowdrop down arrowdrop up arrowleft arrowright arrowup arrowclosedownloadexternal linkfacebookFiltergridlanguageLinkedInlogomenunotificationPinterestsharetwitterSkip to main contentLaws of UX
MenuArticlesBookCardsInfoStore

English
EnglishعربيEspañolفارسیBack to allFitts’s LawThe time to acquire a target is a function of the distance to and size of the target.The time to acquire a target is a function of the distance to and size of the target.TakeawaysTouch targets should be large enough for users to accurately select them.Touch targets should have ample spacing between them.Touch targets should be placed in areas of an interface that allow them to be easily acquired.OriginsIn 1954, psychologist Paul Fitts, examining the human motor system, showed that the time required to move to a target depends on the distance to it, yet relates inversely to its size. By his law, fast movements and small targets result in greater error rates, due to the speed-accuracy trade-off. Although multiple variants of Fitts’ law exist, all encompass this idea. Fitts’ law is widely applied in user experience (UX) and user interface (UI) design. For example, this law influenced the convention of making interactive buttons large (especially on finger-operated mobile devices)—smaller buttons are more difficult (and time-consuming) to click. Likewise, the distance between a user’s task/attention area and the task-related button should be kept as short as possible.SourceFurther ReadingFitts's Law and Its Applications in UXNielsen Norman GroupFitts’ Law In The Touch EraSmashing MagazineFitts’s Law: The Importance of Size and Distance in UI DesignInteraction Design FoundationFitts’s Law on WikipediaWikipediaDesign for Fingers, Touch, and People, Part 1Steven Hoober | UX MattersThe information capacity of the human motor system in controlling the amplitude of movementSemantic ScholarBuy Large Format Poster
Download free posterRelatedDoherty ThresholdProductivity soars when a computer and its users interact at a pace (<400ms) that ensures that neither has to wait on the other.Hick’s LawThe time it takes to make a decision increases with the number and complexity of choices.Aesthetic-Usability EffectUsers often perceive aesthetically pleasing design as design that’s more usable.NextGoal-Gradient EffectBack to Top© Jon Yablonski 2024ContactOval 9 CopyCombined ShapeRectangle 15Oval 3triangle

### pdfs.txt

Data 
Material
Ideas, Information & Concepts 
about DataBook3Index
Data: What’s Next? 05
10
20
46
61Data Everywhere 
Why Do I Need This Book? 
How Does This Set Work? 
Data & Design
Data Has Many Faces
Data in this Book 
Data Can Improve Your Work  
Expertise & Alliances  
Intuition & Gut Feeling 
Data: Roles & Goals 
Data and Y our Project Data Strategist  
Data Creative 
UX Designer  
Guiding Principle  
New Chances (GDPR)
Best Practices 
Be Bold, Explore and Think Critically
User-Centered Design Process
— Understand - Understanding Leads to Insights
— Create - Creation Ends in Ideas
— Build – Building Ends in Reality 4Data is here, data is around us. We create it each time we 
interact with our precious digital companions, mostly with-
out realizing. The digital services and products that we use 
know a lot about us and communicate with each other, in 
the language of data. Data Everywhere 
We usually only become aware of the full scope of our con-
nected environment when things go wrong. For example, 
a security breach in service provider’ s database can reveal 
masses of personal data about millions of people. This can 
include very private information like sexual preferences, 
personal conversations and bank details. Failures in data 
handling, such as these, are unfortunately becoming more 
and more common. 
A whole new universe of possibilities has opened up in 
terms of how we can explore and use data. One big issue 
in this process is the responsible use of that data and the 
consideration of how this can impact people’ s lives.Data is like water. It is stored, it is filtered and  
converted into new forms. Byte by byte. This happens  
in businesses as well as in governments. 5»Behind every single point of 
data is a human—a real  
person.«
Rochelle King,
Global VP Product Design 
and Insights, Spotify6Why Do I Need This Book? 
As designers, we are the forefront of technological ad-
vancements that can have a huge impact on society. We 
draw from the flux of data and give new digital products a 
face with which people can interact. The source of our data 
is usually human; in the form of behavioural tendencies and 
personal information. We are able to take this information, 
reflect on it, create new ideas and validate our existing 
theories. Data allows us to design seamless services and 
beautiful things that benefit many people’ s lives. 
The role of the designer is becoming increasingly broad 
and with this comes increased responsibility to uphold 
what we create. Many companies give few thoughts to the 
consequences of their use of personal data, or use ethically 
questionable ways to collect it. Just take the example of 
Facebook’ s »internet.org« campaign: Which grant people in 
regions with weak infrastructures »free internet« to access 
only facebook. It is important for designers to understand 
the sources of data, how to make the best use of it for their 
project, but also importantly: how to use it in a responsible 
and ethical way.  This book will be your guide to this.7»It seems that we are heading 
towards a critical point, at 
which it will be decided how 
the digital world is going to 
look in the following decades. 
Are advances in technology 
always good in the end? How 
much power should private 
companies have over our 
lives?«
Thomas Schulz ,
author of »Was google wirklich will»8How Does This Set Work? 
This workbook is part of a set, which also includes cards for 
ideation for your project, a canvas and a model for evaluat-
ing your ideas. 
The book should be your guide through the complex 
topic of handling human data in the design process and 
teaches you the basics of the concept data. 
It has been created to help you, regardless of the kind of de-
sign you are working on: whether you are a service designer 
creating a new business model or an interaction designer 
optimising a digital product. It will help you in the form of 
information, tools, and experience to start your project. 
This book does not claim to be a complete guide or cover all 
levels of the topic of data. The focus is on the private sector. 
But when it comes to human data, this is a great starting 
point. 
In the first four chapters, the book gives you a brief over -
view of the topic data. In chapter four »Data and your Pro-
ject« the focus is on different steps of User-Centred Design 
processes to give you first-hand ideas and tools to start 
your project.9Design Human Data KitHow and Why should 
personal data be used? 
Which kind of personal 
data are services using?
What exactly are we 
talking about?Knowledge
Data Material Book1Acting Ethical 
Gathering experience and 
developing attitudes4
Analyse
Personal Data Cards2Validation
Canvas & Privacy Model310Many things in our environment produce data automatical-
ly without human influence. From  automated processes 
in factories to smartphones. Data floats between devices, 
services, and companies. Once produced, recorded, and ag-
gregated they begin their complicated existence. They can 
be anonymized, separated, interpreted, and combined into 
new forms. But it’ s nearly impossible to delete a particular 
data set once it has been produced and is part of the data 
supply chain.Data & Design
Data Has Many Faces 
Mobile DataCompany 1
Anonymizing 
dataCompany 2
Buy data set,
separate dataCompany 3
Trading data set,
combine it with 
other sources
IndividualLocations, Call 
length, App usages11This book looks at data as being more than numerical 
outcomes. Normally, data are distinguished in two rough 
directions: quantitative and qualitative data. 1 Quantitative 
data is gathered in a numerical form, which can be put into 
categories or measured. 2 Qualitative data is empirical and 
comes in the form of observations and interviews. But re-
gardless of the form, all data needs humans to interpret it.
Besides these two distinctions, there are many other 
sources of data, and this book will focus on humans as the 
main source. Generally, this is known as personal data. The 
handling and scope of personal data differs from country to 
country. For example, the US Government has comparative-
ly little regulation over the use of personal data, whereas 
the European Union has much stricter rules. Data in this Book
What happened? 
5320 people visited the web-
shop this month. Only 13% 
bought something.Why did it happened? 
Over 20 people have reported 
payment problems to customer 
support. 1 212This book works with a model of personal data from the 
world economic forum, which was created independently of 
definitions by local governments.
Identity
HealthdataContentRelationshipsGovernment  
RecordsActivity
CommunicationWhich videos did 
I watch? Who are my 
friends?What did I have 
for lunch?Certificate of 
good conductPersonal data affects many 
areas of our lives
Individual13Voluntary data - created and explicit-
ly shared by individuals, e.g. content in 
social networks Observed data - records the actions of 
individuals, e.g. location data when using 
mobile phones.Inferred data - Data about individuals 
based on the analysis of volunteers or 
observed information, e.g. credit scores
We define personal data as... 
in the categories of...Data (and metadata) created 
by and about people14Data Can Improve Y our Work 
Models like the User-Centered Design or Human-Centered 
Design approach focus on users and their needs at all 
stages of the design process: from the initial research and 
strategy phase to the design and development of a product. 
The right mix of data will help you and your team to identify 
problems (quantitative data: e.g., surveys, a/b testing, web 
analytics) and let you get to the bottom of why something 
is happening (qualitative data: e.g., interviews, observa-
tions). This mix will increase the quality of the work by your 
team and ensure that people and their needs are always 
at the forefront of your thinking. In the chapter »Data and 
Your Project« this book will give you tools and strategies to 
help you make the most of the data available to you for your 
project.
»If you only have quantitative 
data and no qualitative data, 
you understand what happened 
but you don't understand why. 
If you have only qualitative 
data, you understand why but 
not what happened.«
Dave Lippman,
(VP Design eBay)15Expertise & Alliances 
Speak with a data analytics team or developers who 
regularly work with data. Y ou don’t have to become a 
data scientist or a business analyst yourself. As designers, we are able to overcome silo mentality with 
our interdisciplinary approach of combining methods from 
different fields. We ask questions to gain a new perspective 
on situations. When you are new to the field of data, there 
is no shame in beginning by asking questions in order to un-
derstand the practices of your company or client. What do 
we need the data for? How do we aggregate data? How will 
our use of personal data impact people’ s lives? These are all 
relevant questions. 
Sometimes not all your questions can be answered by the 
person who you usually consult about your projects. But 
the experts are there if you look for them; people who can 
give you answers or help you to refine your questions inside 
the work environment. 
But the more you know about data processes and the mod-
els behind them, the more chance you have of influencing 
the current practices within your project or company. Get 
in touch with people and share your current understand-
ing. This will help you build on your knowledge and create 
alliances for future ideas.16Intuition & Gut Feeling 
Designing in a digital age is always a fine balance between 
data and intuition. Data shows you in hard numbers or 
softer analysis the performance of your work. Do the ideas 
which you and your team created work? How are people 
responding to your ideas? Far too often discussions go in 
the direction of data (or performance) vs. intuition. But this 
doesn’t lead us anywhere. Data can give you hints or sug-
gestions to start your work and give you answers beyond 
»yes« or »no«. But they do not provide the ultimate truth. 
They can give you answers to your questions if you ask the 
right ones - depending on the method and the diversity of 
your team. But it’ s always up to you to decide if you take 
these suggestions on board. Use data experts and methods 
to strengthen your feeling about an idea.
Quantitative 
DataQualitative 
DataIntuition
Data Informed17It's not about becoming a data expert yourself. According 
to King, Churchill and Tan in the book »Designing with Data: 
Improving the User Experience with A/B Testing" there are 
two distinct categories to describe the different levels of 
data knowledge appropriate for different kinds of projects. 
Combine your experience and intuition with well designed 
and suitable data to make better decisions. Stay true to the 
credo »lead through your intuition, be informed by data, be 
driven by empathy.« In the chapter »Data and your Project« 
this book will show you tools and strategies to benefit from 
data in your project.It is good to be data informed when dealing with a 
concrete project, as it helps you to know more about 
a specific problem. It is better to be data aware when 
dealing with a broader range of problems, as it helps 
you to think more strategically about the use of data.
Data 
informedData 
aware2118Data aware
A more philosophical and stra-
tegic view on data. 
You think about many kinds of 
problems with a diverse set of 
data in mind. 
Example: »We have a plan to 
improve our service by offering 
customers their data in one 
place.«Data informed
The practice around data. 
Being data informed is a crea-
tive and highly iterative pro-
cess. You have an awareness 
of options and mechanisms to 
help you learn more about a 
specific problem.
Example: »Our online behavior 
data shows, that customers 
hardly use our FAQ section. 
Let’ s ask customer support and 
interview some customers to 
find out why.«1 219»Good design begins with 
honesty, asks tough questions, 
comes from collaboration and 
from trusting your intuition«
Freeman Thomas,
(Industrial Designer)20Our ideas about specific job roles within companies are 
changing and expanding due to the increase in the sourc-
es of data available to us and the larger range of projects 
that arise from this. Data permeates our projects from all 
sides and makes it necessary that we adapt ourselves and 
our tasks accordingly. This chapter describes new ideas for 
professional roles. Which may arise.Data: Roles & Goals21Similar to the Design Strategist, the Data Strategist com-
bines creative and analytical skills to create innovative 
strategies. The role implies discovering new opportunities 
in the data field and working on strategies to plan, store and 
use aggregated data in an ethical and balanced way for all 
involved parties. For example, a Data Strategist could work 
with different stakeholders to create an overview about a 
company’ s data silos and ideate new ways to connect these 
silos to benefit customers in the future.  
Responsibilities 
As a Data Strategist you …
• … are a business partner at 
strategy level and communi-
cate with stakeholders on an 
equal level 
• … are in charge of discovering 
the (hidden) data silos of com-
panies involved in your project  
• .. break silo thinking inside 
companies and ask questions 
about current data practices 
• … speak the language of ex -
perts in the business and (tech) 
data field 
• … are in charge of helping 
companies create healthy long 
term data strategies
• ... support product/project 
teams with your insightsKnowledge 
As Data Strategist you have...
• … a balanced ethics compass
• … an understanding of the 
impact and importance of 
quid pro quo strategies with 
people and their data
• ... an understanding of com-
mon practices of data aggre-
gation 
• … an advanced understand-
ing of data supply chains and 
their influence on business 
cases/models
• … an overview of the data 
market and its playersData Strategist 22A Data Creative explores current trends in technology and 
looks to see if they can use or adapt parts of these technol-
ogies for use in their company/project. This knowledge can 
be used to inspire people to come up with innovative ideas, 
with an ethical and balanced approach. For example, the 
Data Creative can experiment with open AI technology and 
current data sources to inspire companies to improve their 
customer service. 
Responsibilities 
As a Data Creative you …
• … a balanced ethics compass
• … an advanced understand-
ing of interpretation of data 
(sources/sets)
• … knowledge about using de-
sign techniques which can help 
you and other people to gain 
new perspectives on….
• ... a good understanding of 
data visualization in order to 
communicate your ideas  
• ... the ability to speak different 
languages to communicate 
your ideas to different target 
groups  Knowledge 
As Data Creative you are … 
• … curious about new technol-
ogies and current trends 
• … patient and passionate: you 
broaden people’ s minds and 
help them to see new possi-
bilities 
• … brave in overcoming silo 
mentality inside companies 
• … able to unite people for 
your vision
• … able to  inspire people with 
new possibilities of technol-
ogies Data Creative23The UX designer, short for User Experience Designer, has 
emerged from different fields with different specialisms. 
Depending on the work environment, the profile of the 
UX Designer is constantly shifting. The definition given in 
this book could therefore deviate from your own personal 
experience.  UX Designer 
Design Business
T echnologyUXUX Designers work on the full range of the user 
experience development process for a product. They 
ensure user satisfaction and act as advocates for users 
in the process. 24Responsibilities 
As a UX Designer you …
• … the ability to discuss/evalu-
ate visual design outcomes  
• … an understanding of current 
technologies  
• … the ability to prototype your 
ideas in the form of interaction 
design concepts
• … an understanding of how 
to interpret data (qualitative/
quantitative)
• … knowledge about using de-
sign techniques which can help 
you and your team to gain new 
perspectives on problems
• ... the ability to speak different 
languages to communicate 
your ideas to different target 
groups  
• ... be able to iterate data
• … combine user needs and 
business goals on an equal 
level 
• … understand how to 
interpret data (qualitative/
quantitative)Knowledge 
As UX Designer you are … 
• … coordinate/perform prod-
uct research 
• … communicate/ align with 
stakeholders
• … create interaction design 
concepts with your visual 
design team members
• … build information architec-
tures
• … ensure the alignment of 
user needs and product goals 
at all stages of the develop-
ment process
• … guarantee the quality of 
the output by encouraging 
communication within the 
product team
• … integrate data sources 
to enhance the user expe-
rience of your projectAdditional Data Abilities25The UX designer, short for User Experience Designer, has 
emerged from different fields with different specialisms. 
Depending on the work environment, the profile of the 
UX Designer is constantly shifting. The definition given in 
this book could therefore deviate from your own personal 
experience.  Data Abilities for UX Designers 
Understanding 
and iterationBe Data iterateInclude Data 
into your projectBalance user needs 
& business needsData 
informed26Understanding Data Outcomes 
As mentioned in the section »Data in this Book« there are 
two main categories of data: qualitative and quantitative. 
Each of them uses a different approach for garnering the 
data, but only together can they create a full picture of a 
situation. As a UX Designer you are in charge of interpreting 
results garnered from these methods. You have to enable 
your team to make choices based on data outcomes. This 
does not mean blindly trusting the data outcomes. Data 
iteration will be a big part of your job. See »Being Data Liter -
ate« for the definition.  
When you are working in a small company or a company 
which is starting to use possible data sources, you will 
find yourself executing data related tasks like interviewing 
people, testing the assumptions of product development 
teams, running a/b tests, iterating behavior data sets from 
digital products or running benchmarks. This doesn’t mean 
that you have to understand all the tasks in detail. But you 
should be ready to dive into a new level of complexity. 
Speaking the same language as the data experts will help 
you to communicate and develop a higher level of under -
standing of them and their work.
Requirements
• Create an understanding of the methods used to aggre-
gate data
• Perform aggregation of data by yourself 
• Ensure your team has a basic understanding of the 
methods 
• Be data literate and maintain a healthy scepticism
• Connect data experts with resources within your project 
or company to create the best outcome27Purpose
Type of data
Form of data
Type of analysis
Collection methodQualitative Data
Understand & interpret 
social interactions
Words, Images or Sub-
jects
Open ended responses, 
interviews, participant 
observations, notes
Identify patterns
Interviews, observations Quantitative Data
Test hypotheses, look 
at cause & effect and 
make predictions
Numbers & Statistics
(Online) statistics in 
the form of reports 
and data tables 
Identify (statistical) 
relationships
(Online) surveys, (web) 
analytics28Being Data Literate
»When you don’t understand 
what data can and can’t tell you 
and your work is being dictated 
by decisions based on that lack 
of understanding—well, your 
work and product might end up 
being rubbish.«
Jared M. Spool,
(researcher, co-founder of Center 
Centre and the founder of UIE)In short, being data literate means maintaining a healthy 
scepticism, or as Dan Turner describes it: »bullshit detec-
tion«.1 This means when you come into contact with data, 
for example in the form of product statistics, interview 
results or business analytics you should always check the 
source & context of the data, potential biases and even 
numerate the data.
1 Turner, Dan. „Why We Should All Be Data Literate», 12. Februar 2017. http://alista-
part.com/article/why-we-should-all-be-data-literate.29Check source and context
Ask questions and talk about the context until you under -
stand and can answer questions like: 
• What is the source of the data? 
• How was the data collected?
• What can the data tell you? 
• What can’t the data tell you? 
• What metric was used to form the data? 
• Is the metric still up to date? 
Be numerate
»30% more conversion« sounds a lot. But what does this 
actually entail? You need to know the numbers behind 
these kind of statements. With questions like: 
• How much is the current amount? 
• How large is the whole sample?
• How much effect do the results from the sample have 
on the real world?
Check your biases 
Everyone has cognitive biases and that is OK. You should be 
aware of that and adjust your actions accordingly, especially 
when you are interpreting data. Selection bias1 describes 
a situation in which the sample you are measuring is not 
random or representative. This can happen when you acci-
dentally or intentionally try to skew the results or carelessly 
overlook the context.
Confirmation bias1 means that you only analyze the parts of 
the data which confirm your thesis. Ask yourself regularly 
during the interpretation questions like:30• Which data do you want to select to measure some-
thing? 
• What do you want to measure? 
• Did you check the context of your interpretation? 
• Do the results speak for or against your thesis?
• Are there any data that contradict your thesis?
If you want to check your data literacy level in detail you 
do this with the matrix from »Doing Good with Data« 
from Helena Sternkopf or for companies you can use 
the Forrester model »The Digital Maturity Model 4.0« 
from the »Digital Business Transformation Playbook«31Currently there is what has been termed as a »free culture« 
of people on the Internet. This means people are used not 
to pay for things they find online. They are willing to pay a 
lot for the access to the internet in form of smartphone, but 
online they are reluctant to spend money e.g. software. To 
counter this, companies are resorting to »free« access to 
their services. But free really only refers to the first time you 
access the service. With every subsequent use, personal 
data is generated which are collected, cleaned and newly 
linked to other sources of data by these companies. The 
people using the service have little control over the pro-
cessing of the data and no share in the profits.
This approach creates an unhealthy cycle for companies 
and people. To maintain and increase profits, companies 
must constantly attract new users. The goal is to keep the 
user connected to the service as long as possible to gener -
ate more data and iterations.Balancing People’s Needs and 
Business Goals
More Users
More time and atten-
tion for the Platform 
More interaction 
with the Platform 
More Advertising 
and Data More Profit & 
Content & more 
Awareness32To counteract this cycle, it is important to bear in mind 
three factors: transparency, control and value. In combina-
tion, this model will benefit people as well as companies. 
It gives each party involved the opportunity to develop a 
healthy data partnership. 
People
• Giving people control over 
their data promotes people's 
trust in a company and will 
increase the willingness to 
correct mistakes in their ag-
gregated data. 
• Educating people about the 
value of their data will in-
crease their view of value for 
a product.
• Reasonable handling of per -
sonal data will increase the 
identification of people with 
the values of a company. 
• People’ s lives change con-
stantly, the easer they can 
port their data, the higher is 
the chance them begin to ex -
periment with their data and 
create new ideas.Companies
• Creating a solid business 
model besides selling person-
al data ensures stable scaling 
with less pressure on getting 
more people to aggregate 
data from.
• Caring about the data of 
customers means creating a 
long-term trust relationship 
with customers. This helps to 
stabilize the market position. 
• Less data means less prob-
lems, the more data compa-
nies store the more they have 
to take care of, which means 
a steady increase of costs and 
non-calculated risks. 
• Creating assessable products 
without using an aggressive 
approach on personal data 
aggregations means creat-
ing an innovate competitive 
advantage.Why is a Healthy Data Partnership Important? 33Transparency
Create transparent processes in which all parties know 
which data is being captured, why and how the data is fur -
ther processed.The Basis for a Balanced Partnership
TransparencyControlValue
The following points must be clearly communicated before 
and during data refinement: 
• What data will be captured? 
• Why this data will be captured? 
• How the data will be processed and shared?
• How the data will be stored and secured? Although personal data is fragmented and abstract, 
people feel the need to control it. So, invisible processes 
must be made visible and tangible. 34Control
Guarantee all data producing parties the right to access, 
amend, blur and port the data they produce. 
People want control over the data they produce. This con-
trol can be separated into four different rights: 
Value
Acknowledge the value of the generated data and make 
sure that there is always an equivalent and appropriate 
equivalent.
Individual datasets seem to have an inherent value. But 
they form the basis for mining and interpretation in order 
to create new information. This means that the dataset will 
create an equal or even bigger value. • The right to access their data
• The right to amend their data
• The right to blur their data
• The right to port their data
Uncontrolled proliferation of this information must be pre-
vented under all circumstances. 3536Data: Ethics & Y ou 
Guiding Principle 
As designers we come into contact with a lot of different 
people. We work for different clients and stakeholders and 
design products and services for a wide range of users. 
What defines these people as individuals are often criteria 
such as their personal goals, life plans and their political 
orientation. Online, it is easy to see that people separate 
these different aspects of their personality into different 
digital identities. On Facebook, for example, they may be 
open and friendly, talking about things that have happened 
in daily life and joking around. In contrast, on business 
networks such as LinkedIn and Xing, they are typically more 
serious and focus on sharing only the essentials. In this 
way, they live out different aspects on their personality on 
each digital platform and create  different sets of data about 
themselves. This makes them the owner of this data and it 
should be their decision if and when they want to share the 
data, or connect different parts of their digital identities. 
People act as individuals in the real world. T angible 
and unique. In the digital world people create digital 
identities for their facets. They become their own data 
source. Which gives them the right to access, amend, 
blur and port their produced data.  37New Chances (GDPR)
The European government passed a new privacy law 
called »General Data Protection Regulation« (GDPR) which 
includes new rules for governments and companies in 
handling and processing personal data. The new law was 
created from the citizen’ s perspective to maximize trans -
parency and enhance digital rights. The new rules will enter 
into force in May 2018. This gives us, as designers, the 
opportunity to align our products and services more closely 
with the rights and needs of people. The new law is not a 
burden but a strong partner for true people-centricity. Here 
are some of the most important facts:  
Consent
A company or organization must obtain the con-
sent of people whose data are processed. This 
must be communicated in a clear and simple lan-
guage. It is a company’ s responsibility to prove 
that a individual has actively given consent. 
Data Portability
Individuals have the right to take their data, 
which they shared with a company, when they 
change to another service (provider). 
Age Limit
Children below 16 years cannot give consent 
for processing their data. (Individual states can 
lower the age limit)
Profiling
Individuals have the right to object to the crea-
tion of profiles of their data. Companies must 
communicate clearly when they use customers 
data. 38Privacy by Design
Companies and organizations must minimize the 
processing of personal data and create trans -
parency in relation to its handling. This means 
pseudonimizing data as soon as possible. 
Accountability
Companies and organizations which process 
data must have a privacy policy. They must docu-
ment data processing procedures and ensure the 
responsibility of their employees.
The Right to Erasure  
(or The Right to be Forgotten)
Individuals have the right to delete their personal 
data. This includes information such as links and 
copies of data held by third parties. 
The Right to Know About Data Breaches
Companies and organizations must report seri-
ous breaches of data protection rules to the na-
tional supervisory authority as soon as possible. 
The notification must take place within 72 hours.
Fines
Fines can be issued by any company from 20 
Million Euros up to 4% of a company's annual 
turnover.
Privacy Impact Assessment (Pia)
Companies and organizations which are process -
ing data must prepare reports which describe the 
influence of their processes on individuals' rights 
and freedoms. 39Data Protection Officer
Public institutions, companies and organizations 
with core business data processing and system-
atic monitoring are obliged to appoint a data 
protection officer (DSB). The DSB is an employee 
with expertise in data protection laws that en-
sure compliance with EU directives.
Data Exchange With Countries Outside the EU
Companies and organizations may not transfer 
personal data to other countries outside of the 
EU, if they don’t have the same protection stand-
ards.  
Conditions for Processing Data
The collection and processing of personal data 
may only take place if there is a certain legitimate 
purpose. The data collected must be relevant, 
minimal and absolutely necessary for this pur -
pose. The data cannot be reused and must be 
deleted after processing for the communicated 
purpose.40Best Practices
A few companies have already taken the chance to go fur -
ther than the current regulations. They empower people to 
take control of their data and establish a trustworthy data 
partnership. These companies provide people with tools to 
enhance their data privacy or claim »privacy by default« as 
one of their core values. These are just a few examples how 
human-centered products and services can be inspiring and 
successful. 
Core Facts
• Clear communication of data handling in 
their privacy policy
• Customers can use the app without an 
account
• Customers can port their data anytime 
• Anonymized data will be used for clinical 
and academic research
• Located in Germany under strict data 
protection lawsThe Berlin based company helps women 
monitor their monthly cycle and fertility and 
provides new insights into reproduction and 
health research. The company made the 
protection of their 5 Million users’ extremely 
sensitive data one of their core values. Clue - Period and Ovulation Tracker 
helloclue.com
Health41Core Facts
• Clear communication of data handling in 
their privacy policy
• No creation of profiles of people’ s  
behavior 
• No tracking of IP addresses of people’ s 
devices 
• No usage of unique cookies to follow 
people on other sites 
Core Facts
• Clear communication of data handling in 
their privacy policy
• Located in Europe under strict data pro-
tection lawsFounded on the principles of breaking the 
»filter bubble« effect and enhancing people’ s 
privacy, the company provides a search en-
gine which does not follow or track people. 
Supported by on one of the original Skype 
investors and former Skype engineers, wire 
is a messenger service built upon the idea of 
private communication. It provides end-to-
end encrypted chats and video calls on many 
platforms. DuckDuckgo – Search Engine 
duckduckgo.com
Wire Messenger 
wire.comSearch
Communicate42• End-to-end encrypted video calls, moni-
tor sharing, file sharing and chats 
• Focus on user friendliness
Core Facts
• Customers can port their data at any 
time 
• Customers can use the device without 
transferring their data to TomTom serv -
ers 
• TomTom only transfers data after con-
sent from customers 
• Located in Europe under strict data pro-
tection lawsThe company that originally provided naviga-
tion maps and hardware for cars has created 
a fitness tracker. Customers can use the 
tracker without TomTom services and port 
their data anytime. TomTom – Fitness Tracker
wire.com
Health43Be Bold, Explore and Think 
Critically
Today’ s abundance of data enables us to rethink current 
ways of working, explore new processes and build on our 
existing knowledge. To do this we need people who are 
prepared to question how we use this data and people who 
can transform it from something abstract into something 
usable, tangible and sustainable. Designers are in a position 
to do this by working in interdisciplinary teams to create 
tools to explore data through visualizations, interfaces and 
data services. 
We are in a middle of a period of change. We are working 
with ever increasing amounts of data. For example, online 
surveys results, interviews, protocols or online behavior 
statistics. The sources of data will grow and become a 
standard component of our day to day work.
This book is here to prepare you for these changes. 
It is meant to inspire you to be bold, to welcome new 
material, explore new possibilities that arise and think 
critically about the use of data. 441. Find new material. Reach out to find people 
who can help you expand on your knowledge. 
2. We can be the link between different disci-
plines, connecting people and knowledge to 
create meaningful new things.
3. When you are accountable to your users, you 
are probably also eager to find ways to repre-
sent them in your decisions. Be BoldExplore
Think 
Critical45»You have a responsibility to 
the community at large to make
sure that what you’re signing 
up to design is worth being 
designed. That’s right, kids: I’m 
interjecting ethics into the mix.
You are responsible for the 
work you put into the world.«
Mike Monteiro,
(founder of muledesign)46Data and Y our Project 
User-Centered Design Process 
This version of the User-Centered Design process is great-
ly simplified and should serve as a guide. You can remove 
or add parts and adapt them to your way of working. This 
chapter will show you how you can use data at different 
stages of the User-Centered Design process. You will find a 
few examples of data sources, strategies for collecting data 
and tips on how to use the Design Human Data Kit. 
       Discover                         Deﬁne                                            Prototype                              Ideate TESTTESTITERATE & 
REFLECT47Scoping Actions
Different parts of your process require different methods. 
It’ s all about the right timing and context. With this easy 
model you can estimate the methods you should use with 
these questions: 
What do you want to do?
1. How good should the results be? (quality)  
2. How fast do you want it done? (schedule) 
3. How much may it cost? (cost)
Time Cost
QualityScope 
Change
Expensive SlowLow
Quality48The Process
How do you know which kind of data you need? Where 
should you begin? Mostly, you can start with two factors: 
the topic you are working on and the nature of your ques -
tions.
Erica Hall has provided us with a great guide for deciding 
which methods to use in her book »Just Enough Research«.
Product OrganisationPeople
CompetitionQuestion about ...
   Descriptive Generative              Descriptive Evaluative    Evaluative Analytic                                Analytic Evaluative1 2
3 4
1. Interviews, Contextual Inquiry, Literature Review
2. Interviews, Usability Testing, A/B Testing
3. SWOT Analysis, Brand Audit
4. Usability Testing, Competitive Analysis, Heuristic Anal-
ysis49To start you project you must fully understand the current 
situation, discover dependencies and define the goal of 
your project. When you don’t understand the problem, your 
solutions will only scratch the surface or will have no effect. 
That’ s why this phase is the longest and most intensive, so 
use the opportunity to gather as much data as you can and 
refine it for your team.  
Tip: Consider checking the source and context of your 
data, be numerate and check your biases while you are 
building your data basis. See the chapter »Being Data 
Literate« for more details. Understand - 
Understanding Leads to Insights
Examples of Data Sources - General Approach
Studies
Scope
Cheap & Quick
Sometimes free or available for a 
small fee from independent com-
panies / NGOs / 
Governments.Studies can be compiled on different topics and can include different meth-
ods such as statistics, surveys etc.
More Expensive & Good
Paid studies from research com-
panies or organisations about a 
whole branch of an industry. 
Example: pwc.comData Types
Numbers & StatisticsData Category
Quantitative50Statistics
Scope
Cheap & Quick
Sometimes free or available for a 
small fee from independent com-
panies / NGOs / 
Governments.The collection, analysis, interpretation, presentation, and organization of 
data.
More Expensive & Good
Paid statistics from research 
companies or organisations with 
exposé and more prepared base 
on a whole topic.
Example: statista.comData Types
Numbers & StatisticsData Category
Quantitative
Surveys
Scope
Cheap & Quick
Sometimes free or available for a 
small fee from independent com-
panies / NGOs / Governments.A questionnaire that the target audience can complete in different ways, 
mostly by phone
Data Types
Numbers & StatisticsData Category
Quantitative (Sometimes a 
mix of both cat.)51Reports
Scope
Cheap & Quick
Sometimes free or available for a 
small fee from independent com-
panies / NGOs / 
Governments.Reports are mostly published by specified companies or organizations with 
focus on one topic
More Expensive & Good
Paid reports from research com-
panies or organisations about a 
whole branch of an industry or a 
specific topic. 
Example: gfk.comData Types
Numbers & StatisticsData Category
Quantitative (Sometimes a 
mix of both cat.)
Government Data Sets 
Scope
Cheap & Quick
Most of the time Governments 
offer this resources for free. But 
sometimes there are harder to 
find.
Example: govdata.deData sets from different ministries from sectors such as state budget, 
traffic or environment.
Data Types
Numbers & StatisticsData Category
Quantitative52Examples of Data Sources - Specific Approach
Data Types
Numbers & StatisticsData Category
Quantitative (Sometimes a 
mix of both cat.)Online Surveys
A questionnaire that the target audience can complete over the Internet.
Scope
Cheap & Quick
Promoting a small survey with 
people you know or throw a com-
pany’ s channels More Expensive & Good
Conducting detailed surveys in a 
pool of people recruited.
A/B T esting 
Determining which of two alternatives is better received by the target 
audience.
Scope
Cheap & Quick
You can set up a low fidelity 
prototype and test it with a small 
amount of people from a paid 
pool. More Expensive & Good
You can create two versions of 
a product/feature and compare 
them in a live setting of you cur -
rent product/service
Example: 
optimizely.com Data Types
Numbers & StatisticsData Category
Quantitative53Data Types
Numbers & StatisticsData Category
QuantitativeAnalytics Data
A special set of performance and behavioural data collected to analyse 
potential errors and potential for improvement.
Scope
Cheap & Quick
You can ask the marketing/per -
formance department for more 
information.More Expensive & Good
You can work with a data analyst 
to set up an analysis tool and ana-
lyse the data together for several 
months to find patterns. 
Example:  matomo.org  
Data Types
Words, Images or Subjects 
Numbers & StatisticsData Category
QuantitativeCustomer Data
Data about customers which is stored within or processed by your  
company.
Scope
Cheap & Quick
You can inform yourself about 
your company's customer data in 
every department More Expensive & Good
You can involve different stake-
holders and ask them to communi-
cate their upscale customer data. 54Data Types
Words, Images or SubjectsData Category
QualitativeInterviews
Interviews allow you to probe attitudes, beliefs, desires, and experiences 
to get a deeper understanding of the people who are using your site/prod-
uct/service.
Scope
Cheap & Quick
Guerrilla approach:  ask people 
you know, who could fit the target 
group profile, interview people in 
a coffee shop and provide free cof-
fee or recruit inside your company. 
(To quantify your approach you 
can use remote platforms)More Expensive & Good
Use a recruiting agency to specify 
your target group and pay the 
participants for their participation. 
(To quantify your approach you 
can use remote platforms)
Data Types
Words, Images or SubjectsData Category
QualitativeUsability T esting 
Usability testing refers to evaluating a product or service by testing it with 
representative people.
Scope
Cheap & Quick
Guerrilla approach:  ask people 
you know, who could fit the target 
group profile, interview people in 
a coffee shop and provide free cof-
fee or recruit inside your company. 
(To quantify your approach you 
can use remote platforms)More Expensive & Good
Use a recruiting agency to specify 
your target group and pay the 
participants for their participation. 
(To quantify your approach you 
can use remote platforms)55Data Types
Words, Images or SubjectsData Category
QualitativeUX Benchmarking Competitor Analysis
Usually carried out in combination 
with the analysis of competitors. 
The potential competitors and UX 
focal points are analysed.Analysis of the strengths and 
weaknesses of current and poten-
tial competitors.
Scope
Cheap & Quick
You can do it alone or ask a mem-
ber of your product/design team.More Expensive & Good
You can carry this out with a group 
of experts to combine different 
perspectives. 
Data Types
Words, Images or SubjectsData Category
QualitativeHeuristic Evaluation
In a heuristic evaluation experts review an interface or product and com-
pare it against accepted usability principles.
Scope
Cheap & Quick
You can do it alone or ask a mem-
ber of your product/design team.More Expensive & Good
You can carry this out with a group 
of experts to combine different 
perspectives. 56After you have viewed and edited the aggregated data 
from the "Understand" phase and defined the goals of your 
project, it's all about putting the insight you have gained 
from this into concrete ideas. The Design Human Data Kit 
provides you with a lot of tools to ideate with your interdis -
ciplinary team. You will notice that the Create and Proto-
type phases will merge seamlessly into one another. It is 
tempting to immerse yourself in the creation of prototypes. 
However, allow yourself and your team to discuss, discard 
and play out ideas. Create a system of comparing and 
testing your ideas, that may come from gut feeling, against 
your findings from the data.Create -  
Creation Ends in Ideas
Co-creation is a good way to integrate a physical 
representation of your findings. If people, your number 
one data source, are part of the process, there is an 
increased chance that your team will achieve a balanced 
result for each party. 57You have come up with ideas which fit with your data basis. 
Now you can transform your concrete ideas into proto-
types. These can be paper prototypes, simple click-proto-
types with Wireframe screens or high fidelity design proto-
types. As soon as you begin to test your ideas with relevant 
people from your target audience the better. Please bear in 
mind, to use both qualitative and qualitative methods.
Examples of Data Sources Build –  
Building Ends in Reality
Acceptance T est (lab)
Scope
Cheap & Quick
Guerrilla Approach:  Ask people 
you know, who could fit in the tar -
get group profile, Interview people 
in a coffee shop and provide 
free coffee or recruit inside your 
company. User Acceptance Testing generally verifies that the deliverable meets the 
agreed upon requirements. (Usability Testing instead  seeks to verify an 
implementation's approach works for the target group.)
More Expensive & Good
Use a recruiting agency to specify 
your target group and pay the 
participants for their appearing Data Types
Words, Images or SubjectsData Category
Qualitative & Quantitative58Acceptance T est (online)
User Acceptance Testing generally verifies that the deliverable meets the 
agreed upon requirements. (Usability Testing instead  seeks to verify an 
implementation's approach works for the target group.)
Scope
Cheap & Quick
Online Testing platforms provide 
a simple recruiting to test your 
prototype for a small budget. The 
tests can be moderated or unmod-
erated. More Expensive & Good
To quantify your results, you can 
use a recruiting agency to increase 
the number of people you test or 
recruit directly from the Testing 
platform with your target group 
criteria. Data Types
Words, Images or Subjects
Numbers & StatisticsData Category
Qualitative & Quantitative
Data Types
Numbers & StatisticsData Category
Quantitative (Sometimes a 
mix of both cat.)Online Surveys
A questionnaire that the target audience can complete over the Internet.
Scope
Cheap & Quick
Promoting a small survey with 
people you know or throw a com-
pany’ s channels More Expensive & Good
Conducting detailed surveys in a 
pool of people recruited.59Interviews
Interviews allow you to probe attitudes, beliefs, desires, and experiences 
to get a deeper understanding of the people who are visiting your site/
product/service.
Scope
Cheap & Quick
Guerrilla Approach:  Ask people 
you know, who could fit in the tar -
get group profile, Interview people 
in a coffee shop and provide 
free coffee or recruit inside your 
company. More Expensive & Good
Use a recruiting agency to specify 
your target group and pay the 
participants for their appearing.  Data Types
Words, Images or SubjectsData Category
Qualitative
Crowd T esting
Crowd Testing helps you to find errors and blind spots in User flows in the 
developing process.  
Scope
Cheap & Quick
You are recruiting a small beta 
group from existing customers or 
you are using a vendor with a small 
package for a smaller project. 
Example: test.io More Expensive & Good
To perform crowd testing regu-
larly in the product development 
process us a larger provider with a 
subscription.
Example:.applause.comData Types
Words, Images or SubjectsData Category
Qualitative60A/B T esting 
Determining which of two alternatives is better received by the target 
audience.
Scope
Cheap & Quick
You can set up a low fidelity 
prototype and test it with a small 
amount of people from a paid 
pool. More Expensive & Good
You can create two versions of 
a product/feature and compare 
them in a live setting of you cur -
rent product/service
Example: 
optimizely.com Data Types
Words, Images or SubjectsData Category
Qualitative61Data: What’s Next? 
The book has given you an introduction into the world of 
data. Relationships between data and design dependencies 
and effects of data use on people are shown. The book 
and the set are intended as a basis for discussion and as 
a way to promote new ideas for balanced data concepts. 
The intuition-lead and interdisciplinary way that designers 
work is an advantage in a world in which data is becoming 
omnipresent. We play an increasingly important role in the 
design processes of products, services and companies. We 
are able to make the data accessible to other people, we 
mediate between people of other disciplines and are able to 
elicit the bigger picture from hard facts with our intuition. 
If we use this same approach to deal with human data, our 
work will be extended into a new dimension. Designers 
should lead the way in terms of the ethical and responsible 
use of data and as soon as we start doing this, the smooth-
er the transition to data-awareness will be. We should all be 
lead by intuition, informed by data and driven by empathy. 
Y ou can find more information like articles, 
reports, book recommendations to this topic at 
designhumandata.net

Mental Models
AI-powered systems can adapt over time. Prepare users for
change—and help them understand how to train the system.
This chapter covers:
Which aspects of AI should we explain to our users?
How should we introduce AI to the user initially—and thereafter?
What are the pros and cons of introducing our AI as human-like?
Want to drive discussions, speed iteration, and avoid pitfalls? Use the worksheet.What’s new when working with AI
A mental model is a person’s understanding of how something works and how their actions affect
it. People form mental models for everything they interact with, including products, places, and
people. Mental models help set expectations for what a product can and can’t do and what kind of
value people can expect to get from it. Mental models can also serve as bridges between
experiences. For example, if you know how to steer a bicycle, you know something about how to
steer a motorcycle.
However, users’ mental models may not always match what a product can actually do.
Mismatched mental models can lead to unmet expectations, frustration, misuse, and product
abandonment. Often, product creators unintentionally set incorrect mental models for users by not
considering the early user experience with a product or not fully explaining how the product works.
Key considerations:
➀ Set expectations for adaptation. AI allows for more systems to adapt, optimize, and personalize
for users, and probability-based user experiences have become more common over time.
Building on the familiarity of existing mental models can help users feel comfortable.
➁ Onboard in stages. When introducing users to an AI-powered product, explain what it can do,
what it can’t do, how it may change, and how to improve it.
➂ Plan for co-learning. People will give feedback to AI products, which will adjust the models and
change how people interact with them — which will change the machine learning models further.
Users’ mental models will similarly change over time.
➃ Account for user expectations of human-like interaction. People are more likely to have
unachievable expectations for products that they assume have human-like capabilities. It’s
important to communicate the algorithmic nature and limits of these products to set realistic
user expectations and avoid unintended deception.➀ Set expectations for adaptation
Most products are highly static. You can bet that the hammer you buy today will be the same
hammer tomorrow. There have also been responsive products for quite a while — products that
can adapt how they respond based on user input over time. These systems keep track of whether
or not an output was useful, and update how they respond going forward. Using a digital example,
many streaming media services will adjust their recommendations based on your interaction with
previous ones. This can in turn create an expectation that other products will adapt based on user
interactions.
With AI becoming more prevalent in products and experiences, we can expect to see more
experiences that change in response to users. One of the biggest opportunities for creating
effective mental models of AI products is to build on existing models, while teaching users the
dynamic relationship between their input and product output.
Identify existing mental models
Start by thinking about how people currently solve the problem that your product will use AI to
address. That existing solution will very likely inform their initial mental model for your product. For
example, if people currently label their email messages manually the assumption could be that an
AI-powered email product — somehow — follows the same process that the user does. In this case,
that would be: read the email, think about the meaning, context, and importance, and attach a label
accordingly. Therefore, it may surprise users that the ML model could use other signals—time of
day the message was sent or length of the email—to determine the label.Key concept
To understand the context for the user’s relationship to your AI product, work through
some of the questions below:
What is the user trying to do?
What mental models might they carry over to your product?
What is the step-by-step process that novice users currently use to accomplish the
task?
How uniform is this process between different users?
Apply the concepts from this section in Exercise 1 in the worksheet➁ Onboard in stages
Onboarding is the process of helping a new user or customer get to know a product or service. The
onboarding experience begins before users purchase or download your product or even visit your
website, and continues indefinitely. As with any product, it’s important to consider the different
stages of introducing your AI and how mental models form and change along the way.
Introduce and set expectations for AI
After identifying your users’ existing mental models, imagine how information your user received
before their first interaction with the product — including marketing messages, ads, or manuals —
has shaped their expectations. Collaborate closely with your marketing team to develop
appropriate and consistent messaging.
Many products set users up for disappointment by promising that “AI magic” will help them
accomplish their tasks. This kind of messaging can establish mental models that overestimate
what the product can actually do. Though product developers may intend to shield users from a
product’s complexity, hiding how it works can set users up for confusion and broken trust. It’s a
tricky balance to strike between explaining specific product capabilities, which can become overly
technical, intimidating, and boring, and providing a high-level mental model of your AI-powered
product.Aim for
Emphasize how the app will benefit users. Learn more
Avoid
Don’t emphasize the underlying technology.
Here are some messaging guidelines for setting the right expectations for your product:
Be up front about what your product can and can’t do the first time the user interacts with it,
ideally in your marketing messages.
Offer examples of how it works that clarify the value of the product.
Let people know up front that it may need their feedback to improve over time.heck_circle_outline not_interestedCommunicate why people should continue to provide feedback, focusing on the value to them.
Explain the benefit, not the technology
Often as product creators, we’re fascinated by the underlying technologies that make products and
experiences possible. This is especially true if we’ve cracked a hard technical problem for the first
time. However, make sure to evaluate which details users need to build a good mental model. If
they’re interested in understanding the underlying technology of your product, you can always
provide more detail with tooltips and progressive disclosure. If you do talk about the AI, focus on
how it specifically makes part of the experience better or delivers new value.
See more about explaining AI at the right level of detail in the Explainability + Trust chapter.
Only introduce new features when needed
As users explore the product, use relevant and actionable “inboarding” messages to help them
along. Try to avoid introducing new features when users are busy doing something unrelated. This
is especially important if you’re updating an existing product with new AI features that change the
function or user experience. People learn better when short, explicit information appears right
when they need it.Aim for
Introduce an AI-driven feature at the moment it is
relevant to the user. Learn more
Avoid
Don’t introduce AI-driven features as part of a long
introductory list of product features.
Design for experimentationheck_circle_outline not_interestedMany people learn best by tinkering with a new experience. People sometimes skip onboarding
steps because they’re eager to start using the system, and reading even a few screens feels like it’s
in the way. By keeping onboarding short, you’ll let them get right to it. Suggest a low-risk or
reversible action they can try right away — users are often curious about how an AI-powered
feature or product will behave, so encourage that with a small, contained initial experimentation
experience. For example, applying photo filters is easy to test out and undo with a tap.
One caveat is that a user’s willingness or ability to spend time experimenting depends on their goal
in using your product. For example, an average consumer who purchases a new smart speaker
might enjoy spending time experimenting with different commands and questions. In contrast, a
busy enterprise user might regard testing commands and functions as just one more chore in a
busy day.
Regardless of their goals, point users towards where they can quickly understand and benefit from
your product. Otherwise, they may find the boundaries of the system by experimenting in ways it
isn’t prepared to respond to. This can lead to errors, failure states, and potentially erosion of trust
in your product.
Learn more about helping users get back on track in the Errors + Graceful Failure chapter.Aim for
Encourage experimentation and reassure users that
experimenting won’t dictate their future experiences.
Learn more
Avoid
Don’t assume users want the AI to start learning from
the first use.heck_circle_outline not_interestedKey concept
Onboarding is all about setting up the interaction relationship between the user and your
product. Here’s a simple messaging framework to get you started: 
 
This is { your product or feature },  
and it’ll help you by { core benefits }. 
Right now, it’s not able to { primary limitations of AI }. 
Over time, it’ll change to become more relevant to you. 
You can help it get better by { user actions to teach the system }.
 
Apply the concepts from this section in Exercise 2 in the worksheet➂ Plan for co-learning
Because AI-powered products can adapt and get better over time, the user experience can change.
Users need to be prepared for that, and adjust their mental model as necessary.
Connect feedback with personalization
In onboarding, let users know how the feedback they provide helps the AI personalize their
experience. You can tie this to the user benefit with phrasing like “you can improve your experience
by giving feedback on the suggestions you receive”, and letting them know where and how to do
so.
There are two ways to collect feedback:
Implicit feedback is when people’s actions while using the product help improve the AI over
time. There should be a place in your product where users can see which signals are being
used to what end, and this should be disclosed in your terms of service.
For example, choosing to listen to the next suggested song in a music app confirms the
model’s prediction that the song is relevant to you. That fact should be part of the definition,
user benefit, and terms of how the app works.
Explicit feedback is when people intentionally give feedback to improve an AI model, like
picking categories of music they’re interested in. This kind of feedback can help the user feel
more in control of the product. If you can, explain precisely what impact the feedback will have
on your AI, and when it will take effect.
When the system collects feedback, explain how continually teaching the system benefits the user.
Be clear about what information will help your AI learn and how it will improve the product output.
See examples and much more detail in the Feedback + Control chapter.
Fail gracefullyThe first time the system fails to meet expectations, the user will likely be disappointed. However,
if the mental model includes the idea that the system learns over time, and learns better with the
right input, then failure, especially the first failure the user encounters, becomes an opportunity to
establish the feedback relationship. Once this relationship is set, users will see each failure not
only as more forgivable, but also something that they can help fix. This buy-in can help cement the
mental model of co-learning.
When your system isn’t certain, or can’t complete a request, make sure there’s a default user
experience that doesn’t rely on AI. That way, the burden of educating your AI doesn’t stop users
from getting things done. When your product fails gracefully, it doesn’t get in the user’s way, and
they see feedback as a way to make their objectives even easier over time, while still being able to
use your product right now.
See examples and much more detail in the Errors + Graceful Failure chapter.Aim for
Let users know an error occurred and give them a way to
complete the task manually. Learn more
Avoid
Don’t create dead-ends when an AI feature fails. These
miss the opportunity to shape the user’s mental model
about the system’s limitations.
Remind, reinforce, and adjustheck_circle_outline not_interestedSometimes products become part of a user’s everyday routine, so their mental models get formed
and reinforced by ongoing use. But some products are only meant to be used occasionally. For
these products, mental models might erode over time, so it’s helpful to consider ways to reinforce
them, or to remind users of the basics.
You can also help strengthen mental models across AI products by maintaining consistent
messaging about the user benefits of improving AI with feedback. Over time, users may adopt a
common mental model that recognizes AI solutions and their strengths and weaknesses,
becoming more comfortable with what they’ll get and how they can shape their experience. There
are a few things you can do to increase the odds of that happening:
Keep track of user needs
Monitor how the product is being used. Reviewing your product logs can show you behavior or
use trends that point to user confusion or frustration. This can help you determine when you
might need to help users rebuild or adjust their mental models. If your product is only meant to
be used for a short time or to achieve a specific goal, that will determine how frequently mental
models should be reinforced or updated.
See more about metrics in the User Needs + Defining Success chapter.
Adapt to the evolving user journey
If how a feature works changes or improves significantly — enough that a user would notice —
consider whether your users need “re-boarding” to the new experience. Re-boarding is also
useful when adding new features, or if your system starts using new or different data for an
existing feature.
If the system is simple and the mental model is clear and memorable, it’s possible that only a
little reinforcement is required. A quick user study with people who have used the product
previously, but not in the last month or so, could reveal what kind of nudge, if any, might be
most helpful.➃ Account for user expectations of human-like
interaction
A number of products have launched in recent years that are designed to be anthropomorphic or
human-like, such as Cortana, Alexa, Google Assistant, or Siri. This choice has advantages and
disadvantages that should be weighed carefully. It’s true that people tend to reflexively infer human
characteristics from voice interfaces, and some interactions, such as conversational interfaces,
are inherently human-like. However, if the algorithmic nature and limits of these products are not
explicitly communicated, they can set expectations that are unrealistic and eventually lead to user
disappointment, or even unintended deception.
When users confuse an AI with a human being, they can sometimes disclose more information
than they would otherwise, or rely on the system more than they should, among other issues.
Therefore, disclosing the algorithm-powered nature of these kinds of interfaces is a critical
onboarding step. Specifically, your messages should make it extremely clear that the product is not
a human, in a way that’s accessible to all users regardless of age, technical literacy, education level
or physical ability.
This topic is the subject of ongoing research, and these considerations are just a first step. Expect
more on this topic in future editions of the Guidebook.
Clearly communicate AI limits and capabilities
People may struggle to form an accurate or useful mental model of an anthropomorphized AI-
powered product because the way these systems execute tasks is inherently different than the way
a person would. On the surface, AI-powered functionality might seem similar to the manual
method but the mental model might not map precisely.
For example, “automatic photo tagging” sounds like the tool is tagging photos the same way a
person would, just “automatically”. If someone hasn’t used this tool before, their mental model of
this process is by default, a human one. The app may be able to find and tag all the pictures of a
particular friend, just as a person would, but miss some that show her from the back. This is an
unexpected break: of course most people can recognize their friends from multiple angles, but this
tool can’t.A disconnect like this doesn’t necessarily mean that the product itself or the mental model is
broken. Not all humans have the same abilities — sight and hearing are not a given — and the
product is still doing an incredible task that humans can’t do: scanning thousands of photos,
identifying the subjects, and labeling them. The key is to communicate the system’s limits and
capabilities in a way that doesn’t create or support expectations of super-human abilities. AI
doesn’t do anything the same way people do, so though this model is convenient, it’s pretty fragile.
Often the idea of a generalized “helper AI” is easier to grasp and more inviting for users, but the
risk of mistrust is high when the system’s limits aren’t clear. When users can’t accurately map the
system’s abilities, they may over-trust the system at the wrong times, or miss out on the greatest
value-add of all: better ways to do a task they take for granted. Choose the level of humanization
based on how well your AI’s capabilities match the user’s perceptions of what a human can do.Aim for
Describe AI features in terms of helping people improve
while setting the right expectations for what the AI can
do. Learn more
Avoid
Don’t create unrealistic expectations by presenting the
AI as human-like when it can actually do far less than a
person.
Cue the correct interactionsheck_circle_outline not_interestedLeveraging human characteristics to build mental models is particularly useful if your product
interactions rely on distinctly human behaviors, such as conversation. Using the first person in
chatbots and voice interactions can help people intuitively understand how to use your system. It’s
much easier for users to understand that they can talk to something that invites them to in a
conversational way.
However, this approach has its risks. Specifically, if your conversational AI refers to itself as “I”, the
corresponding user mental model includes near-perfect natural language processing, which your AI
may not be able to pull off yet. It’s a delicate balance between cueing the right type of interaction
while trying to limit the level of mismatched expectations or failures.
Aim for
Set expectations for the kind of commands the AI can
understand to reinforce the right mental models. Learn
moreAvoid
Don’t set unrealistic expectations about what the AI can
do, especially compared to humans.heck_circle_outline not_interestedSummary
Mental models for AI-driven products are influenced by multiple factors including: existing mental
models for similar features or products, marketing messages from your team, onboarding and
expectations setting, and the feedback relationships in your product. When you set out to help
users construct the right mental models for your AI, consider the following:
➀ Set expectations for adaptation. Help people get the most out new AI uses by identifying and
building on existing mental models. Ask yourself questions like “What is the user trying to do?”,
“What mental models might already be in place?,” and “Does this product break any intuitive
patterns of cause and effect?”
➁ Onboard in stages. Set realistic expectations early. Describe user benefits, not technology.
Describe the core value initially, but introduce new features as they are used. Make it easy for
users to experiment with the AI in your product.
➂ Plan for co-learning. Connect feedback to personalization and adaptation to establish the
relationship between user actions and the AI output. Fail gracefully to non-AI options when
needed.
➃ Account for user expectations of human-like interaction. Clearly communicate the algorithmic
nature and limits of these products to set realistic user expectations and avoid unintended
deception.
Want to drive discussions, speed iteration, and avoid pitfalls? Use the worksheet

Guidelines for Human-AI Interaction 
Saleema Amershi, Dan Weld*†, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, 
Jina Suh, Shamsi Iqbal, Paul N. Bennett, Kori Inkpen, Jaime Teevan, Ruth Kikin-Gil, and Eric Horvitz 
Microsoft† Paul G. Allen School of Computer 
Redmond, WA, USA Science & Engineering 
{samershi, mivorvor, adamfo, benushi, pennycol, jinsuh, University of Washington 
shamsi, pauben, kori, teevan, ruthkg, horvitz} Seattle, WA, USA 
@microsoft.com weld@cs.washington.edu 
ABSTRA
CT 
Advances in artifcial intelligence (AI) frame opportunities 
and challenges for user interface design. Principles for human-
AI interaction have been discussed in the human-computer 
interaction community for over two decades, but more study 
and innovation are needed in light of advances in AI and 
the growing uses of AI technologies in human-facing appli-
cations. We propose 18 generally applicable design guide-
lines for human-AI interaction. These guidelines are vali-
dated through multiple rounds of evaluation including a user 
study with 49 design practitioners who tested the guidelines 
against 20 popular AI-infused products. The results verify 
the relevance of the guidelines over a spectrum of interaction 
scenarios and reveal gaps in our knowledge, highlighting op-
portunities for further research. Based on the evaluations, we 
believe the set of design guidelines can serve as a resource to 
practitioners working on the design of applications and fea-
tures that harness AI technologies, and to researchers inter-
ested in the further development of guidelines for human-AI 
interaction design. 
CCS CONCEPTS 
• Human-centered computing → Human computer in-
teraction (HCI) ;• Computing methodologies → Artif-
cial intelligence . 
*Work done as a visiting researcher at Microsoft Research. 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies 
are not made or distributed for proft or commercial advantage and that 
copies bear this notice and the full citation on the frst page. Copyrights 
for components of this work owned by others than the author(s) must 
be honored. Abstracting with credit is permitted. To copy otherwise, or 
republish, to post on servers or to redistribute to lists, requires prior specifc 
permission and/or a fee. Request permissions from permissions@acm.org. 
CHI 2019, May 4–9, 2019, Glasgow, Scotland Uk 
© 2019 Copyright held by the owner/author(s). Publication rights licensed 
to ACM. 
ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 
https://doi .org/10 .1145/3290605 .3300233 KEY
WORDS 
Human-AI interaction; AI-infused systems; design guidelines 
ACM Reference Format: 
Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Four-
ney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul 
N. Bennett, Kori Inkpen, Jaime Teevan, Ruth Kikin-Gil, and Eric 
Horvitz. 2019. Guidelines for Human-AI Interaction. In CHI Con-
ference on Human Factors in Computing Systems Proceedings (CHI 
2019), May 4–9, 2019, Glasgow, Scotland Uk. ACM, New York, NY, 
USA, 13 pages. https://doi .org/10 .1145/3290605 .3300233 
1 INTRODUCTION 
Advances in artifcial intelligence (AI) are enabling develop-
ers to integrate a variety of AI capabilities into user-facing 
systems. For example, increases in the accuracy of pattern 
recognition have created opportunities and pressure to inte-
grate speech recognition, translation, object recognition, and 
face recognition into applications. However, as automated 
inferences are typically performed under uncertainty, often 
producing false positives and false negatives, AI-infused sys-
tems may demonstrate unpredictable behaviors that can be 
disruptive, confusing, ofensive, and even dangerous. While 
some AI technologies are deployed in explicit, interactive 
uses, other advances are employed behind the scenes in 
proactive services acting on behalf of users such as auto-
matically fltering content based on inferred relevance or 
importance. While such attempts at personalization may be 
delightful when aligned with users’ preferences, automated 
fltering and routing can be the source of costly information 
hiding and actions at odds with user goals and expectations. 
AI-infused systems1 can violate established usability guide-
lines of traditional user interface design (e.g., [31, 32]). For 
example, the principle of consistency advocates for minimiz-
ing unexpected changes with a consistent interface appear-
ance and predictable behaviors. However, many AI compo-
nents are inherently inconsistent due to poorly understood, 
1In this paper we use AI-infused systems to refer to systems that have 
features harnessing AI capabilities that are directly exposed to the end user. probabilistic behaviors based on nuances of tasks and set-
tings, and because they change via learning over time. AI-
infused systems may react diferently depending on lighting 
or noise conditions that are not recognized as distinct to 
end users. Systems may respond diferently to the same text 
input over time (e.g., autocompletion systems suggesting 
diferent words after language model updates) or behave 
diferently from one user to the next (e.g., search engines 
returning diferent results due to personalization). Inconsis-
tent and unpredictable behaviors can confuse users, erode 
their confdence, and lead to abandonment of AI technology 
[7, 22]. Errors are common in AI-infused systems, rendering 
it difcult to reliably achieve the principle of error preven-
tion. This has contributed to the large and growing body of 
work on AI explanations and interpretability to support hu-
man verifcation of proposed actions aimed at reducing the 
likelihood of unwarranted or potentially dangerous actions 
and costly outcomes (e.g., [14, 21, 23, 36, 38, 44]). 
For over 20 years, the human-computer interaction (HCI) 
community has proposed principles, guidelines, and strate-
gies for designing user interfaces and interaction for appli-
cations employing AI inferences (e.g., [16, 17, 33]). However, 
the variability of AI designs (e.g., varying capabilities and 
interaction styles of commercial conversational agents im-
pacting user engagement and usability [26]) and high-profle 
reports of failures, ranging from humorous and embarrassing 
(e.g., autocompletion errors [8]) to more serious harm when 
users cannot efectively understand or control an AI system 
(e.g., collaboration with semi-autonomous cars [41]), show 
that designers and developers continue to struggle with cre-
ating intuitive and efective AI-infused systems. Ongoing 
advances in AI technologies will generate a stream of chal-
lenges and opportunities for the HCI community. While such 
developments will require ongoing studies and vigilance, we 
also see value in developing reusable guidelines that can be 
shared, refned, and debated by the HCI community. The de-
velopment and use of such shared guidelines can help with 
the design and evaluation of AI-infused systems that people 
can understand, trust, and can engage with efectively. 
In this work, we synthesize over 20 years of learning in 
AI design into a small set of generally applicable design 
guidelines for human-AI interaction. Specifcally, our contri-
butions are: 
• A codifcation of over 150 AI-related design recommenda-
tions collected from academic and industry sources into a 
set of 18 generally applicable design guidelines for human-
AI interaction (see Table 1). 
• A systematic validation of the 18 guidelines through mul-
tiple rounds of iteration and testing. 
We hope these guidelines, along with our examination 
of their applications in AI-infused systems, will serve as a resource for designers working with AI and will facilitate 
future research into the refnement and development of prin-
ciples for human-AI interaction. 
2 RELATED WORK 
For over 20 years, the academic community has proposed nu-
merous guidelines and recommendations for how to design 
for efective human interaction with AI-infused systems. For 
example, Norman [33] and Höök [16] both recommended 
building in safeguards like verifcation steps or controlling 
levels of autonomy to help prevent unwanted adaptations 
or actions from intelligent systems. Others recommended 
managing expectations so as not to mislead or frustrate 
users during interaction with unpredictable adaptive agents 
[16, 20, 33]. Horvitz’s formative paper on mixed-initiative 
systems [17] proposed principles for balancing autonomous 
actions with direct manipulation constructs, such as support-
ing user-driven invocation of intelligent services, scoping 
actions based on inferred goals and confdences, and infer-
ring ideal action in light of costs, benefts, and uncertainties. 
The latter guideline was operationalized via the introduc-
tion of a decision-theoretic methodology to guide decisions 
about acting on AI inferences versus waiting for user in-
put, based on consideration of expected costs and benefts 
of performing AI automation under uncertainty. 
In some cases, specifc AI design recommendations have 
received considerable attention within the academic commu-
nity. For example, a large body of work exists and continues 
to grow around how to increase transparency or explain 
the behaviors of AI systems (e.g., [14, 21, 23, 36, 38, 44], to 
name a few). Similarly, when and how to automatically adapt 
or personalize interfaces has been studied extensively in a 
variety of scenarios (e.g., [9, 11–13]). 
Others in the community have studied how to design for 
specifc human-AI interaction scenarios. For example, re-
searchers have been studying how to efectively interact 
with intelligent agents for many years (e.g., [18, 33]). This 
scenario has also had a recent resurgence of interest given ad-
vances in natural language processing and embedded devices 
driving the proliferation of conversational agents [26, 29, 35]. 
Similarly, researchers have for decades studied human in-
teraction with intelligent context-aware computing systems 
including how to design for understandability and control 
of the underlying sensing systems [3, 23] and how to sup-
port ambiguity resolution [ 10]. Recent advances in sensing 
technologies and the widespread availability of commercial 
ftness and activity trackers have continued to drive interac-
tion research in these domains [37, 45]. 
Despite all of this work, the ongoing stream of articles and 
editorials in the public domain about how to design in the 
face of AI (e.g., [2, 24, 25, 39, 42]) suggests designers need 
more guidance. This may be partly due to design suggestions AI Design Guidelines Example Applications of Guidelines InitiallyG1 Make clear what the system can do.
Help the user understand what the AI system is capable of 
doing. [Activity Trackers, Product #1] “Displays all the metrics that 
it tracks and explains how. Metrics include movement metrics 
such as steps, distance traveled, length of time exercised, and 
all-day calorie burn, for a day.” 
G2 Make clear how well the system can do what it can 
do. Help the user understand how often the AI system may 
make mistakes. [Music Recommenders, Product #1] “A little bit of hedging 
language: ‘we think you’ll like’.” During interactionG3 Time services based on context. 
Time when to act or interrupt based on the user’s current 
task and environment. [Navigation, Product #1] “In my experience using the app, it 
seems to provide timely route guidance. Because the map up-
dates regularly with your actual location, the guidance is timely.” 
G4 Show contextually relevant information.
Display information relevant to the user’s current task and 
environment. [Web Search, Product #2] “Searching a movie title returns show 
times in near my location for today’s date” 
G5 Match relevant social norms. 
Ensure the experience is delivered in a way that users would 
expect, given their social and cultural context. [Voice Assistants, Product #1] “[The assistant] uses a semi-
formal voice to talk to you - spells out “okay” and asks further 
questions.” 
G6 Mitigate social biases.
Ensure the AI system’s language and behaviors do not rein-
force undesirable and unfair stereotypes and biases. [Autocomplete, Product #2] “The autocomplete feature clearly 
suggests both genders [him, her] without any bias while sug-
gesting the text to complete.” When wrongG7 Support efcient invocation.
Make it easy to invoke or request the AI system’s services 
when needed. [Voice Assistants, Product #1] “I can say [wake command] to 
initiate.” 
G8 Support efcient dismissal.
Make it easy to dismiss or ignore undesired AI system ser-
vices. [E-commerce, Product #2] “Feature is unobtrusive, below the 
fold, and easy to scroll past...Easy to ignore.” 
G9 Support efcient correction.
Make it easy to edit, refne, or recover when the AI system 
is wrong. [Voice Assistants, Product #2] “Once my request for a reminder 
was processed I saw the ability to edit my reminder in the UI 
that was displayed. Small text underneath stated ’Tap to Edit’ 
with a chevron indicating something would happen if I selected 
this text.” 
G10 Scope services when in doubt.
Engage in disambiguation or gracefully degrade the AI sys-
tem’s services when uncertain about a user’s goals. [Autocomplete, Product #1] “It usually provides 3-4 suggestions 
instead of directly auto completing it for you” 
G11 Make clear why the system did what it did.
Enable the user to access an explanation of why the AI 
system behaved as it did. [Navigation, Product #2] “The route chosen by the app was 
made based on the Fastest Route, which is shown in the subtext.” Over timeG12 Remember recent interactions. 
Maintain short term memory and allow the user to make 
efcient references to that memory. [Web Search, Product #1] “[The search engine] remembers the 
context of certain queries, with certain phrasing, so that it can 
continue the thread of the search (e.g., ‘who is he married to’ 
after a search that surfaces Benjamin Bratt)” 
G13 Learn from user behavior. 
Personalize the user’s experience by learning from their 
actions over time. [Music Recommenders, Product #2] “I think this is applied be-
cause every action to add a song to the list triggers new recom-
mendations.” 
G14 Update and adapt cautiously.
Limit disruptive changes when updating and adapting the 
AI system’s behaviors. [Music Recommenders, Product #2] “Once we select a song they 
update the immediate song list below but keeps the above one 
constant.” 
G15 Encourage granular feedback.
Enable the user to provide feedback indicating their prefer-
ences during regular interaction with the AI system. [Email, Product #1] “The user can directly mark something as 
important, when the AI hadn’t marked it as that previously.” 
G16 Convey the consequences of user actions.
Immediately update or convey how user actions will impact 
future behaviors of the AI system. [Social Networks, Product #2] “[The product] communicates 
that hiding an Ad will adjust the relevance of future ads.” 
G17 Provide global controls.
Allow the user to globally customize what the AI system 
monitors and how it behaves. [Photo Organizers, Product #1] “[The product] allows users to 
turn on your location history so the AI can group photos by 
where you have been.” 
G18 Notify users about changes.
Inform the user when the AI system adds or updates its 
capabilities. [Navigation, Product #2] “[The product] does provide small in-
app teaching callouts for important new features. New features 
that require my explicit attention are pop-ups.” 
Table 1: Our 18 human-AI interaction design guidelines, roughly categorized by when they likely are to be applied during 
interaction with users, along with illustrative applications (rated as “clearly applied” by participants) across products tested 
by participants in our user study. being scattered throughout diferent academic circles and 
venues, making them difcult to fnd (e.g., there is relevant 
work in a wide variety of venues including AAAI, UbiComp, 
RecSys, SIGIR, HRI, KDD). Moreover, potential design sug-
gestions for AI are often not presented explicitly as such. 
In many cases, researchers identify usability issues with AI 
systems and suggest possible solutions in the discussion or 
future work sections of their academic papers. For example, 
Lugar and Sellen [26] identify variability in user expecta-
tions of conversational agents as causing usability issues and 
propose setting realistic expectations as a possible solution 
in their discussion. Similarly, Lee et al [22] studied automatic 
changes to search result lists during user interaction and 
suggested caution in updating those lists to balance stability 
with presenting new content to users. While these proposed 
solutions could be generalized into principles for designers, 
not presenting them as such makes them difcult to discover. 
It can also be difcult to understand if and how design guid-
ance stemming from one community or interaction scenario 
extends to others. For example, Bunt et al. [4] showed that, 
while explanations of AI behaviors have shown promise in 
complex and high-risk scenarios such as sensor-based ubiq-
uitous computing systems or decision-support systems for 
medical or fnancial domains, they may be less important 
for relatively low-cost scenarios such as search and music or 
movie recommenders. 
In this work we 1) synthesize a unifed set of design guide-
lines from a variety of communities and sources and 2) 
systematically examine those guidelines in a variety of AI-
infused systems to validate their applicability and relevance. 
The closest to our work is Horvitz’s set of principles for 
mixed-initiative systems [17], noting that 8 of our 18 guide-
lines map to principles outlined in that work. We celebrate 
its 20-year anniversary by refecting on learnings from the 
community since its publication. Moreover, recent work has 
warned that the lack of rigorous validations of proposed 
design heuristics in specifc domains makes it difcult to 
gauge the utility of those heuristics [ 15]. We developed the 
guidelines shown in Table 1 using a four-phase process. In 
Phase 1 we consolidated more than 150 design recommen-
dations from multiple sources into a set of 20 guidelines. In 
Phase 2 we conducted an internal modifed heuristic evalu-
ation of the guidelines, revising the set down to 18. Phase 
3 consisted of a user study in which 49 participants used 
heuristic evaluation to assess the guidelines’ relevance and 
clarity. Based on their feedback, we rephrased some of the 
guidelines to improve clarity and, in Phase 4, conducted an 
expert evaluation of the revisions to validate the fnal set. 
3 PHASE 1: CONSOLIDATING GUIDELINES 
We gathered AI design recommendations from three sources: • A review of AI products and guidelines originating from 
industry. We collected guidelines asserted internally in our 
company and externally, and grouped them into themes; 
we audited a sample of AI products within and outside 
our company against the themes; and cross-referenced 
themes with internal customer feedback (reviews and bugs 
reported about our company’s AI products). 
• Recent public articles and editorials about AI design (e.g., 
[2, 24, 25, 39]). 
• Relevant scholarly papers about AI design (see Related 
Work section). 
While we drew AI design guidelines from the academic 
literature, the list we captured may not be exhaustive because, 
as discussed in Related Work, potential design guidelines are 
often not presented explicitly as such, making them difcult 
to search for via terms or combinations of terms such as 
“AI”, “machine learning”, “design”, “principle” or “guideline”. 
Further, as the feld is evolving rapidly, we found the most 
up to date guidance about AI design in industry sources via 
articles published in the public domain. 
From these sources, we obtained 168 potential AI design 
guidelines. Three members of our team conducted an asyn-
chronous afnity diagramming process, clustering the guide-
lines into related concepts. This resulted in 35 concepts which 
we then fltered by removing concepts we deemed to be ei-
ther too vague to design for directly (e.g., “build trust”), too 
specifc to a particular AI scenario (e.g., “establish that the 
bot is not human”), or not AI specifc (e.g., “display output ef-
fectively”). Filtering reduced our set of concepts to 20, each of 
which we then summarized in a sentence or phrase, forming 
our frst iteration of the guidelines. We organized the guide-
lines into four top-level categories based on when during 
the user’s interaction they applied: “Initially” (Guideline 1 & 
Guideline 2), “During interaction” (Guideline 3 - Guideline 6), 
“When wrong” (Guideline 7 - Guideline 11), and “Over time” 
(Guideline 12 - Guideline 18). Next, we tested the guidelines 
via a modifed heuristic evaluation. 
4 PHASE 2: MODIFIED HEURISTIC EVALUATION 
We conducted an evaluation to test and iterate on the initial 
set of 20 AI design guidelines. We modeled our study af-
ter a heuristic evaluation [31], a common discount usability 
testing method where evaluators examine an interface for vi-
olations of a given set of usability guidelines. As the primary 
goal was to evaluate our design guidelines rather than to 
evaluate an interface, we modifed the heuristic evaluation 
by asking evaluators to attempt to identify both applications 
and violations of the proposed guidelines in an interface and 
to refect on the guidelines themselves during the evaluation. 
Eleven members of our team participated in this evalua-
tion. Team members selected AI-infused products or features of their choice and then looked for applications or viola-
tions of our initial set of design guidelines over a one-hour 
period. In total, we inspected 13 AI-infused products or fea-
tures including: two diferent email products with a feature 
for fltering unimportant emails, a navigation system, an 
e-commerce website with product recommendations, two 
photo organization products, a design assistance feature in 
a productivity software, a research assistance feature in a 
productivity application, a social network news feed feature, 
a web search service, and an image search service. These 
products were diferent from the products used in Phase 3. 
After the modifed heuristic evaluation, we reviewed the 
fndings and refections about each guideline and discussed 
issues and revision strategies for conficting interpretations 
and ambiguities. For example, our initial phrasing of Guide-
line 9 (“allow efcient correction”) and Guideline 17 (“al-
low coarse controls”) caused several evaluators to confuse 
instance-level corrections with global-level settings (sev-
eral evaluators identifed adjusting settings as applications 
of Guideline 9 rather than Guideline 17). We subsequently 
rephrased Guideline 17 to include the term “global”. 
We also identifed opportunities for merging related or 
redundant guidelines. For example, the initial set included 
“informing the user when to take control” and “fallback to 
a human where appropriate”. Our evaluations found few 
applications of these guidelines, and we determined both of 
them to be instances of Guideline 10 (initially phrased “scope 
services when uncertain”) and therefore removed them as 
distinct guidelines. Similarly, applications of “enable users to 
change privacy permissions” and “allow private mode” were 
deemed as instances of Guideline 17 (initially phrased “allow 
coarse controls”) and were merged with that guideline. 
We also decided to remove some guidelines that resulted in 
few or no applications during our evaluations. For example, 
neither the guideline to “explore vs. exploit in moderation” 
nor to “be especially conservative in the beginning” resulted 
in any identifable usage across the products or features we 
examined. While these guidelines are important at the AI 
modeling level, they appeared to be difcult to observe or 
design for in an interface. 
After these sessions we reformulated the remaining guide-
lines to follow a consistent format and to clarify issues identi-
fed by evaluators. Specifcally, we proposed that each guide-
line adhere to the following criteria: 
• It should be written as a rule of action, containing about 
3-10 words and starting with a verb. 
• It should be accompanied by a one-sentence description 
that qualifes or clarifes any potential ambiguities. 
• It should not contain conjunctions so that designers can 
clearly validate whether it is applied or violated in an 
interface. Removing conjunctions meant splitting some guidelines. 
For example, an initial guideline to “allow efcient invoca-
tion, correction, and dismissal” became three (to “support 
efcient invocation,” “support efcient dismissal,” and “sup-
port efcient correction,” Guidelines 7-9). 
Phase 2 produced a set of 18 guidelines that closely match 
the guidelines in Table 1. In the following sections we de-
scribe a user study that tested these 18 guidelines and a sub-
sequent expert validation of the guidelines that we slightly 
rephrased after the user study (resulting in the fnal proposed 
set shown in Table 1). 
5 PHASE 3: USER STUDY 
We conducted a user study with 49 HCI practitioners to 
1) understand the guidelines’ applicability across a variety of 
products; and 2) get feedback about the guidelines’ clarity. Procedure 
We modeled the user study after a heuristic evaluation. We 
assigned each participant to an AI-driven feature of a product 
they were familiar with and asked them to fnd examples 
(applications and violations) of each guideline. 
First, we helped participants become familiar with the 
guidelines by providing a document that included at least 
one application and one violation for each. The examples 
came from a range of AI-infused products and were pre-
sented with a 1-2 sentence description and a screenshot 
where appropriate. 
Participants were then instructed to play around with their 
assigned feature and fll out a form asking a series of ques-
tions. For each guideline, the form asked participants to frst 
determine if the guideline “does not apply” to their assigned 
feature (i.e., irrelevant or out of scope) and, if not, to explain 
why. If a participant judged that a guideline should apply 
to their assigned feature and they observed applications or 
violations, the form requested participants to provide their 
own examples, and, for each example, a rating of the ex-
tent of the application or violation on a 5-point semantic 
diferential scale from “clearly violated” to “clearly applied”, 
along with an explanation of the rating. Participants were 
incentivized with an additional monetary gratuity to include 
screenshots to illustrate the examples. After completing the 
evaluation, participants submitted their examples and ratings 
and flled in a fnal questionnaire which asked them to rate 
each guideline on a 5-point semantic diferential scale from 
“very confusing” to “very clear” and provide any additional 
comments about the guidelines. 
We estimated the study would take approximately one 
hour to complete based on our modifed heuristic evaluation 
study from Phase 2. Participants were given one week to 
complete the study on their own time and were compensated 
with an Amazon Gift Card worth a minimum of $50 and up to $70 based on the number of applications or violations for 
which they provided screenshots. 
Products 
One objective of our study was to determine if and how each 
of our design guidelines manifests in a variety of AI-infused 
products. We used a maximum-variance sampling strategy 
[28] to select popular AI-infused products that covered a 
wide range of scenarios. 
First, we searched online for rankings of top apps, soft-
ware, and websites in the U.S. for both mobile and desktop 
devices. This search resulted in 13 lists from sources such as 
app stores (Apple, Google Play, Windows), and Web trafc 
rankings [1, 6, 40]. From these lists, we selected the top 10 
products in each and then fltered out any that were ofensive, 
game related, or did not currently use AI to drive any of their 
main end-user facing services (determined by examination 
of the product or reading supplemental help documentation 
and news media articles when necessary). 
Next, we grouped the remaining products by their primary 
use case, resulting in 10 categories (e.g., email, e-commerce, 
social networking). We then selected two products per cate-
gory based on market share as determined by recent online 
statistics reports (e.g., [19]). Finally, we selected a promi-
nent AI-driven feature to evaluate per product. In total, we 
selected 20 products, two of which were from Microsoft. 
Many of the products we selected were available on multi-
ple platforms and devices. We attempted to evaluate products 
on a variety of platforms. Table 2 shows our fnal list of prod-
uct categories, features and platforms. 
Participants 
We recruited participants via HCI and design distribution 
lists at a large software company. During recruitment we 
screened for people with at least one year of experience work-
ing in or studying HCI (e.g., in roles such as user experience 
design and user experience research) and familiarity with 
discount usability testing methods (e.g., heuristic evaluation, 
cognitive walkthrough). We listed all possible product and 
platform combinations, and asked respondents to select the 
options they were familiar with and comfortable evaluating. 
We endeavored to assign 2-3 participants to each prod-
uct according to recommendations for heuristic evaluations. 
Nielsen [30] recommends 2-3 evaluators when evaluators 
have both usability experience and familiarity with the prod-
uct being tested. We also assigned participants so that each 
product was evaluated by people with a range of experience 
in discount usability techniques and no product was eval-
uated by participants with only limited experience. When 
participants dropped out of the study, we replaced them 
by assigning new participants from a wait list of eligible 
respondents, trying to maintain 2-3 evaluators per product. Product Category Feature Participants 
E-commerce (Web) Recommendations 6 
Navigation (Mobile) Route planning 5 
Music Recommenders 
(Mobile) Recommendations 5 
Activity Trackers (De-
vice) Walking detection 
and step count 5 
Autocomplete (Mobile) Autocomplete 5 
Social Networks (Mo-
bile) Feed fltering 5 
Email (Web) Importance fltering 5 
Voice Assistants (De-
vice) Creating a reminder 
with a due date 5 
Photo Organizers (Mo-
bile) Album suggestions 4 
Web Search (Web) Search 4 
Table 2: Product categories and features tested in the user 
study, and the number of participants assigned to each. 
In the end, 49 people (29 female, 18 male, 2 preferred not 
to answer) participated in our study. Participants spanned 
ages 18-55: 5 were in the age range of 18-24, 24 were in the 
age range of 25-34, 13 were aged 35-44 and 7 were aged 45-54. 
Of these participants, 19 were researchers, 12 were design-
ers, 11 were HCI or design interns from various universities 
worldwide, and the remaining 7 were a mix of engineers, 
product managers or vendors. The participants’ experience 
working in or studying HCI/UX was as follows: 1-4 years 
(23 participants), 5-9 years (14 participants), 10-14 years (9 
participants), 15-19 years (1 participant), 20+ years (2 par-
ticipants). Thirty-nine participants self-reported as being 
highly or very highly experienced at discount usability test-
ing methods while 10 reported as having medium to low 
levels of experience (we screened out participants with “very 
low” levels of experience). Participants were from 4 diferent 
countries spanning 3 continents. While we recruited partici-
pants using internal mailing lists, we took steps to mitigate 
sampling bias to ensure the results do not exclusively repre-
sent one organization’s mindset, in addition to including the 
11 external participants. Our questionnaires asked partici-
pants to rate the extent to which an example is illustrative 
of a guideline and the clarity of each guideline’s wording on 
Likert scales. These questions are unlikely to be infuenced 
by company values. Moreover, our main sampling criterion 
was experience with discount usability methods. It is un-
likely that the entirety of participants’ professional training 
and experience were internal. 
Adjustments and Misinterpretations 
To obtain accurate counts of examples of the proposed guide-
lines across products, we reviewed participant responses for 
the following cases: • Duplicate applications or violations of a guideline for any 
given product (55 instances). For example, two diferent 
participants identifed the same application of Guideline 
1 for an activity tracker: “This guideline is applied in the 
activity summary view, where it shows a summary of my 
‘move’, ‘exercise’ and ‘stand’ metrics.” and “Displays all the 
metrics that it tracks and explains how. Metrics include 
movement metrics such as steps, distance traveled...” The 
55 duplications were removed from the analysis. 
• Instances where participants used “does not apply” to indi-
cate that they could not fnd examples of a guideline rather 
than to indicate that the guideline is not relevant for the 
product they were testing, as we intended by this desig-
nation (73 instances). For example, “To be quite honest I 
believe that this would apply, however I can’t think of a 
way to show it.” and “Cannot fnd examples of application 
or violation.”. These 73 instances were also removed from 
the analysis. 
• Instances where participants used “does not apply” to in-
dicate that a guideline was violated (20 instances). For 
example, “Even in the setting page, there’s no option for 
changing or customizing anything for the autocomplete 
function.” and “[Voice Assistant, Product #1] did not pro-
vide additional hints or tips to educate me on what the 
system is capable of achieving beyond the task I had al-
ready asked it to run.” We reclassifed these instances as 
violations. 
• Instances where participants misinterpreted one guideline 
for another, discussed further below (56 instances). 
We identifed these cases using a two-pass process where 
participant responses were frst reviewed by one member 
of our team to identify each case and then those cases were 
verifed or invalidated by another member of our team. We 
removed 14 additional instances from our analysis when the 
two reviewers from our team disagreed on any of these cases. 
Results 
Our evaluation in this phase focused on two key questions, 
each addressed in one of the subsections below: 1) Are the 
guidelines relevant? That is, can we identify examples of 
each guideline across a variety of products and features? 2) 
Are the guidelines clear? That is, can participants understand 
and diferentiate among them? 
Relevance. Across the 20 products they evaluated, partici-
pants identifed 785 examples of the 18 guidelines, after the 
adjustments described earlier: 313 applications, 277 viola-
tions, 89 neutrals (rated at the mid-point between “clearly 
applied” and “clearly violated”), and 106 instances of “does 
not apply”. Figures 1a-1c show the guideline counts per prod-
uct category for applications, violations, and “does not apply”, 
respectively. Figure 1d shows an aggregate of all applicable ratings, including neutral responses. Finally, Table 1 shows 
example applications participants provided for each guide-
line (marked as “clearly applied” by the participant). 
In this analysis, we use the following interpretation con-
structs to better understand results from Figure 1. First, we 
use the total number of applications and violations as an in-
dicator of the overall evidence of a guideline being relevant 
(e.g., Guidelines 1, 12, 17). Second, relevant guidelines with a 
high positive diference between the number of applications 
and violations are guidelines which are not only relevant but 
also widely implemented for the set of products in the study 
(e.g., Guidelines 1, 4, 12). Third, relevant guidelines with a 
high negative diference between the number of applications 
and violations are guidelines which, despite their importance, 
are still not widely implemented (e.g., Guidelines 2, 11, 17). 
Fourth, we discuss guidelines with the highest numbers of 
"does not apply" (e.g., Guidelines 3, 5, 6). 
Participants found at least one application or violation of 
each of our guidelines in each product category we tested, 
suggesting broad evidence of the guidelines’ relevance. While 
participants were able to identify examples of each guideline 
in most of the product categories we tested, voice assistants 
had the largest number of “does not apply” instances re-
ported, while photo organizers, activity trackers and voice 
assistants had the fewest numbers of total applications or 
violations. Interestingly, each of these product categories in-
volves a mode of operation or input data type beyond simple 
graphical user interfaces and text (specifcally, interaction 
over images or sensor data, or voice-based interaction). 
No instances of Guideline 10 “Scope services when in 
doubt” were reported for the two social networks we tested 
and no instances of Guideline 14 “Update and adapt cau-
tiously” were reported for the two activity trackers. Some 
participants reported that these guidelines were hard to ob-
serve in a single session or without knowledge about the 
underlying AI algorithms. For example, one participant noted 
that Guideline 10 was “More difcult to assess unless you 
have a lengthy period of time with the product - and po-
tential guidance for understanding the behind-the-scenes 
mechanisms,” possibly referring to understanding when the 
AI system was “in doubt”. Similarly, for Guideline 14, one 
participant said, “It’s a bit difcult to assess this in a sin-
gle session.” These guidelines were, however, observed in 
all other products that participants tested in our study, so 
such difculty could be attributed to the guidelines not be-
ing applied or being difcult to observe in these particular 
products. 
Relevant guidelines that have signifcantly (at least 40%) 
more applications than violations are evidence of being widely 
implemented across products. This is also an indicator that 
there exist current mechanisms in the intersection of AI (a) Counts of “clear application” or “application” (b) Counts of “clear violation” or “violation” 
responses. responses. 
(c) Counts of “does not apply” responses. (d) Counts of all responses, excluding “does not 
apply” and including neutral. 
Figure 1: Counts of applications (top left), violations (top right), and “does not apply” (bottom left) responses in our user study. 
Rows show counts by guideline, while columns show counts by product category tested. and design that facilitate the implementation of such guide-
lines. For example, frequent item sets and location detec-
tion were two common mechanisms used to support Guide-
line 4 in showing contextually relevant information (e.g., 
[E-commerce, Product #2] “The feature assumes I’m about to 
buy a gaming console and shows accessories and games that 
would go with it...” or [Web Search, Product #2] “Searching a 
movie title returns show times near my location for today’s 
date”). For Guideline 12, multiple products leverage the his-
tory of user interactions to suggest a reduced cache of items 
that might be more useful to the user (e.g., [Navigation, Prod-
uct #1] “Opening the app shows a list of recent destinations, 
as well as allows you to access ’favorite’ locations.”). 
Some guidelines emerged as relevant, but not widely im-
plemented, as indicated by the large number of violations. 
For example, Guideline 11 “Make clear why the system did 
what it did” had one of the highest number of violations, 
despite the large volume of active research in the area of in-
telligibility and explanations. This guideline also had one of 
the fewest reported instances of “does not apply”, suggesting 
that participants could imagine opportunities for explana-
tions, but were often unable to obtain them. In some cases, 
participants reported violations when they were unable to 
locate any explanation at all (e.g., [E-commerce, Product #1] 
“I have no idea why this is being shown to me. Is it trying 
to sell me stuf I do not need?” and [Music Recommender, 
Product #1] “Even when drilling down into a song there 
is no explanation for why this particular song was recom-
mended.”). In other cases, participants reported violations 
when explanations were provided but were seemingly in-
adequate for their purposes (e.g., [Email, Product #1] “This 
does list out things which afect it, but they don’t explain it 
in a clear manner. Do each of these afect it equally?” and 
[Navigation, Product #1] “It always says the suggested route 
is the “best route” but it doesn’t give you the criteria for why 
that route is the best.”). These results suggest that partici-
pants could envision explanations being useful in most of 
the products we tested, but more work is necessary to under-
stand the level of explanations people may desire and how 
designers can produce them. In some cases, explanations 
might be undesirable, for fnancial or business reasons (e.g. 
adversarial (gaming) behavior by Web page authors would 
be exacerbated if search engines explained their ranking.). 
Guidelines 3, 5, and 6 had the highest number of "does 
not apply" ratings. Several participants indicated that Guide-
line 3 was not applicable because the products they were 
testing presented services only when explicitly requested 
by the user. For example, for one of the E-commerce prod-
ucts, one participant stated, “I feel this guideline does not 
apply for the recommendations page. It [is] a very ‘pull’ kind 
of interaction.”; i.e., the user views recommendations while 
browsing and there are no ‘push’ notifcations. Similarly, for one of the Web Search engines we tested, one participant 
stated, “[the search engine] does not generally interrupt a 
user at any point. The mobile app has notifcations, which 
might be relevant here, but the desktop website does not. 
Generally speaking, AI services pop up based on when the 
user searches and what he or she searches for, not based on 
an ongoing session.” This guideline is therefore likely more 
relevant for products that take proactive actions without 
explicit user requests, such as sending notifcations. 
Guideline 5 “Match relevant social norms” and Guideline 
6 “Mitigate social biases” had some of the most reported in-
stances of “does not apply”. Examination of these instances 
revealed that in some cases participants frmly believed these 
guidelines were not relevant for the products they were test-
ing while other participants reported either applications or 
violations of these guidelines in those same product cate-
gories. For example, one participant reported about one of 
the navigation products tested that “information is not sub-
ject to biases, unless users are biased against fastest route”. 
However, a diferent participant was able to identify a viola-
tion of this guideline for the same product category “Regards 
the ‘Walking’ transport there’s no way to set an average 
walking speed. [The product] assumes users to be healthy.” 
Similarly, one participant reported about one of the voice 
assistants we tested that “Nothing in this interaction had any 
social biases that it could reinforce.”, while another stated 
about the same product that “While it’s nice that a male 
voice is given as an option, the default [voice assistant] voice 
is female, which reinforces stereotypical gender roles that 
presume a secretary or receptionist is female.” Some partici-
pants, however, had no trouble identifying bias: "I typed in 
’black’ in the search bar and it came back with images of 
me as well as my niece [...] it saw a black face and used that 
as its frame of reference for all pictures, then returned all 
pictures of me and my family without images of other black 
spaces in an environment". 
Guidelines 5 and 6 were noted as the least clear by our 
participants in their (see Figure 2), with several participants 
remarking about the difculty of imagining social norms 
beyond their own or recognizing potential sources of bias 
(e.g., “Hard for a designer to implement, because it requires 
them to think outside of their own social context”, “Doesn’t 
apply to me but to potential other people.”, and “This is hard 
to measure. Who defnes what is undesirable and unfair?”). 
These assessments suggest that a diverse set of evaluators 
may be necessary to efectively recognize or apply these 
guidelines in practice. Alternatively, designers may need 
specifc training or tools to recognize social norms and biases. 
GenderMag[ 5], a method for identifying gender biases in 
user interfaces, is one such tool, but further work is needed 
in this area. Figure 2: Subjective evaluations by study participants about 
the clarity of the 18 AI design guidelines. 
Clarity and Clarifications. Figure 2 presents clarity ratings 
for all guidelines. To identify guidelines in need of further 
clarifcation, we reviewed these ratings and the 56 misinter-
pretations explained in the section Adjustments and Misin-
terpretations. We noted guidelines as needing further clarif-
cation when errors were determined to be systematic, which 
we defned as having four or more instances confused with 
another guideline or having multiple participants making 
similar comments about clarity. From this analysis, we iden-
tifed and addressed the following issues: 
Guidelines 1, 2, and 11 (originally phrased as “Make ca-
pabilities clear”, “Set expectations of quality” and “Make 
explanations of behavior available”) had 13 misinterpreted 
instances (5 between Guidelines 1 and 2; 8 between Guide-
lines 1 and 11) and several comments about these being 
hard to diferentiate (e.g., one participant commented on 
Guideline 2 that “I don’t know what is diferent between this 
guideline and the guideline #1”). To clarify, we revised these 
guidelines using parallel language while emphasizing the in-
tended diferences (Guideline 1 is about what the system can 
do, Guideline 2 is about how well the system can do it, and 
Guideline 11 is about explaining why something happened, 
after the fact). 
Guideline 4 (originally phrased as “Show contextually rel-
evant information. Display information about the user’s in-
ferred goals and attention during interaction.”) was confused with Guideline 13 (originally phrased as “Learn from user 
behavior. Personalize the experience based on the user’s past 
actions”) six times. Examination revealed that most of these 
errors were due to “preferences” and “personalization” being 
considered as “relevant context”. To clarify, we rephrased 
these guidelines as in Table 1, emphasizing the diference 
between a user’s “current context” (e.g., “current task and 
environment”) and personalization which we intended to 
mean learning about preferences “over time”. 
Guidelines 3 and 4 (originally phrased as “Time services 
based on context” and “Show contextually relevant infor-
mation”) were confused with each other in four instances. 
Several participants commented that this was because what is 
displayed and when it is displayed are often related (e.g., “pro-
vide the right information at the right time” and “The time 
when I’m specifcally looking for DP to HDMI cable should 
be the most ideal time to recommend possible variations in 
DP to HDMI”). However, we decided to keep these guidelines 
separate to avoid conjunctions and updated Guideline 3 to 
use the same language of “current task and environment” as 
Guideline 4. 
Guideline 12 (originally phrased as “Maintain working 
memory”) was confused with Guideline 13 (“Learn from 
user behavior”) seven times, seemingly because the term 
“memory” was being interpreted as something that happens 
over time. To clarify, we revised these guidelines as in Table 1 
to emphasize the diference between maintaining short term 
memory of recent interactions and learning behaviors over 
time. 
Guidelines 15 and 17 (originally phrased as “Encourage 
feedback” and “Provide global controls”, respectively) were 
confused six times, seemingly because the diference between 
local (or instance-level) feedback and global feedback (e.g., 
settings that impact behaviors on all instances) was still 
unclear despite introducing the term “global” after our frst 
heuristic evaluation in Phase 2. We therefore revised these 
Guidelines as in Table 1 to further emphasize that Guideline 
15 is about granular feedback that happens during a specifc 
interaction, while Guideline 17 is about global customization 
of behaviors. 
These revisions resulted in the fnal set of guidelines pre-
sented in Table 1, which we further evaluated with experts 
as described in the following section. 
6 PHASE 4: EXPERT EVALUATION OF REVISIONS 
To verify whether the revisions we proposed in the pre-
vious section improved our guidelines, we conducted an 
expert review. Expert reviews have been shown to be efec-
tive at identifying problems related to wording and clarity 
[27, 34, 43]. For this purpose, we defned experts as people 
who have work experience in UX/HCI and who are familiar 
with discount usability methods such as heuristic evaluation. Figure 3: Number of experts out of 11 who preferred the re-
vised or the old version. One participant suggested their own 
alternative for Guideline 3. 
We reasoned that experts with experience in applying var-
ious guidelines to design solutions would be able to assess 
whether our guidelines would be easy to understand and 
therefore to work with. 
We recruited 11 experts (6 female, 5 male) from the same 
large company through snowball sampling. Of these experts, 
6 were UX designers, 3 were UX researchers, and two were 
in research and product planning roles. Their length of ex-
perience working in UX or HCI was more than 20 years (1), 
16-20 years (4), 11-15 years (3), and 2-5 years (3). Partici-
pants self-reported their familiarity with discount usability 
methods as very high (5), high (4), and medium (2). 
First, we asked each expert to review the 9 revised guide-
lines independently. They chose, for each guideline, the ver-
sion they thought was easier to understand (the old version 
or the version we revised after in Phase 3). Then the experts 
reviewed the pairs of guidelines that emerged in Phase 3 as 
confusing or overlapping. For each pair, we asked experts to 
rate whether the two guidelines mean the same thing and 
the difculty of distinguishing between them. We compen-
sated participants with a $30 gift card for an estimated time 
commitment of 45 minutes. 
Figure 3 shows that experts preferred the revised versions 
for all but Guideline 15. Revisions appear to have helped dis-
tinguish between the pairs of guidelines Phase 3 participants 
had trouble with, but fve experts still found Guidelines 1 
and 2 somewhat difcult to distinguish (Table 4). Since the 
revision of Guideline 15 made it easy to distinguish it from 
17, we decided to keep it. 
Table 3 illustrates the evolution of the frst two guidelines 
through the four phases. 
7 DISCUSSION & FUTURE WORK 
We synthesized guidance proposed over the past 20 years 
about the design of human-AI interaction into a set of 18 
AI usability guidelines. These guidelines were iteratively re-
fned in four phases by a team of 11 researchers, and were 
applied or reviewed by an additional 60 designers and us-
ability practitioners. Over the various stages of development, Phase 1: Consolidating guidelines 
Set appropriate expectations. 
Set accurate expectations to give people a clear idea of 
what the experience is and isn’t capable of doing. 
Phase 2: Internal evaluation Set appropriate expectations. 
Phase 3: User study 
G1: Make capabilities clear. Help the user understand what 
the AI system is capable of doing. 
G2: Set expectations of quality. Help the user understand 
what level of performance the AI system is capable of 
delivering. Phase 4: Expert evaluation of revisions 
G1: Make clear what the system can do. Help the user 
understand what the AI system is capable of doing. 
G2: Make clear how well the system can do what it can do. 
Help the user understand how often the AI system may 
make mistakes. 
Table 3: Evolution of Guidelines 1 and 2. 
the guidelines were applied to AI-infused products across 10 
product categories. These eforts provide evidence for the 
relevance of the guidelines across a wide range of common 
AI-infused systems. In terms of utility, we anticipate the 
guidelines will be useful to evaluate existing products and 
emerging design ideas. Our evaluation methods show that 
the guidelines lend themselves well to usability inspection 
methods such as heuristic evaluation. Future work could 
examine the uses and value of these guidelines at various 
stages of design. 
We recognize that there is a tradeof between generality 
and specialization, and that these guidelines might not ade-
quately address all types of AI-infused systems. For example, 
we reported that some guidelines do not directly apply to AI 
systems that lack graphical user interfaces (e.g., voice-based 
virtual assistants and activity trackers). Additional guidelines 
may be necessary to help designers and developers create 
intuitive and efective products with these properties or in 
these product categories. Likewise, specialized guidelines 
may be required in certain high-risk or highly regulated areas 
such as semi-autonomous vehicles, robot-assisted surgery, 
and fnancial systems. We hope the 18 guidelines presented 
here and their validation process stimulate and inform future 
research into the development of domain-specifc guidance. 
Our work also intentionally focused on AI design guide-
lines that we believed could be easily evaluated by inspection 
of a system’s interface. For example, we excluded broad prin-
ciples such as "build trust", and focused instead on specifc 
and observable guidelines that are likely to contribute to 
building trust. Previous work, however, has proposed guide-
lines that impact the usability of AI-infused systems but must be considered when constructing the AI model. For exam-
ple, we excluded Horvitz’s [ 17] principle of “inferring ideal 
action in light of costs, benefts, and uncertainties” and guid-
ance about being “especially conservative in the beginning” 
because these require decisions to be made at the modeling 
layer of a system. We foresee the value of future work to 
investigate how designers and model developers can work 
together to efectively apply these guidelines in AI-infused 
systems. For example, given the expected performance of an 
AI model, designers may recommend specifc designs that 
reduce costs while optimizing benefts to users (e.g., display-
ing multiple options to users until the performance of the AI 
model is improved enough to take proactive action on the 
user’s behalf). 
Our decisions to optimize for generality, and to focus on 
observable properties, serve as a reminder that interaction 
designers routinely encounter these types of trade-ofs. We 
anticipate situations where there will be interactions and 
trade-ofs in attempts to employ several of the guidelines. 
As an example, if a system uses a complex or deep model to 
achieve a high level of performance, it may be challenging 
to both convey the consequences of user actions (Guideline 
16), while also actively learning from user behavior (Guide-
line 13). Further research is necessary to understand the 
implications of these potential interactions and trade-ofs for 
the design of AI systems and to understand how designers 
employ these guidelines "in the wild." 
Finally, we recognize that our guidelines only begin to 
touch on topics of fairness and broader ethical considera-
tions. Ethical concerns extend beyond the matching of social 
norms (Guideline 5) and mitigating social biases (Guideline 
6). As an example, an AI system may adhere to each of these 
guidelines and yet impact people’s lives or livelihoods in a 
consequential manner. It is imperative that system designers 
carefully evaluate the many infuences of AI technologies 
on people and society, and that this remains a topic of ongo-
ing research and intense interest. Ethics-focused guidelines 
can be difcult to fully evaluate in a heuristic evaluation, 
and successful detection of problems may depend on who 
is performing the evaluation. Our results related to Guide-
lines 5 “Match relevant social norms” and 6 “Mitigate social 
biases” suggest that diversity among evaluators helps iden-
tify a range of issues that might be invisible to members of 
majority groups. 
8 CONCLUSION 
We proposed and evaluated 18 generally applicable design 
guidelines for human-AI interaction. We distilled the guide-
lines from over 150 AI-related design recommendations and 
validated them through three rounds of evaluation. We are 
hopeful that application of these guidelines will result in 
better, more human-centric AI-infused systems, and that our Guidelines Meanings: 
Diferent Distinguish: 
Easy Distinguish: 
Hard Distinguish: 
Neutral/ 
Medium 
1 & 2 10 6 5 0 
1 & 11 11 6 3 2 
3 & 4 10 6 2 3 
4 & 13 11 9 1 1 
12 & 13 9 7 1 3 
15 & 17 10 9 1 1 
Table 4: Number of experts out of 11 who rated each pair of 
guidelines as diferent in meaning and distinguishable. 
synthesis can facilitate further research. As the current tech-
nology landscape is shifting towards the increasing inclusion 
of AI in computing applications, we see signifcant value in 
working to further develop and refne design guidelines for 
human-AI interaction. 
9 ACKNOWLEDGMENTS 
The authors would like to acknowledge the contributions of 
our newest team member, Ever Zayn McDonald. REFERENCES 
[1] Alexa. 2018. Top sites in the United States. Retrieved July, 2018 from 
https://www .alexa .com/topsites/countries/US 
[2] Kathy Baxter. 2017. How to Meet User Expectations for Ar-
tifcial Intelligence. Medium. Retrieved September, 2018 
from https://medium .com/salesforce-ux /how-to-meet-user-
expectations-for-artifcial-intelligence-a51d3c82af6 
[3] Victoria Bellotti and Keith Edwards. 2001. Intelligibility and Account-
ability: Human Considerations in Context-Aware Systems. Human– 
Computer Interaction 16, 2-4 (2001), 193–212. 
[4] Andrea Bunt, Matthew Lount, and Catherine Lauzon. 2012. Are Expla-
nations Always Important?: A Study of Deployed, Low-cost Intelligent 
Interactive Systems. In Proc. IUI ’12. ACM, New York, NY, USA, 169– 
178. 
[5] Margaret Burnett, Simone Stumpf, Jamie Macbeth, Stephann Makri, 
Laura Beckwith, Irwin Kwan, Anicia Peters, and William Jernigan. 2016. 
GenderMag: A method for evaluating software’s gender inclusiveness. 
Interacting with Computers 28, 6 (2016), 760–787. 
[6] comScore. 2018. Latest rankings. Retrieved July, 2018 from https: 
//www .comscore .com/Insights/Rankings 
[7] Maartje de Graaf, Somaya Ben Allouch, and Jan van Dijk. 2017. Why 
Do They Refuse to Use My Robot?: Reasons for Non-Use Derived from 
a Long-Term Home Study. In Proc. HRI ’17. ACM, New York, NY, USA, 
224–233. 
[8] Defy Media. 2015. Damn You Auto Correct! Retrieved September, 
2018 from http://www .damnyouautocorrect .com/ 
[9] T. Deuschel and T. Scully. 2016. On the Importance of Spatial Per-
ception for the Design of Adaptive User Interfaces. In 2016 IEEE 10th 
International Conference on Self-Adaptive and Self-Organizing Systems 
(SASO). 70–79. 
[10] Anind Dey, Jennifer Mankof, Gregory Abowd, and Scott Carter. 2002. 
Distributed Mediation of Ambiguous Context in Aware Environments. 
In Proc. UIST ’02. ACM, New York, NY, USA, 121–130. 
[11] Leah Findlater and Joanna McGrenere. 2004. A Comparison of Static, 
Adaptive, and Adaptable Menus. In Proc. CHI ’04. ACM, New York, NY, 
USA, 89–96. 
[12] Krzysztof Z. Gajos, Mary Czerwinski, Desney S. Tan, and Daniel S. 
Weld. 2006. Exploring the Design Space for Adaptive Graphical User Interfaces. In Proc. AVI ’06. ACM, New York, NY, USA, 201–208. 
[13] Krzysztof Z Gajos, Katherine Everitt, Desney S Tan, Mary Czerwinski, 
and Daniel S Weld. 2008. Predictability and accuracy in adaptive user 
interfaces. In CHI. ACM, 1271–1274. 
[14] Jonathan L. Herlocker, Joseph A. Konstan, and John Riedl. 2000. Ex-
plaining Collaborative Filtering Recommendations. In Proc. CSCW ’00. 
ACM, New York, NY, USA, 241–250. 
[15] Setia Hermawati and Glyn Lawson. 2016. Establishing usability heuris-
tics for heuristics evaluation in a specifc domain: Is there a consensus? 
Applied Ergonomics 56 (2016), 34 – 51. 
[16] Kristina Höök. 2000. Steps to take before intelligent user interfaces 
become real. Interacting with Computers 12, 4 (2000), 409–426. 
[17] Eric Horvitz. 1999. Principles of Mixed-Initiative User Interfaces. In 
Proc. CHI ’99. ACM, New York, NY, USA, 159–166. 
[18] Eric Horvitz, Jack Breese, David Heckerman, David Hovel, and Koos 
Rommelse. 1998. The Lumière Project: Bayesian User Modeling for 
Inferring the Goals and Needs of Software Users. In Proc. UAI ’98. 
Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 256–265. 
[19] IDC Corporate USA. 2018. IDC: The premier global market intelligence 
frm. Retrieved September, 2018 from https://www .idc .com/ 
[20] Anthony Jameson. 2008. Adaptive interfaces and agents. In The human-
computer interaction handbook: Fundamentals, evolving technologies 
and emerging applications (2nd ed.), Andrew Sears and Julie A. Jacko 
(Eds.). CRC Press, Boca Raton, FL, 433–458. 
[21] Todd Kulesza, Margaret Burnett, Weng-Keen Wong, and Simone 
Stumpf. 2015. Principles of Explanatory Debugging to Personalize 
Interactive Machine Learning. In Proc. IUI ’15. ACM, New York, NY, 
USA, 126–137. 
[22] Chia-Jung Lee, Jaime Teevan, and Sebastian de la Chica. 2014. Charac-
terizing Multi-click Search Behavior and the Risks and Opportunities 
of Changing Results During Use. In Proc. SIGIR ’14. ACM, New York, 
NY, USA, 515–524. 
[23] Brian Y. Lim and Anind K. Dey. 2009. Assessing Demand for Intelligi-
bility in Context-aware Applications. In Proc. UbiComp ’09. ACM, New 
York, NY, USA, 195–204. 
[24] Josh Lovejoy. 2018. The UX of AI. Google Design. Retrieved September, 
2018 from https://design .google/library/ux-ai/ 
[25] Josh Lovejoy and Jess Holbrook. 2017. Human-Centered Ma-
chine Learning. 7 steps to stay focused on the user when de-
signing with ML. Medium. Retrieved September, 2018 
from https://medium .com/google-design /human-centered-machine-
learning-a770d10562cd 
[26] Ewa Luger and Abigail Sellen. 2016. "Like Having a Really Bad PA": 
The Gulf Between User Expectation and Experience of Conversational 
Agents. In Proc. CHI ’16. ACM, New York, NY, USA, 5286–5297. 
[27] Aaron Maitland and Stanley Presser. 2016. How Accurately Do Difer-
ent Evaluation Methods Predict the Reliability of Survey Questions? 
Journal of Survey Statistics and Methodology 4, 3 (2016), 362–381. 
[28] Joseph A Maxwell. 2012. Qualitative research design: An interactive 
approach. Vol. 41. Sage publications. 
[29] Chelsea Myers, Anushay Furqan, Jessica Nebolsky, Karina Caro, and 
Jichen Zhu. 2018. Patterns for How Users Overcome Obstacles in Voice 
User Interfaces. In Proc. CHI ’18. ACM, New York, NY, USA, Article 6, 
7 pages. 
[30] Jakob Nielsen. 1992. Finding Usability Problems Through Heuristic 
Evaluation. In Proc. CHI ’92. ACM, New York, NY, USA, 373–380. 
[31] Jakob Nielsen and Rolf Molich. 1990. Heuristic Evaluation of User 
Interfaces. In Proc. CHI ’90. ACM, New York, NY, USA, 249–256. 
[32] D.A. Norman. 1988. The psychology of everyday things. Basic Books, 
New York. 
[33] Donald A. Norman. 1994. How Might People Interact with Agents. 
Commun. ACM 37, 7 (July 1994), 68–71. [34] Kristen Olson. 2010. An examination of questionnaire evaluation by 
expert reviewers. Field Methods 22, 4 (2010), 295–318. 
[35] Martin Porcheron, Joel E. Fischer, Stuart Reeves, and Sarah Sharples. 
2018. Voice Interfaces in Everyday Life. In Proc. CHI ’18. ACM, New 
York, NY, USA, Article 640, 12 pages. 
[36] Emilee Rader, Kelley Cotter, and Janghee Cho. 2018. Explanations As 
Mechanisms for Supporting Algorithmic Transparency. In Proc. CHI 
’18. ACM, New York, NY, USA, Article 103, 13 pages. 
[37] Ruth Ravichandran, Sang-Wha Sien, Shwetak N. Patel, Julie A. Kientz, 
and Laura R. Pina. 2017. Making Sense of Sleep Sensors: How Sleep 
Sensing Technologies Support and Undermine Sleep Health. In Proc. 
CHI ’17. ACM, New York, NY, USA, 6864–6875. 
[38] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. "Why 
Should I Trust You?": Explaining the Predictions of Any Classifer. In 
Proc. KDD ’16. ACM, New York, NY, USA, 1135–1144. 
[39] Katharine Schwab. 2017. 10 Principles For Design In 
The Age Of AI. Retrieved September, 2018 from 
https://www .fastcompany .com/3067632 /10-principles-for-design-
in-the-age-of-ai 
[40] SimilarWeb. 2018. Top websites ranking. Retrieved July, 2018 from 
https://www .similarweb .com/top-websites/united-states 
[41] Jack Stewart. 2018. Why Tesla’s Autopilot Can’t See a 
Stopped Firetruck. Retrieved September, 2018 from https: 
//www .wired .com/story/tesla-autopilot-why-crash-radar/ 
[42] Erica Virtue. 2017. Designing with AI. 
[43] Jolita Vveinhardt and Evelina Gulbovaite. 2016. Expert evaluation of di- ˙ 
agnostic instrument for personal and organizational value congruence. 
Journal of business ethics 136, 3 (2016), 481–501. 
[44] Daniel S Weld and Gagan Bansal. 2018. Intelligible Artifcial Intelli-
gence. arXiv preprint arXiv:1803.04263 (2018). 
[45] Rayoung Yang, Eunice Shin, Mark W. Newman, and Mark S. Ackerman. 
2015. When Fitness Trackers Don’T ’Fit’: End-user Difculties in the 
Assessment of Personal Tracking Device Accuracy. In Proc. UbiComp 
’15. ACM, New York, NY, USA, 623–634. APPENDIX
In this appendix, we illustrate each of our 18 human-AI inter-
action design guidelines with three example applications and 
three example violations provided by our user study partici-
pants when testing the principles against popular AI-infused 
products. Each application was rated as either a “Clear Ap-
plication” or an “Application” by participants, while each 
violation was rated as either a “Clear Violation” or a “Vio-
lation”. For each example we indicate the product category 
the participant was testing, but obscure the specific product 
names.
Guideline 1.
Make clear what the system can do.
Help the user understand what the AI system is capable of 
doing.
Example applications:
•[Navigation, Product #1] “Specific examples of things I
could search for are in the search bar”
•[Activity Trackers, Product #1] “Displays all the metrics
that it tracks and explains how. Metrics include movement
metrics such as steps, distance traveled, length of time
exercised, and all-day calorie burn, for a day.”
•[Social Networks, Product #2] “[The product] communi-
cates to users that it will evaluate and provide to you
potential people to follow based on your interests and the
community of people you follow.”
Example violations:
•[Social Networks, Product #1] “This guideline is violated
because I cannot even tell what this news feed can/will
show.”
•[Photo Organizers, Product #1] “We know the AI is able
to detect and associate an image with a category, but the
user does not know all the categories available.”
•[Voice Assistants, Product #1] “When [the assistant] was
invoked verbally...I was not given any indication of what
commands I could request.”
Guideline 2.
Make clear how well the system can do what it can
do.
Help the user understand how often the AI system may make
mistakes.
Example applications:
•[Music Recommenders, Product #1] “A little bit of hedging
language: ‘we think you’ll like’.”
•[Email, Product #2] “While the interface does not give
any indication about the level of performance possible,
the help page is an application of this heuristic. It sets
the expectation that it will start working right away, but
will get better with use, making it clear that mistakes willhappen and you can ‘teach’ [the product] to better perform,
and failing that, you can set overrides.”
•[Email, Product #1] “There are two things this help text
tells me. First, by calling it ‘magic’ - to me that means
they don’t know exactly how to explain what’s happening
(which means it could do crazy things I didn’t expect).
Second, since I can ‘teach’ it that it’s not important, it
emphasizes that it might be wrong about things (which is
ok cause I can help fix it).”
Example violations:
•[Navigation, Product #1] “There is no indication of ac-
curacy of the time estimates or how conditions may be
changing. There is no measure given of how well the AI
predictions matched the result once you arrive at the des-
tination.”
•[Voice Assistants, Product #1] “Aside from the ‘Hi, how
can I help?’, [the product] does not promise anything more.
No expectation of quality is set.”
•[Social Networks, Product #1] “For some of the ads, there
is a ‘suggested post’ on the top to indicate that this is just
a suggestion. But for the rest of the posts, there is no clue
for me to tell the quality.”
Guideline 3.
Time services based on context.
Time when to act or interrupt based on the user’s current
task and environment.
Example applications:
•[Navigation, Product #1] “In my experience using the app,
it seems to provide timely route guidance. Because the map
updates regularly with your actual location, the guidance
is timely.”
•[Autocomplete, Product #1] “Suggestions are always present
when you might need them (whenever the keyboard is up)”
•[Social Networks, Product #1] “If the user has not accessed
[the product] in a while, the application will let the user
know that there is something new to be explored - a story,
video, etc.”
Example violations:
•[Activity Trackers, Product #2] “Context is very basic, it no-
tifies when I approach my goal; hit my goal; or exceed my
goal. The timing of it is not clear, however. The timestamps
are varied, too... It feels pretty arbitrary; my interpretation
of the reasoning behind the notification can’t be described
by my activity or proximity to the goal.”
•[Email, Product #2] “Sending notifications for unimportant
messages likely something most people will not want as
an interruption.”
•[Voice Assistants, Product #2] “There is no indication of
when [the assistant] will actually remind you of the set
reminder. She just confirms that the reminder has been set(mind you this I regardless if you have this Reminders app
downloaded or not).”
Guideline 4.
Show contextually relevant information.
Display information relevant to the user’s current task and
environment.
Example applications:
•[E-commerce, Product #2] “The feature assumes I’m about
to buy a gaming console and shows accessories and games
that would go with it, and it features those items promi-
nently (above the product information) on the webpage.”
•[Web Search, Product #2] “Searching a movie title returns
show times near my location for today’s date”
•[Navigation, Product #1] “When I use [the product] for
driving directions, it remembers where I parked my car.
Next time when I open the app, it suggests routing me
back to my car.”
Example violations:
•[Activity Trackers, Product #2] “They chose to have a
uniform view regardless of context. When I’m moving or
static, the view is the same. The only change is that the
step counter advances (or not).”
•[E-commerce, Product #1] “If I start looking at a new item
(like paper towels), when I scroll down to the end of the
page, I get recommendations related to the recent items I
viewed (tennis balls)... it doesn’t take into account that I
am currently looking for paper towels and I have already
purchased the tennis balls.”
•[Email, Product #2] “What goes into the [tabs] is the same
all the time. It does not change based on the context, for
example to...emails related to the meeting I’m attending
or the message I’m reading.”
Guideline 5.
Match relevant social norms.
Ensure the experience is delivered in a way that users would
expect, given their social and cultural context.
Example applications:
•[Photo Organizers, Product #1] “[The product’s] album
suggestions feature is able to recognize people’s pets and
uses the verbiage “important cats & dogs”, understanding
that people’s pets are important to users and are like family
even.”
•[Voice Assistants, Product #1] “[The assistant] uses a semi-
formal voice to talk to you - spells out “okay” and asks
further questions.”
•[Navigation, Product #1] “If you select walking, the AI
avoid(s) busy roads and searches for trails.”
Example violations:•[Activity Trackers, Product #1] “Provides a reminder to
stand up without understanding my social context (e.g.,
in a meeting, having lunch with a friend etc)... Does not
consider the social context prior to sending notifications
for activity and does not use tone appropriately - just says
“time to stand!” no matter what”
•[Email, Product #2] “the system does not follow the social
norms of a workplace. For example, one norm is to pay
attention to your manager. However, even with access to
company hierarchies, it isn’t clear that the system will put
messages from one’s direct manager in the [appropriate
tab] automatically.”
•[Voice Assistants, Product #1] “[The assistant] does not
match expected conversation norms. When asked “[wake
command], set a reminder for next week” the AI does not
recognize that the remind me command has been invoked
and responds “Sorry, I can’t set reminders yet.” Only when
the specific command syntax “Remind me to [reminder]
on [date] at [time]” is used does [the assistant] understand
to set a reminder...It seems [the assistant] is unable to
interpret conversational language and instead requires a
very specific command syntax.”
Guideline 6.
Mitigate social biases.
Ensure the AI system’s language and behaviors do not rein-
force undesirable and unfair stereotypes and biases.
Example applications:
•[E-commerce, Product #2] “The feature does not unfairly
assume gender biases in some search results that could
potentially introduce them. For example, a search for tools
or diapers could accidentally serve related products that
are gender biased. The system seems to provide highly
specific recommendations of the very same product type.”
•[Web Search, Product #2] “a search for CEO or Doctor
shows somewhat diverse people in the resulting images...The
images are pretty diverse in terms of gender and ethnicity,
although still lack in some respects such as disability”
•[Autocomplete, Product #2] “The autocomplete feature
clearly suggests both genders [him, her] without any bias
while suggesting the text to complete.”
Example violations:
•[Voice Assistants, Product #1] “When asked “...can you
change your voice” [the assistant] responds in a male voice
saying “Here is an example of my other voice. Would you
like me to use this one?”... While it’s nice that a male
voice is given as an option, the default...voice is female,
which reinforces stereotypical gender roles that presume
a secretary or receptionist is female.”•[Autocomplete, Product #2] “autocomplete suggests names
correctly for Western sounding names but falls short for
ethnic-sounding names.”
•[Navigation, Product #1] “Regards the “Walking” trans-
port there’s no way to set an average walking speed. [The
product] assumes users to be healthy.”
Guideline 7.
Support efficient invocation.
Make it easy to invoke or request the AI system’s services
when needed.
Example applications:
•[Voice Assistants, Product #1] “I can say [wake command]
to initiate.”
•[E-commerce, Product #1] “In addition to the system giving
you recommendations as you browse, you can go to your
“Browsing history > Manage history > More like this” to
get recommendations specific to a particular product.”
•[Web Search, Product #1] “user can highlight a specific
part of an image to search for that specific piece. This
shows up on every image, so user can use it anytime they
like.”
Example violations:
•[Navigation, Product #1] “[The product] remembers where
you parked your car. However if it fails to remember, or I
want it to remember something else (e.g., where I chained
up my bike), it is not possible (or at least not easily discov-
erable) to invoke the capability when I need it.”
•[Navigation, Product #2] “Guideline is violated because
user cannot ask the system for alternative routes if they
are not detected initially.”
•[E-commerce, Product #2] “Many of the products I searched
for did not show the “Customers also considered” AI fea-
ture. There is no way to invoke this feature manually.”
Guideline 8.
Support efficient dismissal.
Make it easy to dismiss or ignore undesired AI system ser-
vices. Example applications:
•[E-commerce, Product #2] “Feature is unobtrusive, below
the fold, and easy to scroll past...Easy to ignore.”
•[Social Networks, Product #2] “[The product] allows the
user to easily hide or report ads that have been suggested
by the AI by tapping the ellipses at the top right of the ad.”
•[Voice Assistants, Product #1] “I can say “nevermind” to
dismiss it once I have said [wake command]. I can also
just not say anything and it stops listening.”
Example violations:
•[Autocomplete, Product #2] “I didn’t see a dismiss button.
I can dismiss it by dismiss the whole keyboard”•[Activity Trackers, Product #1] “The guideline is violated
because it is not clear within the Steps page, how to turn
off the background/ambient step tracking functionality.”
•[Navigation, Product #1] “Suggested locations based on
calendar entries can’t be removed from the suggestions.”
Guideline 9.
Support efficient correction.
Make it easy to edit, refine, or recover when the AI system
is wrong.
Example applications:
•[Navigation, Product #1] “If [the product] is wrong about
where I parked my car, it provides an easy way to edit the
location by dragging on the map.”
•[Web Search, Product #2] “automatically ‘corrects’ spelling
errors, etc. but gives option at top to return to query as
originally typed...Notes that the query had been corrected
and is one click to revert back to original”
•[Voice Assistants, Product #2] “Once my request for a re-
minder was processed I saw the ability to edit my reminder
in the UI that was displayed. Small text underneath stated
“Tap to Edit” with a chevron indicating something would
happen if I selected this text.”
Example violations:
•[E-commerce, Product #1] “I already recently bought the
items which are in my recommendation list & there is no
message to discontinue nor option for users to deselect.”
•[Activity Trackers, Product #1] “As far as I can tell, there is
no way for the user to edit the number of steps collected.
The user can delete the data point altogether...There is just
no way to manually input or change the data.
•[Web Search, Product #1] “Searches can be easily corrected
with a new query (which are sometimes suggested by [the
product] itself). However, editing a seemingly AI system
override to interpret "Sea of" to "SEA to" is not possible.”
Guideline 10.
Scope services when in doubt.
Engage in disambiguation or gracefully degrade the AI sys-
tem’s services when uncertain about a user’s goals.
Example applications:
•[Navigation, Product #1] “If more than one line takes the
same route the user can choose between the preferred
line.”
•[Autocomplete, Product #1] “It usually provides 3-4 sug-
gestions instead of directly auto completing it for you”
•[Voice Assistants, Product #2] “If I didn’t respond or if I
spoke quietly, [the assistant] let me know they had trouble
hearing me”
Example violations:•[Navigation, Product #1] “When searching for a specific
restaurant, if the right place can’t be found, it fails to recog-
nize that you are searching for food and does not suggest
restaurants in your area...The AI doesn’t recognize the
broader user goal and suggest possible alternatives when
it can’t find the exact result.”
•[Email, Product #2] “This heuristic is violated. There is no
indication if the system is unsure. The system does not
ask for assistance (e.g. request feedback on an uncertain
classification). It is not clear how it decides what to do
with unclear messages, or what the current quality of the
model is, beyond the information from the help screen
which says the system will improve over time.”
•[Music Recommenders, Product #2] “The system doesn’t
ask for user input about its recommendations, nor does it
provide a way for users to provide input.”
Guideline 11.
Make clear why the system did what it did.
Enable the user to access an explanation of why the AI system
behaved as it did.
Example applications:
•[E-commerce, Product #1] “Clicking “Why recommended”
explains why they have recommended that particular item
to you.”
•[Music Recommenders, Product #2] “I think this applies
because each of recommendation has some information
as to which songs are displayed on it - similar to the song,
from the same artist, from the same album etc.”
•[Navigation, Product #2] “The route chosen by the app
was made based on the Fastest Route, which is shown in
the subtext.”
Example violations:
•[Music Recommenders, Product #2] “The system provides
no information about why the recommended songs/artists
are chosen.”
•[Email, Product #2] “There is no indication of why a mes-
sage is classified as it is, and I cannot find a way to find out.
A message could be classified as [unimportant] because of
the content, the sender, or any number of other reasons
and no details are available, either per message or as a
summary of the [unimportant category] rules which have
been learned.”
•[Activity Trackers, Product #2] “There are no explanations
in the app about how walking detection and step count
are measured. The system is pretty deterministic in how
it makes measurements about my walking behaviour and
then how it matches them with the initial goal I set.”Guideline 12.
Remember recent interactions.
Maintain short term memory and allow the user to make
efficient references to that memory.
Example applications:
•[Navigation, Product #1] “Opening the app shows a list
of recent destinations, as well as allows you to access
“favorite” locations.”
•[Web Search, Product #1] “[The search engine] remembers
the context of certain queries, with certain phrasing, so
that it can continue the thread of the search (e.g., “who
is he married to” after a search that surfaces Benjamin
Bratt)”
•[Voice Assistants, Product #1] “[The assistant] seems to re-
member conversation context at least one command back.
When asked “[wake command], what’s the reminder?” she
announces the last unheard remind me.”
Example violations:
•[Social Networks, Product #1] “This guideline is violated
since there is no indication of “what you have read”
•[Web Search, Product #2] “Although many food/recipe
searches were made right before, a search for “stir fry” has
a music video as a top result”
•[Voice Assistants, Product #2] “Nope set the same reminder
twice to drink water at 4:15 and it had no idea”
Guideline 13.
Learn from user behavior.
Personalize the user’s experience by learning from their ac-
tions over time.
Example applications:
•[Music Recommenders, Product #2] “I think this is applied
because every action to add a song to the list triggers new
recommendations.”
•[Social Networks, Product #1] “I am pretty sure they do
this as I have observed that I get more ads of a certain type
if I accidentally or deliberately hovered over the ad for a
while. I also have a suspicion that friends are also preferred
that are more likely to generate a like or comment from
me. It is less clear how negative signals are taken into
account.”
•[Email, Product #1] “(My guess is) the system learns from
what previous emails have attracted more attention from
me (i.e. longer/more frequent reply, reading time taken,
longer email threads, etc.) and infer email importance.”
Example violations:
•[Web Search, Product #1] “The search results do not take
into account the user’s previously visited sources. In this
example from real life: I search for recipes on [the search
engine] all the time, and I only ever click on recipes from4 sources: Serious Eats, Pioneer Woman, 101 Cookbooks,
and Smitten Kitchen. I often search for these sites as nav-
igational queries on [the search engine]. However, [the
search engine] rarely surfaces recipes from these sites for
me.”
•[Activity Trackers, Product #1] “The app notifies/nudges
users to push them to achieve goals, but I haven’t seen a
change in behavior even though my patterns have changed. ”
•[Navigation, Product #1] “If you don’t take the suggested
route because you don’t want stop and go traffic on the
highway, it never learns. You can have it suggest routes to
avoid tolls and highways, but you have to manually select
those preferences.”
Guideline 14.
Update and adapt cautiously.
Limit disruptive changes when updating and adapting the
AI system’s behaviors.
Example applications:
•[Music Recommenders, Product #2] “Once we select a song
they update the immediate song list below but keeps the
above one constant.”
•[Social Networks, Product #1] “Think this is good. When I
unfollow someone it shows there stuff for a little bit? But
after a day or so its gone. Or once I reload. But not RIGHT
away.”
•[Web Search, Product #2] “After clicking and returning
from a search result, the order of the search results didn’t
change. The updated “people also searched for” that was
relevant to the clicked result was highlighted and con-
tained”
Example violations:
•[E-commerce, Product #1] “Maybe this is just my expe-
rience, but when I accidentally browse an item suddenly
my entire recommendation list changes to things relevant
to that new item. The change is really jarring, especially
when the browsing is a result of a curious moment or an
accident. For example, I just clicked on one camera after
viewing a lot of tennis balls and all my recommendations
changed from tennis related items to electronic devices.”
•[Social Networks, Product #1] “The refresh (pulling down
action) can sometimes be triggered unintentionally and
thus causes some posts disappeared.”
•[Social Networks, Product #2] “If I’m in the middle of
watching a video post, every now and then they will scroll
me up to the first post.”
Guideline 15.
Encourage granular feedback.
Enable the user to provide feedback indicating their prefer-
ences during regular interaction with the AI system.Example applications:
•[Social Networks, Product #2] “[The product] allows the
user to “Hide an Ad,” and then when doing so, solicits
feedback to improve relevancy of future ads. ”
•[Music Recommenders, Product #1] “Love/dislike buttons
are prominent and easily accessible.”
•[Email, Product #1] “The user can directly mark some-
thing as important, when the AI hadn’t marked it as that
previously.”
Example violations:
•[Voice Assistants, Product #2] “Once [the assistant] per-
formed the task I had asked of it, there was no additional
ability to customize the experience or give feedback on my
satisfaction; even when I chose to remove the reminder
right after I verbally requested it.”
•[Photo Organizers, Product #2] “There is no feedback chan-
nel for the user to validate the album suggestions.”
•[Navigation, Product #2] “The system does not do this.
For example, if a user were to consistently pick a route
home from work that was not the main route, then there
might be patterns in traffic or circumstances that might
be considered. If the user (instead of spouse) picked up
a child on the way home from work because traffic was
bad on the normal route, then the system should learn this
habit, or allow the user to program it in... Doesn’t let the
user tweak the routes based on prior behavior.”
Guideline 16.
Convey the consequences of user actions.
Immediately update or convey how user actions will impact
future behaviors of the AI system.
Example applications:
•[Music Recommenders, Product #1] “Tapping the like/dislike
button results in immediate popups informing that the user
will receive more/fewer recommendations like it.”
•[Social Networks, Product #2] “[The product] communi-
cates that hiding an Ad will adjust the relevancy of future
ads.”
•[Web Search, Product #1] “With different filters, the search
results are auto updated.”
Example violations:
•[Social Networks, Product #1] “You can unfollow or like
or interact but how that affects you isn’t clear. It just sorta
happens.”
•[Email, Product #1] “It’s clear there is some consequence
for the user actions, but it’s not well-defined. So while it ex-
ists, the lack of clarity on the exact outcomes for behavior
are unclear.”•[Photo Organizers, Product #2] “There isn’t any messages
to confirm that the system will learn from my dismiss or
save action.”
Guideline 17.
Provide global controls.
Allow the user to globally customize what the AI system
monitors and how it behaves.
Example applications:
•[Web Search. Product #2] “It has settings such as...private
results that help users get results that are more relevant
to them.”
•[Photo Organizers, Product #1] “[The product] allows
users to turn on your location history so the AI can group
photos by where you have been.”
•[Navigation, Product #2] “A few options to adjust my pref-
erences for how I want to get directions. Uses common
patterns for multi-select and single-choice.”
Example violations:
•[Email, Product #2] “The only option is to turn the system
on or off. It otherwise applies to all messages at all times. It
is not clear how the system works, or what data it monitors,
but presumably it applies to entire email contents.”
•[Music Recommenders, Product #2] “[The product] does
not provide a mechanism to turn off tracking of listening
data (at least not in the process of building a playlist) or
to impact what it learns.”
•[Navigation, Product #1] “There is no apparent way to
customize what information the system has access to or
what it learns. Marked locations can be removed, but oth-
erwise, I see no customizability with regard to data access
or behavior.”
Guideline 18.
Notify users about changes.
Inform the user when the AI system adds or updates its
capabilities.
Example applications:
•[Email, Product #2] “The help tab for the interface features
a “What’s new” section which could be used to inform the
user about AI system additions or capability updates.”
•[Social Networks, Product #2] “Updates of privacy and
regulations...They do post their updated privacy or legal
regulations and make the UI inaccessible until the user
agrees.”
•[Navigation, Product #2] “I don’t have a way to show this,
but it does provide small in-app teaching callouts for im-
portant new features. New features that require my explicit
attention are pop-ups.”
Example violations:•[Music Recommenders, Product #1] “The algorithm feels
like it constantly updates, with a slightly different feel to
my recommendations every week. However there is no
explanation of what has changed.”
•[Social Networks, Product #1] “It’s always a mystery when
[the product] updating the ranking algorithm.”
•[Web Search, Product #2] “there are no notifications or
mentions when the search algorithm changes or new capa-
bilities are added, such as disambiguation, the presentation
of recipes directly, etc...Updates or changes are only no-
ticeable with use (like new AI feature applications) while
others are completely unknown (like changing the search
algorithm to return more diverse CEO images)”

Principles of Mixed-Initiative User Interfaces
Eric Horvitz
Microsoft Research
Redmond, WA 98025 USA
+1 425 936 2127
horvitz@microsoft.com
ABSTRACT
Recent debate has centered on the relative promise of
focusing user-interface research on developing newmetaphors and tools that enhance users’ abilities to directlymanipulate objects versus  directing effort toward
developing interface agents that provide automation. In thispaper, we review principles that show promise for allowingengineers to enhance human—computer interaction throughan elegant coupling of automated services with directmanipulation. Key ideas will be highlighted in terms of theLookOut system for scheduling and meeting management.
Keywords
Intelligent agents, direct manipulation, user modeling,probability, decision theory, UI design
INTRODUCTION
There has been debate among researchers about where greatopportunities lay for innovating in the realm of human—computer interaction [10]. One group of researchers hasexpressed enthusiasm for the development and applicationof new kinds of automated services, often referred to asinterface “agents.” The efforts of this group center onbuilding machinery for sensing a user’s activity and takingautomated actions [4,5,6,8,9].  Other researchers havesuggested that effort focused on automation might be betterexpended on exploring new kinds of metaphors andconventions that enhance a user’s ability to directly
manipulate  interfaces to access information and invoke
services [1,13].  Innovations on both fronts have been fastpaced. However, there has been a tendency for a divergenceof interests and methodologies versus focused attempts toleverage innovations in both arenas.
We have pursued principles that provide a foundation for
integrating research in direct manipulation with work oninterface agents. Our goal is to avoid focusing solely on onetack or the other, but to seek valuable synergies between thetwo areas of investigation.  Surely, we should avoidbuilding complex reasoning machinery to patchfundamentally poor designs and metaphors.   Likewise,   wewish to avoid limiting designs for human–computer
interaction to direct manipulation when significant powerand efficiencies can be gained with automated reasoning.There is great opportunity for designing innovative userinterfaces, and new human–computer interaction modalitiesby considering, from the ground up, designs that takeadvantage of the power of direct manipulation andpotentially valuable automated reasoning [2].
PRINCIPLES FOR MIXED-INITIATIVE UI
Key problems with the use of agents in interfaces includepoor guessing about the goals and needs of users,inadequate consideration of the costs and benefits ofautomated action, poor timing of action, and inadequateattention to opportunities that allow a user to guide theinvocation of automated services and to refine potentiallysuboptimal results of automated analyses. In particular,little effort has been expended on designing for a mixed-
initiative approach to solving a user’s problems—where we
assume that intelligent services and users may oftencollaborate efficiently to achieve the user’s goals.
Critical factors for the effective integration of automated
services with direct manipulation interfaces include:
(1) Developing significant value-added automation . It is
important to provide automated services that providegenuine value over solutions attainable with direct
manipulation.
(2) Considering uncertainty about a user’s goals .
Computers are often uncertain about the goals andcurrent the focus of attention of a user. In many cases,systems can benefit by employing machinery forinferring and exploiting the uncertainty about a user ’s
intentions and focus.
(3) Considering the status of a user ’s attention in the
timing of services.  The nature and timing of automated
services and alerts can be a critical factor in the costsand benefits of actions. Agents should employ modelsof the attention of users and consider the costs and
benefits of deferring action  to a time when action will
be less distracting.
(4) Inferring ideal action in light of costs, benefits, and
uncertainties . Automated actions taken under
uncertainty in a user ’s goals and attention are
associated with context-dependent costs and benefits.The value of automated services can be enhanced by
guiding their invocation with a consideration of theexpected value of taking actions .
(5) Employing dialog to resolve key uncertainties . If a
system is uncertain about a user ’s intentions, it should
be able to engage in an efficient dialog with the user,considering the costs  of potentially bothering a user
needlessly.
(6) Allowing efficient direct invocation and
termination. A system operating under uncertainty
will sometimes make poor decisions about invoking —
or not invoking —an automated service. The value of
agents providing automated services can be enhancedby providing efficient means by which users candirectly invoke or terminate the automated services.
(7) Minimizing the cost of poor guesses about action
and timing.  Designs for services and alerts should be
undertaken with an eye to minimizing the cost of poor
guesses , including appropriate timing out and natural
gestures for rejecting attempts at service.
(8) Scoping precision of service to match uncertainty,
variation in goals.    We can enhance the value of
automation by giving agents the ability to gracefully
degrade  the precision of service to match current
uncertainty. A preference for “doing less ” but doing it
correctly under uncertainty can provide user ’s with a
valuable advance towards a solution and minimize theneed for costly undoing or backtracking.
(9) Providing mechanisms for efficient agent −user
collaboration to refine results. We should design
agents with the assumption that users may often wish tocomplete or refine an analysis provided by an agent.
(10) 
 Employing socially appropriate behaviors for
agent −user interaction. An agent should be endowed
with tasteful default behaviors and courtesies thatmatch social expectations  for a benevolent assistant.
(11) Maintaining working memory of recent
interactions.  Systems should maintain a memory of
recent interactions with users and provide mechanismsthat allow users to make efficient and naturalreferences to objects and services included in “shared ”
short-term experiences.
(12) Continuing to learn by observing.  Automated
services should be endowed with the ability to continueto become better at working with users by continuing tolearn about a user ’s goals and needs.
A TESTBED FOR MIXED-INITIATIVE UI
The LookOut project has focused on investigating issues
with overlaying automated scheduling services onMicrosoft Outlook, a largely direct-manipulation basedmessaging and scheduling system. LookOut automationidentifies new messages that are opened and brought tofocus and attempts to assist users with reviewing their
calendar and with composing appointments.
Value-Added Service: Calendaring and Scheduling
When invoked, LookOut parses the text in the body andsubject of an email message in focus and attempts toidentify a date and time of associated with an event impliedby the sender. The system then invokes Outlook ’s
calendaring subsystem, brings up the user ’s online
appointment book, and attempts to fill in relevant fields ofan appointment record.  The system displays its guesses tothe user and allows the user to edit its guesses and to savethe final result.
LookOut ’s scheduling analysis centers on a goal-specific
parsing of the text contained in the email message that hasfocus. The system notes when a new message is being read,or when a message comes into focus that has not yet beenanalyzed. The system first establishes the date a messagewas sent as an  anchor date  and attempts to normalize its
view based on the composition date.  For example, if amessage was written yesterday and contains text referring toscheduling a meeting for "tomorrow," the system willunderstand that the message is referring to "today."
If LookOut cannot identify an implied date and time, the
system degrades its goal to identifying a span of time that ismost relevant given the text of the message (i.e., a specificday, week, or month), and then displays a scoped view ofthe calendar to the user. The user can directly manipulatethe proposed view and, if appropriate, go on to scheduleappointments manually.
LookOut has knowledge about typical patterns of
expression in email about meetings and times. Beyondunderstanding the variety of ways that people refer to datesand times, the system understands the temporal implicationsof suggestions about information in email messages aboutholding meetings at various times in the future ( e.g.,
“sometime tomorrow, ” “later in the week, ” “next week, ”
“within a couple of weeks, ” “in May, ” etc.), at prototypical
times during the day ( e.g., “morning, ” “afternoon, ” and
“evening ”), as well as during typical recurrent events ( e.g.,
“at breakfast, ” “grab lunch, ” and “meet for dinner, ” etc.).
LookOut analysis reduces the number of interactions and
complexity of navigation required of the user.  WithoutLookOut, users must navigate to the appropriate graphicalbutton or menu item to open their calendar, search for theappropriate day, input the appropriate times and fill in thesubject of the meeting.  LookOut performs this operationautomatically or via a single interaction, depending on themodality selected.  Even when LookOut guessesincorrectly, the user is placed in an approximately correctposition in the calendar and can refine an approximateguess about the implied appointment.
Decision Making Under Uncertainty
Users can directly invoke LookOut by clicking on an iconthat is always present on the system tray of the MicrosoftWindows shell. However, the system also works to
automatically identify a user ’s goals by considering the
content of messages being reviewed. LookOut processes theheader, subject, and body of the message and, based on thisinformation, assigns a probability that a user would like toview the calendar or schedule an appointment, byemploying a probabilistic classification system that istrained by watching the user working with email. Thesystem makes decisions about appropriate actions as afunction of an inferred probability that the user has a goalof performing scheduling and calendaring operations. Inparticular, the inferred probability that service is desired isused by LookOut to make a decision about whether to applya second phase of analysis that provides the user withautomated calendaring and scheduling.
Depending on the inferred probability —and on an
assessment of the expected costs and benefits of action —
the system decides to either (1) do nothing but simply waitfor continued direct manipulation of Outlook or manualinvocation of LookOut, (2) to engage the user in a dialogabout his or her intentions with regards to providing aservice, or (3) to go ahead and attempts to provide itsservice by invoking its second phase of analysis.
Multiple Interaction Modalities
LookOut can be configured to be operated in a solelymanual modality or can be placed in one of severalautomated-assistance modalities. In manual operation, thesystem will only take action if a user clicks on the smallLookOut icon appearing in the system. When invoked,LookOut analyzes the email message that has system focus.Users can tell the system to display an alerting symbol (redcheck mark) on the system-tray icon when LookOut wouldhave taken action if it had been in an automated-assistancemodality. By hovering the cursor over the icon on thesystem tray, a summary of the intended action appears.Figure 1 displays the direct invocation of LookOut.  Asshown in the figure, a menu with dynamically populatedoptions pops up, letting the user schedule or organize ameeting, or schedule from text on the system clipboard.
When placed in a basic automated-assistance mode,
LookOut works by launching and populating fields inOutlook windows. In this mode, the system also employstraditional dialog boxes to request additional informationfrom users when appropriate. LookOut can also operate in asocial-agent modality  projecting an explicit social presence
in the form of animated characters, drawn from the MSAgent social user-interface package. When in this mode, thesystem issues queries to users and announces the results ofanalyses with an anthropomorphic presence.
When LookOut is in the social-agent modality, it operates
in a handsfree manner, establishing an audio channel forinteracting with LookOut, further reducing mouse andkeyboard interaction with the Outlook system. In thehandsfree mode, the system employs a text-to-speech (TTS)Figure 1. Manual invocation of LookOut. By hovering a
cursor over the LookOut icon, a user can examineLookOut ’s guess. By clicking on the LookOut icon on the
system tray, the user invokes the appointment service.
system and automated speech recognition system developed
by Microsoft Research to engage users in a natural dialogabout their intentions. If LookOut is confident enough in itsassessment of a user ’s goals, a character appears and
mentions that it has readied a calendar view to show theuser or has created a tentative appointment beforedisplaying the results. At lower levels of confidence,LookOut inquires about a user ’s interest in either seeing the
calendar or scheduling an appointment, depending on thesystem ’s analysis of the message being viewed. After asking
the user, the system listens for an answer without requiringadditional keys or buttons to be pressed.
Figure 2 displays a sequence of screens demonstrating
LookOut ’s operation within the social-agent modality.
After a message is analyzed behind the scenes, the systemdecides it is worthwhile to engage the user in a dialog aboutcreating an appointment.  An animated assistant appearsand engages the user with speech (a text balloon option isturned on in this case to relay the content of the speech withtext).  The user can indicate via speech that an appointmentis desired with one of several natural acknowledgments,including “yes,” “yeah, ” “sure, ” “do it. ” Given a go ahead,
LookOut creates an appointment and reviews it with theuser with text-to-speech, before evaporating, leaving theresult behind for refinement and saving. If the user hadexpressed disinterest in going ahead with the appointmentby simply closing the message or by responding with avariety of natural phrases including “no,” “not now, ” “nah,”
and “go away, ” the agent would have immediately nodded
to confirm an understanding and disappear.
LookOut dynamically scopes the calendar view to its best
guess, given uncertainty or indications about an appropriateview from the message text.  For the case captured inFigure 3, LookOut cannot confidently identify a specific
time and day.  Rather than making a poor guess, LookOut
brings up an appropriate week view on the user ’s calendar.
Handling Invocation Failures
As LookOut is expressly continuing to reason under
uncertainty about the value of taking action, or engaging theuser in a dialog as messages are opened and closed, thesystem can make guesses that simply turn out to be wrong.If the LookOut system fails to automatically infer that userswish to see their calendar or schedule an appointment, thesystem can be directly invoked by clicking on the LookOuticon on the system tray. If LookOut guesses that it isworthwhile to engage the user in a dialog about schedulingbut the user is busy or disinterested in interacting with theservice, the system will pose a question, wait patiently for aresponse, and then make a respectful, apologetic gestureand evaporate. The amount of time the system waits beforetiming out is a function of the inferred probability that auser desires the service. Also, the system increases its dwellon the desktop if it detects signs that the user is thinking,including “hmmm …”, “uh…,” etc. The design of
LookOut ’s behaviors for handling delays with responses
and for reacting to signs that service is being declined wasguided by the goal of giving LookOut the sensibility of anintuitive, courteous butler, who might make potentiallyvaluable suggestions from time to time, but who is carefulto note when the user is simply too busy to even respond —
and to get out of the user ’s way with minimal disturbance.INFERRING BELIEFS ABOUT A USER’S GOALS
If we wish to assist users with potentially complex services,
it can be valuable to consider how such automation can beprovided effectively in light of the uncertainties agents mayhave about users goals. Thus, developing machinery thatendows a system with the ability to explicitly assignlikelihoods to different feasible user intentions can becritical in mixed-initiative systems. Such machinery canextend from sets of rules linked to tables of probabilisticinformation to more complex, real-time inference.
In related work in user modeling, probabilistic models of a
user’s goals have been employed to continue to perform
real-time inference about the probability of alternatefeasible goals as a function of observables including thecurrent program context, a user ’s sequence of actions and
choice of words used in a query [4,6].  Some of this workhas leveraged recent successes in building and reasoningwith Bayesian network models [7,11].
LookOut leverages work in automated text classification for
making decisions about actions.  Alternate textclassification methodologies were explored, including anaïve Bayesian text classifier and text classification based
on the Support Vector Machine (SVM) analysis [3]. Thecurrent version of LookOut assigns probabilities of userintention by employing an SVM text classification based onan efficient linear SVM approximation method developedby Platt [12]. The method was coupled with a methodology
Figure 2. LookOut sequence showing its operation in its explicit social-agent modality. A new message (top left) is analyzed
and a decision is made to engage the user in a dialog (left). After receiving confirmation via speech input, the system createsan appointment and presents its guess to the user for refinement (right).
Figure 3. Automated scoping of calendar.  If LookOut
cannot establish a specific day and time, it attempts toselect a most appropriate span of time to display to the userfor review or refinement through direct manipulation.
for including custom-tailored, task-specific sets of text
features.  Rather than employing text classification in theclassical manner for tasks such as labeling or categorizingdocuments, we harness the methods for learning andreasoning about the likelihood of user goals or tasks withina context. For the assumed context of a user reviewingemail, we wish to assign a likelihood that an email messagethat has just received the focus of attention is in the goal
category  of “User will wish to schedule or review a
calendar for this email”  versus the goal category of “User
will not wish to schedule or review a calendar for thisemail ” based on the content of the messages.
A linear SVM text classifier is built by training the system
on a set of messages that are calendar relevant and calendarirrelevant. At runtime, for each email message beingreviewed, the linear SVM approximation procedure outputsthe likelihood that the user will wish to bring up a calendaror schedule an appointment. The current version ofLookOut was trained initially on approximately 1000messages, divided into 500 messages in the relevant and500 irrelevant messages.
FROM BELIEFS TO ACTIONS
Given uncertainties about a user ’s goals, what automated
actions should be taken? We shall consider the case of adecision about whether or not to invoke the servicesperformed by an intelligent agent. From the perspective ofdecision theory, decisions about action versus inactionshould be directed by expected utility . Autonomous actions
should be taken only when an agent believes that they willhave greater expected value than  inaction  for  the  user,
Table 1. Four outcomes considered in decisions about
whether to engage an intelligent agent to provide service.taking into consideration the costs, benefits, and
uncertainties in the user ’s goals.
Actions, Intentions, and Outcomes
Let us assume an agent has access to inference about the
likelihood of a user ’s goals given observed evidence,
written p(G|E). In LookOut, the probability that a user
wishes to schedule is computed from evidence in patterns oftext contained in a message that has been recently openedor brought to focus.
For decisions about action versus inaction, we must
consider four deterministic outcomes: Either the userindeed has the goal being considered or does not have thegoal and, for each of these states of user intention, thesystem either can take an action or not take the action. Wemap a measure of the value associated with each outcometo a utility  on a zero to one scale, and define utilities as
follows:
• u(A,G): the utility of taking action A when goal G is
true
• u(A,
¬G): the utility of taking action A when goal G is
not true
• u(¬A,G): the utility of not taking action A when goal G
is true
• u(¬A,¬G): the utility of not taking action A when goal
G is not true
These outcomes are summarized in Table 1.The expected utility of taking autonomous action to assist
the user with an action given observed evidence, eu(A|E), is
computed by combining the utilities of the outcomes for thecase where the user desires service and does not desire aservice, weighted by the probability of each outcome, asfollows:
             eu (A|E)=p(G|E)u(A,G) + p(
¬G|E) u(A,¬G)         (1)
We can rewrite this equation in terms of p(G|E), by noting
that p(G|E)=1-p(¬G|E). Thus, the expected utility of
providing autonomous service is,
            eu (A|E)=p(G|E)u(A,G) + [1- p(G|E)] u(A,¬G)      (2)
Figure 4. Graphical analysis of the expected utility of action
versus inaction, yielding a threshold probability for action.1.0 0.0p(G|E)No Action
P*
u(A,¬G)u(¬A,¬G)
u(¬A,G)u(A,G)
Action
Desired Goal Not Desired
Action
No Actionu(A,¬G)
u(¬A,¬G) u(¬A,G)u(A,G)
The expected utility of not taking autonomous action to
assist the user, u(¬A|E), is
        eu (¬A|E)=p(G|E)u(¬A,G) + [1- p(G|E)]u(¬A,¬G)     (3)
We can visualize the implications of these equations by
plotting the expected utility as a function of probability.Figure 4 displays a graph where the horizontal representsthe probability the user has a goal, ranging from zero toone. The vertical axis indicates the expected value of thesystem ’s response. The two outcomes displayed on the right
vertical axis have an expected utility associated withp(G|E)=1.0 —the user indeed having the goal under
consideration. The outcomes listed on the left vertical axisindicate the value of the outcomes when p(G|E)=0. The
expected value of acting for intermediary probabilities ofp(G|E), as dictated by Equation 2, is a line joining the two
deterministic outcomes associated with taking action. Theexpected value of not acting as dictated by Equation 3 is asimilar line joining the two outcomes associated withinaction.
Expected Utility and Thresholds for Agent Action
The lines representing expected utility cross at a specificinferred probability of the user having a goal. At thisthreshold probability, referred to as p*, the expected value
of action and inaction are equal. The best decision to makeat any value of p(G|E) is the action associated with the
greatest expected utility at that likelihood of the user havingthe goal. By inspecting the graph, it is easy to see that it isbest for the system to take action if the probability of a goalis greater than p* and to refrain from acting if the
probability is less than p*.
The threshold probability can be computed for any four
utilities by setting Equations 2 and 3 equal to one anotherand solving for p(G|E). Given four utilities associated with
the four outcomes of interest, a system needs only to checkwhether the probability of the goal is greater or less thansuch a threshold probability to decide on whether it is in thebest interest of the user to invoke a service.
The threshold probability, p*, can be influenced by context-
dependent changes of the utilities associated with one ormore of the outcomes. For example, the utility, u(A,
¬G),
associated with the situation where a system takes actionwhen a goal is not desired, can be significantly influencedby the status of a user ’s attention. The utility of unwanted
action can diminish significantly with increases in the depthof a user ’s focus on another task.  Such a reduction in the
value of action leads to a higher probability threshold.  Incontrast, the utility, u(A,
¬G), associated with the situation
where a system takes action when a goal is not desired,might be greater when more screen real estate is madeavailable. Increased screen real estate can diminish theperceived cost of the needless operation of a schedulingservice that might bring up an appointment that obscuresitems at a user ’s focus of attention.   As another example ofFigure 5. The result of increasing the value of taking
erroneous action. Context-dependent shifts in any of theutilities can change the probability threshold for action.
a context-dependent outcome, the utility, u(
¬A,G),
representing the situation where a system does not takeaction when a user indeed has the goal, may decrease as auser becomes more rushed. Diminishing the value of thisaction reduces the threshold probability for action.
Figure 5 displays geometrically how p* can change with
context. In this case, increasing the utility (decreasing thecost) of outcome u(A,
¬G) of acting when service is not
desired leads to a lowering of the threshold probability thatmust be crossed before action occurs.
Dialog as an Option for Action
Beyond reasoning about whether to act or not to assist auser with an autonomous service, we can also consider theaction of asking users about their goals. We can integrateaction for dialog into the expected utility framework byconsidering the expected value of asking the user aquestion. We now consider the utility of two additionaloutcomes:  the case where an agent initiates dialog about agoal and the user actually desires the goal underconsideration, u(D,G), and the case where the user does not
have the goal, u(D,
¬G). We compute the expected utility of
performing dialog under uncertainty with an equationanalogous to Equation 3.
Figure 5 displays a graph with the addition of a line
representing the expected utility of engaging in a dialog. Ashighlighted in the graph, the utility of engaging in a dialogwith a user when the user does not have the goal in questionis typically greater than the utility of performing an actionwhen the goal is not desired.  However, the utility of asking
a user before performing a desired action is typicallysmaller than the utility of simply performing a desiredaction when the user indeed has the goal. In suchcircumstances, if we follow the rule of selecting the optionwith the greatest expected utility, we see that action can beguided by two new threshold probabilities: the thresholdbetween inaction and dialog, p*
¬A,D, and the threshold
between dialog and action, p*D,A. These two thresholds
provide an instant index into whether to act,  to engage  the1.0 0.0p(G|E)No Action
u’(A,¬G)u(¬A,¬G)
u(¬A,G)u(A,G)
P*’ActionFigure 6. Adding a second action option consisting of
dialog with users about their goals. In this case, thegraphical analysis higlights the origin of two thresholdprobabilities for guiding the action of autonomous services.
user in a dialog about action, or to do nothing, depending
on the assessed likelihood of the user having a goal.
Systems for guiding autonomous service do not necessarily
need to perform explicit computations of expected value.Thresholds can be directly assessed by designers or users.Such directly assessed thresholds for action imply a deeperimplicitly assumed expected-utility model.
The LookOut system employs default utilities for guiding
dialog and action. However, the system also allows users tospecify the utilities for outcomes. Given a set of assessedutilities, the system computes and uses modified thresholdprobabilities. LookOut also allows users to simply specifytwo key threshold probabilities for controlling dialog andaction. At run time, LookOut considers whether the inferredprobability that users desires service is above threshold fordialog or action, versus being consistent with inaction.
USER ATTENTION AND THE TIMING OF SERVICE
Automated activity occurring before a user is ready or openfor the service can be distracting.  On the other hand, delaysin the provision of service can diminish the value ofautomation. We have found that the value of services andalerts can be enhanced through building and applyingmodels of attention that consider the temporal pattern of auser’s focus of attention.
Given the potential value of approaching users with dialog
or actions when users are most ready for a service, weperformed studies to identify the most appropriate timing ofmessaging services as a function of the nature of themessage being reviewed by the user. We addedinstrumentation to LookOut to monitor the length of timebetween the review of messages and the manual invocationof messaging services and collected data from several userswith a goal of building a default temporal-centric model ofattention. We identified a nonlinear relationship betweenthe size of the message being reviewed and the amount oftime users prefer to dwell on the content of the messagesbefore accepting automated calendaring and schedulingoperations. We found that the relationship between messagesize and the preferred time for deferring offers of service
can be approximated by a sigmoid function as representedby the sample data from a user displayed in Figure 7.Continuing studies on timing within the LookOut projectare aimed at examining other factors that can explain dwelltime including ambiguity and complexity of dates and timesmentioned in the message.
In the general case, we can construct a model of attention
from such timing studies and make the utility of outcomestime-dependent functions of message length. Alternatively,we can use timing information separately to defer serviceuntil a user is likely ready to receive it.
The current version of LookOut employs a predetermined
default automated-service timing model based on userstudies. However, the system can also be instructed to builda custom-tailored timing model by watching a userinteracting with email.  The system records the size of eachmessage being reviewed and the amount of time spent oneach message before scheduling operations are invoked andstores cases when it is used in a user-directed manner.When the system enters a learning mode, the systemperforms a regression analysis on the data and fits apiecewise linear model to the data. Alternatively, users cantell the system to delay for a fixed amount of time beforethe service is invoked.
MACHINERY FOR LIFE-LONG LEARNING
LookOut contains a pretrained probabilistic user model andtiming model. However, the system is designed to continueto learn from users. Methods for embedding the capabilityfor life-long learning is a key challenge in ArtificialIntelligence research [14]. LookOut continues to storemessages as calendar relevant and irrelevant, by watchingthe user working with email. If a calendar or schedulingfacility is invoked within a predetermined time horizon, thesystem saves the message as schedule-relevant. The systemalso continues to record the time users dwell on schedule-relevant messages before invoking a calendaring operation.
User can specify a policy for continual learning. Users can
dictate a training schedule that guides the learningcomponent of the system periodically to incrementallyrefine the probabilistic user model and time-based attentionmodel. The ongoing model continues to hone the modelsused for guessing about the relevance of the automatedscheduling services as well as to become a better estimatorof the best time to invoke the services.
SUMMARY AND CONCLUSIONS
We reviewed key challenges and opportunities for buildingmixed-initiative  user interfaces —interfaces that enable
users and intelligent agents to collaborate efficiently. Wefirst presented a set of principles for designing mixed-initiative user interfaces that address systematic problemswith the use of agents that may often have to guess about auser’s needs.  Then, we focused on methods for managing
the uncertainties that agents may  have  about  users ’ goals1.01.0
0.0
p(G|E)Action No Action
P*u(A,¬G)u(¬A,¬G)
u(¬A,G)u(A,G)
P*Dialog
¬A,D D,Au(D,¬G)u(D,G)Figure 7. Sigmoid fit on sample of data from a user
displaying the relationship between dwell time on schedule-relevant messages and the quantity of text in the messagebeing reviewed.
the uncertainties that agents may have about users ’ goals
and focus of attention. We discussed the consideration ofuncertainty, as well as the expected costs and benefits oftaking autonomous action in different situations. Wehighlighted methods and design principles with examplesdrawn from the LookOut system. Research on LookOut haselucidated difficult challenges and promising opportunitiesfor improving human –computer interaction through the
elegant combination of reasoning machinery and directmanipulation. We believe continuing efforts to addressproblems with the design of mixed-initiative user interfaceswill likely yield fundamental enhancements in
human −computer interaction.
ACKNOWLEDGMENTS
Andy Jacobs has served as the primary software engineer
on the LookOut prototype. John Platt developed the linearSVM text-classification methodology used in the currentversion of LookOut. Mehran Sahami assisted with the earlystudies of the use of Bayesian text classification foridentifying schedule-relevant messages. Jack Breese, MaryCzerwinski, Susan Dumais, Bill Gates, Ken Hinckley, DanLing, and Rick Rashid provided valuable feedback on thisresearch.
REFERENCES
1. Ahlberg, C., and Schneiderman, B. Visual information
seeking: Tight coupling of dynamic query filters withstarfield displays. Proceedings of CHI ’94 Human
Factors in Computing Systems  (April 1994) ACM,
313-317.
2. Birnbaum, L., Horvitz, E., Kurlander, D., Lieberman,
H., Marks, J. Roth, S. Compelling Intelligent UserInterfaces: How Much AI? In Proceedings of the 1997
ACM International Conference on IntelligentInterfaces  (Orlando, FL, January 1996).
                    http://www.merl.com/reports/TR96-28/index.html
3. Dumais, S. T., Platt, J., Heckerman, D., and Sahami,
M., Inductive learning algorithms and representationsfor text categorization. Proceedings of CIKM98 .
(Bethesda MD, November 1998). ACM Press, 148-1554. Heckerman, D., and Horvitz, E. Inferring Informational
Goals from Free-Text Queries: A Bayesian Approach,Fourteenth Conference on Uncertainty in ArtificialIntelligence  (Madison WI, July 1998), Morgan
Kaufmann Publishers, 230-237.
                      http://research.microsoft.com/~horvitz/aw.htm
5. Horvitz, E., and Barry, M. Display of Information for
Time-Critical Decision Making. Proceedings of the
Eleventh Conference on Uncertainty in ArtificialIntelligence  (Montreal, August 1995). Morgan
Kaufmann Publishers, 296-305.
 
                    http: //research.microsoft.com/~horvitz/vista.htm
6. Horvitz, E., Breese, J., Heckerman, D., Hovel, D.,
Rommelse, D. The Lumiere Project: Bayesian UserModeling for Inferring the Goals and Needs ofSoftware Users, Fourteenth Conference on Uncertainty
in Artificial Intelligence  (Madison WI, July 1998).
Morgan Kaufmann Publishers, 256-265.
                 
 http: //research.microsoft.com/~horvitz/lumiere.htm
7. Horvitz, E.J., Breese, J., and Henrion, M.  Decision
theory in Expert Systems and Artificial Intelligence.International Journal of Approximate Reasoning ,
Special Issue on Uncertainty in Artificial Intelligence,
2:247-30.
                   http: //research.microsoft.com/~horvitz/dt.htm
8. Lieberman, H., Letizia: An Agent That Assists Web
Browsing, International Joint Conference on Artificial
Intelligence  (Montreal, August 1995). IJCAI.
9. Maes, P. Agents that Reduce Work and Information
Overload. Commun. ACM 37,7, 31-40
10. Maes, P., and Schneiderman, B., Direct Manipulation
vs. Interface Agents: A Debate. Interactions , Vol. IV
Number 6, ACM Press, 1997.
11. Pearl, J. Probabilistic Reasoning in Intelligent Systems:
Networks of Plausible Inference , Morgan Kaufmann
Publishers: San Francisco, 1991.
12. Platt, J. Fast training of SVMs using sequential
minimal optimization.  To appear in: B. Scholkopf, C.Burges, and A. Smola (Eds.) Advances in Kernel
Methods – Support Vector Learning , MIT Press, 1999.
13. Schneiderman, B. Designing the User Interface:
Strategies for Effective Human-Computer Interaction,ACM Press. 1992.
14. Selman, B. Brooks, R.A., Dean, T., Horvitz, E., M.
Mitchell, T., Nilsson, N.J. Challenge Problems forArtificial Intelligence, In: Proceedings of AAAI-96,
Thirteenth National Conference on ArtificialIntelligence  (Portland, OR, August 1996). AAAI Press,
1340-1345.0246810
0 500 1000 1500 2000 2500
Length of message (bytes)Dwell before action (sec)

Explainability + Trust
 
Explaining predictions, recommendations, and other
AI
output to users is critical for building trust. This
chapter
covers:
 
How much should the user trust the AI system?
 
When should we pr ovide explanations?
 
What should we do if we can ’t show why the AI made
a giv en pr ediction?
 
How should we show users the conﬁdence associated
with an AI pr ediction?
 
 
Want t o driv e discussions, speed iter ation, and a void
pitfalls?
Use the worksheet
.
  
What’s new when working with AI
Because AI-power ed systems ar e based on pr obability
and uncer tainty , the right le vel of
explanation is k ey to helping users understand how
the system works. Once users ha ve
clear mental models of the system ’s capabilities and
limits, the y can understand how and
when t o trust it t o help accomplish their goals. In
shor t, explainability and trust ar e
inher ently link ed.
 
 
In this chapter , we’ll discuss consider ations for
how and when t o explain what y our AI
does, what data it uses t o mak e decisions, and the
conﬁdence le vel of y our model’ s
output.
Key consider ations for explaining AI systems:
➀
 Help users calibr ate their trust
. Because AI pr oducts
are based on statistics and
probability , the user shouldn ’t trust the system completely .
Rather , based on
system explanations, the user should know when t o
trust the system ’s predictions
and when t o apply their own judgement.
➁
 Plan for trust calibr ation thr oughout the pr oduct
experience
. Establishing the
right le vel of trust tak es time. AI can change and
adapt o ver time, and so will the
user ’s relationship with the pr oduct.
➂
 Optimiz e for understanding
. In some cases, ther e
may be no explicit,
compr ehensiv e explanation for the output of a complex
algorithm. E ven the
developers of the AI ma y not know pr ecisely how it
works. In other cases, the
reasoning behind a pr ediction ma y be knowable, but
diﬃcult t o explain t o users in
terms the y will understand.➃
 Manage inﬂuence on user decisions
. AI systems often gener ate output that the
user needs t o act on. If, when, and how the system calculates and shows
conﬁdence le vels can be critical in informing the
user ’s decision making and
calibr ating their trust.
Identify what goes into user trust
Trust is the willingness t o tak e a risk based on the
expectation of a beneﬁt.
The following fact ors contribute t o user trust:
●
Ability
is a pr oduct’ s competence t o get the job done.
Does the pr oduct addr ess the
user ’s need, and has it impr oved their experience?
Striv e for a pr oduct that pr ovides
meaningful v alue that is easy t o recogniz e.
●
Reliability
indicates how consistently y our pr oduct
deliv ers on its abilities. Is it
meeting quality standar ds accor ding t o the expectations
set with the user? Only
launch if y ou can meet the bar that y ou’ve set and
described tr anspar ently t o
the user .
●
Bene volence
is the belief that the trusted par ty wants
to do good for the user . What
does the user get out of their r elationship with y our
product, and what do y ou get
out of it? Be honest and up-fr ont about this.
Take the example of an app that can identify plants.
A user will calibr ate their trust in the
app based on their understanding of how well the app
can r ecogniz e a saf e vs. non-saf e
plant fr om a phot o the y’ve just tak en while on a hik e
in natur e, how consistently the app
works during diff erent seasons and in diff erent lighting
conditions, and ﬁnally , how
helpful the app is at k eeping them saf e from plants
that the y are
aller gic t o.The pr ocess t o earn user trust is slow , and it’ ll requir e proper calibr ation of the user ’s
expectations and understanding of what the pr oduct can and can ’t do. In this chapter ,
you’ll see guidance on when and how t o help users
set the right le vel of trust in an
AI pr oduct.➀ Help users calibrate their trust
Users shouldn ’t implicitly trust y our AI system in
all cir cumstances, but r ather calibr ate
their trust corr ectly . Ther e are many r esear ch examples
of “algorithm a version ”, wher e
people ar e suspicious of softwar e systems. Resear chers
have also found cases of
people o ver-trusting an AI system t o do something
that it can ’t. Ideally , users ha ve the
appr opriate le vel of trust giv en what the system can
and cannot do.
For example, indicating that a pr ediction could be
wrong ma y cause the user t o trust
that par ticular pr ediction less. Howe ver, in the long
term, users ma y come t o use or r ely
on your pr oduct or company mor e, because the y’re less
likely to over-trust y our system
and be disappointed.
A iculate data sources
Every AI pr ediction is based on data, so data sour ces
have to be par t of y our
explanations. Howe ver, remember that ther e ma y be
legal, fairness, and ethical
consider ations for collecting and communicating about
data sour ces used in AI. W e
cover those in mor e detail in the chapter on
Data
Collection + E valuation
.
Sometimes users can be surprised b y their own information
when the y see it in a new
context. These moments often occur when someone sees
their data used in a wa y that
appears as if it isn ’t priv ate or when the y see data
they didn ’t know the system had
access t o, both of which can er ode trust. To avoid
this, explain t o users wher e their data
is coming fr om and how it is being used b y the AI
system.Equally impor tant, telling users what data the model is using can help them know when
they have a critical piece of information that the
system does not. This knowledge can
help the user a void o ver-trusting the system in cer tain
situations.
For example, sa y you’re installing an AI-power ed na vigation
app, and y ou click t o accept
all terms and conditions, which includes the ability
for the na vigation app t o access data
from y our calendar app. Later , the na vigation app
alerts you to lea ve your home in 5
minutes in or der t o be on time for an appointment.
If you didn ’t read, r ealiz e, or
remember that y ou allowed the na vigation app t o access
your appointment information,
then this could be v ery surprising.
Your trust in the app ’s capabilities depends on y our
expectations for how it should work
and how aler ts lik e these ar e wor ded. F or instance,
you could become suspicious of the
app’s data sour ces; or , you could o ver-trust that
it has complete access t o all y our
schedule information. Neither of these outcomes ar e
the right le vel of trust. One wa y to
avoid this is t o explain the connected data sour ce
— how the na vigation app knows
about the appointment — as par t of the notiﬁcation,
and t o provide the option t o opt out
of that kind of data sharing in the futur e. In fact,
regulations in some countries ma y
requir e such speciﬁc, contextual explanations and
data contr ols.
Key concept
Whene ver possible, the AI system should explain the
following aspects about data use:
●
Scope
. Show an o verview of the data being collected
about an individual user , and which
aspects of their data ar e being used for what purpose.
●
Reach
. Explain whether the system is personaliz ed
to one user or de vice, or if it is using
aggr egated data acr oss all users.●
Remo val
. Tell users whether the y can r emo ve or r eset some of the data being used.
Apply the concepts fr om this section in Ex ercise 1
in the worksheet
.
Aim for
Tell the user when a lack of data might mean
they’ll need to use their own judgment.
Learn more
Avoid
Don’t be afraid to admit when a lack of data could
affect the quality of the AI recommendations.
Tie explanations to user actions
People learn faster when the y can see a r esponse t o
their actions right awa y, because
then it’ s easier t o identify cause and eff ect. This
means the per fect time t o show
explanations is in r esponse t o a user ’s action. If
the user tak es an action and the AI
system doesn ’t respond, or r esponds in an unexpected
way, an explanation can go a
long wa y in building or r ecovering a user ’s trust.
On the other hand, when the system is
working well, r esponding t o users’ actions is a gr eat
time t o tell the user what the y can
do to help the system continue t o be r eliable.
For example, let’ s say a user taps on the “r ecommendations
for me ” section of an
AI-power ed restaur ant r eser vation app. They only see
recommendations for Italian
restaur ants, which the y rarely visit, so the y’re a
bit disappointed and less trusting that
the app can mak e relevant, personaliz ed recommendations.
If, howe ver, the app ’s
recommendations include an explanation that the system
only r ecommends r estaur ants
within a one-block ar ea, and the user is standing
in the hear t of Little Italy in New Y ork
City, then trust is lik ely to be maintained. The user
can see how their actions — in this
case asking for r ecommendations in a speciﬁc location
— aff ects the system.
Just as y ou might build trust in another person thr ough
back and for th inter actions that
reveal their str engths and weaknesses, the user ’s
relationship with an AI system can
evolve in the same wa y.
When it’ s har der t o tie explanations dir ectly t o user
actions, y ou could use multi-modal
design t o show explanations. F or example, if someone
is using an assistant app with
both visual and v oice inter faces, y ou could lea ve
out the explanation in the v oice output
but include it in the visual inter face for the user
to see when the y have time.Account for situational stakes
You can use explanations t o encour age users t o trust
an output mor e or less depending
on the situation and potential consequences. It’ s
impor tant t o consider the risks of a
user trusting a
false positiv e
,
false negativ e
, or
a prediction that’ s off b y a cer tain
percent.
For example, for an AI-power ed na vigation app, it
may not be necessar y to explain how
arriv al time is calculated for a daily commute. Howe ver,
if someone is tr ying t o catch a
ﬂight (higher stak es and less fr equent than a commute)
they ma y need t o cross-check
the timing of the r ecommended r oute. In that case,
the system could pr ompt them with
an explanation of its limitations. F or example, if
a user enters the local airpor t as their
destination, let them know that tr aﬃc data only
refreshes e very hour .Aim for
Give the user details about why a prediction was
made in a high stakes scenario. Here, the user is
exercising after an injury and needs conﬁdence in
the app’s recommendation.
Learn more
Avoid
Don’t say “what” without saying “why” in a high
stakes scenario.
You can ﬁnd detailed information about giving the user appr opriate guidance in
situations of failur e or low-conﬁdence pr edictions in the
Errors + Gr aceful F ailur e
chapter .
Key concept
As a team, br ainst orm what kinds of inter actions,
results, and corr esponding
explanations would decr ease, maintain, or inﬂate
trust in y our AI system. These should
fall somewher e along a trust spectrum of “No trust”
to “Too much trust”.
Here are some examples fr om our running app:
●
A user who has ne ver run mor e than 3 miles at a time
receiv es a r ecommendation for a
marathon tr aining series.
●
A user tak es the tr aining r ecommendation t o their
personal tr ainer and their tr ainer agr ees
with the app ’s suggestion.
●
A user follows the app ’s suggestion for a r ecovery
run, but it’ s too diﬃcult for them t o
complete.
Apply the concepts fr om this section in Ex ercise 2
in the worksheet
.➁ Calibrate trust throughout the product
experience
The pr ocess t o build the right le vel of trust with
users is slow and deliber ate, and it
starts even befor e users’ ﬁrst inter action with the
product.
Ther e are various oppor tunities t o help users set
their expectations of the pr oduct’ s
abilities and limitations b y providing explanations
throughout, and outside of, the
product experience:
●
Explain in-the-moment
. When appr opriate, pr ovide r easons
for a giv en inf erence,
recommendation, suggestion, etc.
●
Provide additional explanations in the pr oduct
. Leverage
other in-pr oduct
moments, such as onboar ding, t o explain AI systems.
●
Go be yond the pr oduct experience
. In-pr oduct information
may not be suﬃcient,
but y ou can suppor t it with a v ariety of additional
resour ces, such as mark eting
campaigns t o raise awar eness, and educational materials
and liter acy campaigns
to de velop mental models.
For example, y ou ma y onboar d users t o an app that
identiﬁes plants b y explaining some
basic, global pr oper ties of the model tr ained t o classify
plants, such as its known
strengths and limitations, and what it’ s been designed
to optimiz e for . If the model was
trained using a dataset made up of 75% of its examples
representing plants nativ e to
North America, and 25% of its examples coming fr om
South America, this ma y help
users in diff erent locations calibr ate their trust.
You ma y also wish t o explain t o the user
if recall was prioritiz ed o ver pr ecision, as this
may mean mor e conser vativerecommendations that potentially ﬂag cer tain harmless plants as unsaf e. (F or mor e
information on the tr ade-offs between pr ecision and
recall, see the
User Needs +
Deﬁning Success
chapter .)
When the user tries t o identify plants b y giving the
Plant P al app a phot o of a plant, the y
may then see an explanation that highlights which
deﬁning char acteristics of the plant
led the model t o label it b y type and saf ety.
In this section, y ou’ll ﬁnd guidance for building
trust at speciﬁc phases of the pr oduct
experience.
Establish trust from the beginning
When considering using a pr oduct that r elies on technology
that is new t o them, users
may have cer tain concerns. They ma y wonder what the
system can and can ’t do, how it
works, and how the y should inter act with it. They
may also wonder whether the y can
trust it, especially if the y’ve had less fa vorable
experiences with other pr oducts in the
past.
To star t establishing trust with users befor e the y
begin t o use the pr oduct, some best
practices include the following:
●
Communicate the pr oduct ’s capabilities and limitations
clearly t o set expectations,
and do this early
. Focus on the beneﬁt, not the technology .
Users ma y have
misconceptions about AI, trusting it t oo much or t oo
little. F or mor e guidance on
how t o onboar d in stages, see the
Mental Models
chapter .●
Highlight what ’s familiar
. Users look for familiar appear ance and legibility , which
can contribute t o initial trust.
●
Contextualiz e recommendations with thir d-par ty sour ces
.
When onboar ding users
to a new f eatur e or pr oduct, y ou ma y beneﬁt fr om
pointing t o thir d-par ty sour ces
that the y already trust t o jump-star t initial trust
in your pr oduct.
For example, when a user opens up the running r oute
recommendations page on the
Run app for the ﬁrst time, y ou can le verage a known
and trusted thir d-par ty sour ce by
surfacing a shor t list of local running r outes that
are listed in their local municipality ’s
parks and r ecreation website. The app ma y also displa y
a note t o the user that mor e
personaliz ed running r oute r ecommendations will appear
as the y star t inter acting with
the app, b y marking runs complete, and r ating r outes.
You’ll ﬁnd additional guidance that will help y ou
calibr ate users’ trust early on in the
Help
users calibr ate their trust
section, earlier in this
chapter .
Grow trust early on
As y ou onboar d users who ar e new t o your pr oduct,
they’ll likely ha ve a new set of
concerns. They ma y want t o understand which settings
they can edit, especially those
contr olling priv acy and security . They’ll also want
to understand how t o inter act with the
system, and how the y can expect the system t o react
to their input and f eedback.
To build and calibr ate users’ trust as the y get familiar
with the AI pr oduct:
●
Communicate priv acy and security settings on user
data
. Explicitly shar e which
data is shar ed, and which data isn ’t.●
Mak e it easy t o try the pr oduct ﬁrst
. Onboar ding users with a “ sandbo x” experience
can allow them t o explor e and test a pr oduct with
low initial commitment fr om
them.
●
Engage users and giv e them some contr ol as the y get
started
. Giv e them the ability
to specify their pr eferences, mak e corr ections when
the system doesn ’t beha ve as
they expect, and giv e them oppor tunities t o provide
feedback. Setting the
expectation that the system will learn as the y teach
it can help build trust.
For example, a user getting star ted with the
Run app
may wonder how the r outes
displa yed to them wer e chosen. If y ou ask them for
their geogr aphic location as the y’re
setting up their account in the app, y ou’ll want t o
communicate clearly , and at the time
you request the data, that it is the data that will
be used t o select r outes in their vicinity ,
rather than data fr om a GPS, or another app. And once
you’ve intr oduced the geogr aphic
location setting, mak e sur e that the user can ﬁnd
it when the y want t o change it. This
way, if the y ever get tir ed of running r outes in their
neighborhood and want t o try some
further awa y, they can go back t o the location setting
and change it.
Maintain trust
After a user has been onboar ded, and the y’ve speciﬁed
their initial pr eferences and
started teaching the pr oduct thr ough their inter actions
with it, y ou’ll want t o mak e sur e
to addr ess some common concerns that ma y come up as
the user-pr oduct r elationship
matur es. Users will now want t o know how t o edit their
settings, and the y ma y wonder
how the system will r eact t o new needs and contexts.
To maintain trust with users as the y continue using
the pr oduct, y ou ma y choose t o:●
Progressiv ely incr ease aut omation under user guidance
. Allow users t o get used
to the shift fr om human t o machine contr ol, and mak e sur e that the y can pr ovide
feedback t o guide this pr ocess. The k ey is t o tak e
small steps, and mak e sur e that
they land well and add v alue. A utomate mor e when trust
is high, or risk of err or is
low.
●
Continue t o communicate clearly about permissions
and settings
. Ask users for
permissions early . Think about when the user might
want t o review pr eferences
they’ve set in the past, and consider r eminding them
of these settings when the y
shift int o diff erent contexts, and ma y have diff erent
needs. They ma y also for get
what the y’re sharing and why , so explain the r easons
and beneﬁts.
For example, if a Run app user star ted b y setting
themselv es a daily run time goal of 20
minutes on running r outes mark ed “easy ”, and the y’ve
been r eaching this goal e very day
for se veral months, y ou ma y ask them if the y’d like
to upgr ade the diﬃculty le vel of the
routes that the app r ecommends t o them.
Regain or prevent lost trust
During the course of the pr oduct experience, users
may run int o various err ors, which
you can learn mor e about in the
Errors + Gr aceful
Failur e
chapter . Because AI is based
on pr obability and uncer tainty , it will sometimes
get things wr ong. A t such critical
points, users will often be concerned about their
ability t o signal t o the system that an
error has occurr ed, and their ability t o continue
safely once the err or has occurr ed. The
natur e of the err or and y our pr oduct’ s ability t o
recover from it will impact users’ trust.
To maintain trust with users as the y run int o err ors
while using y our pr oduct, y ou can:●
Communicate with appr opriate r esponses
. Let the users know ahead of time that
there is a r ecovery plan in case something goes wr ong, and in the moment, when
something doesn ’t go as expected. Adv ance knowledge
of how the system ma y
beha ve in such cases can help users mak e mor e informed
decisions that the y feel
more comfor table about. F or example, if a user pur chases
an eligible itiner ary
through an online ﬂight booking ser vice, and the
price for the same itiner ary on the
same booking par tner later dr ops below their pur chase
price, then the booking
service ma y notify the user that the y are eligible
for a pa yout equal t o the diff erence
between the lowest price and what the y paid.
●
Give users a wa y for ward, accor ding t o the se verity
of possible outcomes
. Your
appr oach should pr ovide a wa y to deal with the existing
error, and learn t o prevent it
happening again in the pr oduct.
○
Addr ess the err or in the moment
: provide a r emittance
plan that lets users
know how the pr oblem will be addr essed. F or example,
if the Run app
recommended a running r oute in a location wher e the
user was v acationing the
previous week, but is no longer ther e, you ma y notify
the user that running
recommendations in that city ha ve been r emo ved fr om
their curr ent
recommendation list.
○
Prevent the err or fr om r ecurring
: give users the oppor tunity
to teach the
system the pr ediction that the y wer e expecting, or
in the case of high-risk
outcomes, completely shift awa y from aut omation t o
manual contr ol. F or
additional guidance on balancing contr ol and aut omation,
see the
Feedback +
Contr ol
chapter .➂ Optimize for understanding
As described abo ve, explanations ar e crucial for building
calibr ated trust. Howe ver,
offering an explanation of an AI system can be a challenge
in and of itself. Because AI is
inher ently pr obabilistic, extr emely complicated, and
making decisions based on multiple
signals, it can limit the types of possible explanations.
Often, the r ationale behind a par ticular AI pr ediction
is unknown or t oo complex t o be
summariz ed int o a simple sentence that users with
limited technical knowledge can
readily understand. In many cases the best appr oach
is not t o attempt t o explain
everything – just the aspects that impact user trust
and decision-making. E ven this can
be har d to do, but ther e are lots of techniques t o
consider .
Explain what’s impo ant
Partial explanations
clarify a k ey element of how
the system works or expose some of
the data sour ces used for cer tain pr edictions. P artial
explanations intentionally lea ve
out par ts of the system ’s function that ar e unknown,
highly complex, or simply not
useful. Note that
progressiv e disclosur es
can also
be used t ogether with par tial
explanations t o giv e curious users mor e detail.
You can see some example
partial explanations
below
for an AI-power ed plant
classiﬁcation app.Describe the system or explain the output
Gener al system explanations
talk about how the whole
system beha ves, regar dless of
the speciﬁc input. They can explain the types of
data used, what the system is
optimizing for , and how the system was tr ained.
Speciﬁc output explanations
should explain the r ationale
behind a speciﬁc output for a
speciﬁc user , for example, why it pr edicted a speciﬁc
plant pictur e to be poison oak.
Output explanations ar e useful because the y connect
explanations dir ectly t o actions
and can help r esolv e confusion in the context of user
tasks.
Data sources
Simple models such as
regressions
can often sur face
which data sour ces had the
greatest inﬂuence on the system output. Identifying
inﬂuential data sour ces for complex
models is still a gr owing ar ea of activ e resear ch,
but can sometimes be done. In cases
wher e it can, the inﬂuential
featur e(s)
can then
be described for the user in a simple
sentence or illustr ation. Another wa y of explaining
data sour ces is
counter factuals
,
which tell the user why the AI did not mak e a cer tain
decision or pr ediction.
Speci c output
“This plant is most lik ely poison oak because it has
XYZ f eatur es”.
“This tr ee ﬁeld guide was cr eated for y ou because
you submit lots of pictur es of
maple and oak tr ees in Nor th America ”.
“This leaf is not a maple because it doesn ’t ha ve
5 points”.
General system
“This app uses color , leaf shape, and other fact ors
to identify plants”.Model con dence displays
Rather than stating why or how the AI came t o a cer tain
decision,
model conﬁdence
displa ys explain how cer tain the AI is in its pr ediction,
and the alternativ es it consider ed.
As most models can output
n-best classiﬁcations
and
conﬁdence scor es, model
conﬁdence displa ys ar e often a r eadily-a vailable
explanation.
Speci c output
N-best most-lik ely classiﬁcations
Most lik ely plant:
●
Poison oak
●
Maple leaf
●
Blackberr y leaf
Numeric conﬁdence le vel
Prediction: P oison oak (80%)
General system
Numeric conﬁdence le vel
This app categoriz es images with 80% conﬁdence on
average.Conﬁdence displa ys help users gauge how much trust t o put in the AI output. Howe ver,
conﬁdence can be displa yed in many diff erent wa ys, and statistical information lik e
conﬁdence scor es can be challenging for users t o
understand. Because diff erent user
groups ma y be mor e or less familiar with what conﬁdence
and pr obability mean, it’ s
best t o test diff erent types of displa ys early in
the pr oduct de velopment pr ocess.
Ther e’s mor e guidance about conﬁdence displa ys and
their r ole in user experiences in
Section 3
of this chapter .
Example-based explanations
Example-based explanations ar e useful in cases wher e
it’s tricky t o explain the r easons
behind the AI’ s predictions. This appr oach giv es users
examples fr om the model’ s
training set that ar e relevant t o the decision being
made. Examples can help users
understand surprising AI r esults, or intuit why the
AI might ha ve beha ved the wa y it did.
These explanations r ely on human intelligence t o analyz e
the examples and decide how
much t o trust the classiﬁcation.
Speci c output
To help the user decide whether t o trust a “ poison
oak” classiﬁcation, the system
displa ys most-similar images of poison oak as well
as most-similar images of other
leaves.
General system
The AI shows sets of image examples it tends t o mak e
errors on, and examples of
images it tends t o per form well on.Explanation via interaction
Another wa y to explain the AI and help users build
mental models
is by letting users
experiment with the AI on-the-ﬂy , as a wa y of asking
“what if?”. P eople will often test
why an algorithm beha ves the wa y it does and ﬁnd
the system ’s limits, for example b y
asking an AI v oice assistant impossible questions.
Be intentional about letting users
engage with the AI on their own terms t o both incr ease
usability and build trust.
Speci c output
A user suspects the system ga ve too much weight t o
the leaf color of a bush, which
led t o a mis-classiﬁcation.
To test this, the user changes the lighting t o yield
a mor e uniform brightness t o the
bush ’s lea ves to see whether that changes the classiﬁcation.
General system
This type of explanation can ’t be used for the entir e
app gener ally. It requir es a
speciﬁc output t o pla y with.
It’s impor tant t o note that de veloping any explanation
is challenging, and will lik ely
requir e multiple r ounds of user testing. Ther e’s mor e
information on intr oducing AI
systems t o users in the chapter on
Mental Models
.Note special cases of absent or comprehensive
explanation
In select cases, ther e’s no beneﬁt t o including any
kind of explanation in the user
inter face. If the wa y an AI works ﬁts a common mental
model and matches user
expectations for function and r eliability , then ther e
may not be anything t o explain in the
inter action. F or example, if a cell phone camer a aut omatically
adjusts t o lighting, it
would be distr acting t o describe when and how that
happens as y ou’re using it. It’ s also
wise t o avoid explanations that would r eveal pr oprietar y
techniques or priv ate data.
Howe ver, befor e abandoning explanations for these
reasons, consider using par tial
explanations and weigh the impact on user trust.
In other situations, it mak es sense, or is r equir ed
by law , to giv e a complete explanation
— one so detailed that a thir d par ty could r eplicate
the r esults. F or example, in softwar e
used b y the go vernment t o sentence criminals, it would
be reasonable t o expect
complete disclosur e of e very detail of the system.
Nothing less than t otal accountability
would be suﬃcient for a fair , contestable decision.
Key concept
Think about how an explanation for each critical inter action
could decr ease, maintain, or
increase trust. Then, decide which situations need
explanations, and what kind. The
best explanation is lik ely a par tial one.Ther e are lots of options for pr oviding a par tial explanation, which intentionally lea ve out
parts of the system ’s function that ar e unknown, t oo complex t o explain, or simply not
useful. P artial explanations can be:
●
Gener al system
. Explaining how the AI system works
in gener al terms
●
Speciﬁc output
. Explaining why the AI pr ovided a
particular output at a par ticular time
Apply the concepts fr om this section in Ex ercise 3
in the worksheet
.➃ Manage in uence on user decisions
One of the most ex citing oppor tunities for AI is being
able t o help people mak e better
decisions mor e often. The best AI-human par tnerships
enable better decisions than
either par ty could mak e on their own. F or example,
a commuter can augment their local
knowledge with tr aﬃc pr edictions t o tak e the best
route home. A doct or could use a
medical diagnosis model t o supplement their hist orical
knowledge of their patient. F or
this kind of collabor ation t o be eff ectiv e, people
need t o know if and when t o trust a
system ’s predictions.
As described in section 2 abo ve,
model conﬁdence
indicates how cer tain the system is
in the accur acy of its r esults. Displa ying model conﬁdence
can sometimes help users
calibr ate their trust and mak e better decisions, but
it’s not alwa ys actionable. In this
section, we ’ll discuss when and how t o show the conﬁdence
levels behind a model’ s
predictions.
Determine if you should show con dence
It’s not easy t o mak e model conﬁdence intuitiv e.
Ther e’s still activ e resear ch ar ound the
best wa ys to displa y conﬁdence and explain what it
means so that people can actually
use it in their decision making. E ven if y ou’re sur e
that y our user has enough knowledge
to properly interpr et your conﬁdence displa ys, consider
how it will impr ove usability and
compr ehension of the system – if at all. Ther e’s alwa ys
a risk that conﬁdence displa ys
will be distr acting, or worse, misinterpr eted.Be sur e to set aside lots of time t o test if showing model conﬁdence is beneﬁcial for
your users and y our pr oduct or f eatur e. You might choose not t o indicate model
conﬁdence if:
●
The conﬁdence le vel isn ’t impactful
. If it doesn ’t
mak e an impact on user decision
making, consider not showing it. Counterintuitiv ely,
showing mor e granular
conﬁdence can be confusing if the impact isn ’t clear
— what should I do when the
system is 85.8% cer tain vs. 87% cer tain?
●
Showing conﬁdence could cr eate mistrust
. If the conﬁdence
level could be
misleading for less-sa vvy users, r econsider how it’ s
displa yed, or whether t o displa y
it at all. A misleadingly high conﬁdence, for example,
may cause users t o blindly
accept a r esult.
Decide how best to show model con dence
If your r esear ch conﬁrms that displa ying model conﬁdence
impr oves decision making,
the next step is choosing an appr opriate visualization.
To come up with the best wa y to
displa y model conﬁdence, think about what user action
this information should inform.
Types of visualizations include:
Categorical
These visualizations categoriz e conﬁdence v alues
into buck ets, such as High / Medium
/ Low and show the categor y rather than the numerical
value. Consider ations:
●
Your team will determine cut off points for the categories,
so it’ s impor tant t o think
carefully about their meaning and about how many ther e
should be.
●
Clearly indicate what action a user should tak e under
each categor y of conﬁdence.Categorical model conﬁdence visualization.
Learn
more
N-best alternatives
Rather than pr oviding an explicit indicat or of conﬁdence,
the system can displa y the
N-best
alternativ e results. F or example, “This phot o
might be of New Y ork, Tokyo, or Los
Angeles. ” Consider ations:
●
This appr oach can be especially useful in low-conﬁdence situations. Showing
multiple options pr ompts the user t o rely on their own judgement. It also helps
people build a mental model of how the system r elates
different options.
●
Determining how many alternativ es you show will r equir e
user testing and iter ation.
N-best model conﬁdence visualization.
Learn more
Numeric
A common form of this is a simple per centage. Numeric
conﬁdence indicat ors ar e risky
because the y presume y our users ha ve a good baseline
understanding of pr obability .
Additional consider ations:
●
Mak e sur e to giv e enough context for users t o understand
what the per centage
means. No vice users ma y not know whether a v alue lik e
80% is low or high for a
certain context, or what that means for them.
●
Because most AI models will ne ver mak e a pr ediction
with 100% conﬁdence,
showing numeric model conﬁdence might confuse users
for outputs the y consider
to be a sur e thing. F or example, if a user has listened
to a song multiple times, the
system might still show it as a 97% match r ather than
a 100% match.Numeric model conﬁdence visualization.
Learn more
Data visualizations
These ar e graphic-based indications of cer tainty –
for example, a ﬁnancial for ecast
could include err or bars or shaded ar eas indicating
the r ange of alternativ e outcomes
based on the system ’s conﬁdence le vel. K eep in mind,
howe ver, that some common
data visualizations ar e best underst ood b y exper t
users in speciﬁc domains.
Data visualization of model conﬁdence.
Learn more
Key concept
To assess whether or not showing model conﬁdence
increases trust and mak es it easier
for people t o mak e decisions, y ou can conduct user
resear ch with people who r eﬂect the
diversity of y our audience. Her e are some examples
of the types of questions y ou could
ask:
●
“On this scale, show me how trusting y ou ar e of this
recommendation. ”
●
“What questions do y ou ha ve about how the app came
to this r ecommendation?”
●
“What, if anything, would incr ease y our trust in this
recommendation?”
●
“How satisﬁed or dissatisﬁed ar e you with the explanation
written her e?”
Once y ou’re sur e that displa ying model conﬁdence
is needed for y our AI pr oduct or f eatur e,
test and iter ate t o determine what is the right wa y
to show it.
Apply the concepts fr om this section in Ex ercise 4
in the worksheet
.
Summary
If and how y ou off er explanations of the inner-workings
of your AI system can
profoundly inﬂuence the user ’s experience with y our
system and its usefulness in their
decision-making. The thr ee main consider ations unique
to AI co vered in this chapter
were:
➀
 Help users calibr ate their trust
. The
goal of the
system should be for the user t o
trust it in some situations, but t o double-check it
when needed. F actors inﬂuencing
calibr ated trust ar e:
●
Articulate data sour ces
: Telling the user what data
are being used in the AI’ s
prediction can help y our pr oduct a void contextual
surprises and priv acy
suspicion and help the user know when t o apply their
own judgment.●
Tie explanations t o user actions
: Showing clear cause-eff ect r elationships
between user actions and system outputs with explanations
can help users
develop the right le vel of trust o ver time.
●
Account for situational stak es
: Providing detailed
explanations, pr ompting the
user t o check the output in low-conﬁdence/high-stak es
situations, and
revealing the r ationale behind high-conﬁdence pr edictions
can bolster
user trust.
➁
 Calibr ate user trust thr oughout the pr oduct experience
.
The pr ocess t o build the
right le vel of trust with users is slow and deliber ate,
and happens befor e and
throughout the user ’s inter action with the pr oduct.
Ther e are a v ariety of
appr oaches that y ou can use within and ar ound the
product (education,
onboar ding) t o calibr ate trust at each stage.
➂
 Optimiz e for understanding
.
In some cases, ther e
may be no wa y to off er an
explicit, compr ehensiv e explanation. The calculations
behind an output ma y be
inscrutable, e ven to the de velopers of those systems.
In other cases, it ma y be
possible t o sur face the r easoning behind a pr ediction,
but it ma y not be easy t o
explain t o users in terms the y will understand. In
these cases, use par tial
explanations.
➃
 Manage inﬂuence on user decisions
.
When a user
needs t o mak e a decision
based on model output, when and how y ou displa y model
conﬁdence can pla y a
role in what action the y tak e. Ther e are multiple
ways to communicate model
conﬁdence, each with its own tr adeoffs and consider ations.Want t o driv e discussions, speed iter ation, and a void
pitfalls?
Use the worksheet

Data Collection +
Evaluation
 
Sourcing and evaluating the data used to train AI
involve
impo ant considerations. This chapter covers the
following
questions:
 
 
Does our tr aining dataset ha ve the f eatur es and br eadth
to ensur e our AI meets our
users’ needs?
 
Should we use an existing tr aining dataset or de velop
our own?
 
How can we ensur e that the data quality is high?
 
How can we work with labelers t o prevent err ors and
bias in datasets when
gener ating labels?
 
Are we tr eating data work ers fairly?
Want t o driv e discussions, speed iter ation, and a void
pitfalls?
Use the worksheet
.
1What’s new when working with AI
In or der t o mak e predictions, AI-driv en pr oducts must
teach their underlying
machine
learning
model t o recogniz e patterns and corr elations
in data. This data is called
training data
, and can be collections of images, videos,
text, audio and mor e. You can
use existing data sour ces or collect new data expr essly
to train y our system. F or
example, y ou might use a database of r esponsibly cr owdsour ced
data on plants fr om
different r egions ar ound the world t o train an AI-power ed
app that r ecogniz es plants
that ar e saf e to touch.
The tr aining data y ou sour ce or collect, and how those
data ar e
labeled
,
directly
determines the output of y our system — and the quality
of the user experience. Once
you’re sur e that using AI is indeed the right path
for y our pr oduct (see
User Needs +
Deﬁning Success
) consider the following:
➀
 Plan t o gather high-quality data fr om the star t
.
Data is critical t o AI, but mor e time
and r esour ces ar e often inv ested in model de velopment
than data quality . You’ll
need t o plan ahead as y ou gather and pr epar e data,
to avoid the eff ects of poor
data choices fur ther downstr eam in the AI de velopment
cycle.
➁
 Translate user needs int o data needs
. Determine
the type of data needed t o train
your model. Y ou’ll need t o consider
predictiv e power
,
relevance, fairness, priv acy,
and security .
2➂
 Sour ce your data r esponsibly
. Whether using pr e-labeled data or collecting y our
own, it’ s critical t o evaluate y our data and their collection method t o ensur e the y’re
appr opriate for y our pr oject.
➃
 Prepar e and document y our data
. Prepar e your dataset
for AI, and document its
contents and the decisions that y ou made while gathering
and pr ocessing the
data.
➄
 Design for labelers & labeling
. For
super vised learning
,
having accur ate data
labels is crucial t o getting useful output fr om y our
model. Thoughtful design of
labeler instructions and UI ﬂows will help yield
better quality labels and ther efore
better output.
➅
 Tune y our model
. Once y our model is running, interpr et
the AI output t o ensur e it’s
aligned with pr oduct goals and user needs. If it’ s
not, then tr oubleshoot: explor e
potential issues with y our data.
➀ Plan to gather high-quality data from
the sta 
Data is critical t o AI, but the time and r esour ces
invested in model de velopment and
performance often outweigh those spent on data quality .
This can lead t o signiﬁcant downstr eam eff ects thr oughout
the de velopment pipeline,
which we call “
data cascades
”. Her e’s a hypothetical
example of a data cascade:
3Let’s say you’re de veloping an app that allows the user t o upload the pictur e of a
plant, and then displa ys a pr ediction for the plant’ s
type, and whether it is saf e for
humans and pets t o touch and eat it.
When y ou pr epar ed a dataset t o train the image classiﬁcation
model, y ou used
mostly images of plants nativ e to Nor th America because
you found a dataset that
was alr eady labeled and easy t o use t o train the model.
Once y ou released the Plant P al app, howe ver, you
found out that many users wer e
repor ting plant detection err ors in South America.
This is an example of a
data cascade
, as the eff ects
of the mismatch between
training data and user data in the r eal world wer e
dela yed. This cascade could ha ve
been a voided b y including images of plants nativ e
to South America when
developing the AI model, or r eleasing the app t o users
in Nor th America only .
Some data cascades ma y be har d to diagnose, and y ou
may not see their impact until
users r epor t a poor experience.
It’s best t o plan t o use high-quality data fr om the
beginning, whether y ou’re creating a
dataset fr om scr atch or r eusing existing datasets,
and good planning and interr ogating
your dataset can help y ou detect issues earlier . High-quality
data can be deﬁned as:
●
Accur ately r epresenting a r eal-world phenomenon or
entity
●
Collected, st ored, and used r esponsibly
●
Repr oducible
4●
Maintainable o ver time
●
Reusable acr oss r elevant applications
●
Having empirical and explanat ory power
Example of how data issues can compound int o
data
cascades
Most r oles on a pr oduct team and their data par tners
are inv olved in the data pipeline
when de veloping with AI. Understanding their priorities,
workﬂows, and challenges can
point us t o solutions for higher-quality data.
➁ Translate user needs into data needs
Datasets that can be used t o train AI models contain
examples
, which contain one or
more
featur es
, and possibly
labels
.
5
The scope of f eatur es, the quality of the labels,
and r epresentativ eness of the examples
in your tr aining dataset ar e all fact ors that aff ect
the quality of y our AI system.
The table abo ve contains data about r aces that an
app could use t o train an ML model
to predict how enjo yable a giv en race will be. Her e’s
how examples, f eatur es and labels
could aff ect the quality of that model:
Examples
If examples used t o train the run r ecommendation algorithm
only come fr om elite
runners, then the y would lik ely not be useful in cr eating
an eff ectiv e model t o mak e
predictions for a wider user base. Howe ver, they ma y
be useful in cr eating a model
gear ed towar ds elite runners.
Features
If the ele vation gain f eatur e was missing fr om the
dataset, then the ML model would
treat a 3.0 mile uphill run equally t o a 3.0 downhill
mile run, e ven though the human
experience of these is v astly diff erent.
6
Labels
Labels that r eveal the subjectiv e experience of the
runners ar e necessar y to help the
system t o identify the f eatur es that ar e most lik ely
to result in a fun run.
When deciding which examples, f eatur es, and labels
are needed t o train y our ML model,
work thr ough y our data needs on a conceptual le vel,
as shown in the example below .
The example shows the data needs br eakdown for a pr oduct
that aims t o solv e the user
need of “I want t o ﬁt runs int o my busy schedule. ”
Create a dataset speci cation
Just as y ou would cr eate a pr oduct speciﬁcation (such
as a
Product Requir ements
Document
) befor e star ting work on a new f eatur e or
product, consider writing a
document t o specify y our data needs. Use the pr oblem
statement that y ou deﬁned fr om
the user needs t o deﬁne the dataset that y ou will
need.
For example, let’ s say that y ou ar e working on de veloping
the Plant P al app t o help users
identify diff erent types of plants and signal whether
they are saf e to touch and eat or
not. Y ou know that y ou’ll need t o train an image classiﬁcation
model t o do this, and y ou
can star t specifying the sor t of the data that y ou’ll
need t o do this, the formats that y ou’ll
need the data t o be in (image formats, plant pr oper ties,
and “ safe to touch ” and “ safe to
eat” labels), and potential data sour ces.
Get the data
7Once y ou’ve deﬁned the data r equir ements, y ou’ll star t gathering the data.
A good place t o star t is t o determine if ther e are
any existing datasets that y ou can
reuse.
●
Do y ou ha ve access t o existing datasets that meet
your pr oject r equir ements?
Explor e
Dataset Sear ch
to star t looking for a vailable
datasets.
●
Can y ou acquir e an existing dataset b y par tnering
with another or ganization,
purchasing a dataset, or using client data?
If you decide t o acquir e an existing dataset, mak e
sure that y ou ha ve the following
information:
●
Is this data appr opriate for y our users and use case?
●
How was the data collected?
●
Which tr ansformations wer e applied t o it?
●
Do y ou need t o augment it with additional data sour ces
to be useful?
●
Were any tr ade-offs and assumptions made when cr eating
it?
●
What ar e the data compliance standar ds and licensing
information for the dataset?
●
Does the dataset ha ve any documentation, such as a
Data Car d
?
Alternativ ely, or in addition t o existing datasets,
you might need t o create a new dataset
using an in-house data collection t ool or a cr owdsour cing
platform.
Identify the data that you need vs. the data that
you have
8How much data and what type of data do y ou actually need for y our pr oject?
Sometimes, “ more data ” is not the best solution for
your data needs issues.
Use the following questions t o assess the data that
you ha ve as y ou determine what
you need. F or each of y our v ariables:
●
Does any of the data need t o be tr eated diff erently?
Some examples of such data
include:
○
Personally Identiﬁable Information (PII)
○
Protected Char acteristics
○
Variables that can be used t o inf er PII or Pr otected
Char acteristics.
●
What beneﬁt ar e you pr oviding t o the user b y using
this data?
●
Can y ou st ore and use the data secur ely?
●
How long will y ou k eep the data?
●
How much data do y ou actually need t o label?
●
Is the data r epresentativ e of y our users?
○
How would y ou deﬁne r epresentativ eness for y our use
case?
○
How would y ou collect r epresentativ e data?
Balance unde i ing & ove i ing
To build pr oducts t o work in one context, use datasets
that ar e expected t o reliably
reﬂect that context. F or example, for a natur al language
understanding model meant t o
work for speech, it wouldn ’t be helpful t o use wor ds
that users type int o a sear ch engine
as tr aining data — people don ’t type sear ches the
same wa y the y talk.
9If your tr aining data isn ’t properly suited t o the context, y ou also incr ease the risk of
overﬁtting
or
underﬁtting
your tr aining set. Ov erﬁtting
means the ML model is tailor ed
too speciﬁcally t o the tr aining data, and it can
stem fr om a v ariety of causes. If an ML
model has o verﬁt the tr aining data, it can mak e great
predictions on the tr aining data but
performs worse on the test set or when giv en new data.
Models can also mak e poor pr edictions due t o underﬁtting,
wher e a model hasn ’t
properly captur ed the complexity of the r elationships
among the tr aining dataset
featur es and ther efore can ’t mak e good pr edictions
with tr aining data or with new data.
Ther e are many r esour ces that can help the softwar e
engineers and r esear ch scientists
on your team with understanding the nuances of tr aining
ML models so y ou can a void
overﬁtting and underﬁtting, for example
these
from
Google AI. But ﬁrst, inv olve everyone
on your pr oduct team in a conceptual discussion about
the examples, f eatur es, and
labels that ar e likely requir ed for a good tr aining
set. Then, talk about which f eatur es ar e
likely to be most impor tant based on user needs.
Commit to fairness
At every stage of de velopment, human bias can be intr oduced
into the ML model. Data
is collected in the r eal world, fr om humans, and r eﬂects
their personal experiences and
biases — and these patterns can be implicitly identiﬁed
and ampliﬁed b y the ML model.
While the guidebook pr ovides some advice r elated t o
ML fairness, it is not an exhaustiv e
resour ce on the t opic. Addr essing fairness in AI,
and minimizing unfair bias, is an activ e
1 0area of r esear ch. See Google ’s
Responsible AI Pr actices
for recent ML fairness
guidance and r ecommended pr actices.
Here are some examples of how ML systems can fail
users:
●
Repr esentational harm
, when a system ampliﬁes or
reﬂects negativ e ster eotypes
about par ticular gr oups.
●
Oppor tunity denial
, when systems mak e predictions
and decisions that ha ve
real-lif e consequences and lasting impacts on individuals’
access t o oppor tunities,
resour ces, and o verall quality of lif e. Take a look
at
PAIR’s Explor ables
for a series
of inter activ e essa ys that explor e these ideas.
●
Dispr opor tionate pr oduct failur e
, when a pr oduct doesn ’t
work or giv es sk ewed
outputs mor e frequently for cer tain gr oups of users.
●
Harm b y disadv antage
, when a system inf ers disadv antageous
associations
between cer tain demogr aphic char acteristics and user
beha viors or inter ests.
While ther e is no standar d deﬁnition of fairness,
and the fairness of y our model ma y
vary based on the situation, ther e are steps y ou can
take to mitigate pr oblematic biases
in your dataset.
Use data that applies to di erent groups of users
Your tr aining data should r eﬂect the div ersity and
cultur al context of the people who will
use it. Use t ools lik e
Facets
and
WIT
to explor e your
dataset and better understand its
biases. In doing so, note that t o properly tr ain y our
model, y ou might need t o collect data
from equal pr opor tions of diff erent user gr oups that
might not exist in equal pr opor tions
1 1in the r eal world. F or example, t o ha ve speech r ecognition softwar e work equally on all
users in the United States, the tr aining dataset might
need t o contain 50% of data fr om
non-nativ e English speak ers e ven if the y are a minority
of the population.
Consider bias in the data collection and evaluation
process
Ther e is no such thing as truly neutr al data. E ven
in a simple image, the equipment and
lighting used shapes the outcome. Mor eover, humans
are inv olved with data collection
and e valuation, and so, as with any human endea vor,
their output will include human
bias. See mor e in the section on
labeling
below .
For example, sa y you’re creating a r ecommendation
system t o recommend new
health and ﬁtness goals t o users. If the intent is
to set goals that ar e saf ely
achie vable b y users with a wide r ange of baseline
ﬁtness le vels, it’ s impor tant that
the tr aining dataset includes data fr om a v ariety
of user types and not just y oung,
healthy people.
For mor e on the t opic of fairness, see Google ’s Machine
Learning F airness
Overview
and
Crash Course
.
Manage privacy & security
1 2As with any pr oduct, pr otecting user priv acy and security is essential. E ven in the
running-r elated example abo ve, the physiological and
demogr aphic data r equir ed to
train this model could be consider ed sensitiv e.
Here are some suggestions for managing priv acy and
security:
●
You ma y want t o review the data for
PII
and
Protected
Char acteristics
●
You ma y want t o consult with a lawy er befor e collecting
or using such data in y our
region (and y our pr oduct’ s users’ r egions).
●
Don’t assume basic data policies ar e enough t o protect
personal priv acy.
●
Set up the infr astructur e, training and guidance pr ograms
for priv acy pr otection and
plan for situations wher e an adv ersar y might get a
hold of the data.
●
Take extr a steps t o protect priv acy (e.g., anonymiz e
names, e ven if people agr eed
to ha ve their name used) when personal details (e.g.,
addr esses) could be exposed
as par t of AI pr edictions.
Ther e are a number of impor tant questions that arise
due t o the unique natur e of AI and
machine learning. Below ar e two such questions, but
you should discuss these and
others with priv acy and security exper ts on y our team.
What limits exist around user consent for data use?
When collecting data, a best pr actice, and a legal
requir ement in many countries, is
to giv e users as much contr ol as possible o ver what
data the system can use and
how data can be used. Y ou ma y need t o provide users
the ability t o opt out or delete
their account. Ensur e your system is built t o accommodate
this.
1 3Is there a risk of inadve ently revealing user data? What would the
consequences be?
For example, though an individual’ s health data might
be priv ate and secur e, if an AI
assistant r eminds the user t o tak e medication thr ough
a home smar t speak er, this
could par tially r eveal priv ate medical data t o others
who might be in the r oom.
1 4Aim for
Take extr a steps t o protect priv acy
(anonymiz e names for example, e ven if
people agr eed t o ha ve their name used in
community r eviews) when personal
details (such as wher e people liv e) could
be exposed as par t of AI
recommendations or pr edictions.
Learn
more
Avoid
Don’t assume basic data policies ar e
enough t o protect personal priv acy. In this
case, the runner agr eed t o expose her
name in community r eviews, but because
she often star ts runs fr om the same spot,
another user could inf er wher e she liv es.
1 5
Key concept
Once y our team has a high-le vel understanding of the
data y our pr oduct needs, work thr ough
your own tr anslation between speciﬁc user needs and
the data needed t o produce them.
Try to be as speciﬁc as possible during this step.
This will ha ve a dir ect impact on which user
experiences y our team decides t o spend y our r esour ces
on going for ward.
Apply the concepts fr om this section using Ex ercise
1
in the worksheet
➂ Source your data responsibly
Use existing datasets
It ma y not be possible t o build y our dataset fr om
scratch. As an alternativ e, you ma y
need t o use existing data fr om sour ces such as
Google
Cloud A utoML
,
Google Dataset
Sear ch
,
Google AI datasets
, or
Kaggle
. If you’re considering
super vised learning
, this
data ma y be pr e-labeled or y ou ma y need t o add labels
(see mor e on
labeling
, below).
Be sur e to check the terms of use for the dataset
and consider whether it’ s appr opriate
for y our use case.
Befor e using an existing dataset, tak e the time t o
thoroughly explor e it using t ools lik e
Facets
to better understand any gaps or biases. Real
data is often messy , so y ou should
1 6expect t o spend a fair amount of time cleaning it up. During this pr ocess, y ou ma y
detect issues, such as missing v alues, misspellings,
and incorr ect formatting. F or mor e
information on data pr epar ation techniques, check
out the de veloper guidelines on
Data
Prepar ation
. They can help y ou mak e sur e that this
data will be able t o help y ou deliv er
the user experience y ou identiﬁed at the outset.
Build your own dataset
When cr eating y our own dataset, it’ s wise t o star t
by obser ving someone who is an
exper t in the domain y our pr oduct aims t o ser ve —
for example, watching an accountant
analyz e ﬁnancial data, or a botanist classify plants.
If you can inter view them as the y
think or work thr ough the non-ML solution t o the pr oblem,
you ma y be able t o pick up
some insights int o which data the y look at when making
a decision or befor e taking an
action. Instead of one-off par tnerships with domain
exper ts, striv e for tighter , ongoing
collabor ations and sustained r elationships with domain
exper ts thr oughout the pr oject
lifecycle.
You’ll also want t o resear ch a vailable datasets that
seem r elevant and e valuate the
signals a vailable in those datasets. Y ou ma y need
to combine data fr om multiple
sour ces for y our model t o ha ve enough information
to learn.
Once y ou’ve gather ed potential sour ces for y our dataset,
spend some time getting t o
know y our data. Y ou’ll need t o go thr ough the following
steps:
1.
Identify y our data sour ce(s).
1 72.
Review how often y our data sour ce(s) ar e refreshed.
3.
Inspect the f eatur es’ possible v alues, units, and
data types.
4.
Identify any outliers, and inv estigate whether the y’re
actual outliers or due t o err ors
in the data.
Understanding wher e your dataset came fr om and how
it was collected will help y ou
disco ver potential issues.
You ma y need t o assemble a team of data collect ors
if you need t o build a new dataset.
Document y our data collection plan t o help a void quality
issues, and r eview it for bias:
●
Does the wa y you’re asking a question aff ect the answer?
●
Have you pr ovided all of the necessar y label options?
●
Are you lik ely to get imbalanced classes? If so, consider
over-sampling the r arer
class.
Collect live data from users
Once y our model has been tr ained and y our pr oduct
is being used in the r eal world, y ou
can star t collecting data in y our pr oduct t o continually
impr ove your ML model. How y ou
collect this data has a dir ect impact on its quality .
Data can be collected
implicitly
in the
back ground of user activity within y our app or
explicitly
when y ou ask users dir ectly .
Ther e are diff erent design consider ations for each,
which ar e co vered in depth in the
Feedback + Contr ol
chapter .
Capture the real world
1 8Mak e sur e that y our input data is as similar as possible t o real-world data t o avoid
model failur e in pr oduction. Consider y our user: do
they have the time t o tak e
high-quality phot ographs, or will y our model ha ve
to work with users’ blurr y smar tphone
images?
In many cases, y ou’ll ﬁnd that the data captur ed
by users can be starkly diff erent fr om
that in y our tr aining dataset. Instead of striving
for a v ery “clean ” dataset that contains
only v ery high-r esolution images for an image classiﬁcation
problem, or only corr ectly
formatted and typo-fr ee mo vie reviews for a sentiment
analysis pr oblem, allow some
‘noise ’ into your tr aining dataset because y ou’ll
have plenty of it in the r eal world.
Consider forma ing
Real data can be messy! A “z ero” value could be an
actual measur ed “0, ” or an indicat or
for a missing measur ement. A “ countr y” featur e ma y
contain entries in diff erent
formats, such as “US, ” “USA, ” and “United States. ”
While a human can spot the meaning just b y looking
at the data, an ML model learns
better fr om data that is consistently formatted.
Avoid compounding errors from other ML models
If you’re using the output of another ML system as
an input f eatur e to train y our model,
keep in mind that this is a risky data sour ce. Err ors
associated with this f eatur e will be
1 9compounded with y our system ’s overall err or, and the fur ther y ou ar e from the original
training data, the mor e diﬃcult it will be t o identify
error sour ces.
Ther e’s mor e information on determining err or sour ces
in the chapter on
Errors +
Graceful F ailur e
.
Protect personally identi able information
No matter what data y ou’re using, it’ s possible that
it could contain personally
identiﬁable information. Some appr oaches t o anonymizing
data include aggr egation
and r edaction. Howe ver, even these appr oaches ma y
not be able t o completely
anonymiz e your data in all cir cumstances, so consider
consulting an exper t.
Aggr egation
is the pr ocess of r eplacing unique v alues
with a summar y value. F or
example, y ou ma y replace a list of a user ’s maximum
hear tbeats per minute fr om e very
day of the month with a single v alue: their a verage
beats per minute or a categorical
high / medium / low label.
Redaction
remo ves some data t o create a less complete
pictur e. Such anonymization
appr oaches aim t o reduce the number of f eatur es available
for identifying a single user .
Prepare a data maintenance plan
If you want t o create a dataset, consider whether
you can maintain it and if y ou can
affor d the risks of something going unexpectedly wr ong.
Until the dataset is depr ecated,
focus on these tasks t o maintain dataset quality:
2 0●
Preventiv e maintenance
: Prevent pr oblems befor e the y occur . Store your dataset in
a stable r eposit ory that pr ovides diff erent le vels
of access and stable identiﬁers.
This can be diﬃcult for datasets hosted on personal
and lab websites.
●
Adaptiv e maintenance
: Preser ve the dataset while the
real world changes. Decide
which pr oper ties of the dataset should be pr eser ved,
and k eep this data updated
over time. The dataset should still fulﬁll r equir ements,
and continue t o represent the
reality of the phenomena that it measur es.
●
Corr ectiv e maintenance
: Fix err ors. Pr oblems can occur
as a r esult of
data
cascades
. Mak e sur e you ha ve a plan B in case of unfor eseen
problems and human
error. Keep a detailed, human-r eadable log of e verything
that y ou change in the
dataset.
➃ Prepare and document your data
Split your dataset into training and test sets
And ﬁnally , you’ll need t o split the data int o
training
and
test
sets. The model is tr ained
to learn fr om the tr aining data, and then e valuated
with the test data. Test sets ar e data
that y our model hasn ’t seen befor e — this is how y ou’ll
ﬁnd out if, and how well, y our
model works. The split will depend on fact ors such
as the number of examples in y our
dataset and the data distribution.
The tr aining set needs t o be lar ge enough t o successfully
teach y our model, and y our
test set should be lar ge enough that y ou can adequately
assess y our model’ s
performance. This is usually the time when de velopers
realiz e that adequate data can
2 1mak e or br eak the success of a model. So tak e the time t o determine the most eﬃcient
split per centage. A typical split of y our dataset
could r esult in: 60% for tr aining, and 40%
for testing.
This lab
from Google AI off ers mor e details
on data splitting.
Analyze and prepare your data
An impor tant step in all model tr aining pipelines
is handling “ dirty” or inconsistent data.
Data cleaning often consists of two stages: detecting
and addr essing issues.
Examples of oper ations per formed t o clean data include:
●
Extracting structur e
●
Dealing with missing v alues
●
Remo ving duplicates
●
Handling incorr ect data
●
Corr ecting v alues t o fall within cer tain r anges
●
Adjusting v alues t o map t o existing v alues in external
data sour ces
Data cleaning and analysis r equir e iter ation. Analyzing
and visualizing data ma y help
identify issues in y our dataset, possibly r equiring
further cleaning. Y our team ma y need
to return t o this stage once y ou begin t o evaluate
your model, as pr eviously undetected
issues with y our data ma y sur face then, t oo. And if
you ﬁnd something unexpected in
the data, consult with y our domain exper t.
To learn mor e about data pr epar ation, see
Data Pr epar ation
and F eatur e Engineering in
ML
and this
pre-ML checklist
.
2 2Document your data
Dataset documentation can be just as impor tant as
code documentation.
Having a r ecor d of y our dataset’ s sour ces, a list
of oper ations and tr ansformations that
have been applied t o it, its hist ory over time, and
recommended uses can help when y ou
do the following:
●
Shar e your dataset with colleagues on y our team or
on another team
●
Review whether y ou can use or publish y our dataset
●
Compar e multiple datasets side b y side
●
Use the data r esponsibly in t o train a model for an
AI-power ed pr oduct
●
Interpr et the beha vior of an AI model that y ou tr ained
with the data
●
Maintain the dataset for teams and systems that r ely
on it
Data Car ds ar e a form of documentation for datasets,
and include information that can
help answer the following questions about the data:
●
What does it r epresent?
●
What does it look lik e?
●
Wher e does it come fr om?
●
How was it pr epar ed?
●
Can it be used for a speciﬁc use case?
●
How should it be used r esponsibly?
To learn mor e about how t o create a Data Car d to document
your dataset, explor e the
Data Car ds Pla ybook
.
2 3Key concept
ML-driv en pr oducts r equir e a lot of data t o work,
and this is often wher e product teams
falter . Getting enough data t o both tr ain and test
your ML model is critical t o deliv ering a
functional pr oduct. To get y ou star ted, answer the
key questions below:
●
If you need t o create a new dataset, how ar e you planning
to collect the data?
●
If you ha ve an existing dataset, what, if any alter ations
or additions need t o be
made for y our user population?
Apply the concepts fr om this section using Ex ercise
2
in the worksheet
➄ Design for labelers & labeling
For
super vised learning
, accur ate data labels ar e
a crucial ingr edient for achie ving
relevant ML output. Labels can be added thr ough aut omated
processes or b y people
known as
labelers
. “Labelers” is a generic term that
covers a wide v ariety of contexts,
skill sets, and le vels of specialization. Labelers
could be:
●
Your users
: providing “ deriv ed” labels within y our
product, for example thr ough
actions lik e tagging phot os
●
Gener alists
: adding labels t o a wide v ariety of data
through cr owd-sour cing t ools
●
Trained subject matter exper ts
: using specializ ed
tools t o label things lik e medical
images
If people understand what y ou’re asking them t o label,
and why , and the y have the t ools
to do so eff ectiv ely, then the y’re mor e likely to
label the data corr ectly . Training y our
2 4labelers and testing their ability t o complete the labeling task r esponsibly ar e both
centr al to ensuring the quality of y our data.
Ensure labeler pool diversity
Think about the perspectiv es and potential biases
of the people in y our pool, how t o
balance these with div ersity , and how their points
of view could impact the quality of
the labels. In some cases, pr oviding labelers with
training t o mak e them awar e of
unconscious bias has been eff ectiv e in r educing biases.
Here are some questions t o ask when e valuating y our
labeler pool:
●
Are your annotat ors similar t o your end users? E.g.,
are you asking American
annotat ors t o label images of Indian cuisine, or vice
versa?
●
Are ther e cultur al diff erences between labelers and
users that could impact data
quality? E.g., date formatting rules (DD/MM/Y YYY vs.
MM/DD/Y YYY) and
measur ement scales (metric vs. imperial) can diff er.
●
Do labelers know what t o do?
○
Are the y domain exper ts, or do the y need tr aining?
○
Are ther e guidelines on data quality , and ha ve the y
been pr ovided in the
annotat or’s nativ e language?
○
Do the y know what the data will be used for?
Investigate labeler context and incentives
Think thr ough the labeler experience, and how and
why the y are per forming this task.
Ther e’s alwa ys a risk that the y might complete the
task incorr ectly due t o issues lik e
2 5boredom, r epetition, or poor incentiv e design. Incentiv es that focus on v olume r ather
than quality can lead t o bias in y our dataset.
Design tools for labeling
Tools for labeling can r ange fr om in-pr oduct pr ompts
to specializ ed softwar e. When
soliciting labels in-pr oduct, mak e sur e to design
the UI in a wa y that mak es it easy
for users t o provide corr ect information. When building
tools for pr ofessional
labelers, the ar ticle
First: Raters
offers some useful
recommendations lik e the ones
below:
●
Use multiple shor tcuts t o optimiz e key ﬂows
. This
helps labelers mo ve fast and
stay eﬃcient.
●
Provide easy access t o labels
. The full set of a vailable
labels should be visible
and a vailable t o labelers for each item the y are ask ed
to addr ess. It should be
fast and easy in the UI t o apply the labels.
●
Let labelers change their minds
. Labeling can be complicated.
Offer a ﬂexible
workﬂow and suppor t for editing and out-of-sequence
changes so that labelers
can seek second opinions and corr ect err ors.
●
Auto-detect and displa y err ors
. Mak e it easy t o avoid
accidental err ors with
checks and ﬂags.
●
Review thir d-par ty tool capabilities and limitations
.
Learn how labelers ar e
onboar ded, and if their tr aining can be impr oved,
and pilot the pr ocess on the
platform t o verify that labelers ha ve a wa y to provide
feedback and ﬂag
ambiguous data.
2 6●
Explain criteria for acceptance
. Clearly state which err ors can trigger task
rejection.
●
Allow labelers t o mark instances as ‘unsur e’ or skip
them alt ogether
. Don ’t
force labelers t o label an item without pr oviding
checks and balances.
●
Value labeler disagr eements
. Disco vering discr epancies
in how humans
interpr et labels mak es model de velopment mor e prepar ed
for the r eal world, so
mak e sur e to revisit and r eview the data and labels.
When compiling instructions for labeler tasks, don ’t
take specializ ed domain
knowledge for gr anted. Labelers ma y not be as familiar
with the domain and the
task, which lea ves room for ambiguities.
Consider the following r ecommendations when writing
instructions:
●
Provide examples for the task t o illustr ate expectations
.
Include ‘ edge ’ cases.
●
Give step-b y-step task instructions
. Explicitly describe
all of the t ools needed.
●
Break instructions down int o manageable chunks
. Use
bullets for steps, or
rules.
●
Strik e the right balance for task instruction length
.
Compact tasks gener ally
have greater uptak e and turnar ound time. Howe ver,
longer task instructions ar e
helpful when critical details ar e needed t o per form
the task accur ately .
Plan ahead t o conduct r esear ch with y our labelers
to iter ate on task design, and
instruction clarity . Befor e fully launching the task,
pilot the task with a small set of
labelers t o gather their f eedback and example r esults.
You’ll also want t o identify
points of confusion dir ectly fr om the labelers.
2 7And ﬁnally , here are a f ew consider ations for cr eating mor e accessible and inclusiv e
labeler workﬂows:
●
Account for work er envir onments, and the language
of your data collabor ators
.
You can help impr ove the r epresentativ eness of y our
data b y designing tasks for
your data collabor ators.
●
Carefully experiment with the time allotment t o ensur e
that labelers ar e able t o
complete the task at their own pace
. Mak e sur e to
give labelers enough time t o
complete tasks without rushing, and allow them t o
request extr a time if needed.
●
Plan for mobile users in task design and time allotment
.
Most tr aditional data
labeling workﬂows ar e per formed on lapt ops and deskt ops,
but a gr owing online
population is now ‘ mobile-ﬁrst’. While this can open
up oppor tunities for data
collection fr om mor e div erse gr oups, such tasks can
take longer , and r equir e
different task design for low-r esour ce settings. Consider
the following wa ys to
adapt the workﬂow: minimiz e reliance on text and
leverage other modalities
(e.g., images and audio), cr eate intuitiv e icons,
and pr ovide local language
suppor t.
Once y ou’ve collected data fr om labelers, y ou’ll need
to conduct statistical tests t o
analyz e
inter-labeler r eliability
. A lack of r eliability
could be a sign that y ou ha ve
poorly-designed instructions.
2 8Aim for
Mak e labeler instructions as speciﬁc and
simple as possible. Her e, the phr ase
“running shoes” easily rules out the
selection of other athletic shoe types lik e
soccer cleats.
Learn mor e
Avoid
Don’t use instructions that can be interpr eted
multiple wa ys. Her e, someone ’s subjectiv e
deﬁnition of “ athletic ” might or might not
include dance shoes, for example.
2 9
Key concept
Befor e designing t ools for y our labelers, r esear ch
their needs the same wa y you would think
about y our end-users. Their motiv ation and ability
to do their job well has a dir ect impact on
everything else y ou build down the line.
●
Who ar e your labelers?
●
What is their context and incentiv e?
●
What t ools ar e the y using?
Apply the concepts fr om this section in Ex ercise 3
in the worksheet
➅ Tune your model
Once y our model has been tr ained with y our tr aining
data, e valuate the output t o assess
whether it’ s addr essing y our tar get user need accor ding
to the success metrics y ou
deﬁned. If not, y ou’ll need t o
tune
it accor dingly .
Tuning
can mean adjusting the
hyperpar ameters of y our tr aining pr ocess
, the par ameters
of the model or y our r ewar d
function, or tr oubleshooting y our tr aining data.
To evaluate y our model:
●
Use t ools lik e the
What-If t ool
and the
Language Interpr etability
Tool (LI T)
to inspect
your model and identify blindspots.
●
Test, test, test on an ongoing basis.
3 0○
In early phases of de velopment, get in-depth qualitativ e feedback with a
diverse set of users fr om y our tar get audience t o
ﬁnd any “r ed ﬂag” issues with
your tr aining dataset or y our model tuning.
○
As par t of testing, ensur e you’ve built appr opriate
and thoughtful mechanisms
for user f eedback. See mor e guidance for this in the
Feedback + Contr ol
chapter .
○
You ma y need t o build cust om dashboar ds and data visualizations
to monit or
user experience with y our system.
○
Be par ticularly car eful t o check for secondar y eff ects
that y ou ma y not ha ve
anticipated when determining y our r ewar d function,
a concept co vered in the
User Needs + Deﬁning Success
chapter .
○
Try to tie model changes t o a clear metric of the
subjectiv e user experience lik e
cust omer satisfaction, or how often users accept a
model’ s recommendations.
In addition t o impr oving standar d metrics (e.g., accur acy),
you need a str ategy for how
to deal with a system that doesn ’t beha ve as expected.
Mak e sur e to test y our model
befor e and after any changes. Y ou ma y have to troubleshoot
the tr aining data in
particular .
Consider the following:
●
Low data quality , or not enough high-quality data
.
Can y ou go back and collect
additional better data?
●
Unintended consequences
. These ar e oppor tunities for
design changes. Look for:
○
Errors in output, and patterns in them
○
Changes in data that can lead t o changes in model
performance (data drift)
3 1○
Errors fr om the system itself, the context it’ s in or what the user wants
○
How can y ou a void these consequences in the next iter ation?
○
What other pr oblems might arise next time & how do
you mitigate them?
●
Parts of the pr oject which ar e par ticularly diﬃcult
for users t o understand
. A user
might see something as an err or if it’ s not explained
correctly
○
Scan for omissions or white lies
○
Provide an explanation for these situations. E.g.,
“We use all y our lik ed songs
to gener ate r ecommendations, not just y our fa vorite
songs. ”
Once y ou’ve identiﬁed issues that need t o be corr ected,
you’ll need t o map them back t o
speciﬁc data f eatur es and labels (or lack ther eof),
or model par ameters. This ma y not
be easy or str aightfor ward. Resolving the pr oblem
could inv olve steps lik e adjusting the
training
data distribution
, ﬁxing a labeling issue
or gathering mor e relevant data. Her e’s a
hypothetical example of how a team might tackle tuning:
Let’s say our running app was launching a new f eatur e
to calculate calories burned
and mak e recommendations for mid-run changes t o help
users burn their tar get
number of calories.
During beta testing, it was obser ved that users r eceiving
these r ecommendations
were far mor e likely than other users t o quit mid-run.
Moreover, users who followed
the r ecommendations and completed the run and wer e
less lik ely to return for a
second run within the same week. The pr oduct manager
originally assumed that this
featur e was a failur e, but after user inter views and
a deeper look at the data, it turned
3 2out that the algorithm wasn ’t properly weighting impor tant data when calculating
estimated calorie burn lik e the outside temper ature
and a user ’s weight.
After some user r esear ch, it became clear that some
users wer e quitting because
they didn ’t trust the calorie calculation and ther efore
didn ’t see the point in accepting
the app ’s recommendations for mid-run changes.
The engineering team was able t o re-tune the algorithm
and launch a successful
featur e.
Key concept
Tuning is an ongoing pr ocess for adjusting y our ML
model in r esponse t o user
feedback and issues that arise due t o unfor eseen cir cumstances.
Tuning ne ver
stops, but it is especially impor tant in the early
phases of de velopment.
●
What is our plan for doing early testing of our model?
●
Is our set of early beta users div erse enough t o properly
test our model?
●
What metrics will we use t o determine if our tuning
is successful?
Apply the concepts fr om this section on tuning b y
exploring the
What-if t ool
. Explor e
more about tuning models in r esponse t o user f eedback
in the
Feedback + Contr ol
chapter .
3 3Summary
Data is the bedr ock of any ML system. Ha ving r esponsibly
sour ced data, fr om a r elevant
context, check ed for pr oblematic bias will help y ou
build better systems and ther efore
more eff ectiv ely addr ess user needs. K ey consider ations
for data collection and
evaluation:
➀
 Plan t o gather high-quality data fr om the star t
.
Plan ahead as y ou gather and
prepar e data, t o avoid the eff ects of poor data choices
further downstr eam in the
AI de velopment cy cle.
➁
 Translate user needs int o data needs
. Think car efully
as a cr oss-functional team
about what f eatur es, labels, and examples y ou will
need t o train an eff ectiv e AI
model. W ork systematically t o break down user needs,
user actions, and ML
predictions int o the necessar y datasets. As y ou identify
potential datasets, or
formulate a plan t o collect them, y ou’ll need t o be
diligent about inspecting the
data, identifying potential bias sour ces, and designing
the data collection methods.
➂
 Sour ce your data r esponsibly
. As par t of sour cing
data, y ou’ll need t o consider
relevance, fairness, priv acy, and security . You can
ﬁnd mor e information in
Google ’s
AI Principles
and
Responsible AI Pr actices
. These
apply whether y ou ar e using an
existing dataset or building a new tr aining dataset.
3 4➃
 Prepar e and document y our data
. Prepar e your dataset for AI, and document its
contents and the decisions that y ou made while gathering
and pr ocessing the
data.
➄
 Design for labelers & labeling
. Corr ectly labeled
data is a crucial ingr edient t o an
effectiv e super vised ML system. Thoughtful consider ation
of your labelers and the
tools the y’ll be using will help ensur e your labels
are accur ate.
➅
 Tune y our model
. Once y ou ha ve a model, y ou will
need t o test and tune it
rigor ously . The tuning phase inv olves not only adjusting
the par ameters of y our
model, but also inspecting y our data – in many cases,
output err ors can be tr aced
to problems in y our data.
Want t o driv e discussions, speed iter ation, and a void
pitfalls?
Use the worksheet
3 5

Artificial Intelligence  
for Children
TOOLKIT
MARCH 2022Contents
© 2022 World Economic Forum. All rights 
reserved. No part of this publication may 
be reproduced or transmitted in any form 
or by any means, including photocopying 
and recording, or by any information 
storage and retrieval system.Disclaimer 
This document is published by the  
World Economic Forum as a contribution 
to a project, insight area or interaction. 
The findings, interpretations and 
conclusions expressed herein are a result 
of a collaborative process facilitated and 
endorsed by the World Economic Forum 
but whose results do not necessarily 
represent the views of the World Economic 
Forum, nor the entirety of its Members, 
Partners or other stakeholders.Introduction
1 C-suite and corporate decision-makers’ checklist
Where companies can fall short
Actions
The rewards of leading 
2 Product team guidelines
Foundational principles 
The challenge
Definition of children and youth
Social networks
Overarching limitations
Putting children and youth FIRST
Fair 
Inclusive 
Responsible 
Safe 
Transparent
3 AI labelling system
4 Guide for parents and guardians
Benefits and risks
Contributors
Endnotes3
6
7
8
9
10
11
13
13
14
14
15
15
17
19
21
24
29
31
31
33
35
Images: Getty Images
Artificial Intelligence for Children
2This toolkit is designed to help companies 
develop trustworthy artificial intelligence for 
children and youth.Introduction
For the first time in history, a generation of children is 
growing up in a world shaped by artificial intelligence 
(AI). AI is a set of powerful algorithms designed to 
collect and interpret data to make predictions based 
on patterns found in the data.
Children and youth are surrounded by AI in many 
of the products they use in their daily lives, from 
social media to education technology, video games, 
smart toys and speakers. AI determines the videos 
children watch online, their curriculum as they learn, 
and the way they play and interact with others.
This toolkit, produced by a diverse team of youth, 
technologists, academics and business leaders, is 
designed to help companies develop trustworthy 
artificial intelligence (AI) for children and youth and 
to help parents, guardians, children and youth 
responsibly buy and safely use AI products.
AI can be used to educate and empower 
children and youth and have a positive impact 
on society. But children and youth can be 
especially vulnerable to the potential risks posed 
by AI, including bias, cybersecurity and lack of accessibility. AI must be designed inclusively to 
respect the rights of the child user. Child-centric 
design can protect children and youth from 
the potential risks posed by the technology.
AI technology must be created so that it is both 
innovative and responsible. Responsible AI is safe, 
ethical, transparent, fair, accessible and inclusive. 
Designing responsible and trusted AI is good for 
consumers, businesses and society. Parents, 
guardians and adults all have the responsibility to 
carefully select ethically designed AI products and 
help children use them safely. 
What is at stake? AI will determine the future of 
play, childhood, education and societies. Children 
and youth represent the future, so everything must 
be done to support them to use AI responsibly 
and address the challenges of the future. 
This toolkit aims to help responsibly design, 
consume and use AI. It is designed to help 
companies, designers, parents, guardians, children 
and youth make sure that AI respects the rights of 
children and has a positive impact in their lives. 
Artificial Intelligence for Children
March 2022
Artificial Intelligence for Children
3Who are you?
A corporate decision-maker , member of a product team or a parent or guardian?Corporate users
The checklist for C-suite executives and guidelines 
for product teams contain actionable frameworks 
and real-world guidance to help your company 
design innovative and responsible AI for children  
and youth. By using these guidelines, you can lead 
as a trusted company that delights your child users.
Companies should keep in mind that children often 
use AI products that were not designed specifically 
for them. It’s sometimes difficult to predict what 
products might later be used by children or youth. 
As a result, you should carefully consider whether 
children or youth might be users of the technology 
you’re developing. If they are, you should carefully 
consider how to help increase the benefits and 
mitigate potential risks posed by the technology for 
children and youth. The C-suite is responsible for setting the culture 
around responsible AI and strategy for and 
investment in AI products. The checklist is designed 
to help executives learn more about the benefits 
and risks of AI for children and youth so you can 
better lead, innovate and grow.
Read more about the C-suite checklist.
Product teams design, develop and deploy  
the AI technology that children and youth will  
use. Responsible design starts with product  
teams and continues to be their ongoing 
responsibility. The guidelines are designed for 
engineers, developers, product managers and  
other members of the product team to use 
throughout the product life cycle.  Companies 
should keep in 
mind that children 
often use AI 
products that 
were not designed 
specifically 
for them.Putting children and youth FIRST checklist
Fair
Inclusive
Responsible
Safe
Transparent
Artificial Intelligence for Children
4Consumers: Parents and guardians 
Parents and guardians decide which AI-powered technologies to buy 
for their children. By educating yourselves and better understanding the 
benefits and risks posed by the technology, you can make deliberate and 
informed decisions that can protect your children and be sure AI has a 
positive impact on their lives.
Learn more about the Guide for parents and guardians
The tool for parents and guardians is designed based on the AI labelling 
system (Figure 1) to understand these six important categories of AI. AI labelling system 
The AI labelling system is designed to be included in all AI products on 
their physical packaging and online accessible through a QR code. Like 
nutritional information on food packaging, the labelling system is designed 
to concisely tell consumers – including parents and guardians, as well as 
children and youth – how it works and the options available to the users. 
All companies are encouraged to adopt this tool to help create greater trust 
and transparency with the purchasers and child users of their products. 
Learn about the AI labelling system 
Age Data use
AI use NetworksSensors Accessibility
AI labelling system FIGURE 1
Source: World Economic Forum
Artificial Intelligence for Children
5C-suite and  
corporate decision-
makers’ checklist1
Actionable frameworks and real-world 
guidance help companies design innovative 
and responsible AI for children and youth.
This checklist is for C-suite executives of companies 
that provide products and services incorporating 
artificial intelligence (AI) intended for use by children 
and youth. Many companies use AI to differentiate 
their brands and their products by incorporating 
it into toys, interactive games, extended reality 
applications, social media, streaming platforms 
and educational products. With little more than 
a patchwork of regulations to guide them, 
organizations must navigate a sea of privacy  
and ethics concerns related to data capture  and the training and use of AI models. Executive 
leaders must strike a balance between realizing  
the potential of AI and helping reduce the risk 
of harm to children and youth and, ultimately, 
their brand. Building on a foundation established 
in the World Economic Forum “Empowering AI 
Leadership: AI C-Suite Toolkit”, the checklist is 
intended to help C-suite executives and other 
corporate decision-makers reflect upon and act  
to create and support responsible AI for this 
vulnerable population.
Trusted and responsible AI for children and youth:  
A checklist for executives
Attracted by the extraordinary opportunity to 
innovate with AI, companies are moving at a 
record pace to incorporate AI into toys, broadcast 
and social media, smart speakers, education 
technology, virtual worlds and more.  
AI ranges in complexity and impact from simple 
recommendation and customization engines 
to deeply immersive experiences that imitate 
and simulate human behaviour, emotions and 
interactions. Implemented thoughtfully, these 
systems can delight, teach and evoke interaction 
with their young users, enabling them to grow and 
develop at their own pace and according to their 
learning styles. But implemented without careful 
forethought and the guidance of child development experts and ethicists, AI can hinder development 
and infringe on the rights of vulnerable users. 
With the checklist, leaders can learn how even 
companies that mean well overlook potential issues 
and how to mitigate the risks associated with AI 
adoption. Executives should aspire to the highest 
possible ethical and social standards regarding 
child development, suitability for purpose, non-
bias, accessibility and privacy. Doing so provides 
tremendous potential beyond the opportunity to do 
good. It can elevate your brand and enable you to 
position your company as a trustworthy steward of 
sought-after products and services to your primary 
buyers: parents, grandparents, teachers, educators  
and other care providers. 
Artificial Intelligence for Children
6Given the acceleration of AI adoption and a lag in 
broadly accepted standards and guidance, leaders 
might be caught off guard. What are the riskiest 
behaviours that your teams should avoid? 
 –Not disclosing how AI is used: Companies 
that think buyers may object to AI may conceal 
or downplay its use. Be transparent about the 
use of AI and why you are using it. 
 –Amplifying and perpetuating bias: AI 
modelling can contain inaccuracies and 
oversimplifications that lead to inaccessibility 
and bias against marginalized groups, such as 
disabled communities and users from different 
cultural and socio-economic backgrounds.
 –Skipping user-focused validation: Bypassing 
user and expert validation of suitability for purpose during design and prototyping  
stages can diminish the potential value  
of AI and cause harm. 
 –Leaving privacy and security gaps:  
Data security, privacy and consent to  
collect and use data are complicated due  
to cybersecurity threats and a patchwork  
of regulations that vary geographically.  
These concerns reach past the useful life  
of a product: For minors, parents provide 
consent, but their children may claim  
their right for their data to be forgotten  
as they get older.
With these potential stumbling blocks in mind,  
what steps can corporate leaders take to protect 
and enhance their brand while leveraging the 
remarkable potential of AI?Where companies can fall short
 Executive 
leaders should 
create a culture 
of responsibility 
backed by 
resources that 
enable responsible 
AI from design to 
end-of-product use 
and beyond.
Artificial Intelligence for Children
7Executive leaders should create a culture of 
responsibility backed by resources that enable 
responsible AI from design to end-of-product use 
and beyond. These steps are recommended:
1. Know the legal duties and regulatory 
constraints: 
Leverage existing guidance, such as the Institute 
of Electrical and Electronics Engineers’ (IEEE) 
Code of Ethics,1 UNICEF’s Policy Guidance on 
AI for Children2 and World Economic Forum 
guidance,3 as well as the guidance contained 
in this toolkit and guidelines for the product 
team, AI labelling system, and resources 
for parents and guardians and children and 
youth. Commit to internal and, if possible, 
external AI oversight. Report compliance and 
leadership measures publicly and in simple 
language so buyers can understand.
2. Build a diverse and capable team: 
Include ethicists, researchers, privacy 
specialists, educators, child development 
experts, psychologists, user-experience (UX) 
designers and data scientists. Collaborate with 
non-profit organizations and educational and 
research institutions for more expertise. 
3. Train your team and provide resources for 
success with this checklist: 
Educate team members about the importance 
of responsible and trustworthy AI and provide them access to the skills, tools and time 
they need to execute your vision. Have open 
dialogue about unintended consequences, 
possible worst-case scenarios, and the reasons 
for ensuring your teams are considering the five 
AI characteristics critical to putting children and 
youth FIRST (Figure 2). 
 
For more information, refer to the product team 
guidelines, which offers detailed guidance on 
the five areas.
4. Offer expertise to inform development of 
regulations, standards and guidance: 
Contribute to public forums on how AI is  
being used in your products or services.  
Share your experience in proposing guidance 
and requirements. 
5. Welcome principled efforts to label  
products and services: 
These should be done according to the potential 
impact of AI on users. Endorse and participate in 
activities to develop labelling and rating standards. 
Label your offerings to help consumers make 
informed choices based on recommendations 
about, for example, user age, accessibility factors 
and whether a camera and microphone are being 
used. For additional information about labelling 
recommendations, see the AI labelling system.Actions
Putting children and youth FIRST checklist FIGURE 2
Company culture and processes address ethics and bias concerns regarding 
how AI models are developed by people and the impact of AI models in use.
AI models interact equitably with users from different cultures and with different 
abilities; product testing includes diverse users.
Offerings reﬂect the latest learning science to enable healthy cognitive, social, 
emotional and/or physical development. 
The technology protects and secures user and purchaser data, and the 
company discloses how it collects and uses data and protects data privacy; 
users may opt out at any time and have their data removed or erased.
The company explains in non-technical terms to buyers and users why AI is 
used, how it works and how its decisions can be explained. The company also 
admits AI’s limitations and potential risks and welcomes oversight and audits.
Source: World Economic Forum
Artificial Intelligence for Children
8The rewards of leading
When you deliver responsible AI-based offerings and engage in the development of 
standards, you can do much more than just affect your bottom line. You help young 
users grow into the best versions of themselves – a generation empowered by AI. 
References
 –Benjamin, Ruha, Race after Technology: Abolitionist Tools for the New Jim Code, Polity Books, 2019,  
https://academic.oup.com/sf/article-abstract/98/4/1/5681679?redirectedFrom=fulltext 
 –Coeckelbergh, Mark, AI Ethics, MIT Press, 2020, https://mitpress.mit.edu/books/ai-ethics
 –Dubber, Markus D., Frank Pasquale and Sunit Das (eds), The Oxford Handbook of Ethics of AI, Oxford University 
Press, 2020, https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780190067397.001.0001/
oxfordhb-9780190067397 
 –O’Neil, Cathy, Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy, 
Crown Publishing Group, 2016, http://www.governance40.com/wp-content/uploads/2019/03/Weapons-of-Math-
Destruction-Cathy-ONeil.pdf 
 –Russell, Stuart, Human Compatible: Artificial Intelligence and the Problem of Control, Penguin Publishing Group, 
2019, https://books.google.ch/books/about/Human_Compatible.html?id=8vm0DwAAQBAJ&redir_esc=y 
 –United Nations, “Young people help draw up UN digital protection recommendations”, UN News, 24 March 2021, 
https://news.un.org/en/story/2021/03/1088182 
Artificial Intelligence for Children
9Product team guidelines2
Responsible design starts with product teams 
and continues to be their ongoing responsibility 
throughout the product life cycle.
Introduction
Why?
Who?
How?Product teams design, develop and deploy the AI technology that children 
and youth will use. Responsible design starts with product teams and 
continues to be your ongoing responsibility throughout the product life 
cycle. These guidelines are designed to help you develop responsible AI 
products for children and youth. 
The entire product team: developers, programme managers, technical 
writers, product owners, software architects, UX designers, marketing 
managers and anyone else with a hand in product development.
Dive into the five categories of “Putting children and youth FIRST” – Fair, 
Inclusive, Responsible, Safe and Transparent (Figure 3). Each theme is 
also organized into three sections: goals, greatest potential for harm, and 
mitigate risks. Use these categories and resources as a starting point. 
Responsible AI is a journey, and you’ll want to form a diverse and dynamic 
team as you develop AI for children and youth. 
Source: World Economic ForumPutting children and youth FIRST FIGURE 3
Ethics, bias and liability
Accessibility, neuro-differences and feedback from kids
Age- and developmental-stage-appropriate, reflects the  
latest learning science and is designed with kids in mind
Does no harm; cybersecurity and addiction mitigation
Can explain how the AI works and what it is being used for  
to a novice or lay audience 
Artificial Intelligence for Children
10Foundational principles
The United Nations Convention on the Rights of  
the Child lays out numerous principles for protecting 
the rights, dignity, autonomy and safety of children. 
But the first principle under Article 3 guides many  
of the others: 
“In all actions concerning children, whether 
undertaken by public or private social welfare 
institutions, courts of law, administrative authorities 
or legislative bodies, the best interests of the 
child shall be a primary consideration.”4
The best place to start is with a simple question: 
“Does the system I’m building have the best 
interests of children in mind?” Perhaps the 
answer is not “no”, but “I’m not sure”. And what 
if it is an emphatic “yes!”? No matter the answer, 
it is important to consider whether the positive 
impact can be clearly articulated and establish 
strategies for determining whether or not your 
system is having this intended impact. The goal 
of these guidelines is to help you identify the risks 
and uncover potential blind spots as a product 
is envisioned, built, tested and deployed.
Human-centred design is the act of starting first 
with the person for whom a product is being built. 
In that way, it is possible to prioritize the needs, 
desires and scenarios of use over the capabilities 
of the technology. Building products for children 
entails going a step further and taking a child-
centred design approach.5 In doing so, you will 
take more responsibility for the psycho-social 
development stage of your customers, the risks 
they may encounter with your technology, and your 
role in limiting harm. Doing so can help you ask the right questions about not only the desirability of 
your product, but also the fitness and safety of it.
These guidelines are not just for product teams 
building with children and youth in mind. They 
are relevant to products that children and youth 
might use. Social, media, gaming and even 
productivity platforms are all highly likely to be 
used by children and youth, independent of the 
expressed or implied target age.6 Because of 
this, the hope is that these guidelines are applied 
across more than just the narrowly defined 
market of smart toys for children and youth.
As a member of a product team developing 
technology for customers, you are beholden to their 
greatest potential and their riskiest vulnerabilities.  
In these guidelines, five AI characteristics are 
explored that developers, engineers, designers,  
UX professionals and programme managers  
should apply to their work. When designing AI, 
children and youth must be put FIRST – where 
AI-powered technology is built fairly, inclusively, 
responsibly, safely and transparently. Each of  
the five characteristics includes these elements –  
goals, the potential for harm and risk mitigation 
guidance – in a checklist (Figure 4), as well as 
further links/resources.
Applying these principles will not be easy, nor is it 
intended to be. Easy is not the way of great product 
work, so you are invited to dig in, reflect, perhaps 
get uncomfortable, and come out the other side 
with technology that respects and celebrates the 
most precious, cherished and vulnerable users: 
children and youth.
 The best place 
to start is with a 
simple question: 
“Does the system 
I’m building have 
the best interests of 
children in mind?”
Artificial Intelligence for Children 11Checklist – Putting children and youth FIRST
Goals Greatest potential  
for harmMitigate risksFIGURE 4
Fairness for the user and 
their dignity are paramount 
Bias in training, expression and 
feedback in the AI is assumed 
and actively addressed
Effort is spent  
understanding liability
Threat analysis includes  
how the AI could be 
weaponized for harmBreaches of trust  
and consent
Emotional and 
developmental harm
Bias, unequal access 
and impactEmploy proactive strategies for responsible governance
Use ongoing ethical thinking and imagination
Employ ethical governance for fairness 
Test and train with data to understand the behaviour of the model 
and its areas of bias
Accessibility is built-in; it is 
not an afterthought
“Inclusive” accounts for and 
celebrates neurodiversity
Technology development cycle 
and testing includes feedback 
from children and youthExclusion by design
Bias in, bias out,  
bias internalizedBuild research plans, advisory councils and participant pools that 
represent high variability in the target audience
Actively seek user experience failures that create experiences  
of exclusion
Test and train with data to understand the behaviour of the model 
and its areas of bias
The technology is age-
appropriate and has a 
cognitive-development-
stage-appropriate design
The technology reflects the 
latest learning science
The technology is created 
with children and youth at 
the centre of the design and 
development processTechnology gone 
rogue
Unsophisticated, 
inflexible AI models
Built for small,  
silly adultsBuild advisory councils and research participant pools that 
represent high variability in the target audience
Actively seek user experience failures that create negative experiences
Overcommunicate privacy and security implications
Build conviction around the behaviour of the AI and how it might 
adjust to a user’s development stageResponsible
The technology does no harm 
to customers and cannot be 
used to harm others
Cybersecurity, including  
the privacy and security  
of customer data, is a  
high priority
The potential for over-use is 
acknowledged and addiction 
mitigation is actively built inUn/intended 
malicious, oblique  
or naive usage
An unsafe community 
A callous observer
Demographics 
allowed to define  
the user
Data privacy and 
security breachesConduct user research to inform scenario planning for nefarious 
use cases and mitigation strategies
Build a multivariate measurement strategy
Build a transparent, explainable and user data-driven relationship 
model between the child, guardian and technology to identify and 
mitigate harm
Have the product team develop subject-matter expertise in 
technology concerns related to children and youth
Build a security plan that takes children’s and youth’s cognitive, 
emotional and physical safety into accountSafe
Everyone on the team can 
explain how the AI works and 
what the AI is being used for 
to a novice or lay audience
Anyone who wants to 
understand the AI is  
easily able to do soLack or obfuscation of 
informed consent
Skirted or ignored 
governmental rules 
and regulations 
The burden of 
security and privacy 
is left to the user
Excluded guardiansConfirm the terms of use are clear, easy to read and accessible to a 
non-technical, literate user
Clearly disclose the use of high-risk technologies, such as facial 
recognition and emotion recognition, and how this data is managed
Explicitly mention the geographic regions whose data protection 
and privacy laws are honoured by the technology
Use more secure options as default and allow guardians to opt in to 
advanced features after reading their specific terms of use
Clearly specify the age group for which the application is built
Provide guidelines for the environment in which the technology is 
meant to be used
Create alert mechanisms for guardians to intervene in case a risk is 
identified during usageTransparent
Source: World Economic Forum
Fair
Inclusive
Artificial Intelligence for Children
12The challenge
People active in technology – ethicists, user 
researchers, software developers, programme and 
product managers, and designers – wrote these 
guidelines with people like themselves in mind: 
developers, programme managers, technical writers, 
product owners, software architects, UX designers, 
marketing managers, and anyone else with a hand in 
product development. The objective is to guide you 
through some of the risks associated with building 
AI for children and youth. Admittedly, little time 
was spent addressing the value of AI and machine 
learning (ML), and the goodness that technology 
can bring to the lives of children and youth. The 
purpose of these guidelines is not to discourage the use of AI in product design; instead, it is to help 
bring balance to the propensity to see only the 
positive potential outcomes of the products built. 
The challenge is to consider the other side of 
the AI-infused products you are building. These 
guidelines can be used to interrogate the work 
being undertaken. They will help uncover and 
mitigate the deficiencies and possible risks 
introduced in a design before customers find 
them. The hope is that by helping to do this, 
product teams can be confident in, proud of 
and celebrated for the responsible AI they 
bring into the lives of children and youth. 
Definition of children and youth
There is no single definition of children and youth. 
They are people whose bodies and brains are still 
developing. Most cannot yet drive a car or hold 
a job. The UN defines children as people under 
18 years of age. It is even possible to consider 
children and youth to be up to 26, since the 
prefrontal cortex only completes its development 
up to that age.7 Children have shorter attention 
spans and limited vocabulary (in some cases). 
Age can be measured by years on this planet or 
abilities on tests of cognitive skills, physical dexterity 
or emotional intelligence. Age, like most human 
concepts, is not an absolute. Due to the variability 
of human capability relative to age, it is important 
to think beyond age groups and leverage instead 
the more reliable concepts of cognitive, emotional 
and physical stages8 as a way to understand, 
target, communicate and market a product. Spending much time with children and youth reveals 
how self-centred they can be. This is a result of 
brain development, and varies as a function of 
developmental stage.9 This self-centredness is 
excellent for self-preservation but can morph into 
something unpleasant when children and youth 
encounter negative experiences. As they are 
quick to take credit for the sky being blue, a child 
might also take credit for their parents’ divorce. 
Their self-centredness means everything is their 
fault – the good things and the bad – and their 
vulnerability, especially viewed through this lens, 
cannot be overstated. Child and youth customers 
will likely internalize the good and bad parts of 
technology. A product team’s job is to work through 
what this means and mitigate it accordingly.
Artificial Intelligence for Children
13Social networks
Depending on your AI or product goals, you may 
be connecting to or building a social network inside 
your product. These guidelines do not deeply 
explore the risks of social networks for children and 
youth. If a product includes a social component, 
however, the following are recommended:
 –Focus on safety: guard against nefarious actors 
who will exploit your system to gain access 
to children and youth for their own gains (e.g. 
computer viruses, child exploitation, bullying)
 –Focus on fairness: design creative alternatives 
to embedding implicit social hierarchies into 
your experiences (e.g. custom avatar clothes 
that cost real-world money; accumulation of 
likes and followers) The following information will help initiate thinking 
about the risks of social networks with children  
and youth:
 –Raising Children Network (Australia),  
“Social media benefits and risks: children  
and teenagers”, 22 December 2020
 –Kaspersky, Kids Safety, “The dangers of  
social networks”, 26 February 2016
 –Texas A&M University, Division of Information 
Technology, “7 Tips for Safe Social Networking” It is important 
to think beyond 
age groups and 
leverage instead 
the more reliable 
concepts of 
the cognitive, 
emotional and 
physical stages.
Overarching limitations
When it comes to researching and working with 
children and youth, the experience of engineers 
is probably limited. It is strongly recommended 
to formally consult with experts in the fields of 
child development, developmental science, 
psychology and learning sciences, among 
others, to evaluate AI that will be used by 
children and youth. Experts will be needed who 
can objectively ask questions about the value, 
safety and utility of your product, and who:
 –Interrogate your AI/ML and help you understand 
not only the biases within it, but also ways to 
mitigate it –Develop user research plans10 that take 
a multivariate approach to your product 
questions: qualitative and quantitative methods; 
longitudinal research and traditional usability 
work; contextual inquiry and interviews; and 
benchmarking and scorecarding
Additionally, among the resources listed, technology 
design researchers whose work focuses on 
technology for children are cited (in particular,  
Jason Yip, Julie Kientz and Alexis Hiniker). Their 
work captures much more depth and nuance  
about the risks of AI affecting children than is 
possible to include in these guidelines.
Artificial Intelligence for Children 14Whenever data is collected, systems are engineered or products are sold, ethical obligations arise to 
be fair and honest, and to do good work and avoid harm. These obligations are all the more pressing 
when working with children and youth, who are among the most vulnerable members of society. 
Adults have a special responsibility to help them flourish and to shield them from harm. Technologies 
and systems powered by AI and ML could transform how people interact with each other. But they 
also bring potential bias, exclusion and lack of fairness to their users. With this potential for change 
and shift in power also comes requisite moral duties. As a result, designers, developers, maintainers, 
archivists11 and researchers of AI-driven tools for children and youth are urged to be mindful of the 
sensitivity and ethical ramifications of their work as they design fair AI systems. 
Greatest potential for harmPutting children and youth FIRST
The news is full of examples of biased and 
discriminatory AI models. Without careful design, 
AI models can be biased and unfair, violate 
trust and consent, and cause emotional and 
developmental harm to child and youth users. 
Breaches of trust and consent
While product teams should always endeavour 
to be worthy of their users’ trust, safeguarding 
the health and safety of children requires them 
to be even more vigilant. Consent from parents/
guardians and their children should be solicited 
before collecting data from them, and parents/
guardians and children must be informed about 
what data is collected and how it is being used, 
have control over how their data circulates (as with 
standards such as the General Data Protection 
Regulation’s [GDPR] “right to be forgotten”12) 
and secure access to the data once collected.Emotional and developmental harm
Adults have a responsibility to confirm that the 
material shown to children is directed towards  
their well-being and flourishing. Children are  
rapidly developing their autonomy, agency,  
habits and relationships with technology and  
each other, and the way systems are designed  
can negatively affect this development without  
care and oversight.13
Bias, unequal access and impact
Algorithmic decision-making can all too often 
reinforce existing societal biases and prejudices, 
and cause unequal impacts across different 
populations. A single aggregate performance 
metric, such as accuracy, may fail to capture 
and recognize the people being punished, 
left out or mistreated by your system.
Risk mitigation 
Employ proactive strategies for responsible 
governance
Just as pilots and surgeons have a preflight checklist, 
a simple set of factors to dwell on before starting 
a project can produce significant benefits and help 
reduce risk. This approach is favoured by Loukides, 
Mason and Patil in Ethics and Data Science,14 
and their checklist can be instantiated in software 
repositories via templating libraries such as deon.15
Some question-based checklists, such as the 
Berkley-Haas ethics questions (drawn from the 
work of Simon Longstaff16), draw on many existing 
ethical frameworks: –Would I be happy for this decision to be on  
the public record?
 –What would happen if everybody did this?
 –How would I like it if someone did this to me?
 –Will the proposed course of action bring  
about a good result?
 –What will the proposed course of action do to my 
character or the character of my organization?
 –Is the proposed course of action consistent with 
my espoused values and principles?Inclusive
Responsible
Safe
Transparent
Artificial Intelligence for Children
15 Ethical 
governance is 
the practice of 
understanding, 
evaluating, 
questioning 
and updating 
technology based 
on the stated 
ethical goals of 
the product.Last, connected with ethical checklists are vision 
documents, manifestos or sets of principles that 
lay out virtues to strive for when building AI-related 
systems. Helpful examples include:
 –Lupi, Giorgia, “Data Humanism, The Revolution 
will be Visualized” 
 –D’Ignazio, Catherine, and Lauren Klein, 
Data Feminism, MIT Press, 2020
 –Data Capitalism, “Data for Black Lives”
These checklists are just the start of incorporating 
ethics into your design; they are not complete 
descriptions of a project’s ethical implications or 
sufficient proof that a project was designed ethically. 
Checklists are conversation starters rather than 
conversation enders. Designers should also be 
cognizant of the specific contexts of their work: 
checklists for one type of design may not extend 
to others (e.g. a preflight checklist for a pilot and a 
pre-op checklist for a surgeon look very different). It is 
your obligation as the creator of a product to research 
and leverage the relevant work done by others to 
confirm the ethical treatment of your customers.17
Use ongoing ethical thinking and imagination
You should build ongoing ethical evaluation into 
your development cycle,18 making sure to include 
stakeholders from outside your team. Ideally, external 
stakeholders should be included who will be affected 
by your technology. Some strategies for carrying out 
these ongoing reflections can be found in Data for 
Children Collaborative’s Ethical Assessment Tool.19 
Employ ethical governance for fairness 
Ethical product design20 is not a one-and-done 
procedure: just as managers might regularly check 
in with their employees to see how their work is 
progressing, or to assess the overall health of a 
project, you need to regularly consider the ethical 
“health” of your project. Ethical governance is the 
practice of understanding, evaluating, questioning and updating your technology based on the stated 
ethical goals of the product.21 Periodic internal 
assessment is crucial as the scope and execution 
of the work changes over time. And as people are 
often limited by their own individual perspectives 
on how work is going, your review should require 
periodic external assessment. Governance councils, 
ethics review boards and public feedback can 
identify concerns that you would have missed and 
provide external metrics and criteria to avoid bad 
outcomes during product development. 
All AI is biased, and with bias comes ethical concerns. 
You will identify potential harm in this kind of exercise, 
and this is not an indication of failure! Instead, it is a 
problem to understand and manage. The potential 
harms should be explored and documented early 
and revisited throughout the design process and 
during the product’s life cycle. As with other ethical 
considerations, stakeholders from various disciplines 
– and particularly experts in child development in this 
case – should participate in these processes. At each 
stage, your governance practice should include a 
mitigation plan for potential harms. 
The potential for harm does not end when the product 
development cycle ends. Besides confirming that you 
adhere to all applicable laws and regulations related 
to your product, ethical governance requires that you 
have considered potential harms that may result from 
discontinued product support or availability. 
Test and train with data to understand the 
behaviour of the model and its areas of bias
Questions to consider are:
 –How has the product defined and measured  
the biases in the AI? 
 –How have these biases been remediated? 
 –What gaps or benefits were uncovered  
from the synthesis of research you conducted  
on your AI?
Artificial Intelligence for Children 16Inclusion is an essential ingredient in people’s sense of emotional, psychological and physical 
safety. Humans are social animals who struggle to make progress on most developmental scales 
without a sense of community. All people crave a sense of belonging and are naturally attuned to 
feelings of exclusion, inclusion and the resulting uncertainty.22 Children and youth often lack the 
coping skills necessary to manage negative feelings of exclusion (real or perceived). By not focusing 
on building an inclusive experience, you may cause cognitive, emotional or social distress and 
harm.23 Feelings of exclusion can harm a child’s confidence, feelings of self-worth and development.
Technology teams may be inclined to equate inclusion with accessibility. The Smart Toy Awards,24 
developed in collaboration with the World Economic Forum, defines accessibility as an AI-
powered toy that’s accessible for children with physical, mental and learning disabilities, including 
neurodiversity, and children speaking languages other than English and from other cultures. This 
type of inclusivity is as important as the emotional inclusivity already noted.
Any AI model internalizes the bias in its programmers 
and data. This can cause unintentional exclusion by 
design and in practice, which is particularly harmful 
and problematic for children and youth, who are 
vulnerable and require even greater care.
Exclusion by design
Technology has many forms of exclusion.25 The 
words used in the interface, the complexity or 
learning curve of features, and the lack of accessibility 
features are just a few ways in which products actively 
exclude people who would otherwise be customers. 
Unlike children, adults are able to reason about states 
of their own or others’ exclusion (this wasn’t built 
with me in mind; accessibility is expensive; we’re too 
early in our product cycle to localize these strings). 
This reasoning reduces the psychological, emotional 
and physical harm adults feel when excluded. 
Children and youth, however, may not always have 
this perspective. The exclusion they experience may 
be unchecked and could result in negative feelings 
about themselves and their abilities.
Bias in, bias out, bias internalized
All AI is biased.26 Data collection and sampling 
methods result in models and training data that 
reflect the inevitable flaws of a human-created 
system. Bias in AI can cause harm when it assumes 
attitudes, abilities, capabilities and beliefs that 
are different from the user’s. When technology 
concludes something about the user, it runs the risk of insulting, confusing, embarrassing, excluding 
or demeaning the person. Something as obvious 
as giving female-identifying users flower patterns 
(not bulldozers) for their avatars’ clothes is a risk 
to a child’s sense of personal identity and enforces 
potentially harmful societal norms and standards. 
Even worse, a child born with a cleft lip might be 
excluded from a camera filter because bias in the 
training data only further isolates them from the 
experience of their peers.27 The result of these 
biases manifesting in the experience can cause user 
confusion, negative self-talk or self-esteem, and 
reinforcement of bullying experiences.
The concept of bias in AI has been well documented; 
several resources can help to address the limitations 
in your own work:
 –McKenna, Michael, “Machines and Trust: How 
to Mitigate AI Bias”, Toptal Developers
 –Manyika, James, Jake Silberg and Brittany 
Presten, “What Do We Do About the  
Biases in AI?”, Harvard Business Review,  
25 October 2019
 –PwC, “Understanding algorithmic bias and how 
to build trust in AI”, 18 January 2021
 –Yenireddy, Deepti, “Breaking Gender bias In 
Artificial Intelligence”, LinkedIn, 12 April 2017 Feelings of 
exclusion can 
harm a child’s 
confidence, 
feelings of 
self-worth and 
development.Fair
Responsible
Safe
Transparent
Greatest potential for harm
Artificial Intelligence for Children
17Risk mitigation 
Build research plans, advisory councils and 
participant pools that represent high variability 
in the target audience
Your product roadmap should include robust 
feedback loops from users, parents/guardians 
and education professionals at each stage of the 
development. It is critical that this feedback is 
collected early (ideally before any code is written) 
and that the feedback continues after the product 
has shipped. You should plan to collect explicit 
(verbal, behavioural and sentiment) feedback at 
each development stage from your target customers 
(children, youth and parents/guardians), as well as 
feedback on stage and age appropriateness from 
experts at the same cadence and with the same level 
of rigour as your user testing. Finally, at all stages of 
development and research/testing, the team must be 
able to answer why AI is included in the product. For 
every risk identified, how are you able to justify the 
risks the AI introduces relative to the rewards?
Actively seek user experience failures that 
create experiences of exclusion 
You need to include children and youth in each step of the development cycle, and to continually 
document how the product has enabled a variety 
of children and youth to successfully participate. 
You may decide to exclude a user type. These 
exclusions should be documented, shared and 
discussed internally to build consensus, and 
reflected in your marketing. During product  
testing, design free-form and directed-usage 
user research studies which target areas already 
identified that could exclude children and youth 
from using the product as intended or desired.  
You should purposely push the bounds of your 
product before your customers do it for you.
Test and train with data to understand the 
model’s behaviour and its areas of bias
Acknowledge that your AI is biased. Seek to 
understand its limitations and document how  
these biases could harm children and youth.  
How are you able to mitigate the bias? Could  
said mitigation inevitably introduce a new bias? 
What gaps or benefits were uncovered from a 
deeper understanding of your AI? Should these  
be disclosed to your customers?
Artificial Intelligence for Children
18Greatest potential for harm
Introducing intelligence into an otherwise static 
system introduces human-like characteristics, which 
is part of what makes AI so attractive to consumers. 
This is also what makes it dangerous. The brains of 
children and youth seek signals of love, belonging 
and inclusion,28 and these signals are significantly 
more salient than what adults experience.29 
Therefore, children and youth will not read signals in 
the same way as adults.30 Because of this, product 
teams must understand that children and youth are 
not their customer and that they could be building 
something which may introduce harm. As a result, 
they should carefully analyse the risks, seek greater 
understanding and develop mitigation techniques.
Technology gone rogue
When it comes to some of society’s most vulnerable 
citizens, skirting or ignoring established regulations 
related to their treatment is unethical. Children and 
youth are not deemed capable of understanding the 
implications of data sharing, personal identifiable 
information leaks or the risks associated with 
granting access to their data.31 Lack of compliance 
with local, state, regional and country regulations 
can be catastrophic for technology developers.
Unsophisticated, inflexible AI models
Human physical, emotional and cognitive 
development are not in sync, nor are they consistent in their speed or trajectory.32 For example, an 
11-year-old can have the body of an 18-year-old, 
the emotional intelligence of a 7-year-old, and 
the cognitive abilities of a 13-year-old. When that 
same 11-year-old turns 12, they could have the 
body of a 19-year-old, the emotional intelligence 
of a 10-year-old and the cognitive abilities of a 
10-year-old due to a concussion they sustained. 
The unpredictability, speed and fluidity of human 
development necessitates sophisticated AI for 
children and youth that can reasonably flex across 
stages of development. This is achievable with the 
guidance from authorities and subject-matter experts 
in child development, psychology, AI and ethics.
Built for small, silly adults
Children and youth are not just physically smaller 
versions of adults who have limited vocabulary and 
less intelligence than the product team. Similar to 
the failures of the “pink it and shrink it”33 approach 
to feminizing products made with only men in 
mind, not treating children as a legitimate, holistic 
and independent target audience carries risks.34 
The brains of children and youth are different from 
those of adults. This means that they are both less 
and more capable than an adult on a myriad of 
cognitive, social and physical factors. Ideally, you 
are able to leverage their abilities to deliver a great 
user experience.
 The 
unpredictability, 
speed and 
fluidity of human 
development 
necessitates 
sophisticated AI for 
children and youth 
that can reasonably 
flex across stages 
of development.The goal of this theme is to confirm that product teams have internalized their responsibilities 
towards the children and youth who use their products. This starts with product teams considering 
(and mitigating) the possibility that they may not have the skills or expertise to adequately evaluate 
the risks of introducing their AI-enabled product to children and youth. Next, product ideation, 
design, planning, development and testing should be grounded in age and development-stage 
appropriateness, with methods to test for appropriateness that reflects the latest learning science. 
Layered on this traditional product cycle should be considerations for the emotional, psychological 
and physical safety of the children and youth being targeting. Responsible AI design is an act 
of collaboration between the product team and their customers and their guardians, as well as 
experts in learning science, ethics, developmental psychology and other relevant research fields. InclusiveFair
Safe
Transparent
Artificial Intelligence for Children 19Risk mitigation 
Build advisory councils and research  
participant pools that represent high  
variability in the target audience
Questions to consider:
 –With the product’s business model in mind, 
how were the development stage and age 
appropriateness confirmed? 
 –Why was AI included in the product? How do 
you justify the risks the AI introduces relative to 
the rewards?
 –When and how often (and not “if”) have the 
research and testing of the product included 
kids, parents/guardians, teachers and subject-
matter experts to confirm the developmental 
stage and age appropriateness?
 –How does the product confirm a feedback loop 
for the user, parents/guardians and education 
professionals into future iterations, features and 
product roadmap?
Actively seek user-experience failures that 
create negative experiences
Recommendations to consider:
 –Include children and youth in each step of the 
development cycle 
 –Continually document how the product has 
ensured that all children and youth can participate
 –Allow for free-form product testing as well as 
directed usage; focus on areas the team has 
already identified as risky, which could exclude 
children and youth from using the product as 
intended/desiredOvercommunicate privacy and security 
implications
Questions to consider:
 –How does the management of data comply 
with governing data laws and policies related to 
consumers, specifically children (i.e. GDPR,35 
Children’s Online Privacy Protection Act 
[COPPA],36 Age Appropriate Design Code,37 
among others)?
 –How are users informed and notified of any 
commercial activities related to the product  
or third parties?
 –How does the product and the use of AI enable 
the user to interact safely with others?
Build conviction around the behaviour of 
your AI and how it might adjust to a user’s 
development stage
Questions to consider:
 –Can you articulate how your product addresses 
the variability you expect to see in your user’s 
development stage, and how your AI may (or 
may not) accommodate for that variability?
 –Will your AI adjust its behaviour based on 
implicit signals of the developmental stage  
(e.g. physical dexterity, logic/problem solving 
ability, language ability)?
 –Are users able to correct the AI if incorrect 
conclusions are made about the users’ 
developmental stage?
Artificial Intelligence for Children
20Psychosocial development is typically predicated on feelings of safety and security.38 Children 
and youth whose environments are chaotic, dangerous and unpredictable struggle to meet 
developmental milestones, including learning milestones, emotional regulation and bonding. This 
makes sense – the brain of a child at risk will allocate its precious resources to keeping itself alive 
above acquiring the next developmental milestone. This is a steep price for children and youth to 
pay, however, no matter the severity of their experience.
Children can easily find themselves in harm’s way. Their underdeveloped prefrontal cortex means 
they are less able to predict consequences and are more impulsive, lack self-control and lack the 
experience to know when they are being manipulated.39 They will seek instant gratification and may 
not have interest in limiting things like screen time, purchases and interaction with online strangers. 
For these reasons, the product team must consider themselves an ally for the children’s and youth’s 
guardians, jointly taking responsibility for protecting all users of the technology from harm.
Greatest potential for harm
Sadly, many people, organizations and technology 
actors go to great lengths to harm children and 
youth or exploit their vulnerabilities for their own 
personal gain. A product team’s job is to consult 
with experts and think through how they may 
be unintentionally helping malicious actors harm 
children and youth with their technology, and then 
build ways to prevent or mitigate that harm. 
The greatest potential for harming children and 
youth with technology can include:
Un/intended malicious, oblique or naive usage
Technology can unintentionally support negative 
behaviours and outcomes in several ways.40 These 
are often unintended oversights by product teams, 
but they are nevertheless your responsibility.  
Certain categories of use particularly concern 
children and youth:
 –Malicious intent: The individual has the express 
intent of causing harm or using the product in a 
way that is dangerous to themselves or others.
 –Naivety/ignorance: This happens when a user 
ignores safety warnings or intentionally takes 
risks without recognizing consequences. This 
is particularly concerning among children and 
youth without fully developed frontal lobes or 
those with alternative learning styles. See the 
“Transparent” section for more advice on how  
to mitigate these issues.
 –Oblique use: People do not always use your 
creations the way you intended them to. It does 
not make it wrong, but it can demonstrate the 
creator’s lack of imagination to use an opportunity 
to mitigate risk and make a safer product. An unsafe community
Product teams can be naive about how their 
technology will be used in social situations. Only in 
recent years has the potential threat, toxicity and risk 
of social technology been illustrated. Some people 
who are able to hide behind technology will do and 
say unsavoury things.41 People with ill intent will  
exploit your technology to access those vulnerable 
in your communities. Social currency, such as 
followers and likes, will be used as indicators of 
personal self-worth (or the lack thereof). Adults 
struggle with the real-world consequences of this 
reality, both in controlling their behaviour in an online 
environment and in managing the emotional fallout 
from upsetting online encounters. These struggles 
will only be amplified for children and youth.
A callous observer
If your technology facilitates conversations 
between the child or youth and the machine, you 
must anticipate cases where the user divulges 
information related to potential harm or risky 
situations (e.g. self-harm or abuse committed by 
an adult). You don’t want your product to ignore, 
diminish, joke, emphasize or overreact to this 
input. Instead, you must decide during product 
development what this relationship will be, who is 
involved (e.g. teacher, parent/guardian, therapist, 
emergency services) and clearly articulate to all 
actors the course of escalation and resolution if a 
harmful scenario is detected.
Another way the technology can ignore the needs 
of vulnerable users is by failing to address overuse 
or addiction mitigation.42 If a child or youth is 
obsessively using your product, will you know?  
Do you know what harm obsessive use or overuse 
could introduce to your user? Eye strain, repetitive  The product 
team must consider 
themselves 
an ally for the 
children’s and 
youth’s guardians, 
jointly taking 
responsibility for 
protecting all users 
of the technology 
from harm.InclusiveFair
Responsible
Transparent
Artificial Intelligence for Children
21strain injury, emotional instability, sleep disruption, 
vertigo and diminished capacity to distinguish 
between fantasy and reality are among the 
unintended consequences of overusing technology. 
Demographics allowed to define the user
People are more than demographics, and while 
they know this intellectually, they can fall victim to 
assuming too much about others when demographic 
data is available. People tend to forget that behaviour 
is one of the most robust data sources for predicting 
what they will do with technology. Because of this 
risk, product teams should invest in a variety of 
data from which to triangulate their predictions. 
Demographic data should be supplemented and tempered by behavioural inputs and explicit 
indicators of preference. 
Data privacy and security breaches
Your first line of defence in keeping your customers 
safe is the privacy and security features that you 
have built into your technology. The need for robust 
feature development around the protection of your 
customers’ data cannot be overemphasized. This 
includes but is not limited to security and privacy 
of in-app data. Any methods by which others can 
access and resell data, or exploit, embarrass, bully, 
financially/emotionally/physically harm or otherwise 
hurt your customers, should be modelled, mitigated 
and revisited over the product's life cycle.
Risk mitigation 
Conduct user research to inform scenario 
planning for nefarious use cases and  
mitigation strategies
 –Malicious intent: Can you detect malicious 
use cases? Who should be informed 
when these are detected? What is the 
child's or youth’s role in notification versus 
the guardian? Is the technology able to 
suspend itself when this happens? What 
negative consequences will occur if auto-
detection of malicious use is wrong? 
 –Naivety/ignorance: Can you detect these use 
cases and redirect or accommodate the user 
with a different interaction path? Have you built 
conviction into your model’s interpretability? 
What are the potential cases where physical or 
emotional harm of the child or youth could occur 
if your technology is used naively? Do these 
risks need to be addressed with the guardian 
and/or the child or youth during set-up? –Oblique use: There is no substitute for user 
research to detect oblique use cases, which 
should ideally be ethnographic and real-world 
usage. Early in the development cycle and 
continuing through release, the team and 
external stakeholders should brainstorm all the 
potential ways your creation may be used and 
the resulting unintended consequences. This 
data should be supplemented by actual child 
or youth users who are given the opportunity to 
use your technology however they desire.
Build a multivariate measurement strategy
No single metric can measure the fairness, 
inclusivity, responsibility, safety and transparency 
of your product. Accordingly, you need multiple 
indicators of your product’s health, both quantitative 
(what happened) and qualitative (why it happened). 
Scepticism towards traditional product metrics  
of adoption and usage should also be employed,  
as these traditional metrics (net promoter  
Artificial Intelligence for Children
22score and daily active user) are based on adult 
users and lack considerations for children and 
youth. Some recommendations for how to  
build this measurement strategy and whom  
to consult include:
 –Conduct user studies, ethnography, community 
juries,43 and Consequence Scanning 
workshops,44 such as Judgment Call,45  
with a professional user researcher.
 –Schedule design workshops to identify and 
address risks, and encourage engineering teams 
to own these strategies and solutions (e.g. use 
Microsoft’s Harms Modeling Framework46). 
 –Confirm that metrics and optimization used  
for interactions are not inadvertently “addictive”. 
For example, ask these questions: What 
happens if this metric hits 100%? What are  
the intended and unintended consequences if 
these metrics hit 100%? If 100% is too much, 
what is the right amount? Who should answer 
that question?
Build a transparent, explainable and user  
data-driven relationship model between the 
child, guardian and technology to identify  
and mitigate harm
As mentioned, when building for children and 
youth, you are also building for parents, teachers 
and guardians. You should design the guardian’s 
experience with your technology with the same level 
of careful consideration as you do the child's and 
youth’s experience. Key questions to consider for 
verifying that all customers have been taken into 
account are:
 –When the tool learns about a potential harm (e.g. 
child self-harm, hurting others, or being hurt by a 
guardian, adult, or other child or youth), what does 
the tool do? 
 –In the case of security or privacy breaches, 
such as hacking or viruses, how are guardians 
informed? What action is taken on behalf of the 
guardian, child or youth?
 –In reporting risks, what risks does the tool 
report, to whom, and at what cadence? 
 –What data is logged for regulation auditing 
purposes? (Refer to COPPA to understand  
the requirements47) –How can parents or guardians control or not 
control the technology their child uses? Are 
controls asynchronous or available in real time?
 –Is a mechanism in place to automatically shut 
the tool down if a risk is identified?
Have the product team develop subject-matter 
expertise in technology concerns related to 
children and youth
All members of the development team should 
be engaged in building some personal expertise 
in child and youth development. This, however, 
should not replace the need to engage with 
experts in the fields of child psychology, 
development, technology, and design for children 
and youth. Some proactive ways to increase 
sensitivity and the ability to identify risk include 
these actions:
 –Review the work of design experts in the field48
 –Understand what can go wrong even when 
well-intentioned design is delivered to children 
and youth: The cautionary tale of the “My 
Friend Cayla” smart toy49
 –Develop success metrics that are “paired”50  
for balance among user, business and 
technology needs
Build a security plan that takes the children's 
and youth’s cognitive, emotional and physical 
safety into account
What is your plan if a hacker gets access to the 
system and then to your customers, their data  
and personal information? 
 –How is the data encrypted? Is it encrypted  
 in transit or at rest? 
 –What sort of personal data is necessary to 
collect? Can it be anonymized to further 
protect privacy? 
 –Confirm that any personal/sensitive data 
is highly protected in case of hacking, etc. 
Protected data categories for children are  
wider-ranging than for adults.51 When building 
for children and 
youth, you are 
also building for 
parents, teachers 
and guardians.
Artificial Intelligence for Children
23Transparency in AI can take many forms. First, there are the clear disclaimers all products must 
deliver to customers based on local and state regulations. Product teams are encouraged to include 
the proposed AI labelling system, which is part of this toolkit, in each product – both on the physical 
packaging and accessible online through a QR code. Products with AI for children and youth should 
include the following six categories and explanations to create transparency among the product, the 
buyer (parent/guardian or other adult) and end user (children or youth):
 Transparency 
around security, 
privacy and 
permissions 
helps reduce or 
prevent unintended 
consequences 
that arise from 
naive usage.Age: What age or developmental stage would this 
product be recommended for? What material could 
the AI potentially expose to the user and how is this 
material determined to be age- and developmental-
stage-appropriate?
Accessibility: How is this product accessible for 
children and youth of different ages and with diverse 
disabilities and educational backgrounds? Has the 
AI been trained and tested with inclusion in mind?
Camera and microphone: Does this product use 
either and can they be turned on and off? Is the 
device always observing the user or other people 
using the product?
Networks: Does this product allow the user to 
socialize with other users through networked  
play or a social network? How does the product 
create a safe and healthy social experience?  
What community rules and regulations are in  
place to confirm that a child will not be put in  
a dangerous situation?
AI use: How does this product use AI? How does 
the product’s use of AI benefit the user and their experience? How does this product’s use of AI 
pose potential risks to the user?
Data use: How is the user’s data being used? Who 
holds this information and whom is it shared with? 
Where is the user’s data stored and how protected 
is it? How does this product communicate the use 
of user data?
Product developers should also consider how 
they build their AI to encourage its responsible 
use. Transparency around security, privacy and 
permissions helps reduce or prevent unintended 
consequences that arise from naive usage. 
Designing with the goal of transparency should 
also manifest in the experience you build, helping 
establish the trust and comfort you likely want your 
audiences to feel towards your AI.
Finally, transparency is achieved throughout the 
lifetime of the product. Day 1, when the customer 
first unboxes and uses the technology, is fertile 
ground to establish honest disclosure with your 
user. Day 100, when the technology takes a major 
update with enhanced functionality, should not be 
ignored as another opportunity for transparency. InclusiveFair
Responsible
Safe
Artificial Intelligence for Children
24Greatest potential for harm
AI models can be inherently opaque and difficult 
to understand, including by children and youth as 
well as their parents and guardians. You do not 
want to design a “black box” that is impossible to 
understand or explain. Without proper transparency, 
AI can ignore laws, obfuscate consent, and exclude 
parents and guardians from the process. AI that lacks 
transparency can also put an undue burden of privacy 
and security on the user. Remember that transparency 
breeds trust, which leads to greater engagement and 
enjoyment with, and success of, the product. 
The greatest potential for harm of AI that is not 
transparent includes:
Lack or obfuscation of informed consent
AI technology is usually built as a feedback loop 
– the back-and-forth flow of information from the 
user to the technology and back again. Because 
the technology intends to learn from its user, 
there is a social (and legal) contract implicit in this 
conversation. Accordingly, developers of AI must 
acquire informed consent, where the user (or 
parent/legal guardian) has the capacity to knowingly 
and willingly agree to the terms of this contract and 
can accept or reject it with no penalty, at any time. 
A common practice in technology is to include 
this informed consent in the end-user license 
agreement. For adults, this practice works as a way 
to gather informed consent but, for children, it can 
be seen as an attempt at obfuscation. Because 
the stakes are so high with kids and youth, it is 
recommended that informed consent be an explicit, 
even celebrated, act in your technology. It might 
also need to be an act of consent for the user and 
their parent/legal guardian. For this reason, it is 
important to think through what each customer is 
consenting to, who has the capability to consent 
and to what, and design mechanisms for each to 
actively provide their agreement.Skirted or ignored governmental rules  
and regulations 
The responsibility to comply with local rules and 
regulations related to your technology is on you, the 
product team and the company selling the product. 
The country, regional, state and local rules you 
follow in the development of your product should be 
clear to your consumer. 
The burden of security and privacy is left  
to the user
Ideally, you are able to build AI that still works well 
even if the security and privacy settings are enabled 
and turned up to their maximum settings. This is 
even more imperative for AI-powered technology for 
kids, where the default settings should be at their 
most restrictive and conservative for the protection 
of your customers. Further, it should be your 
responsibility to disclose both the advantages and 
risks of adjusting the security and privacy levers. At 
any stage of use, your customers should be able to 
understand the implications (good and bad, related 
to their data or the experience of the technology) of 
their decisions.
Excluded guardians
Any technology targeted at children and youth  
has two primary users: the child and their guardian.  
The relationship your technology builds with the 
guardian is as important to the safe use of AI as  
the technology itself. You should inform, integrate 
and, if possible, listen to the guardians of your user; 
you should inform them during product consideration 
so they know if your technology is right for their child 
(see above); and you should inform them during  
the set-up, where they learn the parameters of  
use and boundary cases of risk. And finally, you 
should collaborate with them in keeping tabs on 
usage, when boundaries are crossed or risky 
behaviour is detected. 
Risk mitigation 
Confirm that the terms of use are clear, easy  
to read and accessible to a non-technical, 
literate user
Avoid using complicated technical or legal jargon 
when explaining the terms and conditions of use. 
Keep the terms of use to a reasonable length. If 
either of these is unavoidable, present a simplified 
(perhaps even fun and engaging) version to the user 
that explains important points in everyday language 
accessible to a non-tech-literate guardian.52Clearly disclose the use of high-risk 
technologies (e.g. facial recognition an emotion 
recognition) and how this data is managed
 –All high-risk technologies used in the application 
must be presented to the guardian upfront. 
 –Ingestion, analysis and storage of data collected 
by the technology must be clearly explained, 
along with options for opting in/out of security 
and privacy options. Transparency 
breeds trust, which 
leads to greater 
engagement and 
enjoyment with, 
and success of, 
the product.
Artificial Intelligence for Children
25 –Identify and design scenarios of informed 
consent for Day 1 use as well as Day 100  
(when the technology may take an update  
with expanded functionality). Confirm that the 
new requests for consent (e.g. the camera 
is now included in the AI experience) are 
well designed and include guardians. 
 –The exact technologies classified as high  
risk will vary with time, and thus need to  
be revisited in both product design and 
methods of disclosure. 
 –The user must be informed and ideally given  
the option to opt out of how their data is 
collected for purposes of high-risk technology 
(i.e. whether it is used only in-app, sent to  
a third party, stored in the cloud, etc.).
Explicitly mention the geographic regions 
whose data protection and privacy laws are 
honoured by the technology
 –Specify the regions whose data protection and 
privacy laws have been considered during the 
design and development of the application. 
 –Be specific in mentioning legal sections/clauses 
rather than using vague language. 
 –Revisit these at regular intervals since these 
laws are currently being framed and updated  
by most nations.
Use more secure options as default and allow 
guardians to opt in to advanced features after 
reading their specific terms of use
 –Set the default options to the most secure and 
least intrusive to add an additional layer of safety 
for every user. 
 –Present detailed information on the technology 
used when the guardians decide to opt in for  
a feature that uses AI.
 –Work through the matrix of user experience 
based on security feature options. For instance, how will your technology (and AI) behave if 
the microphone is disabled but the camera is 
allowed? Can you explain the outcome of this 
matrix to customers?
Clearly specify the age group for which the 
application is built
Children of different age groups have different 
responses to stimuli due to their developing 
brains.53 Thus, it is essential that guardians be 
given accurate information on the developmental 
stage and/or age group for which the technology 
was built. By disclosing this level of detail you 
help guardians decide not only if but how to 
introduce a particular child to the technology.
Provide guidelines for the environment in which 
the technology is meant to be used
Product teams must confirm the guardian is 
informed of the environment of intended use (e.g. 
in school as part of a group activity or at home 
under the supervision of an adult). This not only 
helps with purchase decisions, but also increases 
the probability that the technology will be used 
properly and with the greatest chance of customer 
success and satisfaction. It is also useful to include 
further details, such as recommended hours 
of usage per week and indicators of misuse.
Create alert mechanisms for guardians to 
intervene in case a risk is identified during usage 
The product development cycle should build 
threat models that include methods of misuse 
and risky behaviour (e.g. overuse, bullying, 
inappropriate content). An outcome of this threat 
modelling should be solutions that allow for the 
detection of misuse and methods of intervention, 
for example the high number of hours used and 
friend requests from unrecognized contacts. 
Product documentation should include the potential 
threats and the features guardians and users can 
leverage to mitigate risk, such as data consumption 
monitoring, visibility into in-app messages and 
the ability to block/report suspicious users.
 The exact 
technologies 
classified as 
high risk will vary 
with time, and 
thus need to be 
revisited in both 
product design 
and methods of 
disclosure.
Artificial Intelligence for Children
26References
 –Brenner, Grant Hilary, “What Makes Internet Trolls Tick?”, Psychology Today, 5 August 2019,  
https://www.psychologytoday.com/us/blog/experimentations/201908/what-makes-internet-trolls-tick
 –Brewster, Thomas, “Child Tracker App ‘Leaks 6.8 Million Texts, 1.8 Million Photos’ From Kids’ Phones”, Forbes,  
22 February 2016, https://www.forbes.com/sites/thomasbrewster/2016/02/22/kids-texts-and-photos-leaked-by-uknow  
 –Castle, Stephen, “Boris Johnson Retreats in a U.K. Exam Debacle”, The New York Times, 15 September 2020 
update, https://www.nytimes.com/2020/08/17/world/europe/england-college-exam-johnson.html 
 –Children & Adversity Information, sponsored by Global Children’s Fund, “How they are disadvantaged: What makes 
kids more vulnerable”
 –Chordia, Ishita, Jason Yip and Alexis Hiniker, “Intentional Technology Use in Early Childhood Education”, Proceedings 
of the ACM on Human-Computer Interaction, vol. 3, issue CSCW, November 2019, Article No. 78, pp. 1-22,  
https://doi.org/10.1145/3359180 
 –Coldewey, Devin, “After breach exposing millions of parents and kids, toymaker VTech handed a $650K fine by FTC”, 
TechCrunch, 8 January 2018, https://techcrunch.com/2018/01/08/after-breach-exposing-millions-of-parents-and-kids-
toymaker-vtech-handed-a-650k-fine-by-ftc  
 –Common Sense, Technology Addiction: Concern, Controversy, and Finding Balance, 2016, https://www.
commonsensemedia.org/sites/default/files/uploads/research/csm_2016_technology_addiction_research_brief_1.pdf 
 –Data For Children Collaborative with UNICEF, “Our Ethical Assessment is Now Live!”, 23 April 2020, https://www.
dataforchildrencollaborative.com/news-from-the-unicef-data-for-children-collaborative/our-ethical-assessment-is-now-live  
 –Di Placido, Dani, “YouTube’s ‘Elsagate’ Illuminates the Unintended Horrors of the Digital Age”, Forbes, 28 November 
2017, https://www.forbes.com/sites/danidiplacido/2017/11/28/youtubes-elsagate-illuminates-the-unintended-
horrors-of-the-digital-age/?sh=711f7d986ba7   
 –Doteveryone, “Consequence Scanning – an agile practice for responsible innovators”, https://doteveryone.org.uk/
project/consequence-scanning
 –Designing for Children’s Rights Guide, https://childrensdesignguide.org
 –Federal Trade Commission, “Children’s Online Privacy Protection Rule (‘COPPA’), Children’s Online Privacy Protection 
Act of 1998, 15 U.S.C. 6501-6505, Children’s Privacy, https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-
reform-proceedings/childrens-online-privacy-protection-rule
 –Finiin, Abubakar, “The Frustrating Reality of Getting A-Level Grades Without Doing Exams”, VICE, 17 August 2020, 
https://www.vice.com/en/article/bv83ea/a-level-results-algorithm-uk 
 –Hill, Kashmir and Aaron Krolik, “How Photos of Your Kids Are Powering Surveillance Technology”, The New York 
Times, October 2019, https://www.nytimes.com/interactive/2019/10/11/technology/flickr-facial-recognition.html 
 –Hoffmann, Anna Lauren, “Data Ethics for Non-Ideal Times”, 30 September 2020,  
https://static1.squarespace.com/static/5b8ab61f697a983fd6b04c38/t/5f74b0d450b24a77b4db1996/1601482964607/
Hoffmann+-+Data+Ethics+for+Non-Ideal+Times+Lecture+Notes.pdf  
 –IDC 2017 Workshop on Equity & Inclusivity, “Outcomes”, 28 June 2017, https://idc2017equityinclusivity. 
wordpress.com/outcomes 
 –International Organization for Standardization (ISO), Popular Standards, “ISO/IEC 27001: Information Security 
Management”, https://www.iso.org/isoiec-27001-information-security.html
 –ISO Online Browsing Platform, “ISO/IEC 27002:2013(en) Information technology – Security techniques – Code of 
practice for information security controls”, https://www.iso.org/obp/ui/#iso:std:iso-iec:27002:ed-2:v1:en
 –Intersoft Consulting, “Art. 17 GDPR: Right to erasure (‘right to be forgotten’)”, https://gdpr-info.eu/art-17-gdpr
 –Kientz, Julie A., “In Praise of Small Data: When You Might Consider N-of-1 Studies”, GetMobile: Mobile Computing 
and Communications, vol. 22, issue 4, December 2018, pp. 5-8, https://doi.org/10.1145/3325867.3325869 
 –Legal and professional standards:
 –Association for Computing Machinery (ACM), Code of Ethics and Professional Conduct, adopted 22 June 2018, 
https://www.acm.org/code-of-ethics
 –Intersoft Consulting, General Data Protection Regulation (GDPR), https://gdpr-info.eu
 –Liu, Feifei, “Designing for Kids: Cognitive Considerations”, Nielsen Norman Group,  
16 December 2018, https://www.nngroup.com/articles/kids-cognition 
 –United Nations Human Rights, Office of the High Commissioner, UN Convention on the Rights of the Child, 
https://www.ohchr.org/en/professionalinterest/pages/crc.aspx
 –U.S. Department of Health & Human Services, “Children: Information on Special Protections for Children as 
Research Subjects”, 18 March 2016 update, https://www.hhs.gov/ohrp/regulations-and-policy/guidance/special-
protections-for-children/index.html  
 –Maheshwari, Sapna, “On YouTube Kids, Startling Videos Slip Past Filters”, The New York Times, 4 November 2017, 
https://www.nytimes.com/2017/11/04/business/media/youtube-kids-paw-patrol.html 
Artificial Intelligence for Children
27 –Microsoft Azure, “Community jury”, 1 November 2021, https://docs.microsoft.com/en-us/azure/architecture/guide/
responsible-innovation/community-jury 
 –Microsoft Azure, “Foundations of assessing harm”, 8 November 2021, https://docs.microsoft.com/en-us/azure/
architecture/guide/responsible-innovation/harms-modeling
 –Microsoft Azure, “Judgment Call”, 12 November 2021, https://docs.microsoft.com/en-us/azure/architecture/guide/
responsible-innovation/judgmentcall
 –Montreal AI Ethics Institute, The State of AI Ethics: January 2021, https://montrealethics.ai/wp-content/
uploads/2021/01/State-of-AI-Ethics-Report-January-2021.pdf
 –Moore, Shannon Dawn Maree, Bruno De Oliveira Jayme and Joanna Black, “Disaster Capitalism, Rampant EdTech 
Opportunism, and the Advancement of Online Learning in the Era of COVID19”, Critical Education, vol. 12, no. 2, 2021, 
https://ices.library.ubc.ca/index.php/criticaled/article/view/186587
 –Royal Society For Public Health, “Over 1 in 10 young gamers get into debt by buying loot boxes”, 23 December 2020, 
https://www.rsph.org.uk/about-us/news/over-1-in-10-young-gamers-get-into-debt-because-of-loot-boxes.html  
 –Rubegni, E., Jason Yip and P . Baxter, “Why does he know my name?”, Exploring failure in designing AI, robots and 
intelligent technologies for children, Interaction Design and Children 2020 Workshop on “Creating opportunities for 
children’s reflections on AI, Robotics and other intelligent technologies”, 2020
 –Shneiderman, Ben, “Bridging the Gap Between Ethics and Practice: Guidelines for Reliable, Safe, and Trustworthy 
Human-centered AI Systems”, ACM Transactions on Interactive Intelligent Systems, vol. 10, no. 4, 2020,  
https://dl.acm.org/doi/10.1145/3419764 
 –Specia, Megan, “Parents, Students and Teachers Give Britain a Failing Grade Over Exam Results”, The New York 
Times, 14 August 2020, https://www.nytimes.com/2020/08/14/world/europe/england-a-level-results.html 
 –Swauger, Shea, “Remote testing monitored by AI is failing the students forced to undergo it”, NBC News,  
7 November 2020, https://www.nbcnews.com/think/opinion/remote-testing-monitored-ai-failing-students-forced-
undergo-it-ncna1246769
 –Toolkits and checklists
 –AI Now Institute, “Algorithmic Accountability Policy Toolkit”, October 2018, https://ainowinstitute.org/aap-toolkit.pdf
 –AIethicist.org, “AI Frameworks, Guidelines, Toolkits”, https://www.aiethicist.org/frameworks-guidelines-toolkits
 –Appropriating Technology, “Ten Rules of Technology”, 21 June 2019, http://appropriatingtechnology.org/?q=node/296
 –Data For Children Collaborative with UNICEF, “Our Ethical Assessment is Now Live!”,  
23 April 2020, https://www.dataforchildrencollaborative.com/news-from-the-unicef-data-for-children-
collaborative/our-ethical-assessment-is-now-live 
 –Loukides, Mike, Hilary Mason and DJ Patil, Ethics and Data Science, O’Reilly Media Inc., 25 July 2018,  
https://www.amazon.com/Ethics-Data-Science-Mike-Loukides-ebook/dp/B07GTC8ZN7
 –Reisman, Dillon, et al., Algorithmic Impact Assessments: A Practical Framework for Public Agency Accountability , 
AI Now Institute, April 2018, https://ainowinstitute.org/aiareport2018.pdf
 –Vallor, Shannon, “An Ethical Toolkit for Engineering/Design Practice”, Santa Clara University, Markkula Center for 
Applied Ethics, 22 June 2018, https://www.scu.edu/ethics-in-technology-practice/ethical-toolkit
 –Vinney, Cynthia, “What Is Attachment Theory? Definition and Stages”, ThoughtCo, 24 October 2019,  
https://www.thoughtco.com/attachment-theory-4771954
 –Wang, Amy, “’I’m in your baby’s room’: A hacker took over a baby monitor and broadcast threats, parents say”,  
The Washington Post, 20 December 2018, https://www.washingtonpost.com/technology/2018/12/20/nest-cam-
baby-monitor-hacked-kidnap-threat-came-device-parents-say
 –Whittaker, Meredith, et al., Disability, Bias, and AI, AI Now Institute, New York University (USA), November 2019, 
https://ainowinstitute.org/disabilitybiasai-2019.pdf
 –Yip, Jason C., et al., “Laughing is Scary, but Farting is Cute: A Conceptual Model of Children’s Perspectives 
of Creepy Technologies”, CHI ‘19: Proceedings of the 2019 CHI Conference on Human Factors in Computing 
Systems, Paper no. 73, 2019, pp. 1-15, https://dl.acm.org/doi/pdf/10.1145/3290605.3300303?casa_token=d-
1xrAOzDP4AAAAA
Artificial Intelligence for Children
28AI labelling system3
This system promotes transparency and 
trust in child and youth users, their parents 
and guardians.
The AI labelling system (Figure 5) is designed to be included in all AI products 
on their physical packaging and online accessible through a QR code. Like 
nutritional information on food packaging, the labelling system is intended to 
concisely tell consumers, including parents and guardians as well as children 
and youth, how the AI works and what options are available to the users. 
All companies are encouraged to adopt this tool to help create greater trust 
and transparency with the purchasers and child users of their products.
Artificial Intelligence for Children
29FIGURE 5 AI labelling system
Age  
What age are 
the technology 
and content 
designed for?
Accessibility  
Can users with 
different abilities 
and backgrounds 
use it?
Sensors  
Does it watch or 
listen to users  
with cameras  
and microphones?
Networks  
Can users play  
with and talk with 
other people when 
using it?
AI use  
How does it  
use AI to interact 
with users?
Data use  
Does it collect  
personal 
information? –Range of recommended ages in years, e.g. 4-6, 7-10 
 –Tested with children: 
 –Accessible for hearing impaired: 
 –Accessible for visually impaired:
 –What neurodiverse users is it designed to include (e.g. autism, dyslexia)? 
 –What physical disabilities is it designed to include (e.g. fine motor skills, mobility)? 
 –What languages are supported? 
 –Camera:  
 –If Y, can you turn it off?
 –Microphone: 
 –If Y, can you turn it off?
 –Networked play and socialization: 
 –If Y, can the function be turned off? 
 –Facial recognition: 
 –Voice recognition: 
 –Emotion recognition:
 –Gathers data: 
 –Shares data with others: 
 –Can you control whether your data is shared?:  
 –US Children’s Online Privacy Protection Act (COPPA) compliant: 
 – EU General Data Protection Regulation (GDPR) compliant:  
 –UK Information Commissioner’s Office (ICO)  
Age Appropriate Design Code compliant: 
 –Reason for data collection (e.g. to create customized curriculum)  Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
YYY
YN
N
N
N
N
N
N
N
N
N
N
NNN
N
Source: World Economic Forum
Artificial Intelligence for Children
30Guide for parents  
and guardians4
This guide helps decision-making  
about buying and using AI products  
for children and youth.
This guide is designed to educate parents and guardians (Figure 6) to help 
them  understand considerations when buying AI-powered toys, devices 
or apps, such as video games, smart toys, smart speakers, education 
technology products, and more. It is also designed to supplement the  
AI labelling system that may accompany the product or service. 
AI products use sensors and inputs to collect information about whoever uses 
them. The information they collect includes images, videos, patterns of use 
and other data. AI products then use algorithms to interpret the information. 
They make predictions about and suggestions for their users. 
Benefits and risks
AI products have benefits. For example, they can recommend content 
that users might like. But AI products also have risks – they might collect 
information that their consumers do not want them to use or keep. These 
risks carry even more weight when users are children who may or may not be 
ready to make decisions about their digital rights, or who may not fully know 
or understand the impact of AI on their lives. 
Artificial Intelligence for Children 31Guide for parents and guardians – What to consider FIGURE 6
Things you can do Why it matters
Know which developmental stage is appropriate for your child.  
Toys and devices are designed for certain ages. If users are too young, 
the technology and content might be difficult for them to use and could 
expose them to risk. If they are too old, the technology and content 
might not be very interesting or fun. 
The technology should work for all equally despite these differences. 
Users of all abilities should be able to use technology. Some have 
physical or mental disabilities that require accommodations and 
modification. Users look different and speak different languages,  
which could cause problems if the AI is not well designed. 
Find out how the technology protects privacy, such as allowing 
users to turn off cameras or microphones and secure information 
with passwords and preferences regarding data collected by 
these devices.
AI products use input from cameras, microphones and sensors to 
watch, recognize and learn from users. AI products might use facial 
recognition to identify your child’s face or voice recognition to detect 
their voice. These devices and products might also store or send your 
information to another location or be hacked by criminals.
Children should never share personal information or engage with 
people they don’t know, and should beware of people acting  
with malicious intent.
Some AI products enable users to play games and talk with other 
people online. Playing online with others can be fun, but you should be 
sure that your children proceed with caution at all times. 
Know the strengths and limits of AI decisions and suggestions,  
and remember that AI decisions can be wrong. 
AI products might make predictions based on the data collected and 
your child’s prior activity. This might help your child make decisions,  
but it also might label or misread users. 
Change settings and preferences to protect your child’s data.  
Know what kind of information AI products collect, where and  
how long they keep it, and who has access to it. 
AI products can collect data from you and your children and  
store it. Your family’s and child’s information is very important  
and should be protected. Visit the product website. 
Learn more from other 
sources like Common Sense 
Media on choosing the right 
products for different ages 
and developmental stages.
Visit the product website. 
Read user reviews.
Visit the product website. 
Call the company’s 
customer service.
Read about online etiquette 
and online safety.  
Talk with your children and 
use resources like Google’s 
Safety Center for families 
and Be Internet Awesome, 
and other resources.
Read user reviews.  
Learn more about AI 
and how facial and voice 
recognition work.
Visit the product website and 
call the company’s customer 
service to learn what kind 
of information AI products 
collect, where and how long 
they keep it, and who has 
access to it.Age - What age  
is it designed for?
Accessibility - Can users 
with different abilities 
and backgrounds use it?
Sensors - Does it 
watch or listen to 
users with cameras 
and microphones?
Networks - Can users 
play with and talk 
with other people 
when using it?
AI use - How does it use 
AI to interact with users?
 Data use - Does 
it collect personal 
information?  
Why? How? 
Source: World Economic Forum
Artificial Intelligence for Children
32Contributors
AcknowledgementsLead authors
Carla Aerts 
Director, Digital Change, Hodder Education,  
and Founder, Refracted!
Amy Alberts 
Senior Director, User Research, Tableau Software
Jianyu Gao 
World Economic Forum AI Youth Council Member – 
United States
Yakaira Núñez 
Vice-President, Research and Insights Platform, 
Salesforce
Aimee Kendall Roundtree 
Professor and Associate Dean of Research and 
Promotion, Texas State University
Debra Slapak 
Lead, Edge Thought Leadership and Innovation, 
Dell TechnologiesProject lead
Seth Bergeson 
PwC Fellow, World Economic Forum LLC
World Economic Forum LLC
Kay Firth-Butterfield 
Head of Artificial Intelligence and Machine Learning
Patrick Hynes 
Lead, Partner Engagement
Eddan Katz 
Platform Curator
Emily Ratté 
Specialist, Artificial Intelligence and Machine Learning 
Conor Sanchez  
Specialist, Artificial Intelligence and Machine Learning
Maria Luciana Axente 
Lead, Responsible AI and AI for Good, PwC UK
Kathy Baxter 
Principal Architect, Ethical AI Practice, Salesforce
Alex Beard 
Senior Director, Teach For All
Charles-Edouard Bouée 
Co-Founder and Managing Partner, Alpha 
Intelligence Capital
Jasmina Byrne 
Chief of Public Policy, United Nations Children’s 
Fund (UNICEF)
Sam Coates 
Vice-President and Head, Innovation, Interactive 
Business, LEGO Group
Ronald Dahl 
Director, Institute of Human Development, University 
of California, Berkeley
Ilana Golbin 
Director and Lead, Responsible AI, PwCAlison Gopnik 
Professor of Psychology, University of California, 
Berkeley
Dave Graham 
Lead, Technology Advocacy, Dell Technologies 
Beeban Kidron 
Founder and Chair, 5Rights Foundation
Priya Lakhani 
Founder and Chief Executive Officer, CENTURY Tech
Rose Luckin 
Professor of Learner Centred Design, UCL 
Knowledge Lab, University College London 
Gary Meltzer 
Managing Partner, PwC
Illah Nourbakhsh 
K&L Gates Professor of Ethics and Computational 
Technologies, Carnegie Mellon University
Sallie Olmsted 
Lead, Global Communications, i.am MEDIA 
Christopher Payne 
Director, Digital Responsibility, Government and 
Public Affairs, LEGO Group
Artificial Intelligence for Children
33Michael Preston 
Executive Director, Joan Ganz Cooney Center, 
Sesame Workshop
Anand Rao 
Global Leader, Artificial Intelligence, PwC
Aza Raskin 
Co-Founder, Center for Humane Technology 
Karen Silverman 
Founder and Chief Executive Officer,  
Cantellus Group
Matthew Studley 
Wallscourt Associate Professor of Technology 
Ethics, University of the West of England
Sherry Turkle 
Abby Rockefeller Mauzé Professor of the Social 
Studies of Science and Technology, Massachusetts 
Institute of Technology 
Angela Vigil 
Partner and Executive Director, Pro Bono Practice, 
Baker McKenzieSteven Vosloo 
Policy Specialist, Digital Connectivity, United 
Nations Children’s Fund (UNICEF)
Alan Winfield 
Professor of Robot Ethics, University of the West of 
England
The World Economic Forum also thanks the 
following project community members, AI Youth 
Council members and other individuals who 
contributed their time and insights:
Sandrine Amahoro Rutayisire, Danielle Benecke, 
Bianca Bertaccini, Kathleen Esfahany, Joy Fakude, 
Marine Formentini, Matissa Hollister, Grace 
Knickrehm, Nupur Ruchika Kohli, Oliver Leiriao, 
Mariam Al Muhairi, Candice Odgers, Melanie 
Penagos, Chloe Poynton, Guido Putignano, Arwa 
Al Qassim, Pia Ramachandani, Ana Rollán, Sundar 
Sundareswaran, Ecem Yilmazhaliloglu
Artificial Intelligence for Children
34Endnotes
1. Institute of Electrical and Electronics Engineers (IEEE), “IEEE Code of Ethics”, June 2020, https://www.ieee.org/about/
corporate/governance/p7-8.html (accessed 1 December 2021).
2. Dignum, Virginia, Melanie Penagos, Klara Pigmans and Steven Vosloo, Policy guidance on AI for children, Version 2.0,  
United Nations Children’s Fund (UNICEF), November 2021, https://www.unicef.org/globalinsight/reports/policy-guidance-ai-
children (accessed 1 December 2021).
3. World Economic Forum, “Empowering AI Leadership: An Oversight Toolkit for Boards of Directors”, 2019,  
https://spark.adobe.com/page/RsXNkZANwMLEf (accessed 1 December 2021).
4. United Nations Human Rights Office of the High Commissioner, “Convention on the Rights of the Child”, Adopted and 
opened for signature, ratification and accession by General Assembly resolution 44/25 of 20 November 1989, entry into 
force 2 September 1990, in accordance with article 49, https://www.ohchr.org/en/professionalinterest/pages/crc.aspx 
(accessed 30 November 2021).
5. Kalliomeri, Reetta, et al., Child-Centered Design, Save the Children, 2020, https://resourcecentre.savethechildren.net/pdf/
save_the_children_child-centered_design.pdf (accessed 1 December 2021).
6. The Toy Association, “New National Survey Finds Parents Don’t Always Follow Important Toy Safety Guidelines”,  
Press Release, 7 November 2018, https://www.toyassociation.org/PressRoom2/News/2018-news/new-national-survey-
finds-parents-dont-always-follow-important-toy-safety-guidelines.aspx (accessed 1 December 2021).
7. Klein, Cynthia, “Maturation of the Prefrontal Cortex”, bridges 2 understanding, 5 March 2013,  
https://bridges2understanding.com/maturation-of-the-prefrontal-cortex (accessed 1 December 2021).
8. Stanborough, Rebecca, “Ages and Stages: How to Monitor Child Development”, Healthline, 9 December 2019,  
https://www.healthline.com/health/childrens-health/stages-of-child-development (accessed 1 December 2021).
9. Cell Press, “Self-centered kids? Blame their immature brains”, ScienceDaily, 7 March 2012, https://www.sciencedaily.
com/releases/2012/03/120307132206.htm (accessed 1 December 2021).
10. Yukti, “10 Most Important UX Research Methods”, https://www.yukti.io/10-most-important-user-research-methods 
(accessed 9 December 2021). 
11. Society of American Archivists (SAA), “SAA Core Values Statement and Code of Ethics”, August 2020 revision,  
https://www2.archivists.org/statements/saa-core-values-statement-and-code-of-ethics (accessed 1 December 2021).
12. General Data Protection Regulation (GDPR), “Art. 17 GDPR, Right to erasure (‘right to be forgotten’)”,  
https://gdpr-info.eu/art-17-gdpr (accessed 1 December 2021).
13. Hourcade, Juan Pablo, “Interaction Design and Children”, Foundations and Trends in Human–Computer Interaction,  
vol. 1, no. 4, 2007, pp. 277–392, https://www.cs.uic.edu/~i523/hourcade.pdf (accessed 1 December 2021).
14. Loukides, Mike, Hilary Mason and DJ Patil, Ethics and Data Science, O’Reilly Media Inc., July 2018,  
https://www.oreilly.com/library/view/ethics-and-data/9781492043898 (accessed 2 December 2021).
15. Deon, “An ethics checklist for data scientists”, https://deon.drivendata.org (accessed 2 December 2021).
16. Longstaff, Simon, “Ethical issues and decision making”, St James Ethics Centre, 1997, https://web.archive.org/
web/20040920072257/http:/www.ethics.org.au/things_to_read/articles_to_read/general_issues/article_0070.shtm 
(accessed 1 December 2021).
17. Madaio, Michael A., et al., “Co-Designing Checklists to Understand Organizational Challenges and Opportunities around 
Fairness in AI”, in Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI 2020), 2020, 
http://www.jennwv.com/papers/checklists.pdf (accessed 1 December 2021).
18. Gogoll, Jan, et al., “Ethics in the Software Development Process: from Codes of Conduct to Ethical Deliberation”, Philosophy 
& Technology, 2021, https://link.springer.com/article/10.1007/s13347-021-00451-w (accessed 1 December 2021).
19. Data for Children Collaborative with UNICEF, “Our Ethical Assessment Is Now Live!”, 23 April 2020,  
https://www.dataforchildrencollaborative.com/news-from-the-unicef-data-for-children-collaborative/our-ethical-
assessment-is-now-live (accessed 3 December 2021).
20. Mittelstadt, Brent, “Principles alone cannot guarantee ethical AI”, May 2019, https://arxiv.org/ftp/arxiv/
papers/1906/1906.06668.pdf (accessed 3 December 2021).
21. Winfield, Alan, and Marina Jirotka, “Ethical governance is essential to building trust in robotics and artificial intelligence 
systems”, Philosophical Transactions of the Royal Society A, Mathematical, Physical and Engineering Services,  
15 October 2018, https://royalsocietypublishing.org/doi/10.1098/rsta.2018.0085 (accessed 3 December 2021).
22. Association for Psychological Science, “Harlow’s Classic Studies Revealed the Importance of Maternal Contact,”  
20 June 2018, https://www.psychologicalscience.org/publications/observer/obsonline/harlows-classic-studies-revealed-
the-importance-of-maternal-contact.html (accessed 3 December 2021).
Artificial Intelligence for Children
3523. The St. Petersburg-USA Orphanage Research Team, “The Effects of Early Social-Emotional and Relationship Experience 
on the Development of Young Orphanage Children”, Monographs of the Society for Research in Child Development, vol. 
73, no. 3, 2008, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2702123 (accessed 3 December 2021).
24. Smart Toy Awards, in collaboration with the World Economic Forum, “Smart Toy Awards: Shaping the Future of 
Childhood”, 2021, https://www.smarttoyawards.org (accessed 3 December 2021).
25. Stemler, Sam, “Top 8 Most Common Accessibility Issues to Avoid and Solve,” Accessibility Metrics, 16 July 2019, https://www.
accessiblemetrics.com/blog/top-8-most-common-accessibility-issues-to-avoid-and-solve (accessed 3 December 2021).
26. Whittaker, Meredith, et al., Disability, Bias, and AI, AI Now Institute, New York University (USA), November 2019,  
https://ainowinstitute.org/disabilitybiasai-2019.pdf (accessed 3 December 2021).
27. Reddy, Shivani, “The Unfortunate History of Racial Bias in Photography”, https://www.slrlounge.com/unfortunate-history-
racial-bias-photography (accessed 3 December 2021).
28. Hess, Robert D., and Virginia C. Shipman, “Early Experience and the Socialization of Cognitive Modes in Children”,  
Child Development, vol. 36, no. 4, December 1965, pp. 869-886, https://www.jstor.org/stable/1126930  
(accessed 6 December 2021).
29. Kolitz, Daniel, “Do Kids Feel Stronger Emotions Than Adults?”, Gizmodo, 10 September 2018, https://gizmodo.com/do-
kids-feel-stronger-emotions-than-adults-1828933152 (accessed 6 December 2021).
30. Booker, Karene, “Age changes how young children read social cues”, Cornell Chronicle, 14 November 2013,  
https://news.cornell.edu/stories/2013/11/age-changes-how-young-children-read-social-cues (accessed 6 December 2021).
31. Federal Trade Commission, “Children’s Online Privacy Protection Rule: A Six-Step Compliance Plan for Your Business”, 
June 2017, https://www.ftc.gov/tips-advice/business-center/guidance/childrens-online-privacy-protection-rule-six-step-
compliance (accessed 6 December 2021).
32. kinedu, “Children’s development is not linear”, 19 August 2019, https://blog.kinedu.com/childrens-development-is-not-linear  
(accessed 6 December 2021).
33. Contrera, Jessica, “The end of ‘shrink it and pink it’: A history of advertisers missing the mark with women”,  
The Washington Post, 8 June 2016, https://www.washingtonpost.com/lifestyle/style/the-end-of-shrink-it-or-pink-it-a-
history-of-advertisers-missing-the-mark-with-women/2016/06/08/3bcb1832-28e9-11e6-ae4a-3cdd5fe74204_story.html  
(accessed 6 December 2021).
34. Calvert, Sandra L., “Children as Consumers: Advertising and Marketing”, The Future of Children, vol. 18, no. 1,  
Spring 2008, https://www.jstor.org/stable/20053125 (accessed 6 December 2021).
35. Complete guide to GDPR compliance, 2021, https://gdpr.eu (accessed 6 December 2021).
36. Federal Trade Commission, “Children’s Online Privacy Protection Rule (‘COPPA’)”, https://www.ftc.gov/enforcement/rules/
rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule (accessed 6 December 2021).
37. ICO, “Introduction to the Age appropriate design code”, https://ico.org.uk/for-organisations/guide-to-data-protection/ico-
codes-of-practice/age-appropriate-design-code (accessed 6 December 2021).
38. Vinney, Cynthia, “What Is Attachment Theory? Definition and Stages”, ThoughtCo., 24 October 2019,  
https://www.thoughtco.com/attachment-theory-4771954 (accessed 6 December 2021).
39. Children & Adversity Information, sponsored by Global Children’s Fund, “How they are disadvantaged:  
What makes kids more vulnerable”.
40. Dark Patterns, https://www.darkpatterns.org (accessed 6 December 2021).
41. Brenner, Grant Hillary, “What Makes Internet Trolls Tick?”, Psychology Today, 5 August 2019, https://www.
psychologytoday.com/us/blog/experimentations/201908/what-makes-internet-trolls-tick (accessed 6 December 2021).
42. Common Sense, Technology Addition: Concern, Controversy, and Finding Balance, 2016, https://www.
commonsensemedia.org/sites/default/files/uploads/research/csm_2016_technology_addiction_research_brief_1.pdf 
(accessed 6 December 2021).
43. Microsoft Azure, “Community jury”, 1 November 2021, https://docs.microsoft.com/en-us/azure/architecture/guide/
responsible-innovation/community-jury (accessed 6 December 2021).
44. Doteveryone, “Consequence Scanning – an agile practice for responsible innovators”, https://doteveryone.org.uk/project/
consequence-scanning (accessed 6 November 2021).
45. Microsoft Azure, “Judgment Call”, 12 November 2021, https://docs.microsoft.com/en-us/azure/architecture/guide/
responsible-innovation/judgmentcall (accessed 2 December 2021).
46. Microsoft Azure, “Foundations of assessing harm”, 8 November 2021, https://docs.microsoft.com/en-us/azure/
architecture/guide/responsible-innovation/harms-modeling (accessed 6 December 2021).
47. Federal Trade Commission, “Children’s Online Privacy Protection Rule (‘COPPA’)”, https://www.ftc.gov/enforcement/rules/
rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule (accessed 6 December 2021).
48. Designing for Children’s Rights Guide, https://childrensdesignguide.org/ (accessed 6 December 2021).
49. Museum of Failure, “My Friend Cayla – spying doll”, 2014, https://collection.museumoffailure.com/my-friend-cayla 
(accessed 6 December 2021).
Artificial Intelligence for Children
3650. Phadnis, Shree, “Develop Correct Six Sigma Project Metrics”, iSixSigma, https://www.isixsigma.com/methodology/
balanced-scorecard/develop-correct-six-sigma-project-metrics (accessed 6 December 2021).
51. Future of Privacy Forum, “The Federal Trade Commission Updates to the COPPA FAQs”, 21 October 2020,  
https://fpf.org/blog/ftc-updates-coppa-faqs (accessed 6 December 2021).
52. The Simple EULA Project, “Fair EULA: A new step to bridge the gap between corporate and consumer”,  
http://simpleeulas.weebly.com/fair-eulas.html (accessed 6 December 2021).
53. Cragg, Lucy, “The Development of Stimulus and Response Interference Control in Midchildhood”, Developmental 
Psychology, vol. 52, no. 2, November 2015, https://www.researchgate.net/publication/284547902_The_Development_
of_Stimulus_and_Response_Interference_Control_in_Midchildhood (accessed 6 December 2021).
Artificial Intelligence for Children
37World Economic Forum
91–93 route de la Capite
CH-1223 Cologny/Geneva
Switzerland  
Tel.:  +41 (0) 22 869 1212
Fax: +41 (0) 22 786 2744
contact@weforum.org
www.weforum.orgThe World Economic Forum, 
committed to improving  
the state of the world, is the 
International Organization for 
Public-Private Cooperation.
 
The Forum engages the 
foremost political, business  
and other leaders of society  
to shape global, regional 
and industry agendas.

User Needs +
Defining Success
Even the best AI will fail if it doesn’t provide unique value to
users.
This chapter covers:
Which user problems is AI uniquely positioned to solve?
How can we augment human capabilities in addition to automating tasks?
How can we ensure our reward function optimizes AI for the right thing?
Want to drive discussions, speed iteration, and avoid pitfalls? Use the worksheet.What’s new when working with AI
When building any product in a human-centered way, the most important decisions you’ll make are:
Who are your users? What are their values? Which problem should you solve for them? How will
you solve that problem? How will you know when the experience is “done”?
In this chapter, we’ll help you understand which user problems are good candidates for AI and how
to define success. Key considerations:
➀ Find the intersection of user needs & AI strengths. Solve a real problem in ways in which AI
adds unique value.
➁ Assess automation vs. augmentation. Automate tasks that are difficult, unpleasant, or where
there’s a need for scale; and ideally ones where people who currently do it can agree on the
“correct” way to do it. Augment tasks that people enjoy doing, that carry social capital, or where
people don’t agree on the “correct” way to do it.
➂ Design & evaluate the reward function. The “reward function” is how an AI defines successes
and failures. Deliberately design this function with a cross-functional team, optimizing for long-
term user benefits by imagining the downstream effects of your product. Share this function
with users when possible.➀ Find the intersection of user needs & AI
strengths
Like any human-centered design process, the time you spend identifying the right problem to solve
is some of the most important in the entire effort. Talking to people, looking through data, and
observing behaviors can shift your thinking from technology-first to people-first.
The first step is to identify real problems that people need help with. There are many ways to
discover these problems and existing resources online to help you get started. We recommend
looking through IDEO’s Design Kit methods section for examples of how to find problems and
corresponding user needs.
For our example app RUN, user needs might be:
The user wants to get more variety in their runs so they don’t get bored and quit running.
The user wants to track their daily runs so that they can get ready for a 10k in six months.
The user would like to meet other runners at their skill level so they can stay motivated to keep
running.
You should always build and use AI in responsible ways. When deciding on which problem to solve,
take a look at the Google AI Principles, and Responsible AI Practices for practical steps, to ensure
you’re building with the greater good in mind. For starters, make sure to get input from a diverse
set of users early on in your product development process. Hearing from many different points of
view can help you avoid missing out on major market opportunities or creating designs that
unintentionally exclude specific user groups.
Map existing workflows
Mapping the existing workflow for accomplishing a task can be a great way to find opportunities
for AI to improve the experience. As you walk through how people currently complete a process,
you’ll better understand the necessary steps and identify aspects that could be automated or
augmented. If you already have a working AI-powered product, test your assumptions with user
research. Try letting people use your product (or a “Wizard of Oz” test) to automate certain aspects
of the process, and see how they feel about the results.Decide if AI adds unique value
Once you identify the aspect you want to improve, you’ll need to determine which of the possible
solutions require AI, which are meaningfully enhanced by AI, and which solutions don’t benefit from
AI or are even degraded by it.
It’s important to question whether adding AI to your product will improve it. Often a rule or
heuristic-based solution will work just as well, if not better, than an AI version. A simpler solution
has the added benefit of being easier to build, explain, debug, and maintain. Take time to critically
consider how introducing AI to your product might improve, or regress, your user experience.
To get you started, here are some situations where an AI approach is probably better than a rule-
based approach, and some in which it is not.
When AI is probably better
Recommending different content to different users. Such as providing personalized
suggestions for movies to watch.
Prediction of future events. For example, showing flight prices for a trip to Denver in late
November.
Personalization improves the user experience. Personalizing automated home
thermostats makes homes more comfortable and the thermostats more efficient over
time.
Natural language understanding. Dictation software requires AI to function well for
different languages and speech styles.
Recognition of an entire class of entities. It’s not possible to program every single face
into a photo tagging app — it uses AI to recognize two photos as the same person.
Detection of low occurrence events that change over time. Credit card fraud is constantly
evolving and happens infrequently to individuals, but frequently across a large group. AI
can learn these evolving patterns and detect new kinds of fraud as they emerge.
An agent or bot experience for a particular domain. Booking a hotel follows a similar
pattern for a large number of users and can be automated to expedite the process.Showing dynamic content is more efficient than a predictable interface. AI-generated
suggestions from a streaming service surface new content that would be nearly
impossible for a user to find otherwise.
When AI is probably not better
Maintaining predictability. Sometimes the most valuable part of the core experience is its
predictability, regardless of context or additional user input. For example, a “Home” or
“Cancel” button is easier to use as an escape hatch when it stays in the same place.
Providing static or limited information. For example, a credit card entry form is simple,
standard, and doesn’t have highly varied information requirements for different users.
Minimizing costly errors. If the cost of errors is very high and outweighs the benefits of a
small increase in success rate, such as a navigation guide that suggests an off-road route
to save a few seconds of travel time.
Complete transparency. If users, customers, or developers need to understand precisely
everything that happens in the code, like with Open Source Software. AI can’t always deliver
that level of explainability.
Optimizing for high speed and low cost. If speed of development and getting to market
first is more important than anything else to the business, including the value that adding
AI would provide.
Automating high-value tasks. If people explicitly tell you they don’t want a task automated
or augmented with AI, that’s a good task not to try to disrupt. We’ll talk more about how
people value certain types of tasks below.Key concept
Instead of asking “Can we use AI to _________?”, start exploring human-centered AI
solutions by asking:
How might we solve __________ ?
Can AI solve this problem in a unique way?
Apply the concepts from this section in Exercise 1 in the worksheet➁ Assess automation vs. augmentation
When you’ve found the problem you want to solve and have decided that using AI is the right
approach, you’ll then evaluate the different ways AI can solve the problem and help users
accomplish their goals. One large consideration is if you should use AI to automate a task or to
augment a person’s ability to do that task themselves.
Some tasks, people would love for AI to handle, but there are many activities that people want to
do themselves. In those latter cases, AI can help them perform the same tasks, but faster, more
efficiently, or sometimes even more creatively. When done right, automation and augmentation
work together to both simplify and improve the outcome of a long, complicated process.
When to automate
Automation is typically preferred when it allows people to avoid undesirable tasks entirely or when
the time, money, or effort investment isn’t worth it to them. These are usually tasks people are
happy to delegate to AI as they don’t require oversight, or they can be done just as well by someone
(or something) else. Successful automation is often measured by the following:
Increased efficiency
Improved human safety
Reduction of tedious tasks
Enabling new experiences that weren’t possible without automation
Automation is often the best option for tasks that supplement human weaknesses with AI
strengths. For example, it would take a human a very long time to sort through their photo library
and group pictures by subject. AI can do that quickly and easily, without constant feedback.
Consider automating experiences when:
People lack the knowledge or ability to do the task
There are many times when people would do something if they knew how, but they don’t so they
can’t. Or they technically know how, but a machine is much better suited to the task — such as
searching thousands of rows in a spreadsheet to find particular value.There are also often temporary limitations on people, like needing to complete a task quickly,
that can lead to preferences for giving up control. For example, one might save time by using
the automated setting on their rice cooker when they’re rushed to make dinner during the week,
but make their sushi rice by hand over the weekend.
Tasks are boring, repetitive, awkward, or dangerous
There’s little value in attempting to edit a document you wrote without using spell-check. It’s
unwise to check for a gas leak in a building using your own nose when you could use a sensor
to detect the leak. In both of these situations, most people would prefer to give up control to
avoid tasks that don’t provide them value.
Even when you choose to automate a task, there should almost always be an option for human
oversight — sometimes called “human in the loop” — and intervention if necessary. Easy options
for this are allowing users to preview, test, edit, or undo any functions that your AI automates.
When to augment
When building AI-powered products, it’s tempting to assume that the best thing you can do for your
users is automate tasks they currently have to do manually. However, there are plenty of situations
where people typically prefer for AI to augment their existing abilities and give them “superpowers”
instead of automating a task away entirely.
Successful augmentation is often measured by the following:
Increased user enjoyment of a task
Higher levels of user control over automation
Greater user responsibility and fulfillment
Increased ability for user to scale their efforts
Increased creativity
Augmentation opportunities aren’t always easy to define as separate from automation, but they’re
usually more complicated, inherently human, and personally valuable. For example, you may use
tools that automate part of designing a t-shirt, like resizing your art or finding compatible colors.
The design software, in this case, augments the task of t-shirt design, and unlocks limitless
silliness and ingenuity. Consider augmenting people’s existing abilities when:People enjoy the task
Not every task is a chore. If you enjoy writing music, you probably wouldn’t want an AI to write
entire pieces for you. If an algorithm did it for you, you won’t get to participate in the creative
process you love. However, using something like Magenta Studio could help you during the
creative process without taking away the essential humanity of your artistic process.
Personal responsibility for the outcome is required or important
People exchange small favors all the time. Part of doing a favor for someone is the social
capital you gain by giving up your time and energy. For tasks like these, people prefer to remain
in control and responsible to fulfill the social obligations they take on. Other times, when there
is no personal obligation, like paying tolls on roads, an automated system is typically preferred.
The stakes of the situation are high
People often want to, or have to, remain in control when the stakes are high for their role; for
example pilots, doctors, or police officers. These can be physical stakes like ensuring someone
gets off a tall ladder safely, emotional stakes like telling loved ones how you feel about them, or
financial stakes like sharing credit card or banking information. Additionally, sometimes
personal responsibility for a task is legally required. In low stakes situations, like getting song
recommendations from a streaming service, people will often give up control because the
prospect of discovery is more important than the low cost of error.
Specific preferences are hard to communicate
Sometimes people have a vision for how they want something done: a room decorated, a party
planned, or a product designed. They can see it in their mind’s eye but can’t seem to do it justice
in words. In these kinds of situations, people prefer staying in control so they can see their
vision through. When people don’t have a vision or don’t have time to invest in one, they are
more likely to prefer automation.Key concept
Below are some example research questions you can ask to learn about how your users
think about automation and augmentation:
If you were helping to train a new coworker for a similar role, what would be the most
important tasks you would teach them first?
Tell me more about that action you just took, about how often do you do that?
If you had a human assistant to work with on this task, what, if any duties would you
give them to carry out?
Apply the concepts from this section in Exercise 2 in the worksheet➂ Design & evaluate the reward function
Any AI model you build or incorporate into your product is guided by a reward function, also called
an “objective function”, or “loss function.” This is a mathematical formula, or set of formulas, that
the AI model uses to determine “right” vs. “wrong” predictions. It determines the action or behavior
your system will try to optimize for, and will be a major driver of the final user experience.
When designing your reward function, you must make a few key decisions that will dramatically
affect the final experience for your users. We’ll cover those next, but remember that designing your
reward function should be a collaborative process across disciplines. Your conversations should
include UX, Product, and Engineering perspectives at the minimum. Throughout the process, spend
time thinking about the possible outcomes, and bounce your ideas off other people. That will help
reveal pitfalls where the reward function could optimize for the wrong outcomes.
Weigh false positives & negatives
Many AI models predict whether or not a given object or entity belongs to a certain category. These
kind of models are called “binary classifiers”. We’ll use them as a simple example for
understanding how AI’s can be right or wrong.
When binary classifiers make predictions, there are four possible outcomes:
True positives. When the model correctly predicts a positive outcome.
True negatives. When the model correctly predicts a negative outcome.
False positives. When the model incorrectly predicts a positive outcome.
False negatives. When the model incorrectly predicts a negative outcome.A generic confusion matrix illustrating the two kinds of
successes — true positives and true negatives — and
two kinds of errors — false positives and false negatives
— any AI model can make.
Let’s walk through an example using our example app, RUN. Suppose RUN uses an AI model to
recommend runs to users. Here’s how the different model outcomes would play out:
1. True positives. The model suggested a run the user liked and chose to go on. 
2. True negatives. The model did not suggest a run the user would not have chosen to go on.
3. False positives. The model suggested a run to the user that they did not want to go on.
4. False negatives. The model did not suggest a run to the user that they would have wanted to
go on if they knew about it.
When defining the reward function, you’ll be able to “weigh” outcomes differently. Weighing the
cost of false positives and false negatives is a critical decision that will shape your users’
experiences. It is tempting to weigh both equally by default. However, that’s not likely to match the
consequences in real life for users. For example, is a false alarm worse than one that doesn’t go
off when there’s a fire? Both are incorrect, but one is much more dangerous. On the other hand,
occasionally recommending a song that a person doesn’t like isn’t as lethal. They can just decide
to skip it. You can mitigate the negative effects of these types of errors by including confidence
indicators for a certain output or result.Consider precision & recall tradeoffs
Precision and recall are the terms that describe the breadth and depth of results that your AI
provides to users, and the types of errors that users see.
1. Precision refers to the proportion of true positives correctly categorized out of all the true
and false positives.The higher the precision, the more confident you can be that any model
output is correct. However, the tradeoff is that you will increase the number of false negatives
by excluding possibly relevant results.  
 
For example, if the model above was optimized for precision, it wouldn’t recommend every
single run that a user might choose to go on, but it would be highly confident that every run it
did recommend would be accepted by the user. Users would see very few if any runs that
didn’t match their preferences, but they might see fewer suggestions overall.
2. Recall refers to the proportion of true positives correctly categorized out of all the true
positives and false negatives. The higher the recall, the more confident you can be that all the
relevant results are included somewhere in the output. However, the tradeoff is that you will
increase the number of false positives by including possibly irrelevant results.  
 
You can think of this as the model recommonding every run a user might want to go on, and
including other runs the user does not choose to go on. The user however, would always have
suggestions for a run, even if those runs didn’t match their preferences as well.A diagram showing the trade-offs when optimizing for precision or recall. On the left, optimizing for precision can
reduce the number of false positives but may increase the number of false negatives. On the right, optimizing for
recall catches more true positives but also increases the number of false positives.
You’ll need to design specifically for these tradeoffs — there’s no getting around them. Where along
that spectrum your product falls should be based on what your users expect and what gives them
the sense of task completeness. Sometimes, seeing some lower confidence results in addition to
all of the 100% results can help users trust that the system isn’t missing anything. In other cases,
showing lower confidence results could lead to users trusting the system less. Make sure to test
the balance between precision and recall with your users.
Evaluate the reward function outcomesThe next step is evaluating your reward function. Like any definition of success, it will be tempting
to make it very simple, narrow, and immediate. However, this isn’t the best approach: when you
apply a simple, narrow, and immediate reward function to broad audiences over time, there can be
negative effects.
Here are a few considerations when evaluating your reward function:
Assess inclusivity
You’ll want to make sure your reward function produces a great experience for all of your users.
Being inclusive means taking the time to understand who is using your product and making
sure the user experience is equitable for people from a variety of backgrounds and
perspectives, and across dimensions such as race, gender, age, or body shape, among many
others. Designing AI with fairness in mind from the beginning is an essential step toward
building inclusively. Open source tools like Facets and the What-If Tool allow you to inspect your
datasets for potential bias. There’s more on this in the Data Collection + Evaluation chapter.
While the Guidebook provides some advice related to fairness, it is not an exhaustive resource
on the topic. Addressing fairness in AI is an active area of research. See Google’s Responsible
AI Practices for our latest fairness guidance and recommended practices.
Monitor over time
You’ll also want to consider the implications of your chosen reward function over time.
Optimizing for something like number of shares may seem like a good idea in the short term
but over enough time, bombarding users with sharing notifications could create a very noisy
experience. Imagine the best individual and collective user experience on their 100th or 1,000th
day using your product as well as the first. Which behaviors and experiences should you
optimize for in the long run?
Imagine potential pitfallsSecond-order effects are the consequences of the consequences of a certain action. These
are notoriously difficult to predict but it’s still worth your time to consider them when designing
your reward function. One useful question to ask is, “What would happen to our users/their
friends & family/greater society if the reward function were perfectly optimized?” The result
should be good. For example, optimizing to take people to the best web page for a search query
is good, if it’s perfect. Optimizing to keep people’s attention continuously throughout the day
may not provide them benefits in the long run.
Account for negative impact
As AI moves into higher stakes applications and use-cases, it becomes even more important to
plan for and monitor negative impacts of your product’s decisions. Even if you complete all of the
thought exercises in the worksheets, you probably won’t uncover every potential pitfall upfront.
Instead, schedule a regular cadence for checking your impact metrics, and identifying additional
potential bad outcomes and metrics to track.
It’s also useful to connect potential negative outcomes with changes to the user experience you
could make to address them. For example, you could set the following standards and guidance for
you and your team:
If users’ average rate of rejection of smart playlists and routes goes above 20%, we should
check our ML model.
If over 60% of users download our app and never use it, we should revisit our marketing
strategy.
If users are opening the app frequently, but only completing runs 25% of the time, we’ll talk to
users about their experiences and potentially revisit our notification frequency.
As your product matures, check in your product feedback for negative impacts on stakeholders you
didn’t consider. If you find some stakeholders are experiencing negative effects on account of your
product, talk to them to understand their situation. Based on these conversations, strategize ways
to adapt your product to avoid continued negative impact.
An easy way to keep an eye on negative impacts is through social media or alert systems like
Google Alerts. Make sure you’re listening to your users and identifying potential unintended
consequences as early as possible.Key concept
Everyone on your team should feel aligned on what both success and failure look like for
your feature, and how to alert the team if something goes wrong. Here’s an example
framework for this: 
 
If { specific success metric } for __ { your team’s AI-driven feature } { drops below/goes
above }__ { meaningful threshold } We will { take a specific action }.
 
Apply the concepts from this section in Exercise 4 in the worksheetSummary
Aligning your product with user needs is step one in any successful AI product. Once you’ve found
a need, you should evaluate whether using AI will uniquely address the need. From there, consider
whether some parts of the experience should be automated or augmented. Lastly, design your
reward function to create a great user experience for all your users over the long run.
➀ Find the intersection of user needs & AI strengths. Make sure you’re solving a real problem in a
way where AI is adding unique value. When deciding on which problem to solve, you should
always build and use AI in responsible ways. Take a look at the Google AI Principles and
Responsible AI Practices for practical steps to ensure you are building with the greater good in
mind.
➁ Assess automation vs. augmentation. Automate tasks that are difficult or unpleasant, and
ideally ones where people who do it currently can agree on the “correct” way to do it. Augment
bigger processes that people enjoy doing or that carry social value.
➂ Design & evaluate the reward function. The “reward function” is how an AI defines successes
and failures. You’ll want to deliberately design this function including optimizing for long-term
user benefits by imagining the downstream effects of your product and limiting their potentially
negative outcomes.
Want to drive discussions, speed iteration, and avoid pitfalls? Use the worksheet

Feedback + Control
When users give feedback to AI products, it can greatly
improve the AI performance and the user experience over
time. This chapter covers:
How should the AI request and respond to user feedback?
How can we ensure our AI can interpret and use both implicit and explicit user feedback?
What’s the right level of control and customization to give our users?
Want to drive discussions, speed iteration, and avoid pitfalls? Use the worksheet.What’s new when working with AI
User feedback is the communication channel between your users, your product, and your team.
Leveraging feedback is a powerful and scalable way to improve your technology, provide
personalized content, and enhance the user experience.
For AI products, user feedback and control are critical to improving your underlying AI model’s
output and user experience. When users have the opportunity to offer feedback, they can play a
direct role in personalizing their experiences and maximizing the benefit your product brings to
them. When users have the right level of control over the system, they’re more likely to trust it.
Key considerations for feedback and control mechanisms:
➀ Align feedback with model improvement. Clarify the differences between implicit and explicit
feedback, and ask useful questions at the right level of detail.
➁ Communicate value & time to impact. Understand why people give feedback so you can set
expectations for how and when it will improve their user experience.
➂ Balance control & automation. Give users control over certain aspects of the experience and
allow them to easily opt out of giving feedback.➀ Align feedback with model improvement
In general, there are implicit and explicit mechanisms for gathering feedback. For either type of
feedback, it’s important to let users know what information is being collected, what it’s for, and how
its use benefits them. Whenever possible, find ways to use feedback to improve your AI.
Review implicit feedback
Implicit feedback is data about user behavior and interactions from your product logs. This
feedback can include valuable nuggets such as the times of day when users open your app, or the
number of times they accept or reject your recommendations. Often, this happens as part of
regular product usage — you don’t have to explicitly ask for this type of information, but you should
let users know you’re collecting it, and get their permission up front.
We’ve talked about privacy a bit in Mental Models and Data Collection + Evaluation. Users aren’t
always aware of when their actions are being used as input or feedback, so be sure to review the
considerations in the Explainability + Trust and Mental Models chapters when explaining how you’ll
use this data. In particular, you should allow users to opt out of certain aspects of sharing implicit
feedback — like having their behavior logged — and this should be included in your terms of
service.Aim for
Let the user know where they can see their data and
where they can change data-collection settings. Ideally,
do this in-context. Learn more
Avoid
Don’t implicitly collect data without telling people.
Always provide a way to see, and ideally edit, data
collected.
Collect explicit feedbackheck_circle_outline not_interestedExplicit feedback is when users deliberately provide commentary on output from your AI. Often,
this is qualitative, like whether or not a recommendation was helpful, or if and how a categorization
— such as a photo label — was wrong. This can take many forms such as surveys, ratings, thumbs
up or down, or open text fields.
The question and answer choices you provide in explicit feedback should be easy for users to
understand. It’s also important that your wording choices hit the appropriate voice and tone for the
type of feedback you’re requesting, and avoid words or references that can be interpreted as
offensive. Jokes most likely aren’t appropriate when asking about something serious.
Explicit feedback can be used in two ways:
1. You or your team can review user feedback for themes and make changes to the product
accordingly.
2. It can be fed directly back into the AI model as a signal.
If you’re building for the latter, make sure that the feedback data you receive can actually be used
to improve your model. Both your system and your users should understand what the feedback
means.
In most cases, options for feedback responses should be mutually exclusive and collectively
exhaustive. For example, thumbs up versus a thumbs down is unambiguous (“yay” or “nay”),
mutually exclusive (not “yay and nay”), and covers the full range of useful opinions (“meh” isn’t very
actionable). For more granular feedback, show options that match with the way that users evaluate
their experiences.
Interpret dual feedback
Sometimes a single piece of feedback contains both implicit and explicit signals at the same time.
For example, public ‘likes’ are both a way to communicate with others (explicitly) and useful data to
tune a recommendations model (implicitly). Feedback like this can be confusing because there
isn’t always a clear link between what a user does and what a user wants from the AI model. For
example, just because someone interacts with a piece of content doesn’t mean they want to see
more of the same. They could be trying to dismiss it — or giving in to a temporary curiosity.In these cases, it’s important to consider how you’ll use the implicit signal for model tuning. Not
every action can be interpreted in the same way. Similarly, if explicit feedback can have a wide
interpretation, say from “this is OK” to “this is the best thing ever and all I want to see are things
like this from now on”, consider decreasing how it impacts tuning the model.
Design for model tuning
Ideally, what people want to give feedback on aligns with what data is useful to tune your model.
However, that’s not guaranteed. Find out what people expect to be able to influence by conducting
user research. For example, when using a video recommender system, people may want to give
feedback at a different conceptual level than the AI model understands. They may think “show me
more videos about parenthood” while the model interprets “show me more videos by this creator”.
Discuss with your cross-functional stakeholders all the tradeoffs of collecting or not collecting
different types of feedback. Strong, unequivocal signals are great for tuning, but be thoughtful in
how you surmise intent based on behavior. Sometimes, looking at interactions over a longer period
of time can help you distill more accurate patterns of behavior and intent.
Key concept
List out as many events and corresponding feedback opportunities as possible that could
provide data to improve the AI in your product. Cast a wide net - App Store reviews, Twitter,
email, call centers, push notifications, etc. Then, systematically ask what your users and
data are telling you about your product’s experience.
1. What user experience is triggering this feedback opportunity?
2. What kind of content are they providing feedback on?
3. Is this feedback implicit or explicit?
Apply the concepts from this section in Exercise 1 in the worksheet➁ Communicate value & time to impact
For people to take the time to give feedback, it needs to be valuable and impactful. How you
communicate this is key to whether or not your users will engage. Keep in mind that “value” is
often tied to motivation, so frame your feedback requests in terms of specific user benefits.
Before we get into messaging considerations for communicating the user benefit of feedback, let’s
start with why people give feedback in the first place.
Understand why people give feedback
There are many reasons people choose to give feedback about a product or experience. Here are a
few of the canonical reasons along with the pros and cons of each.
Material rewards
Cash payments are highly motivating. Mechanical Turk is an example of this type of reward for
feedback at scale.
Pros
A direct solution to increase feedback
May increase the volume of feedback
Cons
Costly to run over time
May devalue intrinsic motivations
Biases for a subset of users
May decrease feedback quality
Symbolic rewardsThese can include status attainment, such as virtual badges, social proof and group status by
projecting a self image to a community, and social capital, such as a reputation as an expert.
Pros
Low to no cost
Cons
Relies on users caring about how they’re perceived
Creates power imbalances in the community
May inhibit intrinsic motivation
Personal utility
These include “quantified self” experiences including allowing users to track their progress,
bookmark things for later, and explicitly training a personalized AI model — like a
recommendation engine— for more relevant output later on.
Pros
No network effects or community necessary to begin
Cons
Privacy does not support community development
May inhibit intrinsic motivation
Altruism
Altruistic motivations can include community building and helping other people make
decisions, such as leaving a product review, as well as trying to increase fairness, like giving a
conflicting opinion by disagreeing with a particular product review.
ProsPotential for more honest feedback based on a desire to help
Cons
Social desirability biases may lead to extremes in feedback content
Decrease in contributions if the opinion is already represented
Altruism levels may vary across cultures or groups
Intrinsic motivation
Intrinsic motivation is the internal fulfillment people get from the act of expressing themselves.
This includes direct enjoyment from giving feedback, the ability to vent and express opinions,
and the enjoyment of community participation.
Pros
No network effects or community needed to start
People like to do things they enjoy
Cons
Social desirability biases may lead to extremes in feedback content
Align perceived and actual user value
If the benefit isn’t clear and specific, users may not understand why they should give feedback.
They might avoid giving feedback, or if they can’t avoid it, they could give meaningless responses,
or feedback that ends up being harmful to your product or community.
If the user thinks their feedback is only valuable to the product developers, some might decide
purposefully give bad feedback. For example, if users assume that the intent behind your “free” app
is actually to collect data to sell to advertisers without telling them, this could color the feedback
they give in surveys.Ideally, users will understand the value of their feedback and will see it manifest in the product in a
recognizable way. It’s up to you to connect the value users think they’re getting with what your AI
can actually deliver.
Connect feedback to user experience changes
Simply acknowledging that you received a user’s feedback can build trust, but ideally the product
will also let them know what the system will do next, or how their input will influence the AI.
It’s not always possible to communicate specifically when and how a user’s feedback will change
their individual experience. But if you do, make sure your product can deliver on the timeline you
promise. If you can, let users give feedback that has an impact right away.
Here are some approaches for describing feedback timing and impact:
1. “Thanks for your feedback”
Impact timing: None
Scope: None
2. “Thanks! Your feedback helps us improve future run recommendations”
Impact timing: “future” broadly
Scope: All users’ “recommendations”
3. “Thanks! We’ll improve your future run recommendations”
Impact timing: “future” broadly
Scope: Your “recommendations”
4. “Thanks! Your next run recommendation won’t include hills”
Impact timing: “next”. This is a bit vague, unless there’s an established cadence.
Scope: “Hills” category
5. “Thanks. We’ve updated your recommendations. Take a look”Impact timing: “We’ve updated” implies immediately
Scope: Demonstrated content updates
Aim for
Acknowledge user feedback and adjust immediately—or
let users know when adjustments will happen. Learn
moreAvoid
Don’t just thank users—reveal how feedback will benefit
them. They’ll be more likely to give feedback again.heck_circle_outline not_interested
rcle_fillercle_filleay_circle_ay_circle_Set expectations for AI improvements
For many systems, even with user feedback, much of the AI output is likely to be the same as it
was before. As a user provides more and more feedback, each piece will likely have less of an
effect on the AI model. It’s also possible the improvements you make to your model will be too
subtle for your users to register right away.
Sometimes feedback isn’t connected to improving the AI model at all. For example, a product may
include a “show more/less of this” feedback button as part of recommendations, but that feedback
may not be used to tune the AI model. It could simply be a filter on what content is shown and not
have any impact on future recommendations. If this is the case, and users have a mental model of
immediate tuning, this can create mismatched expectations and your users could be confused,
disappointed, and frustrated.
To avoid this situation, you can use the messaging examples above to make sure the feedback
scope and time to impact are clear. The user experience will be better if users know how long it will
take for your model to adjust to their needs.
Even with the best data and feedback, AI model improvements are almost never possible to
implement immediately. Your engineering team may need to wait to implement model updates
until they have additional signals from an individual, more data from a group, or a version release.
The reality of these delays means you need to set clear expectations for when people should
expect improvements to the model’s performance or better output relevance from your AI-powered
product. You can do this with clear design and messaging.Key concept
When thinking about opportunities to ask for user feedback, think about how and when it
will improve their experience with the AI. Ask yourself the following questions about each
feedback request:
1. Do all of your user groups benefit from this feedback?
2. How might the user’s level of control over the AI influence their willingness to provide
feedback?
3. How will the AI change based on this feedback?
4. When will the AI change based on this feedback?
Apply the concepts from this section in Exercise 2 in the worksheet➂ Balance control & automation
For AI-driven products, there’s an essential balance between automation and user control. Your
product won’t be perfect for every user, every time, so allow users to adapt the output to their
needs, edit it, or turn it off. Their context in the real world, and their relationship with the task at
hand dictates how they use your product. We talk more about whether or not to automate tasks or
augment processes in the chapter on User Needs + Defining Success.
Understand when people want to maintain control
When building AI-powered products, it’s tempting to assume that the most valuable product is one
that automates a task that people currently do manually. This could be taking a process that
currently requires seven steps to complete, and compressing it into one command. For example,
imagine a music app that could generate themed song collections, so users don’t have to take the
time to review artists, listen to tracks, decide, and then compile the song list.
The user benefit in products like these may seem obvious, but the teams who make these products
typically learn valuable lessons about how users feel about automation and control. There are
some predictable situations when people prefer to remain in control of task or process — whether
it has AI or not. We talk more about whether or not to automate tasks or augment processes in
the User Needs + Defining Success chapter, but here’s a short refresher.
People enjoy the task
Not every task is a chore. If you enjoy doing something, you probably don’t want to automate
the entire process.
People feel personally responsible for the outcome
For most small favors or personal exchanges, people prefer to remain in control and
responsible to fulfill the social obligations they take on.
The stakes of the situation are high
People typically like to remain accountable for physical stakes such as safety or health,
emotional stakes like expressing feelings, or financial stakes like sharing banking information.Personal preferences are hard to communicate
In situations where people have a creative vision, many people prefer staying in control so they
can maintain ownership and see their plan through to execution.
Understand when people will give up control
There are of course plenty of times when people feel perfectly fine giving up control, and prefer the
help of an AI or automated system.
When they are unable to do a task
Often people would do something if they knew how or had time, but don’t so they can’t. These
limitations can be temporary.
When a task is unpleasant or unsafe
Most people would prefer to give up control to avoid tasks that require a significant effort or
risk for little enjoyment or gain.
Allow for opting out
When first introducing your AI, consider allowing users to test it out or turn it off. Once you’ve
clearly explained the benefits, respect their decision not to use the feature. Keep in mind, they may
decide to use it later.
For your product to augment human tasks and processes, people need to be able to control what it
does based on their situation. One way to allow for this is to provide a way for users to complete
their task the regular, non-automated way. As we mentioned in the Mental Models chapter, the
manual method is a safe and useful fallback. Because errors and failure are critical to improving
your AI, your users will definitely need a manual failsafe, especially in the early days of using your
product.Keep in mind the relative priority of your product in the daily lives of your users. The people using
your product are most likely multitasking, using other products or apps, and generally getting
pulled in many directions. For example, for a navigation app, suggesting a faster alternate route
while someone is driving could get them home more quickly, but if their attention is split between
passengers and traffic conditions, it could be dangerous to use. Remember that your product likely
isn’t the focus of your users’ lives, so keep engagement requests strategic, minimal, and allow for
easy dismissal.
Provide editability
A user’s preferences may change over time, so consider how you’ll give them control over what
preferences they communicate to your ML model, and give them the ability to adjust it. Even if your
system’s previous suggestion or prediction wasn’t relevant before, it may become relevant in the
future. Your product should allow for people to erase or update their previous selections, or reset
your ML model to the default, non-personalized version.Aim for
Allow users to adjust their prior feedback and reset the
system. Learn morecheck_circle_outline
circle_ficircle_fiKey concept
Take time to think about your users’ expectations for control over certain tasks or
processes. Here’s a quick checklist for you and your team to run through before setting up
feedback and control mechanisms:
1. Can your AI accommodate a wide range of user abilities and preferences? 
2. Does your AI deal with highly-sensitive domains, such as health, wealth, or
relationships?
3. Will your AI take a long time to get to the target level of accuracy and usefulness?
4. Is your AI used in high-stakes situations, where it introduces a new mental model? 
5. Are there likely changes in the user’s needs that would require them to “reset” or
otherwise “take over” for the model? 
Apply the concepts from this section in Exercise 3 in the worksheetSummary
When building your AI-powered feature or product, feedback and user control are critical to
developing communication and trust between your user and the system, and for developing a
product that fulfills your users’ needs consistently over time. Feedback mechanisms partner
closely with Mental Models, Explainability + Trust, and how you’ll tune your AI. These three aspects
are key in improving your product for your users.
Remember when working with AI, there are three new considerations for feedback and control
mechanisms:
➀ Align feedback with model improvement. Clarifying the differences between implicit and
explicit feedback, and asking the right questions at the right level of detail.
➁ Communicate value & time to impact. Understanding why people give feedback, and building on
existing mental models to explain benefits and communicate how user feedback will change
their experience, and when.
➂ Balance control & automation. Helping users control the aspects of the experience they want to,
as well as easily opting out of giving feedback.
Want to drive discussions, speed iteration, and avoid pitfalls? Use the worksheet

Chapter 4Chapter 4.
DESIGN 
CHALLENGES 
IN MACHINE 
LEARNING 
PRODUCTSDESIGN 
CHALLENGES 
IN MACHINE 
LEARNING 
PRODUCTSThis fourth chapter was
written by Nadia Piet , 
a design researcher and 
strategist focused on 
AI/ML, data, futures & 
the human experienceAbout Nadia 
Nadia Piet is a design strategist and researcher 
fascinated by how we shape technology, and 
technology shapes us. She’s currently working with 
Bit, a research and prototyping studio on a mission 
to fast-forward the impact of emerging tech. Next 
to her role at Bit, she recently released the AI meets 
Design toolkit in collaboration with Accenture 
Interactive, facilitates workshops with DECODED, and 
previously worked as a freelancer for 7 years across 
a variety of roles, industries, and over 9 different 
countries. In her free time she likes to practice yoga, 
drink oat lattes with dino art, browse her Spotify 
discover weekly playlist, and scout for nudibranches 
in tropical waters.• Introduction
• Themes
+ Trust & Transparency
+ User Autonomy & Control
+ Value Alignment
• Worksheet
• Outro
• Recommended Reading/       
 AppendixChapter 4.Introduction
Every design material comes with unique opportunities 
and challenges. In the same way that designing an event 
poster is different from designing a mobile app, designing 
AI/ML -driven applications is different to designing mobile 
apps.
As we begin to see AI features popping up in our day-
to-day products and services, its challenges begin to 
materialize. They range from UX problems, such as 
explainability and user feedback mechanisms, to greater 
ethical challenges, such as echo chambers and data bias. 
Designing the user experience of adaptive, intelligent, 
and semi-autonomous systems present a range of new 
challenges for us designers to take on.
When thinking or talking about AI, we often imagine 
utopian or dystopian futures. Rarely, we dare to 
acknowledge its impact as something we have a hand in shaping (or even: a design challenge). Technology may be 
neutral and deterministic, but its development is not. As 
designers, we can take the raw material of AI and turn it 
into user, business, and social value.
This chapter is by no means all-encompassing and only 
scratches the surface on the complexities of designing for 
AI. Instead, it aims to provide a starting point for building 
a shared understanding around some of the complexities 
of designing AI/ML interactions, spark discussion, and 
invite everyone to take part in (re-)imagining how to design 
positive user/human experiences in algorithmic systems.
This ebook, which shares my research on designing 
Machine Learning Products, will address 3 different themes 
Trust & Transparency , User Autonomy & Control  and 
Value Alignment , highlighting 9 of the challenges that can 
arise within them, all supported with real life examples.Not all AI features are invisible to the user, nor should we 
want them to be. When confronting our users with these 
new systems, it is our job to help them understand how 
they work, be transparent about their abilities, construct 
helpful mental models, and make them feel comfortable in 
their interactions. Transparency is key to building trust in 
the system, and respecting user trust in your organization.
Why is trust & transparency 
important? 
• Access value
• Avoids confusion and disappointment 
• Lowers drop-out rate 
• Establishes trust in system
• Sustains trust in the brand/organization
• Easier interactions  Theme 1: 
Trust & 
TransparencyCHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS1. Explainability 
Making sense of the machine and communicating to the 
user why the system acts the way it does.
Design Strategy
Include a button to show people the data and features 
(where known) that went into the output and gradual 
detailing of the model’s logic.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSAirbnb
When Airbnb introduced ‘smart pricing’ based on supply 
and demand, adoption wasn’t as high as expected. They 
learned users were happy to be informed by the algorithm, 
but wanted to make the final decision for themselves. 
Airbnb then built an interface where hosts can evaluate 
price changes and accept or reject each of the algorithm’s 
recommendations.
Mixpanel
Mixpanel, the business analytics service company, uses 
machine learning to uncover user insights. The anomaly 
detection feature helps pick up on unusual behavior. 
The image shows the anomaly, but also what data the 
prediction is based on and which segments drive the 
anomaly, so that the user can make an informed decision 
about next steps. It even offers a “share” function to 
consult with a colleague for a 3rd opinion.
CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS2. Managing 
Expectations
Assisting the user to build helpful mental models of what 
the system can and cannot do by being transparent about 
abilities and limitations.
Design Strategy
Proper onboarding during the first interaction with the 
application or feature where abilities and limitations are 
established.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSSiri & Assistant
Each time the user calls upon Siri and it shows this 
screen, Siri has the opportunity to respond to queries 
and gradually introduce the user to its varied abilities. 
Onboarding and setting expectations becomes even 
more important in post-pixel interfaces because the user 
doesn’t have physical affordances nudging them where to 
go and what to do. 
The Assist chatbot doesn’t try to cover up its 
shortcomings, but instead makes the most of its limited 
abilities by explicitly stating its abilities and how a user 
must communicate a query in order for it to be processed 
successfully.
CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS3. Failure + 
Accountability
Assume failure and design graceful recoveries. Take 
accountability for mistakes and minimize the cost of errors 
for your user.
Design Strategy 
Apologizing, minimizing automation bias, allowing the 
user to indicate a mistake, and taking accountability for 
mistakes. CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSGoogle Home & Alexa
I make requests to my Google Home quite frequently 
that are returned with “I’m sorry, I can’t do that yet.’’ 
While disappointing, the apologies and promise of future 
improvement keep me from losing trust. In the example of 
Siri below, we can see it also recommends an alternative 
- a query it understands to be similar to the one initially 
called upon and one it can perform. Both of them 
recognized there is no way to user test against adaptive 
systems so they must be designed for failure.
CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSFail! Chatbots
While we can not predict every possible scenario and ML ’s 
adaptive nature makes testing a bit more tricky, we can 
anticipate obvious failures and prevent them from leading 
to awkward user experiences like below. Test your systems 
in real-life, out-of-the-lab context to bring to the surface 
common and obvious mistakes.
CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSBatman at the door 
One day as B.J. May approached his Nest doorbell, it 
wouldn’t let him in because the model thought he was 
Batman. Fortunately, the designers anticipated failure 
and designed 2 back-up ways for him to intervene and 
still get inside. Consequently, the failure didn’t have many 
consequences other than a funny Twitter thread.
Quote
“For the foreseeable future, 
AI models will sometimes fall 
short. This gap presents an 
opportunity for UX designers” 
Zuliani, 2019CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSQuestions to consider
• How do we build trust? 
Consistency is key for building trust, but it can be hard to 
practice in adaptive systems. 
• What is the right level of trust? 
Too little trust means the user doesn’t get any value from 
the system. Too much trust might lead to automation bias 
and poses risks for both the user and the organization.
• What is the right level of transparency? 
Too little means the user doesn’t trust your system. 
Too much means the user might get confused with an 
overload of information.
• How to design an interface that minimizes the cost to 
the user when the AI makes a mistake? 
Considering the impact of mistakes in your use case, and 
how to retaliate from a bad prediction to not harm trust. • Who is responsible and liable for the consequences of 
mistakes? 
• What are useful mental models to help users 
understand the AI? 
• What are good ways to explain predictions, confidence, 
and the logic underlying them in the interface? 
• How to explain those occasions when even the creators 
don’t know how it works? Theme 2: 
User Autonomy 
& ControlThe user must feel like they’re in charge of the system. 
People have justified concerns about giving up agency to 
(semi-) autonomous systems, and sharing the personal 
data required to make them work well. Respecting the 
human need for autonomy, users need a way to exercise 
consent and control over the system and their data based 
on their individual and contextual needs. One size rarely 
fits all and AI systems are no exception.
Why is user autonomy & 
control important?
Consent. Avoids feeling out of control. Avoid feeling being 
surveilled. Creates more user value through customization. 
Learn about user needs through feedback.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS4. Machine 
Teaching + User 
Feedback 
Allowing the user to teach the machine with implicit and 
explicit feedback loops and collecting direct data input.
Design Strategy 
Building in implicit and explicit feedback loops. 
Considering the latter, give the user a way to quickly 
indicate if this is helpful “yes or no”, then gradually ask for 
more feedback like “why or why not”, and how the system 
could have acted better.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS
Reporting inaccurate prediction scores - Source:  ZendeskZendesk:
Zendesk provides service providers with a predicted 
satisfaction score on their customer’s support tickets, 
so they can get a quick overview of the people who are 
most upset, or most pleased with their service, and can 
act accordingly. Next to the prediction there is a button to 
indicate when the model’s predictions are wrong, and why.Google Cards: 
Google Cards exemplifies a simple way to collect valuable 
feedback to reward or penalize your model. Last month 
they added more granular feedback methods to train the 
algorithm on what an individual user wants and help them 
get more relevant suggestions. 
CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS5. User Controls 
+ Customization 
Giving users the controls to customize the model to their 
needs and intervene with the data or model if needed.
Design Strategy 
Allow users to set intentions and configure parameters.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS
Imagining the Goals and Methods of UX for ML/AI, 
Philip van AllenPersonality Editor:
This speculative concept by Philip van Allen imagines 
what user controls for AI applications might look like. 
In this case it’s a personality editor, but we can imagine 
similar interfaces for other applications.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS6. Data privacy    
+ security
The need to collect, handle, and store user data with care, 
be transparent about who can access what data and why, 
while acknowledging their ownership.
Design Strategy 
Communicating benefits per data share, allowing easy opt-
in/out in a modular way, being cautious in sharing data, 
and making terms & conditions legible. CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS
Ever: 
Ever is an app to store and organize personal photos. 
When news came out that user data was used to train 
facial recognition algorithms, people were not pleased. 
It introduced this screen to communicate how it uses 
data, and gets explicit user consent, or allows them to 
easily opt-out. CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSFail! Data acquisition
A recent controversy happened around a tech giant hiring 
contractors to collect more data for its facial recognition 
models. Homeless people were targeted because they 
seemed more likely to participate in exchange for a 
nominal cash reward. Their faces were captured, while 
they were asked to play a game, and used as training data 
without their informed consent.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSQuote
“Human-centered design has expanded 
from the design of objects (industrial 
design) to the design of experiences 
(adding interaction design, visual design, 
and the design of spaces) and the next step 
will be the design of system behavior: the 
design of the algorithms that determine 
the behavior of automated or intelligent 
systems” 
Frog CEO Harry WestCHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSQuestions to consider
• How to integrate and interpret user feedback?
Will it come from implicit signals or explicit interface actions?
• To what extent should the user be able to customize the model? 
How might we give the user controls to tune the algorithm to their needs?
• How can we respect user data security, privacy, ownership? 
How can we, and should we, make consent more explicit?
• How can the user view, edit and wipe their data profile if it does not 
represent them?
• Is the data used beyond the service itself? 
• How is it protected?
• Is it anonymized?Theme 3: 
Value AlignmentDeploying AI systems across layers of society will affect 
the lives of individuals and groups across the globe in 
different and sometimes unexpected ways. Operating at an 
unprecedented scale and complexity, we must be mindful 
of biases, risks, system dynamics, and consequences, to 
make thoughtful trade-offs in our AI applications. Striving 
for value alignment between man and machine (and those 
operating the machine!) by integrating ethics at the core of 
our projects is required to shape this technology to help 
humanity
Why is value alignment 
important?
Otherwise, what’s the point? Ethics. Impact. Fairness. 
Human-centered. Prevent harm and reinforcing harmful 
bias. We’ve been messing around for too long already.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS7. Computational 
Virtue 
Translating subjective human needs, values, and 
experiences into algorithmic parameters the model can 
optimize for.
Design Strategy
Bench marking usefulness based on use case rather than 
what’s happening in      research. Sometimes the model 
is nowhere near perfect, but as long as it’s better than 
humans (it’s more accurate and/or faster and cheaper) 
there’s value.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSGoogle Clips
Google Clips set out to develop a camera that would 
automatically capture memorable moments in the life 
of young parents. An incredibly subjective and context-
dependent task, it required lengthy human discussions 
to agree on what the qualities of memorable moments 
were, and relied on extensive human training to guide 
the machine’s learning to adopt this understanding.
CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS8. Bias + 
Inclusivity 
Mitigating harmful bias and guarding inclusivity in data and 
models to ensure fair treatment for all.
Design Strategy
Checking for common unconscious bias, and having an 
inter-sectional team and user testing group (diverse in 
terms of gender and race, but also age, digital literacy, 
sexuality, level of education, lifestyle, political/religious 
beliefs, and other variables that might be relevant for your 
case).CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSHiring gender bias
The historical data we feed AI to learn about the world, 
might not always represent the present we inhabit, or 
future we wish to manifest. A clear example is recruitment 
models discriminating against women and minorities. 
The algorithm doesn’t favor anyone in particular It simply 
learns from past data in which majority of hires were white 
males, and perpetuates the pattern. Ensuring fairness in 
your model requires regular audits to detect and correct 
any harmful bias. How big tech companies compare in 
employing women
Share of tech and leadership roles held by women (%)
Source: companies
©FTTech roles Leadership roles
TwitterMicrosoftFacebookGoogleIntelApple0 5 10 15 20 25 30CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS9. Ethics + 
(Un)Intended 
Consequences 
Unprecedented scale, speed and complexity call for a new 
level of thoughtfulness and responsibility in anticipating 
impact and (un)intended consequences.
Design Strategy 
Recognizing good intentions does not equal positive 
impact. Be critical about anticipating potential 
consequences from various lenses, for example by using 
the consequence wheel, which is at times non-compatible 
with the ideology of capitalism and Silicon Valley’s ‘moving 
fast and breaking things’.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS
Affectiva
Affectiva is a market-leader in emotion recognition 
software that originated from MIT’s Media Lab. While 
a lot of the tech industry is catching up to make facial 
recognition work well across ethnicities, Affectiva faces 
the additional challenge of recognizing emotions across 
cultures. Committed to serving clients across the globe, 
they had to ensure their models would generalize well 
across a diverse population. It requires extensive efforts 
and resources to understand facial and physiological 
expressions, in order to build data sets that are inclusive.MIT Moral Machine
The MIT Moral Machine was built to gather human perspectives 
on moral decisions made by machine intelligence, such as 
self-driving cars. Anyone visiting the website is presented with 
a scenario in which the car has messed up, and now (in this 
case, guided by you) it has to choose who to kill. While the 
majority of us have intuitions, such as killing an older person 
over a child, making them explicit, (considering differences 
across cultures, and potentially activating them as a blueprint 
for machine moral decision-making) is a reality that’s pretty 
hard to come to terms with.
What should the self-driving car do?CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSPredicting mental health
While some moral choices appear obvious, many 
challenges around AI ethics sit in a gray area, where right 
or wrong it is not always obvious.
 
Aspiring to provide preventative and early mental health 
care, healthcare providers have successfully built models 
that predict the likelihood of depression and off-set of 
manic episodes in people with bipolar disorder, from social 
media data. Even operating from the noblest intention, 
making such inferences poses complex challenges.
What if the model is wrong and the person, or others, 
start questioning their well-being, it could become a self-
fulfilling prophecy? If the model is right would insurers 
(be allowed to) treat you differently knowing you’re at risk 
of mental illness? If your health insurer can infer such 
predictions from public social media data, could your 
employer? Could this information affect the hiring and 
firing process? Could advertisers use the predictions to target those in a vulnerable state. It’s hard to ‘unsee’ data 
and well-intended endeavours bring about a range of 
ethical dilemmas. Where do we draw the line? In which 
cases is it (un)ethical to collect, infer, and act on such 
data?
Cross-Domain Depression Detection
via Harvesting Social Media.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSQuote
“Now is our opportunity to 
shape that future by putting 
humanists and social scientists 
alongside people who are 
developing artificial intelligence”
Marc Tessier-LavigneCHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSQuestions to consider
• How do we translate subjective human experience into 
models and algorithmic parameters? 
• What to predict? 
• What objectives to optimize for? 
• How to protect the inefficiencies that make the human 
experience meaningful from being optimized to no 
end?
• How do we benchmark and evaluate our models? 
• How to design for positive, and anticipate and respond 
well to negative experiential, cultural, societal impact?
• How can we mitigate harmful bias and ensure fair 
treatment for everyone?
• How do we prevent destructive past patterns from 
leaking into our future models? • Who owns and has access to the data, the models, 
knowledge, and computational power? 
• How do we deal with power shifts as a result?
• How can we anticipate unintended consequences? 
• How do we evaluate our impact and reason our trade-
offs considering there is no universal moral framework? 
• Who is responsible for mistakes? 
• How can we protect against malicious use? 
• Is it more dangerous to release research with the 
risk of malicious use, or to keep research private and 
centralize power? CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSWorksheet
If you are prototyping or building an AI-driven application, you can use the worksheet below 
to jot down and share first thoughts on how you’re going to deal with the UX challenges.
Worksheet: UX of AI challenges
1. Explainability - How will we help our 
user understand certain outcomes?
4. User feedback - How will your user 
provide feedback to the system?
7. Computational translation - How 
will you turn needs into parameters?
10. Which other (design) challenges 
do you foresee?8. Bias & inclusivity - How will you 
prevent bias and guard inclusivity?5. User autonomy - How will the user 
be able to customize their experience?2. Managing expectations - How will 
we establish realistic expectations?3. Graceful failure & accountability - 
How will we design for trust in case of 
failure?
6. Data privacy & security - How will 
you collect, store, and handle data?
9. Ethics & (un)intended 
consequences - How will you look out 
for negative and positive impact?Value 
AlignmentUser Autonomy
& ControlUser Trust
& TransparencyCHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSOutro
As you’ve seen throughout this chapter, building human-centered AI applications is not an 
easy feat, and we’ve only just scratched the surface.
It’s easy to become paralyzed by the scale, complexity, and urgency of these challenges. 
But considering you’ve come this far, I suspect you are not. Or perhaps you are, but are 
channeling your courage to engage with it for that exact reason!
I also suspect you have developed all sorts of thoughts and ideas around the challenges over 
the course of reading this chapter. I’d love to hear about those.
As it’s set to impact all of us across life stages and at scale, designing human-centered AI 
is arguably one of the most interesting and important challenges of our time. It will require 
creativity, thoughtfulness, collaboration, and a commitment to shaping a future we want to 
live in. We’ll need people from all walks of life and all areas of expertise to figure this one out. 
Are you up for the task? 
If you decide to take part (in shaping the future, instead of delegating it to others and 
watching it happen), here are a few suggestions on how to get started.CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTS1. Close to home
Some of these challenges might seem like remote futures, 
but they’re not. Question if anything within your user 
journey is already influenced by algorithms, automation, 
and human-AI-interactions. Consider in what ways AI is 
likely to show up in your context and how these challenges 
appear alongside its opportunities. 
2. Read up
A handful of projects that go into the user experience 
design of AI that I recommend you to read are included 
on the next page. Beyond that, there are great learning 
resources about AI from a more general perspective 
such as Andrew Ng’s AI for Everyone on Coursera or 
elementsofAI.com.
3. Take a stance
In your work, as a designer or otherwise, how can you take 
on an active role in shaping these interactions with human 
values at its core? How can we move past principles, 
and begin building best practices around them? Besides 
creators, what is our role as users, as consumers, in 
demanding these elements of human-centered AI? 4. Join forces
Join fellow practitioners, reach out, share your knowledge 
and ideas, put them into practice. 
If you’re curious to explore the potential of AI within your 
projects, check out the AI meets Design toolkit  for hands-
on tools, exercises, and worksheets that integrate with the 
design thinking process.
This chapter is only a first block for you to build on. No one 
has the answers of what it means to build human-centered 
AI and how we might act on it, but we’re committed to 
looking for and evolving them through design, dialogue, 
and democratization. I hope you join us!CHAPTER 4. DESIGN CHALLENGES IN MACHINE LEARNING PRODUCTSRecommended Reading / Appendix
Experience Design in the Machine Learning Era - Fabien Girardin
Human-Centered AI Cheat Sheet by Josh Lovejoy
Human-Centered Machine Learning
Machine Learning and User Experience: A Few Resources by Michelle Carney
Guidelines for Human-AI Interaction
Projects by IF’s Data Permissions Catalogue
IBM’s Everyday Ethics for Artificial Intelligence
Google’s People + AI Research - Library
Arefact’s Tarot Cards of Tech
Fluxus Landscape of AI Ethics by Şerife Wong and Aparna AshokThis Brain food series will be released 
chapter-by-chapter, stretched over 
several months. In every chapter 
experts will dive deeper into specific 
topics related to AI.FOLLOWING
CHAPTERSFOLLOWING
CHAPTERS

Errors + Graceful
Failure
When AI makes an error or fails, things can get complicated.
This chapter covers:
When do users consider low-confidence predictions to be an “error”?
How will we reliably identify sources of error in a complex AI?
Does our AI allow users to move forward after an AI failure?
Want to drive discussions, speed iteration, and avoid pitfalls? Use the worksheet.What’s new when working with AI
As users interact with your product, they’ll test it in ways you can’t foresee during the development
process. Misunderstandings, false starts, and impropriety will happen, so designing for these
cases is a core component of any user-centered product. Errors are also opportunities. They can
support faster learning by experimentation, help establish correct mental models, and encourage
users to provide feedback.
There are some great guides for communicating errors that still apply when creating AI-driven
features and products, including these Error Messaging Guidelines from the Nielsen Norman
Group.
Key considerations for dealing with errors in AI-driven systems:
➀ Define “errors” & “failure”. What the user considers an error is deeply connected to their
expectations of the AI system. For example, a recommendations system that’s useful 60% of the
time could be seen as a failure or a success, depending on the user and the purpose of the
system. How these interactions are handled establishes or corrects mental models and
calibrates user trust.
➁ Identify error sources. With AI systems, errors can come from many places, be harder to
identify, and appear to the user and to system creators in non-intuitive ways.
➂ Provide paths forward from failure. AI capabilities can change over time. Creating paths for
users to take action in response to the errors they encounter encourages patience with the
system, keeps the user-AI relationship going, and supports a better overall experience.➀ Define “errors” & “failure”
Integrating AI into your product means establishing a relationship that changes as the user
interacts with the AI system. Users will likely come to expect that interactions are curated to their
tastes and behavior, and that experiences will differ from user to user.
What defines an error, then, can also differ from user to user based on their expertise, goals,
mental models, and past experience using the product.
For example, if someone assumes that an AI-driven music recommendation system is only using
songs indicated as “favorites” to provide recommendations, then they might consider it an error if
the system recommends a genre outside of what’s in their favorites list. Someone else who
assumes recommendations are based on a wide range of factors might not consider this an error.
There’s more information on fostering a good user understanding of the system’s capabilities,
limitations, and interaction model in the chapter on Mental Models.
Identify user, system, and context errors
In non-AI systems, “user errors” are typically defined from the point of view of the system
designers, and the user is blamed for “misuse” resulting in errors. “System errors” on the other
hand, are typically defined from a user’s point of view: users blame the system designer for a
product that’s not flexible enough to meet their needs. In AI systems, users can encounter a third
type of error, based on the system’s assumptions about the user. These are context errors.
Context errors are instances in which the AI system becomes less useful through making incorrect
assumptions about what the user wants to do at a certain time or place. As a result, users might
be confused, fail at their task, or abandon the product altogether. Context can be related to
individual lifestyle or preferences, or patterns can be linked to wider cultural values.
For example, if someone using a recipe suggestion app frequently rejects recommendations in the
evening, this pattern should signal to the product team that there may be a persistent reason why.
If the user works a night shift, they might simply prefer breakfast recommendations before they
head to work. Whereas if all of the users in a certain group consistently rejected meat-based
suggestions during a certain time of year, that might be linked to a cultural value or preference that
your team hasn’t accounted for.To prevent or correct for context errors, you’ll need to look at the signals that the AI uses to make
assumptions about the user’s context and evaluate if they are incorrect, overlooked, undervalued,
or overvalued.
Aim for
Provide proactive recommendations when AI has high
confidence about the user’s context. Learn more
Avoid
Don’t act on assumptions. Doing so can lead to context
errors.heck_circle_outline not_interestedContext errors and other errors can be thought of as an interaction between user expectations and
system assumptions. Here’s a breakdown of how user expectations and system expectations
interact and cause errors.
Categorize user-perceived errors
Context errors. These are often true positives: the system is “working as intended,” but the
user perceives an error because the actions of the system aren’t well-explained, break the user’s
mental model, or were based on poor assumptions. For example, if a friend’s flight confirmation
email creates an event on your calendar, but you don’t want or need it.
Addressing these errors depends on their frequency and severity. You could change the way the
system functions to better align with user needs and expectations. Or, adjust your product’s
onboarding to establish better mental models and shift the user’s perception of these situations
from errors to expected behaviors.
Failstates. Your system can’t provide the right answer, or any answer at all due to inherent
limitations to the system. These could be true negatives: the ML is correct in discerning that
there’s no available output for a given input, but according to users, there should be. For
example, if an image recognition app can identify many different kinds of animals, but a user
shows the app a photo of an animal that wasn’t in the training dataset and therefore is not
recognized, that’s still a true negative.
Messages about user-perceived errors should inform the user as specifically as possible about
the system’s limitations.Aim for
Use error states to tell the user what inputs the AI needs
or how the AI works. Learn more
Avoid
Don’t miss an opportunity to explain your AI system.
Diagnose errors that users don’t perceive
Since these errors are invisible to the user, you don’t need to worry about how to explain them in
the user interface, but being aware of them could help you improve your AI.heck_circle_outline not_interestedHappy accidents. The system might flag something as a poor prediction, limitation, or error, but
in rare cases it could be helpful or interesting anyway. For example, a user asks a smart
speaker to take out the trash as a joke, knowing it isn’t possible, and she and her family are
amused at the speaker’s response.
Background errors. Situations in which the system isn’t working correctly, but neither the user
nor the system register an error. For example, if a search engine returns an incorrect result and
the user is unable to identify it as such.
These types of errors may have significant consequences if undetected for long periods of
time. They also have important implications for how your systems measure failure and error
rates. Because you’re unlikely to detect these errors from user feedback, you’ll need a dedicated
quality assurance process to stress test the system and identify “unknown unknowns”.
Account for timing in the user journey
Users may react differently to errors they encounter in the early days of using your product versus
later, when they have more ingrained expectations of what it can and can’t do. How long the user
has been using the product should impact how your AI communicates errors and helps users get
back on track.
For example, when a user interacts with a music recommendation system for the first time, they
might not consider it an error when the initial recommendations aren’t relevant to them. However,
after a year of listening, liking, and adding favorites to playlists, the user might have higher
expectations for the relevance of the system’s recommendations and therefore consider irrelevant
recommendations to be errors.
Weigh situational stakes & error risk
In some situations, AI errors and failure are inconvenient, but in others, they could have severe
consequences. For example, errors in AI-suggested email responses have very different stakes
than errors related to autonomous vehicle handling. This is true for non-AI systems as well, but the
complexity of AI systems and the possibility of context errors requires that you give extra thought
to the stakes of each situation where your AI is making decisions.Any given scenario has inherent stakes, but the risk of errors can change depending on other
contextual factors. For example, if a user is multitasking or is under time pressure while using your
AI-driven product, then they have fewer mental resources available to double-check the system
output.
Gauge the risk for potential errors
Lower
User has expertise in the task
Extremely high system confidence
Many possible successful outcomes
Higher
User is a novice at the task
Reduced attention or response time (multi-tasking)
Low system confidence
Narrow definition of successful outcomes
Assess the stakes of the situation
Lower
Experimentation
Play or creativity
Lightweight entertainment
Non-essential recommendations
Higher
Health, safety, or financial decisions
Sensitive social contextsWhen considering what system responses, user responses, and messaging are required in
different situations, refer to the section on designing your reward function in the User Needs +
Defining Success chapter. Refer also to the high-stakes scenarios and corresponding required
explanations identified in the Explainability + Trust chapter.
Key concepts
Before you start designing how your system will respond to errors, try to identify errors
that your users can perceive already, or that you can predict will occur. Then, sort them
into the following categories.
1. System limitation. Your system can’t provide the right answer, or any answer at all,
due to inherent limitations to the system.
2. Context. The system is “working as intended,” but the user perceives an error because
the actions of the system aren’t well-explained, break the user’s mental model, or were
based on poor assumptions.
Also be on the lookout for background errors, situations in which the system isn’t working
correctly, but neither the user nor the system register an error.
For each situation above, ask yourself:
How does this error impact the user?
Are the stakes high or low for the user in this situation?
Apply the concepts from this section in Exercise 1 in the worksheet➁ Identify error sources
The User Needs + Defining Success chapter illustrates how to design and evaluate the reward
function, which the AI uses to optimize its output. The range and type of possible errors in your
system will depend on this reward function, but generally speaking there are several sources of
errors unique to AI.
Discover prediction & training data errors
These errors come from issues with your training data and the way you’ve tuned your machine
learning model. For example, a navigation app might not have had training data for roads in a
certain geographic region, limiting its capabilities.
Mislabeled or misclassified results
When the output from the system is incorrectly labeled or classified due to poor training data.
For example, inconsistently-labeled berries in the training data for a plant classification app
leads to misclassification of strawberries as raspberries.
Response: Allow users to give guidance or correct the data or label, which feeds back into the
model to improve the dataset or alert the team to the need for additional training data.
Poor inference or incorrect model
When the machine learning model isn’t sufficiently precise , despite having adequate training
data. For example, a plant classification app has a well-labeled dataset that includes berries,
but poor model tuning returns a large number of false positives when identifying strawberries.
Response: Allow users to give guidance, or correct the data or label, which feeds back into the
AI model and helps you tune it.
Missing or incomplete data
When the user reaches the edges of what the model can do based on the data it was trained
on. For example, if a user tries to use a plant classification app on a dog.Response: Communicate what the system is supposed to do and how it works. Then, explain
what it’s missing or its limitations. Allow users to give feedback about the needs that the
system isn’t meeting.
Review the chapters on Data Collection + Evaluation and Explainability + Trust to see more
information on how to identify the right data sources and how to explain them.
Predict or plan for input errors
These errors come from the user’s expectation that the system will “understand” what they really
mean, whether or not the AI is actually capable of doing so.
Unexpected input
When a user anticipates the auto-correction of their input into an AI system. For example, the
user makes a typo and expects the system to recognize their intended spelling.
Response: Check the user’s input versus a range of “expected” answers to see if they intended
one of those inputs. For example, “Did you mean to search for XYZ?”
Breaking habituation
When a user has built up habitual interactions with the system’s UI, but a change causes their
actions to lead to a different, undesired, result.
For example, in a file storage system, the user has always accessed a folder by clicking in the
top right hand region of the interface, but due to newly-implemented AI-driven dynamic design,
folder locations change frequently. Clicking in that area due to muscle memory now opens the
wrong folder.
Response: Implement AI in ways that don’t break habituation, such as by designating a specific
area of the interface for less-predictable AI output. Or, allow users to revert to, choose, or retrain
a specific interaction pattern. See more suggestions in this article on habituation from the
Google Design blog.
Miscalibrated inputWhen a system improperly weights an action or choice. For example, if one search for an artist
in a music app leads to endless recommendations for that artist’s music.
Response: Explain how the system matches inputs to outputs and allow the user to correct the
system through feedback.
Check output quality for relevance errors
Your AI-driven system won’t always be able to provide the appropriate information at the right time.
Irrelevance is often the source of context errors — conflicts between the system working as
intended and the user’s real-life needs. Unlike user input errors, or data errors, these aren’t issues
with the veracity of the information or how the system makes decisions. These errors are issues in
how and when those results are delivered — or not.
Low confidence
When the model can’t fulfill a given task due to uncertainty restraints: lack of available data,
requirements for prediction accuracy, or unstable information. For example, if a flight price
prediction algorithm can’t accurately predict next year’s prices because of changing conditions.
Response: Explain why a certain result couldn’t be given and provide alternative paths forward.
For example, “There’s not enough data to predict prices for flights to Paris next year. Try
checking again in a month”.
Irrelevance
When the system output is high confidence but presented to users in a way that isn’t relevant to
the user’s needs. For example, a user books a trip to Houston for a family funeral and their
travel app recommends some “fun vacation activities”.
Response: Allow the user to provide feedback to improve the system’s function.
Disambiguate systems hierarchy errorsThese errors arise from using multiple AI systems that may not be communicating with one
another. These overlaps can result in conflicts over situational control or a user’s attention. Plan
ahead for how your AI system might interact with other systems, and provide users with multiple
levels of control for managing output and avoiding conflicts.
Multiple systems
When a user connects your product to another system, and it isn’t clear which system is in
charge at a given time.
For example, a user connects a “smart thermostat” to a “smart energy meter,” but the two
systems have different methods of optimizing for energy efficiency. The systems send
conflicting signals to one another and stop working properly.
Response: Explain the multiple systems that are connected, and allow the user to determine
priority. Consider visual ways to represent the relationship between multiple AI systems in the
product interface, perhaps by mapping them onto different locations.
Signal crashes
When multiple systems are monitoring a single (or similar) outputs and an event causes
simultaneous alerts.
Signal crashes increase the user’s mental load because the user has to parse multiple
information sources to figure out what happened, and what action they need to take.
For example, imagine if a user’s voice input was recognized by multiple voice-activated
systems, which simultaneously respond in different ways. That would be overwhelming, and the
user likely wouldn’t know what to do next.
Response: Allow the user to set independent controls for your AI that don’t overlap with other
signals. For example, the watch word for a smart speaker to start listening could be unique. If
your team can avoid creating new context errors, the system could attempt to infer which
system is the one the user intended to have primacy.Key concepts
For each error, try to determine the cause based on the resulting user experience. Ask
yourself what kind of error it could be based on the examples below.  
 
Prediction & training data errors occur when… the system’s capabilities are limited by
its training data.  
Input errors occur when… the user anticipates the auto-correction of their input into an
AI system, or their habituation is interrupted.  
Relevance errors occur when… the system output appears in a time, place, or format
that isn’t relevant to the user’s needs.  
System hierarchy errors occur when… your user connects your product to another
system, and it isn’t clear which system is in charge.
 
Apply the concepts from this section in Exercise 2 in the worksheet➂ Provide paths forward from failure
Setting reasonable expectations about the limitations of your technology helps set up good
experiences with errors, but how users move forward is equally important. Focusing on what your
users can do after the system fails empowers them while maintaining the usefulness of your
product.
If you were a waiter in a restaurant, and a customer wanted something on the menu but the kitchen
ran out, you’d have come up with an alternative option, taking into account their implied
preferences. For example, “We don’t have Coke, but is Pepsi OK?” In the case of higher situational
stakes, there should be an additional check to make sure the alternative is indeed a safe option.
For example, if the user wants a dish the restaurant doesn’t have, but the closest alternative
contains a common allergen, the waiter would want to think twice before making the
recommendation. Your primary goal in these failstates should be to prevent undue harm to the
user and help them move forward with their task.
Create opportunities for feedback
As highlighted in the above sections, many of the errors your users experience require their
feedback in order to improve the system. In particular, error types that aren’t easily recognized by
the system itself, such as mislabeled data, rely on outside feedback to fix.
Include opportunities for users to provide feedback both when presented with an error message as
well as alongside “correct” system output. For example, ask a user what they expected to happen
after a system failure, and provide the option to report inappropriate suggestions.Aim for
Ask the user for feedback if they repeatedly reject AI
outputs. Learn more
Return control to the usercheck_circle_outline
circle_ficircle_fiWhen an AI system fails, often the easiest path forward is to let the user take over. Whether or not
giving users full “override” powers is possible and what it looks like will differ from system to
system. In some cases, reverting to manual control could be risky or dangerous. For example, if a
navigation system stops giving directions altogether to a user who is navigating through an
unfamiliar environment during rush hour traffic.
When this AI-to-manual control transition happens, it’s your responsibility to make it easy and
intuitive for users to quickly pick up where the system leaves off. That means the user must have
all the information they need in order to take the reins: awareness of the situation, what they need
to do next, and how to do it.
Assume subversive use
Though it’s important to write informative and actionable error messages, your team should design
your product knowing that some people will intentionally abuse it. That means that in addition to
mapping out potential negative impacts of your product, like in the User Needs + Defining Success
chapter, you should try to make failure safe, boring, and a natural part of the product. Avoid making
dangerous failures interesting, or over-explaining system vulnerabilities — that can incentivize the
users to reproduce them.
For example, if every time a user marked an email in their inbox as spam, the email app explained
why the system did not classify that message as spam, that could give spammers useful tips on
how to avoid getting caught by the filter.
To get a really clear idea of all the potential dead-ends in your product, invest in beta-testing and
pilot programs. Many products are like a maze of options and possibilities; while the builders focus
on the happy path, users can get caught in the labyrinth.Key concepts
You can use quality assurance exercises and pilots initially to find errors, but you should
continue monitoring to cover any new features you launch. As a team, decide on some
channels you’ll monitor for new error discoveries from your users. Which of the following
error report sources could work for your team?
Reports sent to customer service
Comments and reports sent through social media channels
In-product metrics
In-product surveys
User research
Out-of-product surveys
Deep-dive interviews
Diary studies
As you discover each error, you’ll then need to work as a team to design the correct path
forward from that error.
 
Apply the concepts from this section in Exercise 2 in the worksheetSummary
Learning, machine or otherwise, can’t happen without making mistakes. Designing and building
your system with the knowledge that errors are integral will help you create opportunities for
dialogue with your users. This in turn creates more efficient pathways for error resolution, and for
the users to complete their goals.
When designing your error experience, be human, not machine. Error messages may need to
disclose that the system made a mistake. Address mistakes with humanity and humility, and
explain the system’s limits while inviting people to continue forward.
➀ Define “errors” & “failure”. When dealing with a probabilistic, dynamic system, a user could
perceive a failure in situations where the system is working as intended. Acknowledging that a
product is a work-in-progress can help encourage the adoption and feedback that designers and
engineers need to continue improving the AI.
➁ Identify error sources. The inherent complexity of AI-powered systems can make identifying the
source of an error challenging. It’s important to discuss as a team how you’ll discover errors and
discern their sources.
➂ Provide paths forward from failure. The trick isn’t to avoid failure, but to find it and make it just
as user-centered as the rest of your product. No matter how hard you work to ensure a well-
functioning system, AI is probabilistic by nature, and like all systems, will fail at some point.
When this happens, the product needs to provide ways for the user to continue their task and to
help the AI improve.
Want to drive discussions, speed iteration, and avoid pitfalls? Use the worksheet

Chapter 3.CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIMAKE 
SOCIETY 
SAFER WITH 
DESIGN & AIChapter 3.
MAKE 
SOCIETY 
SAFER WITH 
DESIGN & AIThis third chapter was 
written by Sophie Hart , 
Head Of Design at Vortexa. • Introduction
• With Power AI comes Great Responsibility
• Where, and how, are groups like law 
enforcement, defence and security currently applying AI?
• The importance of conveying risk responsibly
• Situational awareness and rescue: Rapid   AI Map
• Intelligence and evidence gathering: Qumodo Discover
• Digital assistant: TakeDown
• Opportunities are expanding with devices
• ConclusionChapter 3.CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIIntroduction.
In the first two chapters of the Artificial Intelligence Driven 
Design series we focused on what Artificial Intelligence and Machine Learning are and how you can use design to train AI. 
In this chapter by Sophie Hart and the team at Qumodo, 
we get a unique deep dive into how design and AI are used to make society safer, supported by some interesting insights and real life cases.Qumodo researches, designs and develops AI technology - their team of scientists, educators and technicians, work with public and private sector organisations across defence, security and law enforcement to make the world a safer place.CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIWith Power  AI 
comes Great 
Responsibility
Design and artificial intelligence are powerful tools that 
can be used to make the world a safer place. Over the last few years, there’s been an upsurge in interest around AI technology and how it’s used to analyse large volumes of data and provide useful insights. Those aware of its benefits recognise that it can help us be more efficient and accurate in our decision making; we can even train it to decide for us, like self driving cars taking us from A to B. This powerful technology is impacting every industry; from consumer to business to government.
When looking at common case studies on designing for AI, 
we often focus on consumer facing products such as the Roomba or Netflix, probably because their mainstream nature means increased user exposure and understanding of their benefits. What isn’t discussed as often (at least in the design world) is how AI is being used in industries whose primary focus is creating a safer society; industries such as law enforcement, online safety/moderation, and defence and security (for this chapter, we’ll call them public safety industries).
As we’re now at the very heart of a technological 
revolution, a criminal revolution is very likely to follow . 
Unfortunately, with many of the benefits the digital world 
brings, comes the risk of these technological advances being manipulated for bad. For example, chatbots could be used to scam people on a mass scale, or photos being manipulated to tell fake stories.
It’s the responsibility of public safety industries to stay one 
step ahead in order to be able to deal with the scale and volume of these crimes, and to turn the data associated with them into actionable intelligence. AI, now more than ever, is the perfect technology to support this industry, and design is the bridge to its accessibility.CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIWhere and how 
are groups like law enforcement, defence and security currently applying AI? 
Teams at the leading edge are starting to use AI for 
intelligence gathering and decision support. Just a few 
examples of what they’re using are: 
Powerful search capability to explore and link data 
Object detection and facial recognition to help find 
clues in imagesLocation intelligence to solve crimes as well as help with situational awareness in areas of conflict or natural disaster
Chatbots to help make data exchange effortless 
and natural
Controversially, there is some interest in looking at 
predicting crime with AI. This is a rocky area as it’s very 
hard to provide a machine with sufficient data about a 
person to make an accurate prediction. If you don’t have enough data, you have to generalise, and this leaves room 
for bias, which could potentially be unfair or unethical. 
While the industry knows how to capture, manipulate and 
interpret this data, the practical application of it is more 
complex. This is the most critical time to get it done right - as the consequences for getting it wrong, as you can 
imagine, are far graver than Netflix suggesting a film you 
don’t actually want to watch. CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIDesigners need to play a significant role in shaping these 
systems. Typical decisions designers make shouldn’t just involve regular design and UX considerations, such as “Is the brand and company purpose being communicated effectively?” or “Can users navigate the system or site easily and efficiently?” Users in public safety industries often have to make critical decisions under intense time pressure or in dangerous environments, and therefore working with interfaces that have clear visual hierarchy is even more important than in other cases. 
Additionally, they may not be hugely familiar with AI, and so 
it is the designer’s responsibility to get them to engender their trust in the system; to communicate enough about the processes undertaken and demonstrate transparency around how the AI has suggested a decision, so that the user is encouraged to work with it. This is how the AI can be exploited to its fullest, and in these industries this is of 
paramount importance as people’s lives are often at stake . Design and 
Psychology at the heart of what we do
At Qumodo, we’re building AI powered tools for our 
customers, all with the aim of making the world a 
safer place. Ben Gancz, who started the company, was previously a detective for the Police and also worked in an 
R&D team for the UK government. During that time he saw 
teams trying to set up new tech that used AI, and while they were enthusiastic about the new technology, he also 
saw a noticeable drop off in adoption due to the poor 
design and experience of the tools. They were treating it like a traditional computer that does what it’s asked and were put off when it did weird things.CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIPeople often expect and trust machines to work and be 
binary - to be factual 100% of the time. However, machine learning is just that; a learning technology that must be taught. A new type of relationship needs to be built between humans and intelligent machines, people need to understand the machines’ intentions, its limitations and abilities. Any technology using machine learning must be given time to develop, and during that time it needs to be allowed to make mistakes. Those mistakes must then be highlighted, so that the AI learns to make them less and less frequently, and eventually not at all. Drop off in usership is highly likely when the necessity of this process isn’t clearly communicated, meaning that if a system proves unreliable in the first instance, people give up. 
To prevent this, a tool should be designed to demonstrate 
how it has reached its conclusions, in order for users to trust it appropriately. Trust doesn’t need to be inextricably linked to the reliability and maturity of a system, as long as the limitations are explained and understood to be temporary. A user can then appreciate that in certain instances their role is to contribute their decision making expertise to make up for where the machine falls short, meaning overall the system can better itself and become more reliable, resulting in an impressive and effective human machine team.
The importance 
of conveying risk responsibly
Some of the important decisions made by people in 
public safety industries include finding victims of child abuse, determining whether or not someone should be incarcerated, or how quickly teams should be deployed under the threat of a terrorist attack. Therefore, the speed and accuracy of the information provided to them is extremely important, which is why AI can be so beneficial. While timeliness is important, the decision maker should CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIalso be provided with a fully informed, holistic version 
of the story - they need to be shown evidence of the reliability of the source.
Design can help to convey appropriate  trust by showing 
the user information such as:
AI confidence  - this can be done with percentages, ratios, 
traffic light systems and moreSources - naming exactly where the data has been pulled 
from, consider if it’s already well known and trustworthy to the user, also ensuring it has been extracted from an appropriately diverse range of sources
Human driven recommendations  - who else has read, 
suggested or contributed to the information? What is the 
volume of confirmation from other sources?
Regular feedback  - in response to input from the users, 
setting expectations.Through rapid prototyping and working directly with users, 
you should be able to find the sweet spot with building tools that help with quick decision making, but also clear enough that it is accurate and considered.
The familiarity of a tool is also very important for designers 
to consider. In his book, Hooked: How to Build Habit Forming Products, Nir Eyal talks about ‘Triggers, Actions, Rewards and Investment’ - basically tips to consider when building compelling, enjoyable and addictive digital products. For public safety industries, this is just as important as it is in any other industry, however finding a balance between habit-forming and retaining high levels of user attention is key. Users need to be encouraged to keep their critical thinking hats on, and not allow their attention to dwindle. For example, a moderator could be tasked with categorising child abuse imagery - if the AI gives them a false sense of comfort and ease, they could fall into a trap and get lazy with the task, feeding the system incorrect data, in turn making an algorithm less reliable. The system can only learn what it has been taught.CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AISituational 
awareness and rescue: Rapid AI Map
Rapid AI Map is a tool that was first conceived a year ago at 
a hackathon run by the UK Ministry of Defence (MoD). They wanted a system to help Geospatial Analysts produce up-to-date maps for search and rescue operations, such as in the aftermath of tsunamis, hurricanes and earthquakes. Although Google Maps may be very useful to the average consumer, according to techwalla, Google Maps is only updated every one to three years - a timeframe that is not sufficient for troops who have been flown into areas of unrest or where natural disasters have occurred. And while they also have access to satellite and drone generated imagery, they’re unable to convert this into mapping information at speed.This system automatically extracts mapping data from satellite imagery using machine learning. To start with, we focussed on the detection of new and missing buildings and roads, as these were a high priority for the users. When awarded the work from DTSL (Defence, Science and Technology Laboratory), we conducted workshops to dig deeper into requirements. During these sessions we found that Geospatial Analysts were under a lot of time pressure and the current processes were very manual. We also discovered that they had experimented with other object detection algorithms before, however the issues with accuracy made the systems feel unreliable and more effort to correct than it was worth.
To overcome this, machine learning was used with a 
human in the loop to help improve its performance over time, rather than just straight forward machine vision (object detection and classification) processes. Design considerations taken into account include: CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AI
Confidence : A traffic light system, as well as percentages 
are used to display its confidence in its decision making (in 
this instance, recognising buildings and roads). The user 
can quickly identify what it’s certain in by seeing areas of green.
Feedback : The system asks the analysts to help assess 
what has happened to the buildings and roads it is less 
confident with, and quickly confirm whether they’re missing, new or need to be edited. This feedback improves 
the quality of the data, making the algorithm more and 
more accurate over time.
Collaboration : Team members can add qualitative notes, 
and see who else has contributed to the assessment and 
editing of the vectors generated by the algorithm.
Reliable sources : Geospatial analysts are familiar with 
OpenStreetMaps and we will provide links to new sources 
of data, such as satellite imagery from other companies. We’ve also included information about the algorithms 
used, if they are particularly concerned or interested in 
the technology. Intelligence and evidence gathering: CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIIntelligence 
and evidence gathering: Qumodo Discover
Qumodo Discover is an evidence search engine that uses 
AI to help analysts and investigators unearth clues in their ever-growing databases of digital media. The system is currently being tested and used by the UK Police for child abuse investigation, and can also be used for other crimes such as terrorism and fraud. 
Our primary focus was to keep the tool as simple to use 
as possible. These days, the concept of search is second nature to us, but behind the scenes, there is a lot of work that goes in! In the early days, we were lucky to receive a design grant from InnovateUK to give us a bit of breathing space to do our research properly (Tip: both government and the business world are starting to notice and appreciate the ROI on design. Keep an eye out for funding opportunities in your country, there’s probably more than you think!). During the initial research phase, we had a head start, as the Founder Ben was a relatively fresh “user” in the space from his detective days. We also gathered a team of analysts and investigators from other industries to help us make the tool as wide reaching and useful as possible, designing a search tool to:
Understand the facets of data  - take the time to discover 
every parameter and possibility of the data so you can 
help extract what’s useful for the user. If you also keep abreast of AI techniques, you’ll be able to think of new and interesting ideas to combine the two.
Find common search patterns and themes  - if you’ve 
played cluedo before, you’ll know that most investigators 
are looking to string together a story about an event. identities, locations, times, objects, sources etc. Imagine if you could search for Professor Plum holding the candle stick, busted!CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIInteresting results - after understanding the 
parameters of the data and doing user research, our team - which is a hybrid of users, data scientists, designers, developers, psychologists - tinker with what to show, what not to show, what to do with false positives and so-forth.
Show the magic upfront - this was a wise tip from 
InnovateUK. If you have some “secret-sauce” that is significantly more effective than their current method of doing things, facilitated by AI, show them as quickly as possible. This new method might require some onboarding, but good UX can teach the user what to do. 
California sushi roll UX  - In contrast to the point 
above, Nir Eyal (as previously mentioned) has a great 
analogy for how people in the US started to love sushi, have a read here . The main concept was “people don’t 
want something truly new, they want the familiar done differently.” People are used to nice, clean search interfaces - no need to reinvent the wheel.
CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIDigital assistant: 
TakeDown
TakeDown is an app that is currently in its research and 
development phase. It uses AI to empower individuals to regain control of their self-produced explicit images. It’s been recorded that 88% of self-produced explicit images are shared on without the subject’s consent. Whether an individual knows someone has shared an image of them without consent; they are concerned someone has or will do in the future; or they themselves have accidentally shared their image and are worried about where it might end up, TakeDown is designed to help them.
In the first instance the app will focus on the removal of 
self-produced explicit images from social media platforms; and then tackle other content sharing sites. Our motivation is not just the product itself, but to educate individuals about the importance of consent when sharing content of others, as well as access to other support and information for our users. 
We’re hoping that this tool will not only help victims, but 
many other entities that are interested in this crime, including NGOs, police, schools, parents, researchers, 
web-hosts and social media companies. The success 
of the tool is dependent on the balance of trust between the people involved and the technology supplied. So far, we’ve developed a version 1 prototype, but going forward, these are the things we’ll take into consideration:
Appropriate trust and expectation setting  - the system 
uses a chatbot to help explain to the user that firstly, it’s 
not a human, but also explains clearly what it can and 
can’t do. Flexibility a typical form lacks.
Tone of voice  - with such a diverse audience who are in 
a particular state of mind when approaching the app, the 
tone of the chatbot is critical.CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIThe hand over of responsibility between humans         
and technology  - during this research phase, we’re looking 
deeper into when people feel comfortable with humans getting involved, and when they’d rather just communicate with a machine.
Security  - imperative in all technology companies, but 
particularly in a tool like this, we’re exploring finding the 
right balance of making the tool as secure as possible, while remaining accessible to all users.
Brand reputation  - at a time where there is a spotlight 
on responsibility of data handling, we want to be seen as 
accessible, understanding but most importantly, reliable. 
Partnerships  - working closely with social media 
companies, NGOs, police and more will make the app 
more efficient and effective. They will help us to build robust evidence data bundles that they trust so we can remove more humans from the process.CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIOpportunities are 
expanding with devices
There has been a gadget explosion over the last five or so 
years. Technologies like VR and AR have moved further along in the Gartner Hype Cycle  and the hardware is finally 
here to support it. It’s our responsibility as designers to upskill, or at least understand at a high level, what these gadgets can do and what frameworks are needed for them.
While there are some seriously exciting new tools out 
there, desk tools and 2D software are still dominating the business and government worlds. It’s important to continue to make this experience great, as its likely to have 
the biggest impact in the present.Having said that, introducing a new capability (à la the 
California Sushi Roll method) that is easy to learn and understand, such as 3D and touch screen elements, is a good way to bring users on the journey. In defence, VR, AR and digital twins are becoming increasingly popular, however rigorous testing needs to be done to assess whether it actually speeds up a decision maker’s accuracy and speed, or whether a “deeper” experience is actually too overwhelming, maxing out their cognitive load.
If you’ve spent most of your career building beautiful 
websites and slick consumer apps, you may not have needed to think too deeply about the human-computer-interaction (HCI) aspects of what you’re designing. But in law enforcement, defence and security, this is really important. For example, unless fully tested and verified, most soldiers won’t wear gloves on the battlefield with capacitive touch, preventing them from using touchscreens. Some other design considerations for the military include:CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AI• Using dark screens to help save battery
• If someone is being shot at, is glass near the face a bad 
idea?
• How high-stress is their environment? Is the interface you’re designing simple enough to be fool proof? Are the buttons big and clear enough at a glance?
More than ever before, design teams need a diverse range of skills and specialties to help their businesses and customers be ahead of the curve . Looking back at 
the Hype Cycle, I’m curious about smart dust , it’s so 2030!CHAPTER 3. MAKE SOCIETY SAFER WITH DESIGN AND AIConclusion
In summary, when it comes to protecting society, AI is a 
powerful tool that can help to augment user abilities, but it is important for people to clearly think through how these tools are designed. 
There’s still a lot of work to be done to convince the 
industry on why design is important - one way we can take steps towards this is by collecting statistics and sharing compelling examples. When engaging businesses, government and the next generation about what makes the most powerful systems, we need to start talking about STEAM (science, technology, engineering, ARTS and maths) teams rather than just 
STEM. Diversity in thinking creates the most rigorous and 
interesting technology, which is critical when being used in high-risk situations. Every day society is developing a greater reliance on machines, and design is central to bridging the gap . FOLLOWING
CHAPTERSFOLLOWING
CHAPTERS
This Brain food series will be released 
chapter-by-chapter, stretched over 
several months. In every chapter 
experts will dive deeper into specific 
topics related to AI.

Chapter 1.A I  
D R I V E N  
D E S I G NA I  
D R I V E N  
D E S I G NChapter 1.This first chapter was written 
by Joël van Bodegraven  
Product Designer at Adyen, in collaboration with Chris Duffey  Head of AI Strategy & 
Innovation at Adobe, and Awwwards .• Introduction
• What is Artificial Intelligence?
• Changing Relationship with      
 Technology.
• Ethical Challenges
• Designing for AI
• AI Design PrinciplesChapter 1.CHAPTER 1. AI DRIVEN DESIGNIntroduction.
Technology has always been the driver of great 
breakthroughs and innovations. As creators, we are currently living in one of the most exciting eras where technology is making enormous leaps forward.  One of the 
most anticipated technological developments is around automation and Artificial Intelligence .
AI is a much used buzzword nowadays, surrounded by misconceptions and questions regarding its purpose and power. Apart from its known ethical and philosophical challenges, AI can be the catalyst for great user experiences. This chapter provides an outline of what AI is, what its current state is, and what design challenges experts face while designing for AI. 
AI will undeniably shape the user experiences of tomorrow. 
Therefore, this is an excellent opportunity to dive into this world and get to know its ins and outs. CHAPTER 1. AI DRIVEN DESIGN
What is 
Artificial 
Intelligence?
Artificial Intelligence (AI) has many faces and definitions 
attached to it. While most people (who aren’t really familiar with AI) think it is an entirely new technological development, it actually emerged in the 1950s. 
Over the years AI has been developed within the gaming 
industry and has now found its way into our homes and reached an all-time high in terms of advancement, funding, and enthusiasm. If you google Artificial Intelligence, you’ll find many stories and future outlooks on how AI could take over jobs and even how AI could eventually destroy humankind. The fact is, Artificial Intelligence is far from reaching human-like general intelligence. CHAPTER 1. AI DRIVEN DESIGNSo while it is far from 
reaching super intelligence, AI is getting better and better at accomplishing narrowly defined tasks. This creates great opportunities for creators and users to make experiences more seamless, efficient and meaningful. There are three kinds 
of AI according to Chris Noessel:
Narrow artificial intelligence: 
intelligence focused on narrow tasks. Meaning it can learn and infer, but not generalize. 
General intelligence:
is more self-supporting and has also the ability to understand meanings within contexts.
Super intelligence: 
would surpass the intelligence of humans.CHAPTER 1. AI DRIVEN DESIGNMain AI Characteristics.
3. 
AI is narrow 
and very 
focused.1. 
AI is largely 
based  
on data. 4. 
AI is an 
evolving 
term.2. 
AI abilities 
are not 
programmed but learned.CHAPTER 1. AI DRIVEN DESIGN1. 
AI is largely based on data. 
Data is vital for the advancement of AI. Without data, this 
wouldn’t be possible. There has been much controversy around collecting data in general, and the creative community have a big responsibility in how we deal with data. 
2. 
AI’s abilities are not  
programmed  
but learned. 
AI learns and improves along the way, without being 
programmed. It learns from failure and experiences. The more AI executes a specific task, the better it gets.3. 
AI is narrow and very focused. 
AI is good at accomplishing pre-defined specific tasks. 
Uncovering patterns and finding correlations for example.
4. 
AI is an evolving term. 
As mentioned before, AI has many faces and conceptual 
angles to it. From narrow to super intelligence. This means that the meaning and definition of AI can vary per person and is mostly relative to the view that a person has on Artificial Intelligence. This misconception/misalignment of what AI is, is likely to continue since it’s technologically evolving day by day.CHAPTER 1. AI DRIVEN DESIGNArtificial Intelligence has been disruptive on a technical 
level but has also made a significant impact on a societal level. The way we interact and how we relate to machines is rapidly changing.  
Basically, AI is everywhere. On our phones, in our houses, 
watches and even in our cars. The presence of AI changes our interactions and relationship with technology. We used to conduct many tasks ourselves, nowadays we give voice commands to a smart assistant and let it  do the job.
AI-driven products like Google Home, for example, are 
nicely tapping into this space and influence our behavior and perceptions already. 
There’s a noticeable mind-shift going on, and products like 
Google Home have a more prominent place in households. AI-driven products have become more popular, and people are making more use of them than ever before.Changing 
Relationship with 
Technology.
CHAPTER 1. AI DRIVEN DESIGNThe way that people interact is also changing. 
Google Homeowners, for example, often use AI as part of their daily routine. Google recently conducted research on people who own a voice-activated speaker. As it turns out, Google Home has made the life of Google Home-users easier because they are able to multitask more. And more interestingly, people are engaging with their voice-activated speakers as if they were human. They’re saying “please,” “thank you,” and even “sorry.
The following observations show an exciting 
development in how people relate and interact with smart devices. 22%
52%
23%Where do Google Homeowners 
use their AI-driven products? 
72% of people 
who own a voice-activated device speaker say that their devices are often used as a part of their daily routine.
72%KITCHEN
BEDROOMCOMMON  
AREAS
(Figures: courtesy of Google)CHAPTER 1. AI DRIVEN DESIGNDeveloping services or products that are driven by AI-
technology comes with ethical challenges. Much has been said and written over the years around the danger and purpose of AI. Chris Duffey, Head of AI Strategy & Innovation at Adobe had an interesting view on AI’s intent. He said: “technology is neither bad or good, it is really a reflection of the human that is creating it” . 
This statement points out perfectly what responsibility we have as the creative community. The development of AI-technology relies on trust. This is because the development of AI is dependent on data. Without data, an AI wouldn’t be able to make predictions. 
Ethics is a growing issue within the creative industry and 
rightly so, because much of users’ data has been misused by parties in the past who weren’t very focused on data security. Housing of data is one of the ethical challenges that we as the creators community need to solve.Ethical 
Challenges.
CHAPTER 1. AI DRIVEN DESIGN1. 
Housing of 
Data.2. 
Privacy.3. Lack of 
Transparency 
& Control.4. 
Alienation 
of Human 
Capabilities.AI’s Ethical Challenges.CHAPTER 1. AI DRIVEN DESIGNHousing of Data. 
There is a general distrust from users considering the 
discretion behind their data-housing. There is much skepticism due to studies around illegal data-distribution that affects the trust and willingness of users. A worrying attitude because it may inhibit the development of AI eventually. 
Privacy. 
“I have nothing to hide”, that is what most people would have answered if you had asked them about sharing data and privacy before. This mindset has shifted slightly since userdata was massively misused by companies such as Cambridge Analytica.Lack of Transparency & 
Control. 
Outcomes from AI are often perceived as a black box. 
Users will receive content based on their patterns without actually knowing how and why. Studies show that users value transparency and control. They like to be in control and understand the results/actions that stem from AI-driven services and products.
Alienation of Human 
Capabilities. 
There’s an overarching risk with continually distilling human 
knowledge and skills into algorithms. This causes a risk of users getting alienated from the distilled knowledge and skills. The more we delegate with AI, the further we remove ourselves from understanding what and why we do things. CHAPTER 1. AI DRIVEN DESIGNDesigning for 
AI.
As creators, we are constantly looking for new ways of 
creating our products and services. Artificial Intelligence is changing how people experience our products and is also having an impact on our design process. The possibilities of applying AI are endless and can lead to significant experiences. However, we are still in the phase of narrow-AI which means that AI currently is only useful at executing very specific tasks. This means that AI-driven products and services can amplify designers capabilities in specific ways. 
Several experts in the field of design and AI are exploring 
what the best ways are to design for AI. What to keep in mind, what principles to follow and what ethical codes to apply. CHAPTER 1. AI DRIVEN DESIGNHow can AI help in  
a creative process?
Although technology has changed a lot and has automated 
a big part of our work already. The core premise of how we as a creative industry want to act stays the same - we’ll continue to strive for a better user experience. Experience Design is a great place for AI. Besides automating tasks, it can contribute by creating meaningful user experiences. AI support a creative process in many ways and can fulfill several roles. Here are ways AI can support your work:CHAPTER 1. AI DRIVEN DESIGNDesign Support. 
Creativity still remains very much a human endeavor. 
However, AI can do some legwork to enable us to get up to speed. Looking at the framework of human and machine, AI can function as an assistant. It can help with research, collecting data or more creative tasks. Think of color correcting photos or cropping some assets can be one of those handy tasks that incur a lot of overheads. Other, more creative, tasks can only be done by humans because they require emotional intelligence (i.e., empathy). Adobe for example taps into this field with its Artificial Intelligence called Sensei, that will help designers become more efficient at what they do. Sensei Stitch  helps to identify 
patterns in images to help designers patch. AirBnB even developed an AI that is able to recognize paper sketches and instantly turn them into code.Curator. 
What makes us intelligent, is our ability to learn. With AI, we are trying to distill human intelligence into machines, to make experiences more meaningful and personal. Data-points that feed this technology are growing rapidly, partly because of the adoption of smart technology (I.e., Internet of Things). AI, with insights from all those data points and references, can serve as a curator to determine the best personal experience per individual.CHAPTER 1. AI DRIVEN DESIGNEnabling Creativity. 
AI can be an enabler in recognizing design patterns, but 
can also help you to create design. Artists, creatives and developers are applying several AI technologies to enable users to be as creative as they want to be. Think of Prismo  
or Auto Draw  as example. The amazing thing about these 
kind of tools is that people with less creative confidence are also able to let their imagination go. 
Now that we’ve explored the different roles AI can take, 
let’s investigate how we can exploit those capabilities 
within a design process...Design Systems. 
AI is king in uncovering patterns and creating new ones 
that better suit the user. Thinking of design systems, this can turn out to be really handy. More and more companies are trusting AI to take care of their design systems to keep them more consistent for users. Hereby, an AI can even predict eventually what pattern works best based on all the user data it has received. CHAPTER 1. AI DRIVEN DESIGNTechnology will continue to advance and will continue to 
disrupt our lives in ways we cannot even imagine yet. As a creative community, we are shaping what AI can become in the future. We are laying the groundwork for something that could be great. But we also risk setting the stage for something that could turn out badly. 
We have the opportunity to 
shape this future because we 
are at the dawn of an AI-driven 
era. 
Instead of emphasizing extremes of what could be in the 
future, let’s identify how we can work with AI and what principles can help this technology scale (responsibly). What these design principles could be is a burning question for many creatives. Because AI is an evolving phenomenon, it is hard to pinpoint a fixed set of design principles. The following principles have been drafted based on expert’s opinions and are focused on concept and UI.AI Design 
Principles.
CHAPTER 1. AI DRIVEN DESIGN1. Minimal input, 
maximum outcome.
We are living in a world where phenomena 
such as decision fatigue are commonplace. We get bombarded with notifications, stimuli, and expectations which we all need to manage somehow. AI can solve this problem by doing the ‘legwork’ for us. Think of delimited tasks which can be easily outsourced. Nest tapped into this area by setting the temperature right. Uber removed the middleman and made it easier to book a cab. Google’s AI adds value in the email by suggesting automatic responses.
Conceptually, challenge 
yourself to solve significant 
user problems with minimal 
input expected from them. Uber removed and automated 
the hassle and uncertainty  
of calling a cab, by setting a pick-up spot and allowing people to pay within one service.
Google’s AI conducts sentiment analysis and suggests, based on the content of the received email, what response would be appropriate.
AI IN PRACTICE.CHAPTER 1. AI DRIVEN DESIGN
Netflix uses thumbs up or down as tool 
to give feedback.Blendle provides an opportunity for users to give feedback and let the algorithm know if a kind of article works well or not. The red heart is a positive trigger,  the link below forms a negative signal. 2. Design for forgiveness.
Naima van Esch, a UX design specialist at Deloitte 
Digital explored what principles are helpful when designing for AI-enabled  user interfaces.   
In her personal journey, she pointed out the importance of designing for forgiveness. Because AI is certainly gonna make mistakes. As a designer it’s important to ideate on how to cope with this. There are several ingredients that can work. Think of humor - which Naima pointed out - within the UI. Or with functionality whereby users are able to give feedback to systems. At Netflix you can dislike buckets of selections. Blendle you can even give feedback per article. Afterwards it promises to improve the upcoming selection according to the given feedback. 
AI IN PRACTICE.CHAPTER 1. AI DRIVEN DESIGN
The examples above tap into a specific scenario. Looking 
company-wide, an ethical and clear data policy should be at the foundation of every AI-driven product or service. Blendle is very transparent and tells you what they know and why you’re getting what content. (example: “TECH - because you read about this often”).
Netflix builds transparency 
by adding reasoning behind the selection of buckets. (example: “Because you watched Orange is the New Black”). 
AI IN PRACTICE. 3. Design for trust.
Data is key in the advancement of AI. Data is a 
true gift and precious to many users. Therefore, it is important that we design for trust by being transparent in what we know about the user and how we’re gonna use it. If possible, users should be in control and able to modify their data if needed. Data has been a hot topic lately with news coverage about Cambridge Analytica and the Russian collusion within the US Election, which made people more aware and sometimes even reluctant in regard to data-sharing. 
Build trust by creating a 
healthy dynamic in which 
transparency and honesty 
are the cornerstones. CHAPTER 1. AI DRIVEN DESIGN4. Humanize experiences.
As our daily interactions with machines are rapidly 
changing, the value of personality becomes more prominent. Looking at recent findings from Google who studied how people interacted with Google Home, one thing stood out. Users were interacting with it as if it were human. Users said for example “thanks” or “sorry” after a voice-command.  This observation shows the potential of personality within the human-machine relationship. 
People can relate more 
to devices if they have a 
character. The movies Her  and Ex-Machina  both 
explore this concept and illustrate an 
interesting scenario of how personality in AI could have an impact. Both are fictional stories but can trigger your imagination.
AI IN PRACTICE.CHAPTER 1. AI DRIVEN DESIGN5. Design for less choice.
Looking at today’s AI-driven experiences, much of the UX 
is very reactive. As in, products need to be triggered by a voice command, gesture or button in order to activate. Ultimately, AI will proactively trigger users. The current high performing, and overly noisy world leaves very little room for users to be in the moment. 
Design for less choice by 
removing unnecessary 
decisions. 
This creates headspace for users and can even result in 
the appearance of things we hadn’t thought of. Design one step ahead. 
AI IN PRACTICE.
Google taps into designing for less choice with their 
‘slices’ concept, whereby users get to see a predicted action based on their past behavior or actions. Apple introduces a similar concept with shortcuts in their upcoming iOS 12 update. FOLLOWING
CHAPTERSFOLLOWING
CHAPTERS
This Brain Food series will be released 
chapter-by-chapter, stretched over 
several months. In every chapter 
experts will dive deeper into specific 
topics related to AI.

Chapter 2.CHAPTER 2. TRAINING AI WITH DESIGNTRAINING 
AI WITH 
DESIGNTRAINING 
AI WITH 
DESIGNChapter 2.This second chapter was 
written by Pedro Marques 
& Joël van Bodegraven , 
Product Designers at 
Adyen. • Introduction
• The importance of Machine       
 Learning
• How does AI learn?
• Machine Learning, the first step   
 to AI
• Machine Learning applied on    
 design (or as a design pattern)
• The user on the loop
• How do you create this        
 feedback loop in a ML mode?
• Design enabling AI
• Biases
• Join the ML playground!Chapter 2.CHAPTER 2. TRAINING AI WITH DESIGNIntroduction.
In the first chapter, we’ve touched the surface of how AI 
affects our process as creatives and how important data is in delivering meaningful user experiences. In this chapter, we dive deeper into how we can train Artificial Intelligence (from now AI) with design. 
AI relies 
heavily on 
data but how 
does it learn? How does 
AI become 
intelligent?
The goal of this chapter is to introduce and get you started with several methods and techniques to make your AI smarter with design.CHAPTER 2. TRAINING AI WITH DESIGNThe importance 
of Machine Learning.
Code has always been that ‘invisible’ part of great 
experiences. With the dawn of an AI-driven society, Machine Learning has become a design decision as well.Machine Learning is a hot topic in our industry and changes the way we design and create our products. It offers tons of opportunities but also comes with some important challenges. 
One of those challenges is that Machine Learning is now 
a UX-problem. By sharing how Artificial Intelligence learns and how you can have an impact on this as a designer, we hope to spark your imagination and boost your confidence so you can play a bigger role in your next AI-driven project.CHAPTER 2. TRAINING AI WITH DESIGNHow does AI 
learn?
There are several ways that Artificial Intelligence (AI) can 
learn and evolve. Generally you can say that an AI learns from (data) patterns, mistakes/errors and successes (trial and error). Opposed to conventional programming, Machine Learning starts at the end, so you don’t code the solution, the machine itself learns from a set of rules. 
Imagine you want to make the best burger in the world. 
Instead of trying to come up with your own recipe. You buy several great burgers and you start from there. 
You bought a bunch of burgers and tell the machine 
what it is and you tell which parts you like the most. The 
machine takes it from there and deconstructs the burgers 
and comes up with the perfect burger. The ‘magic’ around Artificial Intelligence is, is that you might not even know 
HOW it is done. Perfect BurgerTheCHAPTER 2. TRAINING AI WITH DESIGNMachine 
Learning, the  first step to AI
Machine Learning can be seen as the science of helping 
computers discover patterns and relationships in data. As designers, patterns form a key element in our products, so having a good learning model in place is key for success. Basically, there are three ways in which machines can learn. You have supervised, unsupervised and reinforcement learning.Types Of 
Machine Learning.
Supervised Learning.Train an algorithm to perform classification and regression with a labelled data set.
Unsupervised Learning.Train an algorithm to find clusters and associations in an unlabelled data set.
Reinforcement Learning.Train an agent to take certain actions in an environment without a data set.CHAPTER 2. TRAINING AI WITH DESIGNSupervised Machine Learning:
Let’s stick to the hamburger example. You want to create 
the best burger in the world. To do so, you first need to figure out and learn what a good burger consists of. This is where Machine Learning comes in. The machine in this case, feeds the AI with useful info like what is the best bun, best meat or best cheese to use (based on all the perfect burgers you’ve provided the machine). Machine learning in general is great in performing such single tasks. 
Each part of the burger (bun, meat, cheese) will have in 
this case a machine learning model attached to it. To distinguish and identify what type works best per part.  
And this is how it learns, as you saw you have to provide 
examples to the algorithm, this specific method of learning is called supervised machine learning.  It works the way it implies, just like with a kid, you want it to learn but you still want to supervise the process and make sure that it is accurate. So you supervise the machine by giving examples of perfect burgers (in your view) so it can learn what it consists of. Data that trains the model can have two forms:
1. Labeled data (data that is already labeled, also known as training data), labeled data is just a set of data that already has meaning, for example: This is an apple
2. Unlabelled data (data that is used to train the model)
In the training data, the model will know the features and how to properly label them and in the testing data, even if you know the label, you’ll not disclose that to the model, and that’s how to test its accuracy.CHAPTER 2. TRAINING AI WITH DESIGNOriginal 
Unclustered DataClustered DataUnsupervised Machine 
Learning:
With this type of learning you might know which burgers 
are the best ones but you don’t know what they are made of - the machine will cluster the dataset, that at first looks disorganized, and make its own assumptions and associations.Reinforcement Learning:
Considering reinforcement learning, DeepMind is a company to follow and watch. DeepMind is pursuing the development of General AI . Their mission is crystal clear 
and they act accordingly: “DeepMind’s scientific mission is to push the boundaries of AI, developing systems that can learn to solve any complex problem without needing to be taught how. To achieve this, we work from the premise that AI needs to be general”.
With the help of reinforcement learning, DeepMind is 
developing and iterating on intelligent agents that execute reinforcement learning with unsupervised Auxiliary Tasks. Simply said, these agents perform different strategies (ways to play the game in this case) in order to find the perfect one. Everytime they get ‘killed’ or are ‘game over’, the agent performs an alternative strategy until the agent succeeds.  CHAPTER 2. TRAINING AI WITH DESIGN
Visualisation of an agent in a Labyrinth maze.CHAPTER 2. TRAINING AI WITH DESIGNExcited about 
this? 
      DeepMind wrote a nice paper about it.
There are several other ways to learn and all of them are 
based on the principle that you provide some data, you test its accuracy and you keep doing this process over time while trying to group that data in different ways in order to improve it. CHAPTER 2. TRAINING AI WITH DESIGNMachine Learning 
applied on design (or as a design pattern).
Thus, now that we know HOW machines learn, let’s focus 
on how design adds value in this learning process.
Companies like Google and Netflix are applying Machine 
Learning very effectively and have an interesting approach to it. Google for example is using Machine Learning to make the mail-experience more efficient by applying automatic responses. Netflix applies Artwork Personalization to trigger user’s interest .CHAPTER 2. TRAINING AI WITH DESIGNGmail efficient smart reply.
Google is using Machine Learning to make the email 
experience more efficient and less time consuming. Google identified a need to help users to respond to an email by suggesting quick responses. Google has decades of experience in understanding languages and meanings with their Google Translate platform. They use this capability, together with a hierarchical approach to learning to predict what response is most appropriate. 
Save time with Smart Reply in GmailEfficient Smart Reply, now for GmailHierarchical model of Google.Final Score
Email Body Response Subject Line ResponseCHAPTER 2. TRAINING AI WITH DESIGNNetflix Artwork 
Personalization.
Most of us are watching series on Netflix and we get 
confronted almost daily by suggestions that are a result of machine learning - called the personalized recommendation system. Netflix wants us to discover great content. Showing only a title of a movie or series isn’t enough. It is a great effort to find the single perfect artwork for a 
user. How people find artwork can be very personal and based on specific taste. There is so much diversity in taste 
and preference that Netflix figured it would be a better 
idea to find the best artwork for each of their members to “highlight the aspects of a title that are specifically relevant to them”. Stranger Things for example had different 
artwork variations, each tapping into a different theme.
A Netflix homepage without artwork isn’t very appealing.CHAPTER 2. TRAINING AI WITH DESIGNYou might wonder, how does the Netflix’s Personalized 
Recommendation System decide what artwork to show?  Your viewing history plays a big part in deciding what artwork to show. The image below shows how your viewing history affects the shown artwork based on genres you like and watch. If you watch a lot of romantic movies for example, you may be interested in Good Will Hunting if Netflix shows Matt Damon and Minnie Driver. Whereas if you’re more into comedies, showing Robin Williams would appeal more to you. The same logic can apply to actors and actresses. If you have watched many movies with John Travolta, then artwork with John Travolta would appeal more to you than one with Uma Thurman and visa versa.
CHAPTER 2. TRAINING AI WITH DESIGNNetflix’s Machine Learning 
approach.
Much of the recommendation engine of Netflix is powered 
by machine learning. Netflix applies a contextual bandits approach at which they basically A/B test two algorithms against each other.
Netflix about their method:
“Traditionally, we collect a batch of data on how 
our members use the service. Then we run a new machine learning algorithm on this batch of data. Next we test this new algorithm against the current production system through an A/B test. An A/B test helps us see if the new algorithm is better than our current production system by trying it out on a 
random subset of members.”This means that members in group A +get the new 
algorithm. If there’s a higher engagement in group B the new algorithm will be rolled out — unfortunately this approach didn’t present the expected results and that’s why Netflix applied an online machine learning approach, to learn on the fly instead of waiting for a batch.
To learn more about how Netflix applies machine learning, 
check the article below!
Artwork personalization at NetflixCHAPTER 2. TRAINING AI WITH DESIGNThe user on the 
loop. 
As AI is trained with historical data in order to predict an 
outcome, it can become outdated really fast, take this example:
Let’s say you build a model to anticipate which email is the most important in your user’s inbox, and to do so you take a few things into consideration: Subject, Content, time it takes for the user to interact with a given email, Reply time, and other things.
You train it extensively with historical data and now 
your output is 90% accurate and the model gives you a pretty good estimate, so whenever the user receives a new email, it knows how important that email is.Unfortunately this accuracy will not last forever because something being important is relative to innumerous things so if you don’t update your model you’ll be providing inaccurate predictions without even knowing.
Adding your user’s feedback into the mix might help mitigate this unfortunate outcome.
How to create this feedback 
loop in a ML mode?
Let’s take the email example and see how Google fixed it.
The Gmail Priority inbox ranks email by the 
probability that a user will care about a given email, but something being important is highly personal so the only way to do it is by learning what 
is important in a per-user base and updating it as 
frequently as possible because our priorities shift so our inbox should too.CHAPTER 2. TRAINING AI WITH DESIGNHow is 
it done 
exactly?  
Google provides new users with a “dummy model”  
and trains it every single day by actively watching 
how people interact with their emails. So this model will be improved every 24 hours. This illustration shows how it works.Feedback 
Loop in a ML 
ModeInitial model
Initial model 
is tested with 
past 24 hours 
of test dataPer-user model 
is builtUser interacts 
with their 
emails (within 
24hrs)Model is 
appliedCHAPTER 2. TRAINING AI WITH DESIGNDesign enabling 
AI.
Talking to users and taking their feedback is part of our 
life as designers and this is where we can contribute the most. While we’re building intelligent systems we can play a massive role by making sure our user’s interests and goals are what drives artificial intelligence forward. 
Built-in feedback.
For example, when designing interfaces with AI we should keep in mind that it is possible that the prediction will be wrong.
A great way is to start by building interfaces that have 
structured feedback built in — if your model has made a mistake, structured feedback is often better than a yes/no question.In the Netflix example mentioned earlier, they built a whole 
system just to try and show you the one that will make you 
tick, but what if you actually really dislike that artwork?
If there’s no structured feedback in place, you will solely 
rely on what the machine says is right and you might remove its human factor from the loop.
Don’t try to deceive people.
The main danger of AI, in my view, is that we might outsource important life decisions to a yes or no black box, and if we try to play the human at that moment we might make things worse.
Be sure to tell people what’s happening, show them why 
you’re recommending something YouTube does a great job at this, it recommends you new videos based on what other people have also watched: CHAPTER 2. TRAINING AI WITH DESIGN“Kevin Kenson viewers watch this” with a 
little bit of copy you can give your users more transparency and maybe get them to trust you more in the future because now they know why you recommend them things.
Kevin Kenson viewers watch this
First Look at Nintendo SwitchNintendo · 38M views · 2 years ago
Biases.
When we hear the word Bias we automatically think of something bad. It is biased. 
A bias is an evolutionary gift, it is an ability to make quick 
decisions, a split second reaction that could save your life -- it is just a mental shortcut.
In the book Thinking Fast and Slow Daniel Kahneman 
explores the idea of a fast brain and a slow brain, the fast brain being the one that makes quick decisions and the slow one being our rational brain. The fast brain is made out biases, it is your brain quickly scanning though everything you have experienced in life and making a really fast decision.
But what do we mean when we talk about biases into AI?
There are plenty of examples of AI going wrong and being racist, sexist and so on -- how does that happen?CHAPTER 2. TRAINING AI WITH DESIGNLet’s explain 
it with an 
example:
Amazon was working on this AI to help them 
sort through hundreds of CVs and find the best 
candidate to fill a position, but as they tested 
the output of the model they saw that it was only selecting men and, not only arbitrarily not selecting 
women, but giving any female word a negative 
score -- Why?When you feed a model with historical data you’ll get 
historical bias and just like a human the computer will make a decision based on the data it has available, if that entire dataset contains mostly male words it will most likely 
punish CVs that contain female words. 
Machines don’t inherently have biases but we do and we 
train our models with them and there’s no easy way of fixing it, most of the time we don’t even know we have a bias because that’s what we’ve been trained with.
The first step is to acknowledge that we have unconscious 
biases and after that, only testing and talking to your users will help you keep yourself and your product in check.CHAPTER 2. TRAINING AI WITH DESIGNJoin the ML 
playground!
In this chapter you’ve read a lot about the importance of 
data, how machines learn, what kind of learning methods there are and what impact biases have on AI. A lot of reading but not much interaction and fun, so that’s why Pedro Marques prepared a Machine Learning playground that enables YOU to experience yourself what machine learning is and what you can do with it. Enjoy! 
      Github.
      github.com/pmarquees/mlhowtoFOLLOWING
CHAPTERSFOLLOWING
CHAPTERS
This Brain food series will be released 
chapter-by-chapter, stretched over 
several months. In every chapter 
experts will dive deeper into specific 
topics related to AI.



### pwc.txt

AI is bringing limitless potential to push us forward as a society — but with great potential comes great risks. 

When you use AI to support business-critical decisions based on sensitive data, you need to be sure that you understand what AI is doing, and why. Is it making accurate, bias-aware decisions? Is it violating anyone’s privacy? Can you govern and monitor this powerful technology? Globally, organisations recognise the need for Responsible AI but are at different stages of the journey.

Responsible AI (RAI) is the only way to mitigate AI risks. Now is the time to evaluate your existing practices or create new ones to responsibly and ethically build technology and use data, and be prepared for future regulation. Future payoffs will give early adopters an edge that competitors may never be able to overtake.

Potential AI Risks
A variety of factors can impact AI risks, changing over time, stakeholders, sectors, use cases, and technology. Below are the six major risk categories for application of AI technology. 

Performance
Security
Control
Economic
Societal
Enterprise

Performance

AI algorithms that ingest real-world data and preferences as inputs may run a risk of learning and imitating possible biases and prejudices.
Performance risks include:

Risk of errors
Risk of bias and discrimination
Risk of opaqueness and lack of interpretability
Risk of performance instability

Security

For as long as automated systems have existed, humans have tried to circumvent them. This is no different with AI.
Security risks include:

Adversarial attacks 
Cyber intrusion and privacy risks
Open source software risks

Control

Similar to any other technology, AI should have organisation-wide oversight with clearly-identified risks and controls.
Control risks include:

Lack of human agency
Detecting rogue AI and unintended consequences
Lack of clear accountability

Economic

The widespread adoption of automation across all areas of the economy may impact jobs and shift demand to different skills.
Economic risks include:

Risk of job displacement
Enhancing inequality
Risk of power concentration within one or a few companies

Societal

The widespread adoption of complex and autonomous AI systems could result in “echo-chambers” developing between machines, and can have broader impacts on human-human interaction.
Societal risks include:

Risk of misinformation and manipulation
Risk of an intelligence divide
Risk of surveillance and warfare

Enterprise

AI solutions are designed with specific objectives in mind which may compete with overarching organisational and societal values within which they operate. Communities often have long informally agreed to a core set of values for society to operate against. There is a movement to identify sets of values and thereby the ethics to help drive AI systems, but there remains disagreement about what those ethics may mean in practice and how they should be governed. Thus, the above risk categories are also inherently ethical risks as well. 

Enterprise risks include:
Risk to reputation
Risk to financial performance
Legal and compliance risks
Risk of discrimination
Risk of values misalignment


PwC’s Responsible AI Toolkit
Your stakeholders, including board members, customers, and regulators, will have many questions about your organisation's use of AI and data, from how it’s developed to how it’s governed. You not only need to be ready to provide the answers, you must also demonstrate ongoing governance and regulatory compliance.
Our Responsible AI Toolkit is a suite of customizable frameworks, tools and processes designed to help you harness the power of AI in an ethical and responsible manner - from strategy through execution. With the Responsible AI toolkit, we’ll tailor our solutions to address your organisation’s unique business requirements and AI maturity.

Our Responsible AI Toolkit addresses the three dimensions of Responsible AI 

Governance

Compliance

Risk Management

Bias & Fairness

Interpretability & Explainability

Privacy  

Security

Robustness 

Safety 

Data & AI Ethics 

Policy & Regulation

Who is accountable for your AI system? The foundation for Responsible AI is an end-to-end enterprise governance framework, focusing on the risks and controls along your organization’s AI journey—from top to bottom. PwC developed robust governance models that can be tailored to your organisation. The framework enables oversight with clear roles and responsibilities, articulated requirements across three lines of defense, and mechanisms for traceability and ongoing assessment.

Are you anticipating future compliance? Complying with current data protection and privacy regulation and industry standards is just the beginning. We monitor the changing regulatory landscape and identify new compliance needs your organization should be aware of, and support the change management needed to create tailored organizational policies and prepare for future compliance.

How are you identifying risk? You need expansive risk detection and mitigation practices to assess development and deployment at every step of the journey, and address existing and newly identified risks and harms. PwC’s approach to Responsible AI works with existing risk management structures in your organization to identify new capabilities, and supports the development of any necessary operating models. 

Model risk management of AI and machine learning systems
Managing the risks of machine learning and artificial intelligence models in the financial services industr

Is your AI unbiased? Is it fair? An AI system that is exposed to inherent biases of a particular data source is at risk of making decisions that could lead to unfair outcomes for a particular individual or group. Fairness is a social construct with many different and—at times—conflicting definitions. Responsible AI helps your organisation to become more aware of bias and potential bias, and take corrective action to help systems improve in their decision-making.

Bias Analyzer: Track and mitigate bias in AI model
What is fair when it comes to AI bias

How was that decision made? An AI system that human users are unable to understand can lead to a “black box” effect, where organisations are limited in their ability to explain and defend business-critical decisions. Our Responsible AI approach can help. We provide services and processes to help you explain both overall decision-making and also individual choices and predictions, and we can tailor to the perspectives of different stakeholders based on their needs and uses.

How will your AI system protect and manage privacy? With PwC’s Responsible AI toolkit, you can identify strategies to lead with privacy considerations and to respond to consumers’ evolving expectations. 

2021 Global Digital Trust Insights

What are the security risks and implications that should be managed? Detecting and mitigating system vulnerabilities is critical to maintaining integrity of algorithms and underlying data while preventing the possibility of malicious attacks. The great possibilities of AI come with the need for great protection and risk management. PwC’s approach to Responsible AI includes essential cybersecurity assessments to help you manage effectively.  

Will your AI behave as intended? An AI system that does not demonstrate stability, and consistently meets performance requirements, is at increased risk of producing errors and making the wrong decisions. To help make your systems more robust, Responsible AI includes services to help you identify potential weaknesses in models and monitor long-term performance. PwC has developed specific technical tools to support this area.

Is your AI safe for society? AI system safety should be evaluated in terms of potential impact to users, ability to generate reliable and trustworthy outputs, and ability to prevent unintended or harmful actions. PwC’s Responsible AI services enable you to assess safety and societal impact to support this dimension.  

Is your data use and AI ethical? Our Ethical data and AI Framework provides guidance and a practical approach to help your organisation with the development and governance of AI and data solutions that are ethical and moral. 
As part of this dimension, our framework includes a unique approach to contextualising and applying ethical principles, while identifying and addressing key ethical risks.

Are you positioning your AI toward future compliance? As the regulatory landscape continues to evolve, maintaining compliance and responding to regulatory change will be critical. Leveraging PwC’s approach to Responsible AI can help you identify and evaluate relevant policy, industry standards and regulations that may impact your AI solutions. Operationalize regulatory compliance while factoring in localized differences. 


### youtube_G-xD1bDoNl4.txt

[Music]
to become a good designer you need to
understand and use the power of
psychology in visual perception
how does someone react to your design
when sees it how does his mind interpret
it Gestalt is a psychology movement that
helps us understand and predict these
interpretations our brain tries very
hard to find sounds and visual images
that's why it looks for familiar clues
in the mental visual library it sifts
through millions of image impressions
until it finds an explanation of what
you see you've got a very powerful
computer there in your head back in
nineteen twenties here Stoll
psychologist max Wertheimer Wolfgang
köhler and Kurt Kafka came to conclusion
the sum of the whole is greater than its
parts
that means we see the whole picture
before we see details
according to Gestalt psychology there
are five basic principles of visual
perception similarity proximity
continuity closure figure and ground
according to the principle of similarity
we visually group similar elements that
would be the elements that share similar
characteristics like value size shape
texture color orientation using them as
a group and separate them from other
elements
[Music]
use this principle if you for example
want to emphasize an element just make
it different and everyone will focus on
it
[Music]
when we see elements that are randomly
spaced out we see them as separate
objects once they get closer we see them
as a group of friends we visually group
objects that are close elements that are
closer together as seen as belonging
together you can emphasize an element
just by spacing it away we move our eyes
from one object to another as we would
follow a path well until it's
interrupted your eye naturally follows a
line
affair
a group of shapes or even a lack of
your brain likes simplicity so it always
picks the smoothest paths these two not
those you can emphasize an element by
having other elements point to it which
makes sense the principle of closure
states that we visually finish
incomplete shapes that means we tend to
see the whole shape even when part of
the information is missing if what we
see only suggests explanation you I will
fill in the gaps
how many shapes do you see your first
reaction and the natural one is probably
for three black circles covered by a
white triangle seeing these four shapes
is the simplest interpretation of what
you see not the three circles would cut
out slices our brain likes simple
solutions our brain separates a
foreground from a background on a flat
surface we see an object figure against
its surrounding ground it is also called
positive negative space relationship
same shapes can be seen as a foreground
or a background
[Music]
a color or a tonal value of an element
have nothing to do with determining
whether it's a figure or a ground its
own the context you can create an
interest in your design by working on
negative space instead of the object
itself or even combining both science
did not stay still since nineteen
twenties other principles of perception
were identified here are just a couple
simplicity people intuitively prefer the
simplest solutions possible
what shapes do you see here one disk
into partial disks all three overlapping
disks your first impression was probably
the three overlapping disks because it's
the simplest interpretation of what you
see simplicity of the whole emphasizes
the importance of details
keep it simple to focus on what really
matters elegant design requires minimum
number of steps you take to convey a
message a great deal may be happening on
the page with very few graphics in fact
adding more elements without
understanding their effect can often
make the message confusing so don't
overdo your designs less is more
familiarity it causes a shape to stand
out from its surroundings we tend to see
familiar objects first in this display
of random shapes and lines which element
caught your eye first I bet it was the a
as we focus on it it becomes a figure
while the rest of the elements become
background
[Music]
similarity proximity continuty closure
figuring ground when Gestalt principles
are ignored designed tends to look
unprofessional and sounds confusing
messages we don't want that do we so
bring the power of psychology to a
design work
[Music]

### youtube_5HgkawZdihU.txt

welcome to the intelligence briefing
live what's the buzz where leaders and
Hands-On experts share how they have
turned High into outcome today we'll
talk about how you can use generative a
to improve your user experience in your
applications and who better to talk
about it than someone who's been
teaching hundreds of teams on AI and
analytics over the years Scott cenel hey
Scott thank you so much for joining yeah
I am so excited to be here I can hardly
contain myself thank you for inviting me
awesome hey why don't you tell us a
little bit about yourself who you are
and what you do sure so first of all I
am older than dirt I actually started in
the field in March of
1986 so I've been doing this for quite a
while um I absolutely love helping
people learn all about artificial
intelligence machine learning data
science all those fields done a heck of
a lot of Consulting I've had clients you
may have heard of like Ali Biogen
Mercedes Los Angeles Times folks like
that and so now I'm trying to transfer
that knowledge to others and bring more
people into the field wonderful now
folks for those of you in in the
audience if you're just joining the
stream drop a comment in the chat where
you're joining us from I'm always
curious to see how Global our audience
is um and don't forget to subscribe to
my newsletter the AI memo under
intelligence briefing.com newsletter so
you can stay up to date on how you can
run AI projects successfully that's
important don't miss his newsletter
seriously exactly thank you so Scott
what do you say should we play a little
game to kick things off okay all right
wonderful I win a free car so uh
probably not okay all right well we'll
do it anyway uh but how about reputation
in reputational points excellent all
right look so this this game is called
in your own words and when I hit the
buzzer the wheels will start spinning
when they stop you'll see a sentence and
I'd like to answer i' like you to answer
with the first thing that comes to mind
and why in your own words and to make a
little more interesting you'll only have
60 seconds for the answer now are you
ready for what's the buzz as ready as
I'm going to get I am okay perfect here
we
go if AI wear a song what would it be 60
seconds on the clock go if AI were a
song what would it be I'll tell you what
it would be help by The Beetles because
that's where we're going with this help
I need some info help not just any info
how would that be that would be awesome
right uh we we all can can use a little
more help um absolutely fantastic so and
well within time um I've seen a lot of
I've seen a lot of creative uh answers
um but but help is is
perfect all right now so with that out
of the the way why don't we talk about
the the actual topic of of the show
around us experience um look I think we
we've all obviously seen generative AI
in in the news last year still in the
news this year good thing I think this
year it's more about where the rubber
meets the road uh Implement AI um get
your Pilots out of your lab inter
production but I also see that that it
obviously democratizes access to AI
powered applications and and those
insights so think whether you're a
senior executive or your first year
students English right is is the new
programming language which makes it so
universally applicable and and
accessible but I wonder from from your
perspective what's so remarkable about
generative AI when it comes to user
experience all right so let me throw a
question out to you and the audience at
large when you go to send an email
Andreas we're gonna start with you what
programming language do you use H good
question
uh I don't know what's under the hood
but I would probably use English you
go to the web which programming language
do you use yes you probably just use a
browser right when you go to create a
presentation you use some type of app so
the whole process of creating software
and the point of creating software was
to put things into apps so people didn't
have to reinvent the wheel over and over
and over again but somehow that memo
seems to have been skipped to our
friends in the artificial intelligence
Community whereas no you have to be a
ninja in Python to do anything no you
have to be able to do this you have to
be able to code you need to know IDE so
not only am I going to teach you all the
statistics but I'm also going to teach
you computer science and all these
obscure languages and all this kind of
stuff really we don't require on your
driving test to be able to understand
compression ratios on a gas powered
engine right or at least mine didn't so
the whole process of applications to
simplify things and make things easier
is also about user
experience but programmers a small group
of folks not programmers but programmers
thank you to Nicole for giving me that
phrase is the fact that no no no you
have to be able to do everything I can
do before you can touch
information and then consider the screen
that you see when you go to chat gbt as
an example it's largely a blank screen
with a place to type you don't need to
code anything you don't need to need to
know how to do it even gooey interfaces
it's basically type your answer and hit
enter and so the beauty is people who
have been scared off from our field for
a long time now have access to things
that they never would have had before
and I think it's remarkable a lot of the
stuff that AI does now it did before it
did search before you could generate
text before so what's the difference why
is it so popular now and I'm going to be
really controversial here and I'm going
to say it is not so much that artificial
intelligence has improved it's that
we've simplified the user
interface I love that right um I I I
remember working with customers a couple
years ago on on AI first pilot projects
we didn't call it AI then we called it
machine learning uh be because we wanted
to be very precise and and accurate um
in accuracy for example was one of the
the variables or or one of the the um
piece of information that that we wanted
to display to business users and you
know they they saw 80% accuracy and I
said that's awesome and they tried it
out and the results were garbage said
well actually if it's 95 or 97% that's
when it gets really good and 99% that's
where you want to be and they couldn't
believe that 80% was garbage so right to
your point if you need to expose that if
if you make it simpler to begin with to
interact with these systems that's a
huge opportunity right that's well and
it's funny because you even talk about
the labels We Now call it artificial
intelligence well back when I started it
was Data Mining and no one uses that
phrase anymore and then it was kdd
knowledge Discovery and databases and
then it was Predictive Analytics no
that's not good enough no it's going to
be machine learning no it's gonna be
data science lots of the stuff has been
the same the whole way through but we
keep changing the name just to make
things harder for people right and
that's a great example if you type in
any of those things you're going to get
similar results back because we have
removed that
complexity I I I really love that and
and again for for business users I think
it makes it so much easier to finally
get results and and get useful results
without the complexity of of having to
understand uh the the technical details
in in the background um so by the way
for you in in the audience if you have
any questions for for Scott feel free to
pop them in the chat and we'll take a
look in a couple minutes and take some
of those as well um so speaking of
business users
what do you think there is is the the
potential for them maybe what's an
unexpected aspect of large language
models that you've seen for improving
the user experience there I think a lot
of it is it opens doors and what I mean
by that is um I can tell you that I
myself am probably the worst graphic
designer in the history of the Universe
I may have the heart of a da Vinci but I
have the skill set of a one-armed troll
with a really bad hangover so I can have
ideas oh I'd like to have this image to
be able to convey this message an actual
business use case I want to convey this
message to others and it's very
complicated and I'm trying to think of
how to do it there is no way in he you
could give me all the tools in the world
and that was not going to be helpful but
now I can go into one of the generative
AI tools and say okay I'm looking for
something that sort of looks like this I
can Prototype all kinds of different
things and I'm not even saying that
that's going to be the final result but
the amount of time savings I wouldn't
have even ventured into that realm
before now sort of play around I get a
little more self-confidence I'll try
refining my prompts over time I never
would have done that um I love Adobe
Photoshop and all those products they're
lovely but um yeah that was not going to
help this removes that fear and removing
that fear allows business users to do
all types of tasks that they would have
been afraid to approach
before wonderful yep
[Music]
um I like how you how you also broaden
the the the definition if you will or
the variety of
generative feel in business a lot of the
use cases that we see today are still
focused on text and text generation
summarization um what are the key points
out of this this meeting out of the
meeting minutes or or even things like
um barter or now Gemini summarized this
YouTube video for me um if you can
access it
um absolutely let's just take a simple
example it is very hard for most people
to sit in a series of meetings back
toback there's been all kinds of
research that even a 15minute separation
between meetings does wonders for the
human brain to be able to recover just a
bit when you're even have something as
simple as an AI assistant in a meeting
to take the notes I have to worry less
that I'm typing and writing and
summarizing the point point and
listening and coming up with my response
all at the same time I mean it seems
simple because we have to do it all the
time but it does get complex instead I
can really listen to what's happening
and form my response and not be just
obsessed with note taking it sort of
frees up that cognitive load for me to
do the things I hope I'm better
at yeah I'm really excited to to to see
where this is going right um maybe even
get get some coaching what are the
questions that that I should be asking
following the conversation um in and
having context about me so yeah can I
share a magic trick with you oh only by
exception yes okay
perfect actually one of the things that
if you are new to generative AI one of
the Beautiful Things is if you get stuck
you can ask your question about
generative AI in cat gbt or whatever or
or gemini or whatever your weapon of
choices if you're a stuck or you get an
instruction that you don't fully
understand you can clarify and you can
say well what do you mean by that and a
lot of times students won't do that in a
full classroom setting setting because
they don't want to feel embarrassed they
don't want to feel like oh my boss is
going to think I'm an idiot if I didn't
catch that last thing but if you're in
something like Gemini you can actually
Gemini for use Gemini for some tips on
how to create better Gemini props um
that is one of the things that I think
just opens up all kinds of
possibilities I love just just the power
right that uh that that now is is at our
fingertips um and I mean you know it's
not the first time that that we also
hear it's it's all about language I mean
we've a couple years ago we we've talked
about chatbots as as the new thing as
the new interface for voice commands in
the Enterprise and and what have you and
I think it it hasn't quite happened yet
whether it's in an office where you have
an open space and everybody's talking to
their assistant gets a little loud and
annoying maybe or or let alone field
service I've been in those environments
yes I understand right um all of a
sudden you trigger your uh your desk
neighbors um assistant to to to do
something or whatever that that maybe
we've seen that with Google Assistant
with Alexa in in our homes when they
suddenly go off right or or not even let
alone field service or on an oil rig
where it's just impractical that
somebody speaks to that system given all
all the environmental conditions and and
noise and and everything so what do you
think is is different this time then
when it comes to language um in in voice
large language models what's different
this time compared to chatbots from a
couple years ago the I'm so glad you
asked that question because fortunately
I was prepared with the
response that is this guy your cell
phone why because most people in the
past 10 years have sort of given up to a
large
extent on calls back and forth within
the office us they've just surrendered
but what do we use all the time text
messages text messages is the primary
mean of communication especially for
folks younger than I am which is most
everybody um but that
um that that sort of interface we're
really comfortable with and we use it
all the time and um one of the other
things that helped us was the fact that
with the rise of search engines over the
past 20 years is the fact people are
used to typing in questions and so I
don't have to fool about the timber of
my voice I can take as long as I want
you know it's basically texting to a
really smart entity and for the moment
we're going to keep the hallucinations
and the accuracy issues off to the side
for right now but in general we have
this whole means of access using an
interface that we're so familiar with
which is you're basically a giant text
message system when you're using one of
these zms
right
so that's your answer that's my answer
okay good we even remember the question
because you know that happens to me yeah
all good um so I see Anil here is asking
in in the chat if you have any tips how
to deal or handle copyright issues when
using ux generated from gen
tools yes yes I do um think of all of
the generative AI Tools in one of two
realms one would be brainstorming help
to come up with some different ideas
developing prototypes that type thing
number
two is being able to come up with
different ideas that you couldn't have
thought of on your own so your
brainstorming into the system the
system's brainstorming back to you but
it's like a good first draft in terms of
the copyright issues do not use anything
that comes out of generative AI um it's
already been pretty well established
that you can't copyright stuff that
comes out of generative Ai and I don't
know if anyone else noticed but in the
past month um the patent office has now
said that anything any patent that's
written or comes out of generative AI
will not be recognized and that patent
is it so this is your first step field
this is your brainstorming field this is
the area where I'm going to come up with
new ideas and test some things out so in
terms of copyright avoid it like the
plague think of it as coming up with the
different ideas if you're going to have
an image take the image that you created
as a good example and then send it to
whoever your internal artist is or do it
on your
own wonderful thank you be really
careful yeah um when it comes to ux one
um one of the tools that was really
surprised by uh was was one that tobas
Swingman mentioned a couple months ago
when when he was on the show and there
was versel um verel AI um and you can
give it a prompt and you say hey create
a layout for a
website to do lead capture for example
or as a landing page or a sign up for a
newsletter or something else or even
more complex things in using geni it
does come up with the design and um
shows that to you and you can make
modifications and and you can transfer
that over to to a actual programming
language um so that's where I got
excited because it's not just text
generation not just image generation or
synthetic Voice or video but there are
other really powerful and and useful um
applications where you can use let me
tell you an opport that's missed a lot
by organizations that I think the
generative AI can also help
with for decades when I worked in
marketing I was desperate to understand
what exactly customers were thinking and
I either had to sit down in the customer
service department listen the phone
calls come in or look at me messages
from email requests or whatever else one
of the things you want to look into is
the ability to actually capture what the
first prompts that someone used for an
internal tool were for several reasons
one it helps you improve the ux of the
product overall even when it's not a u
gen of AI interface but number two what
was their starting point we in business
have a nasty tendency to talk to
ourselves we come in and we can't erase
what we think we know so we just assume
that everybody else knows that we assume
that they want this new benefit or this
new feature whatever else you have a
nonstop
collection of user generated research
information take some time to read some
of it For Heaven's Sake I'm not saying
read all of it but you can also ask your
generative AI tool to review what
different uh questions or comments that
have come through what are the most
common aspects because you want to learn
about your customer you want to hit the
customer needs and a great way to
understand why people don't like your
particular ux approach you would really
want to ask them the question well if
you've only got buttons on a website you
can't do that but if you can capture
what people are entering into your
customer service team through the actual
text you will have amazing insights that
you didn't have
before so in a way even even use
generative to summarize the the
information the raw data that that
you're getting and and draw some some
conclusions from it wonderful and that's
where rag comes into place and I think
that's going to become more and more
important um there was some research
that was released by Wharton University
of Pennsylvania I guess two weeks ago
three weeks ago or that's where I found
it I don't know that they generated the
research but that's where I found the
Articles from a Warton Professor was the
fact that if you have a solely
isolated um resource to create your own
J of AI interface does not tend to do
well at all because it loses all the
language Clues so we've got the
specialized information so I fixed that
problem but now I've still got the
interface problem so that's why I think
rag is going to help because it's going
to allow sort of The Best of Both Worlds
yeah and make it tangible and and
preserve that that context yeah um now
I'm I'm wondering if if you're an AI
leader if you want to become an AI
leader in in a business um what do you
need to be aware of then when you want
to introduce loud language models be it
for improving the the user experience or
be it for for other
reasons yeah one of the things that I'm
a little worried about is the fact that
we now want to call everything
artificial intelligence like everything
in the world and this is a funny but
true story because I was like gosh and
this was five years ago AI on this Ai
and that oh our product has ai ai
everywhere and I was like wouldn't it be
funny if someone said that they used
artificial intelligence in a
toaster well I will be darned if in
2017 I didn't find an old ad for a
toaster with artificial intelligence all
right so you know stop using that phrase
for everything just because it's an
interface with a computer does not make
it artificial intelligence um so I think
as a leader there are a lot of folks out
there bless their hearts um Executives
who come back from the golf course and
uh our lady CEO is playing with other
lady CEOs and our guy CEO is playing
with his guy CEOs and they're all
playing golf and they come back and they
say okay we got to do
AI why because everybody else on the
golf cours is doing Ai and I can't go
out on the golf course and say we're not
doing AI I don't want to be
embarrassed what that's terrible so when
you're talking about this field don't do
AI because you want to be able to say
you're doing AI you need to find an
appropriate problem where this is going
to be a good fit so throwing around the
term terms all over the place is not
going to help you also everyone is now
using that phrase so whatever type of
Market Advantage you thought you had 18
months ago by using the phrase
artificial intelligence is gone now
because everyone else is saying so
you're not differentiating yourself so
that's the first sort of problem area
the second problem area is plain old
statistics and machine learning our old
friend logistic regression decision
trees random fors anybody remember those
you know sort of algorithms that we use
for problem solving you're a lot more
likely to get a higher
Roi from solving problems like fraud
detection U response analysis email open
rates all those simple binary outcomes
with a simple algorithm than you are to
go full out and buying all these
platforms for artificial intelligence
you know crawl walk run you don't have
to be full speed at the moment to be
able to make this stuff work take it
easy that that really brings it back to
the basics right and also a bit of that
that misconception that um generative AI
now renders everything else um obsolete
in all of the look logistic regression
and and statistical methods and and so
on it does not right chat GPT does not
generate your demand forecast it it
probably does but not very accurately
right um there is that so um now one one
other question here in the chat I think
is is really interesting that's how soon
will we see Commerce where users can
purchase goods or services within the
chat interface versus using a specific
app what do you think uh is it is it a
multi-year journey is is is it just
connecting another API like a plugin
like like kayak or uh something else
that you can already connect in in chat
GPT what do you think I think you could
probably jury rig it today I wouldn't
necessarily recommend it but um yeah um
with enough Blood Sweat and Tears you
can actually use a gener of AI interface
today as uh to be able to purchase Goods
I don't recommend it because it's still
very buggy but yeah I absolutely think
that in 2024 there're going to be a
bunch of products that offer that
remember that the purpose of Amazon
creating the product which shall not be
mentioned hint hint it rhymes with marxa
um the purpose was not for people to be
able to play music The purpose was they
thought that this amazing device is
going to be in every room in the house
and people are going to be making
purchases with it all the time at one
point they had 10,000 folks working on
Hardware software all that that's a lot
of folks and they completely missed the
boat in my humble opinion on the
interface of the power of things like
chat gbt but they thought that
e-commerce was going to be solved by
this I'm not sure that people
particularly want to go into that type
interface or trusted enough so I don't
think the issue is is that we can't do
the technology or when it's going to
happen it's when our customers really
going to prefer
that what I think is is really
interesting about that that point and
and obviously I I'm using some of those
devices myself and have been using them
for a while is at least personally I I
want to see the item I want to see what
does it look like is it is it large is
it small is it white is it black is a
shade of white or a shade of blue or
something so in in absence of of the
visual cues and
information just relying on on language
and and then also trusting that the
device accurately understands what I
mean or or gives me the options and and
if it's reciting the the options what
was option number one again out of those
three or out of those five and are these
even the the three that I want to see so
limiting Choice
having human communication if you went
into to a store today with a live
salesperson 70% of all communication is
non-verbal it's tone of voice it's body
language you lose all that when you have
a text interface
um you're not going to have any of those
components and we still have a hard time
getting sales professionals to
understand what we want and this is what
they specialize in in life to be able to
do so if we're expecting to
get that type of clarity and community a
let alone your excellent point about the
fact but this doesn't help me see it
this doesn't help me hold it you know
can I hold it up to my couch and make
sure it matches or whatever yeah I love
the VR by the way right see what this
looks like in your room yes for some
that's really helpful yes um for for a
bunch of batteries or or your dish soap
not so much but uh definitely right um
all right hey we're we're getting close
to the end of the show and I was
wondering if you could summarize the key
three takeaways for our audience today
when it comes to generative Ai and
improving user experience with it sure
um number one encourage employees to use
it as a tested ground for brainstorming
not for final results two trying to ban
it is a terrible idea because they're
going to use it anyway and you would
rather have some type of level of
control and understanding what they're
doing um three I would say use it as a
way of researching what people are
really interested in and understanding
customer needs just don't think of it as
a Band-Aid think of it as a fantastic
way to improve the overall customer
experience those would be my top three
wonderful thank you so much Scott was a
pleasure you right thank you for sharing
your expertise with us and for those of
you in the audience for learning with us
I think it was a very insightful session
really appreciate you giving us that
that broad overview and bringing it back
to to business and what really matters
you bet I hope I can come back one day
take care awesome thank you so much see
you next time for another round of the
intelligence briefing Live Well the
buz

